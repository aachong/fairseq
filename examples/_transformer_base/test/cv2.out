nohup: ignoring input
save_dir=./examples/_transformer_base/bash/../checkpoints/cv
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.0005
lrscheduler=inverse_sqrt
warmup_updates=4000
max_epoch=100
r3f_lambda=0
extr='--noised-no-grad --cv --cv-lambda 0.1'
2020-12-19 18:07:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:07:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:14376
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:14376
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:14376
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:14376
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | distributed init (rank 4): tcp://localhost:14376
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 4
2020-12-19 18:08:04 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-19 18:08:08 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=True, cv_lambda=0.1, data='./examples/_transformer_base/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:14376', distributed_no_spawn=False, distributed_num_procs=5, distributed_port=-1, distributed_rank=0, distributed_world_size=5, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3200, max_tokens_valid=3200, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=5, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=0.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/_transformer_base/bash/../checkpoints/cv', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-19 18:08:08 | INFO | fairseq.tasks.translation | [ch] dictionary: 41952 types
2020-12-19 18:08:08 | INFO | fairseq.tasks.translation | [en] dictionary: 31264 types
2020-12-19 18:08:08 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.ch
2020-12-19 18:08:08 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.en
2020-12-19 18:08:08 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin valid ch-en 1664 examples
2020-12-19 18:08:11 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(41952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31264, bias=False)
  )
)
2020-12-19 18:08:11 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-19 18:08:11 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2020-12-19 18:08:11 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2020-12-19 18:08:11 | INFO | fairseq_cli.train | num. model params: 97632256 (num. trained: 97632256)
2020-12-19 18:08:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-19 18:08:11 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-19 18:08:11 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-19 18:08:11 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-19 18:08:11 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-19 18:08:11 | INFO | fairseq.utils | rank   4: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-19 18:08:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-19 18:08:11 | INFO | fairseq_cli.train | training on 5 devices (GPUs/TPUs)
2020-12-19 18:08:11 | INFO | fairseq_cli.train | max tokens per GPU = 3200 and max sentences per GPU = None
2020-12-19 18:08:11 | INFO | fairseq.checkpoint_utils | loading pretrained model from ./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2020-12-19 18:08:13 | INFO | fairseq.trainer | loaded checkpoint ./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt (epoch 80 @ 0 updates)
2020-12-19 18:08:13 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-19 18:08:13 | INFO | fairseq.trainer | loading train data for epoch 1
2020-12-19 18:08:13 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.ch
2020-12-19 18:08:13 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.en
2020-12-19 18:08:13 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin train ch-en 1252977 examples
2020-12-19 18:08:19 | INFO | fairseq.trainer | begin training epoch 1
2020-12-19 18:08:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:08:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:08:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:09:22 | INFO | train_inner | epoch 001:    100 / 2448 symm_kl=0.741, self_kl=0, self_cv=15.056, loss=5.598, nll_loss=1.789, ppl=3.46, wps=27500.7, ups=1.87, wpb=14735.4, bsz=497.5, num_updates=100, lr=1.25975e-05, gnorm=1.795, train_wall=56, wall=71
2020-12-19 18:10:15 | INFO | train_inner | epoch 001:    200 / 2448 symm_kl=0.655, self_kl=0, self_cv=11.177, loss=5.141, nll_loss=1.993, ppl=3.98, wps=27916.2, ups=1.88, wpb=14861, bsz=508.2, num_updates=200, lr=2.5095e-05, gnorm=0.705, train_wall=53, wall=124
2020-12-19 18:11:08 | INFO | train_inner | epoch 001:    300 / 2448 symm_kl=0.643, self_kl=0, self_cv=10.527, loss=5.053, nll_loss=1.996, ppl=3.99, wps=27846.3, ups=1.88, wpb=14835.7, bsz=534.3, num_updates=300, lr=3.75925e-05, gnorm=0.671, train_wall=53, wall=177
2020-12-19 18:12:02 | INFO | train_inner | epoch 001:    400 / 2448 symm_kl=0.642, self_kl=0, self_cv=10.232, loss=5.035, nll_loss=2.02, ppl=4.06, wps=27767.9, ups=1.87, wpb=14836, bsz=520.4, num_updates=400, lr=5.009e-05, gnorm=0.681, train_wall=53, wall=231
2020-12-19 18:12:55 | INFO | train_inner | epoch 001:    500 / 2448 symm_kl=0.637, self_kl=0, self_cv=10.028, loss=5.019, nll_loss=2.032, ppl=4.09, wps=27386.6, ups=1.86, wpb=14706.6, bsz=513.4, num_updates=500, lr=6.25875e-05, gnorm=0.682, train_wall=54, wall=285
2020-12-19 18:13:49 | INFO | train_inner | epoch 001:    600 / 2448 symm_kl=0.629, self_kl=0, self_cv=9.91, loss=4.995, nll_loss=2.021, ppl=4.06, wps=27649.1, ups=1.86, wpb=14844.7, bsz=519, num_updates=600, lr=7.5085e-05, gnorm=0.679, train_wall=54, wall=338
2020-12-19 18:14:43 | INFO | train_inner | epoch 001:    700 / 2448 symm_kl=0.627, self_kl=0, self_cv=9.815, loss=4.988, nll_loss=2.027, ppl=4.08, wps=27593.9, ups=1.86, wpb=14832.9, bsz=540.2, num_updates=700, lr=8.75825e-05, gnorm=0.683, train_wall=54, wall=392
2020-12-19 18:15:37 | INFO | train_inner | epoch 001:    800 / 2448 symm_kl=0.628, self_kl=0, self_cv=9.763, loss=5.011, nll_loss=2.06, ppl=4.17, wps=27483.2, ups=1.86, wpb=14814.1, bsz=508, num_updates=800, lr=0.00010008, gnorm=0.682, train_wall=54, wall=446
2020-12-19 18:16:31 | INFO | train_inner | epoch 001:    900 / 2448 symm_kl=0.63, self_kl=0, self_cv=9.732, loss=5.005, nll_loss=2.057, ppl=4.16, wps=27394, ups=1.86, wpb=14741, bsz=498.3, num_updates=900, lr=0.000112578, gnorm=0.687, train_wall=54, wall=500
2020-12-19 18:17:25 | INFO | train_inner | epoch 001:   1000 / 2448 symm_kl=0.618, self_kl=0, self_cv=9.626, loss=4.995, nll_loss=2.061, ppl=4.17, wps=27449.6, ups=1.85, wpb=14834.9, bsz=533.9, num_updates=1000, lr=0.000125075, gnorm=0.697, train_wall=54, wall=554
2020-12-19 18:18:18 | INFO | train_inner | epoch 001:   1100 / 2448 symm_kl=0.621, self_kl=0, self_cv=9.617, loss=5.013, nll_loss=2.082, ppl=4.23, wps=27409.7, ups=1.86, wpb=14733.3, bsz=519.7, num_updates=1100, lr=0.000137573, gnorm=0.705, train_wall=54, wall=608
2020-12-19 18:19:12 | INFO | train_inner | epoch 001:   1200 / 2448 symm_kl=0.622, self_kl=0, self_cv=9.542, loss=5.025, nll_loss=2.106, ppl=4.31, wps=27308.9, ups=1.86, wpb=14678.3, bsz=487.4, num_updates=1200, lr=0.00015007, gnorm=0.724, train_wall=54, wall=661
2020-12-19 18:20:06 | INFO | train_inner | epoch 001:   1300 / 2448 symm_kl=0.613, self_kl=0, self_cv=9.525, loss=5.007, nll_loss=2.089, ppl=4.25, wps=27430.3, ups=1.85, wpb=14811.5, bsz=513.1, num_updates=1300, lr=0.000162568, gnorm=0.709, train_wall=54, wall=715
2020-12-19 18:21:00 | INFO | train_inner | epoch 001:   1400 / 2448 symm_kl=0.617, self_kl=0, self_cv=9.476, loss=5.021, nll_loss=2.111, ppl=4.32, wps=27569.2, ups=1.85, wpb=14867.5, bsz=527.4, num_updates=1400, lr=0.000175065, gnorm=0.716, train_wall=54, wall=769
2020-12-19 18:21:54 | INFO | train_inner | epoch 001:   1500 / 2448 symm_kl=0.609, self_kl=0, self_cv=9.435, loss=5.03, nll_loss=2.128, ppl=4.37, wps=27505.5, ups=1.85, wpb=14841.8, bsz=533.8, num_updates=1500, lr=0.000187563, gnorm=0.721, train_wall=54, wall=823
2020-12-19 18:22:48 | INFO | train_inner | epoch 001:   1600 / 2448 symm_kl=0.616, self_kl=0, self_cv=9.425, loss=5.052, nll_loss=2.153, ppl=4.45, wps=27347.9, ups=1.85, wpb=14788.4, bsz=498.9, num_updates=1600, lr=0.00020006, gnorm=0.722, train_wall=54, wall=877
2020-12-19 18:23:42 | INFO | train_inner | epoch 001:   1700 / 2448 symm_kl=0.612, self_kl=0, self_cv=9.367, loss=5.045, nll_loss=2.153, ppl=4.45, wps=27529.7, ups=1.86, wpb=14798.4, bsz=510.6, num_updates=1700, lr=0.000212558, gnorm=0.719, train_wall=54, wall=931
2020-12-19 18:24:36 | INFO | train_inner | epoch 001:   1800 / 2448 symm_kl=0.612, self_kl=0, self_cv=9.406, loss=5.048, nll_loss=2.15, ppl=4.44, wps=27679.7, ups=1.86, wpb=14891.2, bsz=509.1, num_updates=1800, lr=0.000225055, gnorm=0.719, train_wall=54, wall=985
2020-12-19 18:25:30 | INFO | train_inner | epoch 001:   1900 / 2448 symm_kl=0.613, self_kl=0, self_cv=9.351, loss=5.076, nll_loss=2.19, ppl=4.56, wps=27421.2, ups=1.85, wpb=14838.8, bsz=504.4, num_updates=1900, lr=0.000237553, gnorm=0.723, train_wall=54, wall=1039
2020-12-19 18:26:24 | INFO | train_inner | epoch 001:   2000 / 2448 symm_kl=0.615, self_kl=0, self_cv=9.313, loss=5.095, nll_loss=2.216, ppl=4.65, wps=27473.9, ups=1.85, wpb=14863.1, bsz=483.1, num_updates=2000, lr=0.00025005, gnorm=0.733, train_wall=54, wall=1093
2020-12-19 18:27:18 | INFO | train_inner | epoch 001:   2100 / 2448 symm_kl=0.613, self_kl=0, self_cv=9.308, loss=5.092, nll_loss=2.214, ppl=4.64, wps=27538.9, ups=1.86, wpb=14827.9, bsz=487.8, num_updates=2100, lr=0.000262548, gnorm=0.739, train_wall=54, wall=1147
2020-12-19 18:28:12 | INFO | train_inner | epoch 001:   2200 / 2448 symm_kl=0.605, self_kl=0, self_cv=9.261, loss=5.074, nll_loss=2.2, ppl=4.6, wps=27492.8, ups=1.84, wpb=14906.9, bsz=537.7, num_updates=2200, lr=0.000275045, gnorm=0.73, train_wall=54, wall=1201
2020-12-19 18:29:06 | INFO | train_inner | epoch 001:   2300 / 2448 symm_kl=0.619, self_kl=0, self_cv=9.259, loss=5.134, nll_loss=2.268, ppl=4.82, wps=27401.9, ups=1.86, wpb=14731.3, bsz=497.8, num_updates=2300, lr=0.000287543, gnorm=0.74, train_wall=54, wall=1255
2020-12-19 18:30:00 | INFO | train_inner | epoch 001:   2400 / 2448 symm_kl=0.605, self_kl=0, self_cv=9.214, loss=5.1, nll_loss=2.235, ppl=4.71, wps=27664, ups=1.85, wpb=14928.9, bsz=508.3, num_updates=2400, lr=0.00030004, gnorm=0.734, train_wall=54, wall=1309
2020-12-19 18:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 18:30:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 18:30:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 18:30:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 18:30:40 | INFO | valid | epoch 001 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.098 | nll_loss 8.123 | ppl 278.73 | bleu 14.85 | wps 5602.7 | wpb 7930.2 | bsz 208 | num_updates 2448
2020-12-19 18:30:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 18:30:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 1 @ 2448 updates, score 14.85) (writing took 4.013239115476608 seconds)
2020-12-19 18:30:44 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-12-19 18:30:44 | INFO | train | epoch 001 | symm_kl 0.626 | self_kl 0 | self_cv 9.876 | loss 5.069 | nll_loss 2.101 | ppl 4.29 | wps 27146.4 | ups 1.83 | wpb 14810.4 | bsz 511.8 | num_updates 2448 | lr 0.000306039 | gnorm 0.754 | train_wall 1315 | wall 1353
2020-12-19 18:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:47 | INFO | fairseq.trainer | begin training epoch 2
2020-12-19 18:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:30:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:30:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:31:21 | INFO | train_inner | epoch 002:     52 / 2448 symm_kl=0.608, self_kl=0, self_cv=9.235, loss=5.067, nll_loss=2.194, ppl=4.58, wps=18154.5, ups=1.23, wpb=14718.1, bsz=493.5, num_updates=2500, lr=0.000312538, gnorm=0.746, train_wall=53, wall=1390
2020-12-19 18:32:15 | INFO | train_inner | epoch 002:    152 / 2448 symm_kl=0.62, self_kl=0, self_cv=9.253, loss=5.091, nll_loss=2.217, ppl=4.65, wps=27698.7, ups=1.86, wpb=14903.9, bsz=536.5, num_updates=2600, lr=0.000325035, gnorm=0.764, train_wall=54, wall=1444
2020-12-19 18:33:09 | INFO | train_inner | epoch 002:    252 / 2448 symm_kl=0.624, self_kl=0, self_cv=9.22, loss=5.129, nll_loss=2.266, ppl=4.81, wps=27357.9, ups=1.85, wpb=14786.3, bsz=496.6, num_updates=2700, lr=0.000337533, gnorm=0.744, train_wall=54, wall=1498
2020-12-19 18:34:03 | INFO | train_inner | epoch 002:    352 / 2448 symm_kl=0.62, self_kl=0, self_cv=9.171, loss=5.121, nll_loss=2.264, ppl=4.8, wps=27395.1, ups=1.86, wpb=14754.5, bsz=531.4, num_updates=2800, lr=0.00035003, gnorm=0.736, train_wall=54, wall=1552
2020-12-19 18:34:56 | INFO | train_inner | epoch 002:    452 / 2448 symm_kl=0.616, self_kl=0, self_cv=9.153, loss=5.123, nll_loss=2.268, ppl=4.82, wps=27734, ups=1.86, wpb=14892.2, bsz=530.4, num_updates=2900, lr=0.000362528, gnorm=0.754, train_wall=54, wall=1605
2020-12-19 18:35:50 | INFO | train_inner | epoch 002:    552 / 2448 symm_kl=0.622, self_kl=0, self_cv=9.116, loss=5.154, nll_loss=2.309, ppl=4.95, wps=27507, ups=1.86, wpb=14814.2, bsz=496.6, num_updates=3000, lr=0.000375025, gnorm=0.749, train_wall=54, wall=1659
2020-12-19 18:36:44 | INFO | train_inner | epoch 002:    652 / 2448 symm_kl=0.628, self_kl=0, self_cv=9.132, loss=5.198, nll_loss=2.356, ppl=5.12, wps=27499.6, ups=1.85, wpb=14826.5, bsz=496.3, num_updates=3100, lr=0.000387523, gnorm=0.749, train_wall=54, wall=1713
2020-12-19 18:37:38 | INFO | train_inner | epoch 002:    752 / 2448 symm_kl=0.621, self_kl=0, self_cv=9.101, loss=5.184, nll_loss=2.345, ppl=5.08, wps=27755, ups=1.86, wpb=14916.4, bsz=490.2, num_updates=3200, lr=0.00040002, gnorm=0.722, train_wall=54, wall=1767
2020-12-19 18:38:32 | INFO | train_inner | epoch 002:    852 / 2448 symm_kl=0.627, self_kl=0, self_cv=9.053, loss=5.212, nll_loss=2.383, ppl=5.22, wps=27291.7, ups=1.85, wpb=14744.7, bsz=515.6, num_updates=3300, lr=0.000412518, gnorm=0.751, train_wall=54, wall=1821
2020-12-19 18:39:26 | INFO | train_inner | epoch 002:    952 / 2448 symm_kl=0.624, self_kl=0, self_cv=9.024, loss=5.217, nll_loss=2.393, ppl=5.25, wps=27550.4, ups=1.86, wpb=14830, bsz=505, num_updates=3400, lr=0.000425015, gnorm=0.745, train_wall=54, wall=1875
2020-12-19 18:40:20 | INFO | train_inner | epoch 002:   1052 / 2448 symm_kl=0.616, self_kl=0, self_cv=8.988, loss=5.208, nll_loss=2.39, ppl=5.24, wps=27536.2, ups=1.85, wpb=14880.4, bsz=520.4, num_updates=3500, lr=0.000437513, gnorm=0.717, train_wall=54, wall=1929
2020-12-19 18:41:14 | INFO | train_inner | epoch 002:   1152 / 2448 symm_kl=0.628, self_kl=0, self_cv=8.991, loss=5.26, nll_loss=2.447, ppl=5.45, wps=27256.6, ups=1.85, wpb=14722.8, bsz=519.4, num_updates=3600, lr=0.00045001, gnorm=0.77, train_wall=54, wall=1983
2020-12-19 18:42:08 | INFO | train_inner | epoch 002:   1252 / 2448 symm_kl=0.62, self_kl=0, self_cv=8.973, loss=5.246, nll_loss=2.435, ppl=5.41, wps=27572.4, ups=1.85, wpb=14883.6, bsz=513.5, num_updates=3700, lr=0.000462508, gnorm=0.737, train_wall=54, wall=2037
2020-12-19 18:43:02 | INFO | train_inner | epoch 002:   1352 / 2448 symm_kl=0.614, self_kl=0, self_cv=8.904, loss=5.238, nll_loss=2.436, ppl=5.41, wps=27476.5, ups=1.85, wpb=14819.3, bsz=529.4, num_updates=3800, lr=0.000475005, gnorm=0.746, train_wall=54, wall=2091
2020-12-19 18:43:55 | INFO | train_inner | epoch 002:   1452 / 2448 symm_kl=0.621, self_kl=0, self_cv=8.92, loss=5.278, nll_loss=2.478, ppl=5.57, wps=27509.8, ups=1.86, wpb=14815.2, bsz=497.8, num_updates=3900, lr=0.000487503, gnorm=0.756, train_wall=54, wall=2145
2020-12-19 18:44:49 | INFO | train_inner | epoch 002:   1552 / 2448 symm_kl=0.621, self_kl=0, self_cv=8.895, loss=5.291, nll_loss=2.496, ppl=5.64, wps=27439, ups=1.86, wpb=14767.3, bsz=489.6, num_updates=4000, lr=0.0005, gnorm=0.773, train_wall=54, wall=2198
2020-12-19 18:45:43 | INFO | train_inner | epoch 002:   1652 / 2448 symm_kl=0.615, self_kl=0, self_cv=8.859, loss=5.288, nll_loss=2.499, ppl=5.65, wps=27437.8, ups=1.86, wpb=14765.8, bsz=520.9, num_updates=4100, lr=0.000493865, gnorm=0.747, train_wall=54, wall=2252
2020-12-19 18:46:37 | INFO | train_inner | epoch 002:   1752 / 2448 symm_kl=0.616, self_kl=0, self_cv=8.84, loss=5.301, nll_loss=2.517, ppl=5.72, wps=27444.7, ups=1.85, wpb=14850.1, bsz=502.4, num_updates=4200, lr=0.00048795, gnorm=0.736, train_wall=54, wall=2306
2020-12-19 18:47:31 | INFO | train_inner | epoch 002:   1852 / 2448 symm_kl=0.617, self_kl=0, self_cv=8.854, loss=5.31, nll_loss=2.525, ppl=5.75, wps=27604.9, ups=1.86, wpb=14873.6, bsz=524.6, num_updates=4300, lr=0.000482243, gnorm=0.76, train_wall=54, wall=2360
2020-12-19 18:48:25 | INFO | train_inner | epoch 002:   1952 / 2448 symm_kl=0.611, self_kl=0, self_cv=8.825, loss=5.296, nll_loss=2.513, ppl=5.71, wps=27557.5, ups=1.85, wpb=14877, bsz=529.3, num_updates=4400, lr=0.000476731, gnorm=0.717, train_wall=54, wall=2414
2020-12-19 18:49:19 | INFO | train_inner | epoch 002:   2052 / 2448 symm_kl=0.613, self_kl=0, self_cv=8.802, loss=5.315, nll_loss=2.539, ppl=5.81, wps=27294.9, ups=1.86, wpb=14645.1, bsz=531.5, num_updates=4500, lr=0.000471405, gnorm=0.786, train_wall=53, wall=2468
2020-12-19 18:50:12 | INFO | train_inner | epoch 002:   2152 / 2448 symm_kl=0.602, self_kl=0, self_cv=8.807, loss=5.288, nll_loss=2.508, ppl=5.69, wps=27552.3, ups=1.86, wpb=14806.2, bsz=505.9, num_updates=4600, lr=0.000466252, gnorm=0.714, train_wall=54, wall=2522
2020-12-19 18:51:06 | INFO | train_inner | epoch 002:   2252 / 2448 symm_kl=0.599, self_kl=0, self_cv=8.833, loss=5.289, nll_loss=2.506, ppl=5.68, wps=27477.1, ups=1.85, wpb=14822.8, bsz=512.5, num_updates=4700, lr=0.000461266, gnorm=0.7, train_wall=54, wall=2575
2020-12-19 18:52:00 | INFO | train_inner | epoch 002:   2352 / 2448 symm_kl=0.605, self_kl=0, self_cv=8.819, loss=5.313, nll_loss=2.535, ppl=5.8, wps=27363.3, ups=1.86, wpb=14716.2, bsz=493.3, num_updates=4800, lr=0.000456435, gnorm=0.734, train_wall=54, wall=2629
2020-12-19 18:52:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 18:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 18:53:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 18:53:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 18:53:08 | INFO | valid | epoch 002 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.056 | nll_loss 8.088 | ppl 272.06 | bleu 14.83 | wps 5036.7 | wpb 7930.2 | bsz 208 | num_updates 4896 | best_bleu 14.85
2020-12-19 18:53:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 18:53:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 2 @ 4896 updates, score 14.83) (writing took 5.3986656833440065 seconds)
2020-12-19 18:53:14 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-12-19 18:53:14 | INFO | train | epoch 002 | symm_kl 0.616 | self_kl 0 | self_cv 8.98 | loss 5.231 | nll_loss 2.416 | ppl 5.34 | wps 26855.2 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 4896 | lr 0.000451938 | gnorm 0.741 | train_wall 1315 | wall 2703
2020-12-19 18:53:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:53:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:53:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:53:17 | INFO | fairseq.trainer | begin training epoch 3
2020-12-19 18:53:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:53:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 18:53:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 18:53:27 | INFO | train_inner | epoch 003:      4 / 2448 symm_kl=0.597, self_kl=0, self_cv=8.835, loss=5.29, nll_loss=2.507, ppl=5.68, wps=17054.9, ups=1.16, wpb=14748, bsz=504.4, num_updates=4900, lr=0.000451754, gnorm=0.687, train_wall=55, wall=2716
2020-12-19 18:54:21 | INFO | train_inner | epoch 003:    104 / 2448 symm_kl=0.61, self_kl=0, self_cv=8.966, loss=5.229, nll_loss=2.416, ppl=5.34, wps=27196.4, ups=1.85, wpb=14719.6, bsz=509.2, num_updates=5000, lr=0.000447214, gnorm=0.674, train_wall=54, wall=2770
2020-12-19 18:55:16 | INFO | train_inner | epoch 003:    204 / 2448 symm_kl=0.605, self_kl=0, self_cv=8.907, loss=5.223, nll_loss=2.418, ppl=5.35, wps=26796.4, ups=1.81, wpb=14833.1, bsz=523.8, num_updates=5100, lr=0.000442807, gnorm=0.698, train_wall=55, wall=2825
2020-12-19 18:56:10 | INFO | train_inner | epoch 003:    304 / 2448 symm_kl=0.606, self_kl=0, self_cv=8.933, loss=5.222, nll_loss=2.414, ppl=5.33, wps=27417.5, ups=1.84, wpb=14882.1, bsz=521.8, num_updates=5200, lr=0.000438529, gnorm=0.661, train_wall=54, wall=2879
2020-12-19 18:57:05 | INFO | train_inner | epoch 003:    404 / 2448 symm_kl=0.605, self_kl=0, self_cv=8.906, loss=5.214, nll_loss=2.409, ppl=5.31, wps=27278.1, ups=1.85, wpb=14782.1, bsz=523.8, num_updates=5300, lr=0.000434372, gnorm=0.683, train_wall=54, wall=2934
2020-12-19 18:57:59 | INFO | train_inner | epoch 003:    504 / 2448 symm_kl=0.596, self_kl=0, self_cv=8.844, loss=5.197, nll_loss=2.399, ppl=5.28, wps=27002.6, ups=1.83, wpb=14793.1, bsz=539.2, num_updates=5400, lr=0.000430331, gnorm=0.693, train_wall=55, wall=2988
2020-12-19 18:58:54 | INFO | train_inner | epoch 003:    604 / 2448 symm_kl=0.603, self_kl=0, self_cv=8.877, loss=5.25, nll_loss=2.455, ppl=5.48, wps=27114.1, ups=1.84, wpb=14765.4, bsz=519.6, num_updates=5500, lr=0.000426401, gnorm=0.677, train_wall=54, wall=3043
2020-12-19 18:59:48 | INFO | train_inner | epoch 003:    704 / 2448 symm_kl=0.602, self_kl=0, self_cv=8.858, loss=5.232, nll_loss=2.438, ppl=5.42, wps=27605.5, ups=1.86, wpb=14828.9, bsz=514.6, num_updates=5600, lr=0.000422577, gnorm=0.691, train_wall=54, wall=3097
2020-12-19 19:00:41 | INFO | train_inner | epoch 003:    804 / 2448 symm_kl=0.605, self_kl=0, self_cv=8.896, loss=5.248, nll_loss=2.45, ppl=5.46, wps=27455.3, ups=1.87, wpb=14692.9, bsz=491.5, num_updates=5700, lr=0.000418854, gnorm=0.67, train_wall=53, wall=3150
2020-12-19 19:01:35 | INFO | train_inner | epoch 003:    904 / 2448 symm_kl=0.599, self_kl=0, self_cv=8.85, loss=5.257, nll_loss=2.467, ppl=5.53, wps=27520, ups=1.86, wpb=14763.3, bsz=499.7, num_updates=5800, lr=0.000415227, gnorm=0.671, train_wall=53, wall=3204
2020-12-19 19:02:29 | INFO | train_inner | epoch 003:   1004 / 2448 symm_kl=0.599, self_kl=0, self_cv=8.88, loss=5.248, nll_loss=2.453, ppl=5.47, wps=27508.5, ups=1.86, wpb=14815.8, bsz=498.2, num_updates=5900, lr=0.000411693, gnorm=0.666, train_wall=54, wall=3258
2020-12-19 19:03:22 | INFO | train_inner | epoch 003:   1104 / 2448 symm_kl=0.592, self_kl=0, self_cv=8.865, loss=5.22, nll_loss=2.425, ppl=5.37, wps=27501.9, ups=1.86, wpb=14777.6, bsz=529.6, num_updates=6000, lr=0.000408248, gnorm=0.696, train_wall=54, wall=3311
2020-12-19 19:04:16 | INFO | train_inner | epoch 003:   1204 / 2448 symm_kl=0.59, self_kl=0, self_cv=8.845, loss=5.231, nll_loss=2.44, ppl=5.43, wps=27487.6, ups=1.86, wpb=14799.9, bsz=532.1, num_updates=6100, lr=0.000404888, gnorm=0.644, train_wall=54, wall=3365
2020-12-19 19:05:10 | INFO | train_inner | epoch 003:   1304 / 2448 symm_kl=0.585, self_kl=0, self_cv=8.826, loss=5.214, nll_loss=2.424, ppl=5.37, wps=27590.1, ups=1.85, wpb=14891.4, bsz=524.6, num_updates=6200, lr=0.00040161, gnorm=0.686, train_wall=54, wall=3419
2020-12-19 19:06:04 | INFO | train_inner | epoch 003:   1404 / 2448 symm_kl=0.592, self_kl=0, self_cv=8.823, loss=5.251, nll_loss=2.466, ppl=5.53, wps=27456, ups=1.86, wpb=14741.1, bsz=513.4, num_updates=6300, lr=0.00039841, gnorm=0.668, train_wall=54, wall=3473
2020-12-19 19:06:58 | INFO | train_inner | epoch 003:   1504 / 2448 symm_kl=0.59, self_kl=0, self_cv=8.823, loss=5.259, nll_loss=2.475, ppl=5.56, wps=27380.5, ups=1.86, wpb=14729.6, bsz=507.7, num_updates=6400, lr=0.000395285, gnorm=0.672, train_wall=54, wall=3527
2020-12-19 19:07:52 | INFO | train_inner | epoch 003:   1604 / 2448 symm_kl=0.581, self_kl=0, self_cv=8.827, loss=5.22, nll_loss=2.432, ppl=5.39, wps=27491.9, ups=1.85, wpb=14885.7, bsz=515.7, num_updates=6500, lr=0.000392232, gnorm=0.64, train_wall=54, wall=3581
2020-12-19 19:08:46 | INFO | train_inner | epoch 003:   1704 / 2448 symm_kl=0.579, self_kl=0, self_cv=8.827, loss=5.204, nll_loss=2.414, ppl=5.33, wps=27667.9, ups=1.86, wpb=14879.5, bsz=505.6, num_updates=6600, lr=0.000389249, gnorm=0.646, train_wall=54, wall=3635
2020-12-19 19:09:39 | INFO | train_inner | epoch 003:   1804 / 2448 symm_kl=0.585, self_kl=0, self_cv=8.831, loss=5.235, nll_loss=2.448, ppl=5.46, wps=27452.8, ups=1.85, wpb=14804.8, bsz=493.1, num_updates=6700, lr=0.000386334, gnorm=0.684, train_wall=54, wall=3689
2020-12-19 19:10:33 | INFO | train_inner | epoch 003:   1904 / 2448 symm_kl=0.581, self_kl=0, self_cv=8.861, loss=5.226, nll_loss=2.433, ppl=5.4, wps=27566.6, ups=1.85, wpb=14873.8, bsz=499.4, num_updates=6800, lr=0.000383482, gnorm=0.658, train_wall=54, wall=3743
2020-12-19 19:11:27 | INFO | train_inner | epoch 003:   2004 / 2448 symm_kl=0.577, self_kl=0, self_cv=8.793, loss=5.234, nll_loss=2.453, ppl=5.47, wps=27553.2, ups=1.86, wpb=14828.8, bsz=504.4, num_updates=6900, lr=0.000380693, gnorm=0.66, train_wall=54, wall=3796
2020-12-19 19:12:21 | INFO | train_inner | epoch 003:   2104 / 2448 symm_kl=0.573, self_kl=0, self_cv=8.836, loss=5.217, nll_loss=2.427, ppl=5.38, wps=27732.1, ups=1.86, wpb=14940.1, bsz=493.8, num_updates=7000, lr=0.000377964, gnorm=0.641, train_wall=54, wall=3850
2020-12-19 19:13:15 | INFO | train_inner | epoch 003:   2204 / 2448 symm_kl=0.581, self_kl=0, self_cv=8.829, loss=5.245, nll_loss=2.459, ppl=5.5, wps=27361.9, ups=1.86, wpb=14744.5, bsz=503.5, num_updates=7100, lr=0.000375293, gnorm=0.645, train_wall=54, wall=3904
2020-12-19 19:14:09 | INFO | train_inner | epoch 003:   2304 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.803, loss=5.218, nll_loss=2.434, ppl=5.4, wps=27667.4, ups=1.86, wpb=14880.4, bsz=522.7, num_updates=7200, lr=0.000372678, gnorm=0.667, train_wall=54, wall=3958
2020-12-19 19:15:03 | INFO | train_inner | epoch 003:   2404 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.819, loss=5.232, nll_loss=2.447, ppl=5.45, wps=27511.4, ups=1.85, wpb=14844, bsz=512.8, num_updates=7300, lr=0.000370117, gnorm=0.667, train_wall=54, wall=4012
2020-12-19 19:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 19:15:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 19:15:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 19:15:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 19:15:41 | INFO | valid | epoch 003 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.98 | nll_loss 8.004 | ppl 256.64 | bleu 15.42 | wps 5579.2 | wpb 7930.2 | bsz 208 | num_updates 7344 | best_bleu 15.42
2020-12-19 19:15:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 19:15:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 3 @ 7344 updates, score 15.42) (writing took 8.244096893817186 seconds)
2020-12-19 19:15:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-12-19 19:15:49 | INFO | train | epoch 003 | symm_kl 0.591 | self_kl 0 | self_cv 8.855 | loss 5.23 | nll_loss 2.438 | ppl 5.42 | wps 26755.5 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 7344 | lr 0.000369006 | gnorm 0.669 | train_wall 1317 | wall 4058
2020-12-19 19:15:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:15:52 | INFO | fairseq.trainer | begin training epoch 4
2020-12-19 19:15:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:15:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:16:28 | INFO | train_inner | epoch 004:     56 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.87, loss=5.157, nll_loss=2.354, ppl=5.11, wps=17407.2, ups=1.17, wpb=14826.9, bsz=515.9, num_updates=7400, lr=0.000367607, gnorm=0.644, train_wall=53, wall=4097
2020-12-19 19:17:22 | INFO | train_inner | epoch 004:    156 / 2448 symm_kl=0.582, self_kl=0, self_cv=8.951, loss=5.14, nll_loss=2.321, ppl=5, wps=27650.2, ups=1.86, wpb=14886.2, bsz=523.3, num_updates=7500, lr=0.000365148, gnorm=0.657, train_wall=54, wall=4151
2020-12-19 19:18:16 | INFO | train_inner | epoch 004:    256 / 2448 symm_kl=0.586, self_kl=0, self_cv=8.942, loss=5.15, nll_loss=2.334, ppl=5.04, wps=27295.3, ups=1.84, wpb=14807.9, bsz=521, num_updates=7600, lr=0.000362738, gnorm=0.672, train_wall=54, wall=4205
2020-12-19 19:19:10 | INFO | train_inner | epoch 004:    356 / 2448 symm_kl=0.587, self_kl=0, self_cv=8.952, loss=5.174, nll_loss=2.361, ppl=5.14, wps=27422.6, ups=1.85, wpb=14812.2, bsz=514.7, num_updates=7700, lr=0.000360375, gnorm=0.639, train_wall=54, wall=4259
2020-12-19 19:20:04 | INFO | train_inner | epoch 004:    456 / 2448 symm_kl=0.593, self_kl=0, self_cv=8.932, loss=5.191, nll_loss=2.383, ppl=5.21, wps=27402.5, ups=1.85, wpb=14799.4, bsz=518.9, num_updates=7800, lr=0.000358057, gnorm=0.669, train_wall=54, wall=4313
2020-12-19 19:20:58 | INFO | train_inner | epoch 004:    556 / 2448 symm_kl=0.584, self_kl=0, self_cv=8.914, loss=5.173, nll_loss=2.364, ppl=5.15, wps=27471.5, ups=1.86, wpb=14804, bsz=516.2, num_updates=7900, lr=0.000355784, gnorm=0.643, train_wall=54, wall=4367
2020-12-19 19:21:52 | INFO | train_inner | epoch 004:    656 / 2448 symm_kl=0.58, self_kl=0, self_cv=8.894, loss=5.17, nll_loss=2.366, ppl=5.15, wps=27487.6, ups=1.85, wpb=14871.8, bsz=522.1, num_updates=8000, lr=0.000353553, gnorm=0.644, train_wall=54, wall=4421
2020-12-19 19:22:46 | INFO | train_inner | epoch 004:    756 / 2448 symm_kl=0.58, self_kl=0, self_cv=8.869, loss=5.162, nll_loss=2.359, ppl=5.13, wps=27482.7, ups=1.85, wpb=14830.7, bsz=512.3, num_updates=8100, lr=0.000351364, gnorm=0.639, train_wall=54, wall=4475
2020-12-19 19:23:40 | INFO | train_inner | epoch 004:    856 / 2448 symm_kl=0.583, self_kl=0, self_cv=8.916, loss=5.178, nll_loss=2.37, ppl=5.17, wps=27342.7, ups=1.85, wpb=14750.9, bsz=489.8, num_updates=8200, lr=0.000349215, gnorm=0.644, train_wall=54, wall=4529
2020-12-19 19:24:34 | INFO | train_inner | epoch 004:    956 / 2448 symm_kl=0.578, self_kl=0, self_cv=8.854, loss=5.164, nll_loss=2.365, ppl=5.15, wps=27515.7, ups=1.86, wpb=14831.4, bsz=553.3, num_updates=8300, lr=0.000347105, gnorm=0.648, train_wall=54, wall=4583
2020-12-19 19:25:28 | INFO | train_inner | epoch 004:   1056 / 2448 symm_kl=0.581, self_kl=0, self_cv=8.908, loss=5.184, nll_loss=2.379, ppl=5.2, wps=27439.2, ups=1.86, wpb=14783.5, bsz=498.4, num_updates=8400, lr=0.000345033, gnorm=0.651, train_wall=54, wall=4637
2020-12-19 19:26:22 | INFO | train_inner | epoch 004:   1156 / 2448 symm_kl=0.58, self_kl=0, self_cv=8.895, loss=5.186, nll_loss=2.384, ppl=5.22, wps=27242.5, ups=1.85, wpb=14731.6, bsz=493.6, num_updates=8500, lr=0.000342997, gnorm=0.65, train_wall=54, wall=4691
2020-12-19 19:27:16 | INFO | train_inner | epoch 004:   1256 / 2448 symm_kl=0.577, self_kl=0, self_cv=8.888, loss=5.172, nll_loss=2.368, ppl=5.16, wps=27488, ups=1.85, wpb=14836.8, bsz=498.2, num_updates=8600, lr=0.000340997, gnorm=0.614, train_wall=54, wall=4745
2020-12-19 19:28:11 | INFO | train_inner | epoch 004:   1356 / 2448 symm_kl=0.582, self_kl=0, self_cv=8.882, loss=5.19, nll_loss=2.391, ppl=5.24, wps=27001.2, ups=1.82, wpb=14806.1, bsz=472.4, num_updates=8700, lr=0.000339032, gnorm=0.625, train_wall=55, wall=4800
2020-12-19 19:29:06 | INFO | train_inner | epoch 004:   1456 / 2448 symm_kl=0.577, self_kl=0, self_cv=8.848, loss=5.188, nll_loss=2.394, ppl=5.26, wps=26676.8, ups=1.81, wpb=14745.1, bsz=513, num_updates=8800, lr=0.0003371, gnorm=0.637, train_wall=55, wall=4855
2020-12-19 19:30:00 | INFO | train_inner | epoch 004:   1556 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.831, loss=5.184, nll_loss=2.392, ppl=5.25, wps=27419, ups=1.86, wpb=14744.6, bsz=513.3, num_updates=8900, lr=0.000335201, gnorm=0.662, train_wall=54, wall=4909
2020-12-19 19:30:55 | INFO | train_inner | epoch 004:   1656 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.845, loss=5.17, nll_loss=2.374, ppl=5.18, wps=27107.1, ups=1.82, wpb=14907.2, bsz=504.9, num_updates=9000, lr=0.000333333, gnorm=0.645, train_wall=55, wall=4964
2020-12-19 19:31:50 | INFO | train_inner | epoch 004:   1756 / 2448 symm_kl=0.572, self_kl=0, self_cv=8.879, loss=5.192, nll_loss=2.394, ppl=5.26, wps=26791, ups=1.81, wpb=14787.2, bsz=485.7, num_updates=9100, lr=0.000331497, gnorm=0.616, train_wall=55, wall=5019
2020-12-19 19:32:44 | INFO | train_inner | epoch 004:   1856 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.853, loss=5.158, nll_loss=2.359, ppl=5.13, wps=27197.3, ups=1.84, wpb=14803.6, bsz=530.8, num_updates=9200, lr=0.00032969, gnorm=0.634, train_wall=54, wall=5073
2020-12-19 19:33:40 | INFO | train_inner | epoch 004:   1956 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.878, loss=5.168, nll_loss=2.367, ppl=5.16, wps=26825, ups=1.81, wpb=14847.9, bsz=522.2, num_updates=9300, lr=0.000327913, gnorm=0.644, train_wall=55, wall=5129
2020-12-19 19:34:34 | INFO | train_inner | epoch 004:   2056 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.831, loss=5.145, nll_loss=2.348, ppl=5.09, wps=27461.2, ups=1.84, wpb=14929.1, bsz=541.4, num_updates=9400, lr=0.000326164, gnorm=0.613, train_wall=54, wall=5183
2020-12-19 19:35:28 | INFO | train_inner | epoch 004:   2156 / 2448 symm_kl=0.568, self_kl=0, self_cv=8.832, loss=5.197, nll_loss=2.407, ppl=5.3, wps=27295.1, ups=1.84, wpb=14846.1, bsz=504.6, num_updates=9500, lr=0.000324443, gnorm=0.653, train_wall=54, wall=5237
2020-12-19 19:36:24 | INFO | train_inner | epoch 004:   2256 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.859, loss=5.196, nll_loss=2.402, ppl=5.29, wps=26877.9, ups=1.81, wpb=14827.1, bsz=513.1, num_updates=9600, lr=0.000322749, gnorm=0.622, train_wall=55, wall=5293
2020-12-19 19:37:18 | INFO | train_inner | epoch 004:   2356 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.86, loss=5.19, nll_loss=2.395, ppl=5.26, wps=27258.3, ups=1.84, wpb=14788.5, bsz=488.6, num_updates=9700, lr=0.000321081, gnorm=0.636, train_wall=54, wall=5347
2020-12-19 19:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 19:38:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 19:38:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 19:38:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 19:38:24 | INFO | valid | epoch 004 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.986 | nll_loss 8.013 | ppl 258.38 | bleu 15.51 | wps 5228.5 | wpb 7930.2 | bsz 208 | num_updates 9792 | best_bleu 15.51
2020-12-19 19:38:24 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 4 @ 9792 updates, score 15.51) (writing took 8.6870500985533 seconds)
2020-12-19 19:38:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-12-19 19:38:33 | INFO | train | epoch 004 | symm_kl 0.576 | self_kl 0 | self_cv 8.881 | loss 5.173 | nll_loss 2.372 | ppl 5.18 | wps 26585.8 | ups 1.8 | wpb 14810.4 | bsz 511.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.641 | train_wall 1326 | wall 5422
2020-12-19 19:38:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:36 | INFO | fairseq.trainer | begin training epoch 5
2020-12-19 19:38:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 19:38:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 19:38:46 | INFO | train_inner | epoch 005:      8 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.822, loss=5.184, nll_loss=2.394, ppl=5.26, wps=16576.8, ups=1.14, wpb=14573.8, bsz=516.2, num_updates=9800, lr=0.000319438, gnorm=0.629, train_wall=55, wall=5435
2020-12-19 19:39:39 | INFO | train_inner | epoch 005:    108 / 2448 symm_kl=0.573, self_kl=0, self_cv=8.983, loss=5.125, nll_loss=2.301, ppl=4.93, wps=27623.4, ups=1.88, wpb=14697.8, bsz=524.2, num_updates=9900, lr=0.000317821, gnorm=0.623, train_wall=53, wall=5488
2020-12-19 19:40:33 | INFO | train_inner | epoch 005:    208 / 2448 symm_kl=0.576, self_kl=0, self_cv=8.975, loss=5.113, nll_loss=2.289, ppl=4.89, wps=27495.5, ups=1.85, wpb=14839.8, bsz=501.9, num_updates=10000, lr=0.000316228, gnorm=0.614, train_wall=54, wall=5542
2020-12-19 19:41:27 | INFO | train_inner | epoch 005:    308 / 2448 symm_kl=0.576, self_kl=0, self_cv=8.955, loss=5.107, nll_loss=2.285, ppl=4.87, wps=27677.4, ups=1.86, wpb=14890.2, bsz=503.4, num_updates=10100, lr=0.000314658, gnorm=0.617, train_wall=54, wall=5596
2020-12-19 19:42:21 | INFO | train_inner | epoch 005:    408 / 2448 symm_kl=0.574, self_kl=0, self_cv=8.909, loss=5.118, nll_loss=2.306, ppl=4.94, wps=27389.1, ups=1.85, wpb=14768.8, bsz=539.9, num_updates=10200, lr=0.000313112, gnorm=0.632, train_wall=54, wall=5650
2020-12-19 19:43:14 | INFO | train_inner | epoch 005:    508 / 2448 symm_kl=0.577, self_kl=0, self_cv=8.929, loss=5.126, nll_loss=2.311, ppl=4.96, wps=27519.8, ups=1.86, wpb=14809.5, bsz=504.6, num_updates=10300, lr=0.000311588, gnorm=0.603, train_wall=54, wall=5704
2020-12-19 19:44:08 | INFO | train_inner | epoch 005:    608 / 2448 symm_kl=0.576, self_kl=0, self_cv=8.919, loss=5.129, nll_loss=2.316, ppl=4.98, wps=27430.5, ups=1.85, wpb=14826.2, bsz=504.6, num_updates=10400, lr=0.000310087, gnorm=0.62, train_wall=54, wall=5758
2020-12-19 19:45:02 | INFO | train_inner | epoch 005:    708 / 2448 symm_kl=0.577, self_kl=0, self_cv=8.923, loss=5.129, nll_loss=2.315, ppl=4.98, wps=27495.1, ups=1.85, wpb=14854.3, bsz=517.1, num_updates=10500, lr=0.000308607, gnorm=0.635, train_wall=54, wall=5812
2020-12-19 19:45:56 | INFO | train_inner | epoch 005:    808 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.877, loss=5.137, nll_loss=2.332, ppl=5.04, wps=27252.1, ups=1.85, wpb=14696.7, bsz=496, num_updates=10600, lr=0.000307148, gnorm=0.616, train_wall=54, wall=5866
2020-12-19 19:46:50 | INFO | train_inner | epoch 005:    908 / 2448 symm_kl=0.572, self_kl=0, self_cv=8.914, loss=5.129, nll_loss=2.317, ppl=4.98, wps=27558.5, ups=1.86, wpb=14845.6, bsz=508.5, num_updates=10700, lr=0.000305709, gnorm=0.634, train_wall=54, wall=5919
2020-12-19 19:47:44 | INFO | train_inner | epoch 005:   1008 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.911, loss=5.115, nll_loss=2.302, ppl=4.93, wps=27555, ups=1.85, wpb=14868.2, bsz=520.3, num_updates=10800, lr=0.00030429, gnorm=0.626, train_wall=54, wall=5973
2020-12-19 19:48:38 | INFO | train_inner | epoch 005:   1108 / 2448 symm_kl=0.573, self_kl=0, self_cv=8.931, loss=5.142, nll_loss=2.329, ppl=5.02, wps=27399.9, ups=1.86, wpb=14770, bsz=497.5, num_updates=10900, lr=0.000302891, gnorm=0.627, train_wall=54, wall=6027
2020-12-19 19:49:32 | INFO | train_inner | epoch 005:   1208 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.89, loss=5.112, nll_loss=2.303, ppl=4.93, wps=27449.7, ups=1.85, wpb=14855, bsz=541.4, num_updates=11000, lr=0.000301511, gnorm=0.61, train_wall=54, wall=6081
2020-12-19 19:50:26 | INFO | train_inner | epoch 005:   1308 / 2448 symm_kl=0.57, self_kl=0, self_cv=8.911, loss=5.137, nll_loss=2.328, ppl=5.02, wps=27457, ups=1.85, wpb=14827.2, bsz=525.8, num_updates=11100, lr=0.00030015, gnorm=0.614, train_wall=54, wall=6135
2020-12-19 19:51:20 | INFO | train_inner | epoch 005:   1408 / 2448 symm_kl=0.57, self_kl=0, self_cv=8.903, loss=5.139, nll_loss=2.33, ppl=5.03, wps=27606.3, ups=1.86, wpb=14866.6, bsz=516.5, num_updates=11200, lr=0.000298807, gnorm=0.602, train_wall=54, wall=6189
2020-12-19 19:52:14 | INFO | train_inner | epoch 005:   1508 / 2448 symm_kl=0.568, self_kl=0, self_cv=8.901, loss=5.141, nll_loss=2.334, ppl=5.04, wps=27488.5, ups=1.86, wpb=14794.1, bsz=518.6, num_updates=11300, lr=0.000297482, gnorm=0.616, train_wall=54, wall=6243
2020-12-19 19:53:08 | INFO | train_inner | epoch 005:   1608 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.885, loss=5.147, nll_loss=2.343, ppl=5.07, wps=27498.6, ups=1.86, wpb=14752.4, bsz=502.6, num_updates=11400, lr=0.000296174, gnorm=0.617, train_wall=53, wall=6297
2020-12-19 19:54:02 | INFO | train_inner | epoch 005:   1708 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.896, loss=5.139, nll_loss=2.333, ppl=5.04, wps=27356, ups=1.85, wpb=14766.5, bsz=511.4, num_updates=11500, lr=0.000294884, gnorm=0.638, train_wall=54, wall=6351
2020-12-19 19:54:55 | INFO | train_inner | epoch 005:   1808 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.889, loss=5.144, nll_loss=2.339, ppl=5.06, wps=27594.3, ups=1.86, wpb=14831.5, bsz=508.2, num_updates=11600, lr=0.00029361, gnorm=0.641, train_wall=54, wall=6404
2020-12-19 19:55:49 | INFO | train_inner | epoch 005:   1908 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.923, loss=5.142, nll_loss=2.332, ppl=5.04, wps=27534.7, ups=1.86, wpb=14842.2, bsz=514.8, num_updates=11700, lr=0.000292353, gnorm=0.598, train_wall=54, wall=6458
2020-12-19 19:56:43 | INFO | train_inner | epoch 005:   2008 / 2448 symm_kl=0.568, self_kl=0, self_cv=8.895, loss=5.163, nll_loss=2.36, ppl=5.13, wps=27478.8, ups=1.86, wpb=14797.9, bsz=481.1, num_updates=11800, lr=0.000291111, gnorm=0.631, train_wall=54, wall=6512
2020-12-19 19:57:37 | INFO | train_inner | epoch 005:   2108 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.89, loss=5.156, nll_loss=2.352, ppl=5.11, wps=27466.6, ups=1.86, wpb=14754.8, bsz=509.2, num_updates=11900, lr=0.000289886, gnorm=0.626, train_wall=54, wall=6566
2020-12-19 19:58:31 | INFO | train_inner | epoch 005:   2208 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.877, loss=5.115, nll_loss=2.309, ppl=4.96, wps=27723.4, ups=1.86, wpb=14919, bsz=532.6, num_updates=12000, lr=0.000288675, gnorm=0.61, train_wall=54, wall=6620
2020-12-19 19:59:24 | INFO | train_inner | epoch 005:   2308 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.873, loss=5.143, nll_loss=2.341, ppl=5.07, wps=27604.6, ups=1.86, wpb=14862.6, bsz=500.4, num_updates=12100, lr=0.00028748, gnorm=0.637, train_wall=54, wall=6674
2020-12-19 20:00:19 | INFO | train_inner | epoch 005:   2408 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.859, loss=5.137, nll_loss=2.336, ppl=5.05, wps=27472, ups=1.85, wpb=14856.5, bsz=525, num_updates=12200, lr=0.000286299, gnorm=0.629, train_wall=54, wall=6728
2020-12-19 20:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 20:00:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:00:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:00:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:00:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:00:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:00:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:00:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:00:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:00:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:00:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:00:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 20:00:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 20:00:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 20:00:55 | INFO | valid | epoch 005 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.994 | nll_loss 8.016 | ppl 258.9 | bleu 15.83 | wps 5219.3 | wpb 7930.2 | bsz 208 | num_updates 12240 | best_bleu 15.83
2020-12-19 20:00:55 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 20:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:01:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 5 @ 12240 updates, score 15.83) (writing took 8.215672610327601 seconds)
2020-12-19 20:01:03 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-12-19 20:01:03 | INFO | train | epoch 005 | symm_kl 0.569 | self_kl 0 | self_cv 8.909 | loss 5.133 | nll_loss 2.323 | ppl 5 | wps 26846.8 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 12240 | lr 0.000285831 | gnorm 0.621 | train_wall 1315 | wall 6772
2020-12-19 20:01:06 | INFO | fairseq.trainer | begin training epoch 6
2020-12-19 20:01:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:01:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:01:44 | INFO | train_inner | epoch 006:     60 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.964, loss=5.116, nll_loss=2.295, ppl=4.91, wps=17163.9, ups=1.17, wpb=14682.4, bsz=490.5, num_updates=12300, lr=0.000285133, gnorm=0.601, train_wall=53, wall=6813
2020-12-19 20:02:38 | INFO | train_inner | epoch 006:    160 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.013, loss=5.052, nll_loss=2.215, ppl=4.64, wps=27723.7, ups=1.86, wpb=14892, bsz=513, num_updates=12400, lr=0.000283981, gnorm=0.628, train_wall=54, wall=6867
2020-12-19 20:03:32 | INFO | train_inner | epoch 006:    260 / 2448 symm_kl=0.574, self_kl=0, self_cv=8.989, loss=5.092, nll_loss=2.264, ppl=4.8, wps=27445.4, ups=1.86, wpb=14782.4, bsz=517.8, num_updates=12500, lr=0.000282843, gnorm=0.612, train_wall=54, wall=6921
2020-12-19 20:04:26 | INFO | train_inner | epoch 006:    360 / 2448 symm_kl=0.574, self_kl=0, self_cv=8.937, loss=5.1, nll_loss=2.281, ppl=4.86, wps=27272.4, ups=1.85, wpb=14702.3, bsz=519, num_updates=12600, lr=0.000281718, gnorm=0.637, train_wall=54, wall=6975
2020-12-19 20:05:19 | INFO | train_inner | epoch 006:    460 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.973, loss=5.108, nll_loss=2.285, ppl=4.87, wps=27562.8, ups=1.86, wpb=14813.6, bsz=488.2, num_updates=12700, lr=0.000280607, gnorm=0.618, train_wall=54, wall=7028
2020-12-19 20:06:13 | INFO | train_inner | epoch 006:    560 / 2448 symm_kl=0.572, self_kl=0, self_cv=8.939, loss=5.094, nll_loss=2.274, ppl=4.84, wps=27412.4, ups=1.85, wpb=14790.8, bsz=527.1, num_updates=12800, lr=0.000279508, gnorm=0.614, train_wall=54, wall=7082
2020-12-19 20:07:07 | INFO | train_inner | epoch 006:    660 / 2448 symm_kl=0.571, self_kl=0, self_cv=8.966, loss=5.098, nll_loss=2.275, ppl=4.84, wps=27288.4, ups=1.85, wpb=14770.2, bsz=518.4, num_updates=12900, lr=0.000278423, gnorm=0.622, train_wall=54, wall=7137
2020-12-19 20:08:01 | INFO | train_inner | epoch 006:    760 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.945, loss=5.087, nll_loss=2.266, ppl=4.81, wps=27813.3, ups=1.87, wpb=14899, bsz=523.6, num_updates=13000, lr=0.00027735, gnorm=0.618, train_wall=53, wall=7190
2020-12-19 20:08:55 | INFO | train_inner | epoch 006:    860 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.955, loss=5.098, nll_loss=2.276, ppl=4.84, wps=27489.5, ups=1.85, wpb=14843.6, bsz=507.2, num_updates=13100, lr=0.000276289, gnorm=0.614, train_wall=54, wall=7244
2020-12-19 20:09:49 | INFO | train_inner | epoch 006:    960 / 2448 symm_kl=0.575, self_kl=0, self_cv=8.917, loss=5.14, nll_loss=2.33, ppl=5.03, wps=27382.2, ups=1.86, wpb=14743.9, bsz=520.9, num_updates=13200, lr=0.000275241, gnorm=0.62, train_wall=54, wall=7298
2020-12-19 20:10:43 | INFO | train_inner | epoch 006:   1060 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.93, loss=5.095, nll_loss=2.278, ppl=4.85, wps=27547.8, ups=1.85, wpb=14895.4, bsz=532.6, num_updates=13300, lr=0.000274204, gnorm=0.61, train_wall=54, wall=7352
2020-12-19 20:11:37 | INFO | train_inner | epoch 006:   1160 / 2448 symm_kl=0.568, self_kl=0, self_cv=8.94, loss=5.118, nll_loss=2.302, ppl=4.93, wps=27729.9, ups=1.86, wpb=14890, bsz=508.2, num_updates=13400, lr=0.000273179, gnorm=0.607, train_wall=54, wall=7406
2020-12-19 20:12:30 | INFO | train_inner | epoch 006:   1260 / 2448 symm_kl=0.569, self_kl=0, self_cv=8.923, loss=5.113, nll_loss=2.298, ppl=4.92, wps=27490.6, ups=1.86, wpb=14797.8, bsz=512.2, num_updates=13500, lr=0.000272166, gnorm=0.627, train_wall=54, wall=7460
2020-12-19 20:13:24 | INFO | train_inner | epoch 006:   1360 / 2448 symm_kl=0.57, self_kl=0, self_cv=8.927, loss=5.127, nll_loss=2.314, ppl=4.97, wps=27363.9, ups=1.86, wpb=14751.1, bsz=505.4, num_updates=13600, lr=0.000271163, gnorm=0.641, train_wall=54, wall=7513
2020-12-19 20:14:18 | INFO | train_inner | epoch 006:   1460 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.939, loss=5.103, nll_loss=2.286, ppl=4.88, wps=27570.2, ups=1.86, wpb=14791.3, bsz=499, num_updates=13700, lr=0.000270172, gnorm=0.615, train_wall=53, wall=7567
2020-12-19 20:15:12 | INFO | train_inner | epoch 006:   1560 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.944, loss=5.112, nll_loss=2.294, ppl=4.91, wps=27604.8, ups=1.86, wpb=14849.9, bsz=483.7, num_updates=13800, lr=0.000269191, gnorm=0.618, train_wall=54, wall=7621
2020-12-19 20:16:06 | INFO | train_inner | epoch 006:   1660 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.854, loss=5.093, nll_loss=2.288, ppl=4.88, wps=27372.6, ups=1.86, wpb=14734.3, bsz=537.7, num_updates=13900, lr=0.000268221, gnorm=0.596, train_wall=54, wall=7675
2020-12-19 20:16:59 | INFO | train_inner | epoch 006:   1760 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.923, loss=5.098, nll_loss=2.283, ppl=4.87, wps=27643.5, ups=1.86, wpb=14847.5, bsz=494.6, num_updates=14000, lr=0.000267261, gnorm=0.613, train_wall=54, wall=7728
2020-12-19 20:17:53 | INFO | train_inner | epoch 006:   1860 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.938, loss=5.117, nll_loss=2.302, ppl=4.93, wps=27407.9, ups=1.86, wpb=14762.9, bsz=487.8, num_updates=14100, lr=0.000266312, gnorm=0.631, train_wall=54, wall=7782
2020-12-19 20:18:47 | INFO | train_inner | epoch 006:   1960 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.911, loss=5.11, nll_loss=2.298, ppl=4.92, wps=27396.8, ups=1.85, wpb=14794, bsz=515.3, num_updates=14200, lr=0.000265372, gnorm=0.604, train_wall=54, wall=7836
2020-12-19 20:19:41 | INFO | train_inner | epoch 006:   2060 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.918, loss=5.111, nll_loss=2.298, ppl=4.92, wps=27694.3, ups=1.86, wpb=14857.1, bsz=496, num_updates=14300, lr=0.000264443, gnorm=0.602, train_wall=53, wall=7890
2020-12-19 20:20:35 | INFO | train_inner | epoch 006:   2160 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.926, loss=5.125, nll_loss=2.313, ppl=4.97, wps=27627.5, ups=1.86, wpb=14875.9, bsz=511.6, num_updates=14400, lr=0.000263523, gnorm=0.624, train_wall=54, wall=7944
2020-12-19 20:21:29 | INFO | train_inner | epoch 006:   2260 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.89, loss=5.116, nll_loss=2.309, ppl=4.96, wps=27437.7, ups=1.85, wpb=14819.5, bsz=527.4, num_updates=14500, lr=0.000262613, gnorm=0.628, train_wall=54, wall=7998
2020-12-19 20:22:23 | INFO | train_inner | epoch 006:   2360 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.869, loss=5.091, nll_loss=2.283, ppl=4.87, wps=27485.4, ups=1.85, wpb=14845.1, bsz=519, num_updates=14600, lr=0.000261712, gnorm=0.616, train_wall=54, wall=8052
2020-12-19 20:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 20:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 20:23:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 20:23:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 20:23:25 | INFO | valid | epoch 006 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.02 | nll_loss 8.046 | ppl 264.26 | bleu 15.81 | wps 5423.5 | wpb 7930.2 | bsz 208 | num_updates 14688 | best_bleu 15.83
2020-12-19 20:23:25 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 20:23:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 6 @ 14688 updates, score 15.81) (writing took 5.101760605350137 seconds)
2020-12-19 20:23:30 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-12-19 20:23:30 | INFO | train | epoch 006 | symm_kl 0.566 | self_kl 0 | self_cv 8.933 | loss 5.103 | nll_loss 2.287 | ppl 4.88 | wps 26921.9 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 14688 | lr 0.000260927 | gnorm 0.618 | train_wall 1314 | wall 8119
2020-12-19 20:23:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:33 | INFO | fairseq.trainer | begin training epoch 7
2020-12-19 20:23:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:23:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:23:45 | INFO | train_inner | epoch 007:     12 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.878, loss=5.086, nll_loss=2.277, ppl=4.85, wps=17829.6, ups=1.21, wpb=14705.6, bsz=516.6, num_updates=14700, lr=0.00026082, gnorm=0.628, train_wall=54, wall=8134
2020-12-19 20:24:39 | INFO | train_inner | epoch 007:    112 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.004, loss=5.054, nll_loss=2.219, ppl=4.66, wps=27686.3, ups=1.86, wpb=14864.4, bsz=496.9, num_updates=14800, lr=0.000259938, gnorm=0.612, train_wall=54, wall=8188
2020-12-19 20:25:32 | INFO | train_inner | epoch 007:    212 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.002, loss=5.035, nll_loss=2.198, ppl=4.59, wps=27636.3, ups=1.86, wpb=14821.7, bsz=515, num_updates=14900, lr=0.000259064, gnorm=0.602, train_wall=53, wall=8242
2020-12-19 20:26:27 | INFO | train_inner | epoch 007:    312 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.976, loss=5.052, nll_loss=2.222, ppl=4.67, wps=27525.6, ups=1.84, wpb=14919.3, bsz=529.4, num_updates=15000, lr=0.000258199, gnorm=0.624, train_wall=54, wall=8296
2020-12-19 20:27:21 | INFO | train_inner | epoch 007:    412 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.028, loss=5.071, nll_loss=2.235, ppl=4.71, wps=27423.9, ups=1.86, wpb=14779.9, bsz=503.6, num_updates=15100, lr=0.000257343, gnorm=0.619, train_wall=54, wall=8350
2020-12-19 20:28:14 | INFO | train_inner | epoch 007:    512 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.952, loss=5.065, nll_loss=2.24, ppl=4.73, wps=27633.2, ups=1.86, wpb=14874.8, bsz=550.6, num_updates=15200, lr=0.000256495, gnorm=0.617, train_wall=54, wall=8404
2020-12-19 20:29:08 | INFO | train_inner | epoch 007:    612 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.961, loss=5.063, nll_loss=2.236, ppl=4.71, wps=27480.5, ups=1.86, wpb=14775.7, bsz=507.3, num_updates=15300, lr=0.000255655, gnorm=0.616, train_wall=54, wall=8457
2020-12-19 20:30:02 | INFO | train_inner | epoch 007:    712 / 2448 symm_kl=0.571, self_kl=0, self_cv=8.959, loss=5.083, nll_loss=2.26, ppl=4.79, wps=27437.8, ups=1.86, wpb=14770.5, bsz=489.8, num_updates=15400, lr=0.000254824, gnorm=0.628, train_wall=54, wall=8511
2020-12-19 20:30:56 | INFO | train_inner | epoch 007:    812 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.946, loss=5.062, nll_loss=2.238, ppl=4.72, wps=27424.6, ups=1.85, wpb=14811, bsz=524.5, num_updates=15500, lr=0.000254, gnorm=0.639, train_wall=54, wall=8565
2020-12-19 20:31:50 | INFO | train_inner | epoch 007:    912 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.97, loss=5.087, nll_loss=2.262, ppl=4.8, wps=27561, ups=1.85, wpb=14872.4, bsz=500.2, num_updates=15600, lr=0.000253185, gnorm=0.608, train_wall=54, wall=8619
2020-12-19 20:32:44 | INFO | train_inner | epoch 007:   1012 / 2448 symm_kl=0.57, self_kl=0, self_cv=8.955, loss=5.098, nll_loss=2.277, ppl=4.85, wps=27393.7, ups=1.85, wpb=14784.1, bsz=517.1, num_updates=15700, lr=0.000252377, gnorm=0.619, train_wall=54, wall=8673
2020-12-19 20:33:38 | INFO | train_inner | epoch 007:   1112 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.933, loss=5.073, nll_loss=2.253, ppl=4.77, wps=27525.6, ups=1.85, wpb=14883.9, bsz=517.7, num_updates=15800, lr=0.000251577, gnorm=0.603, train_wall=54, wall=8727
2020-12-19 20:34:32 | INFO | train_inner | epoch 007:   1212 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.939, loss=5.089, nll_loss=2.27, ppl=4.82, wps=27643, ups=1.86, wpb=14890.6, bsz=510.5, num_updates=15900, lr=0.000250785, gnorm=0.608, train_wall=54, wall=8781
2020-12-19 20:35:26 | INFO | train_inner | epoch 007:   1312 / 2448 symm_kl=0.572, self_kl=0, self_cv=8.987, loss=5.111, nll_loss=2.288, ppl=4.88, wps=27299.9, ups=1.85, wpb=14743.6, bsz=488.1, num_updates=16000, lr=0.00025, gnorm=0.631, train_wall=54, wall=8835
2020-12-19 20:36:20 | INFO | train_inner | epoch 007:   1412 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.949, loss=5.079, nll_loss=2.258, ppl=4.78, wps=27536.7, ups=1.85, wpb=14857, bsz=507.8, num_updates=16100, lr=0.000249222, gnorm=0.616, train_wall=54, wall=8889
2020-12-19 20:37:14 | INFO | train_inner | epoch 007:   1512 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.929, loss=5.102, nll_loss=2.286, ppl=4.88, wps=27366, ups=1.86, wpb=14747.3, bsz=529.6, num_updates=16200, lr=0.000248452, gnorm=0.624, train_wall=54, wall=8943
2020-12-19 20:38:08 | INFO | train_inner | epoch 007:   1612 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.933, loss=5.075, nll_loss=2.256, ppl=4.78, wps=27290.2, ups=1.85, wpb=14769.3, bsz=504.3, num_updates=16300, lr=0.000247689, gnorm=0.616, train_wall=54, wall=8997
2020-12-19 20:39:02 | INFO | train_inner | epoch 007:   1712 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.958, loss=5.1, nll_loss=2.28, ppl=4.86, wps=27386.2, ups=1.85, wpb=14767.6, bsz=497.8, num_updates=16400, lr=0.000246932, gnorm=0.611, train_wall=54, wall=9051
2020-12-19 20:39:56 | INFO | train_inner | epoch 007:   1812 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.947, loss=5.079, nll_loss=2.259, ppl=4.79, wps=27401.1, ups=1.85, wpb=14786.8, bsz=504.9, num_updates=16500, lr=0.000246183, gnorm=0.637, train_wall=54, wall=9105
2020-12-19 20:40:50 | INFO | train_inner | epoch 007:   1912 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.912, loss=5.075, nll_loss=2.259, ppl=4.79, wps=27519.6, ups=1.85, wpb=14879.9, bsz=526.6, num_updates=16600, lr=0.00024544, gnorm=0.607, train_wall=54, wall=9159
2020-12-19 20:41:44 | INFO | train_inner | epoch 007:   2012 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.922, loss=5.103, nll_loss=2.29, ppl=4.89, wps=27329.3, ups=1.85, wpb=14778.3, bsz=497.4, num_updates=16700, lr=0.000244704, gnorm=0.616, train_wall=54, wall=9213
2020-12-19 20:42:38 | INFO | train_inner | epoch 007:   2112 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.927, loss=5.086, nll_loss=2.27, ppl=4.82, wps=27382, ups=1.84, wpb=14857.6, bsz=520.1, num_updates=16800, lr=0.000243975, gnorm=0.606, train_wall=54, wall=9267
2020-12-19 20:43:32 | INFO | train_inner | epoch 007:   2212 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.898, loss=5.085, nll_loss=2.273, ppl=4.83, wps=27520.6, ups=1.85, wpb=14837.6, bsz=544.8, num_updates=16900, lr=0.000243252, gnorm=0.621, train_wall=54, wall=9321
2020-12-19 20:44:26 | INFO | train_inner | epoch 007:   2312 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.873, loss=5.087, nll_loss=2.279, ppl=4.85, wps=27397, ups=1.85, wpb=14809.9, bsz=505.4, num_updates=17000, lr=0.000242536, gnorm=0.601, train_wall=54, wall=9375
2020-12-19 20:45:20 | INFO | train_inner | epoch 007:   2412 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.951, loss=5.102, nll_loss=2.284, ppl=4.87, wps=27236.3, ups=1.85, wpb=14722.7, bsz=505.4, num_updates=17100, lr=0.000241825, gnorm=0.625, train_wall=54, wall=9429
2020-12-19 20:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 20:45:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:45:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:45:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:45:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:45:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:45:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 20:45:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 20:45:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 20:45:54 | INFO | valid | epoch 007 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.037 | nll_loss 8.061 | ppl 267.05 | bleu 15.52 | wps 5160.3 | wpb 7930.2 | bsz 208 | num_updates 17136 | best_bleu 15.83
2020-12-19 20:45:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 20:45:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 7 @ 17136 updates, score 15.52) (writing took 5.010662235319614 seconds)
2020-12-19 20:45:59 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-12-19 20:45:59 | INFO | train | epoch 007 | symm_kl 0.564 | self_kl 0 | self_cv 8.951 | loss 5.08 | nll_loss 2.258 | ppl 4.78 | wps 26865 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 17136 | lr 0.000241571 | gnorm 0.617 | train_wall 1317 | wall 9469
2020-12-19 20:46:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:46:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:46:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:46:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:46:02 | INFO | fairseq.trainer | begin training epoch 8
2020-12-19 20:46:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:46:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 20:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 20:46:42 | INFO | train_inner | epoch 008:     64 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.018, loss=5.062, nll_loss=2.227, ppl=4.68, wps=17863.7, ups=1.22, wpb=14668.8, bsz=470.1, num_updates=17200, lr=0.000241121, gnorm=0.634, train_wall=53, wall=9511
2020-12-19 20:47:36 | INFO | train_inner | epoch 008:    164 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.013, loss=5.037, nll_loss=2.199, ppl=4.59, wps=27406.3, ups=1.86, wpb=14756.1, bsz=504.7, num_updates=17300, lr=0.000240424, gnorm=0.635, train_wall=54, wall=9565
2020-12-19 20:48:30 | INFO | train_inner | epoch 008:    264 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.02, loss=5.038, nll_loss=2.2, ppl=4.59, wps=27475, ups=1.86, wpb=14802.5, bsz=514.3, num_updates=17400, lr=0.000239732, gnorm=0.608, train_wall=54, wall=9619
2020-12-19 20:49:24 | INFO | train_inner | epoch 008:    364 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.025, loss=5.061, nll_loss=2.224, ppl=4.67, wps=27384.9, ups=1.86, wpb=14748.7, bsz=497, num_updates=17500, lr=0.000239046, gnorm=0.609, train_wall=54, wall=9673
2020-12-19 20:50:18 | INFO | train_inner | epoch 008:    464 / 2448 symm_kl=0.577, self_kl=0, self_cv=9.025, loss=5.068, nll_loss=2.232, ppl=4.7, wps=27306.6, ups=1.85, wpb=14745.6, bsz=502.3, num_updates=17600, lr=0.000238366, gnorm=0.639, train_wall=54, wall=9727
2020-12-19 20:51:12 | INFO | train_inner | epoch 008:    564 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.016, loss=5.04, nll_loss=2.204, ppl=4.61, wps=27510.6, ups=1.85, wpb=14832, bsz=515.1, num_updates=17700, lr=0.000237691, gnorm=0.63, train_wall=54, wall=9781
2020-12-19 20:52:06 | INFO | train_inner | epoch 008:    664 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.003, loss=5.065, nll_loss=2.233, ppl=4.7, wps=27289.4, ups=1.85, wpb=14780, bsz=520.1, num_updates=17800, lr=0.000237023, gnorm=0.625, train_wall=54, wall=9835
2020-12-19 20:53:00 | INFO | train_inner | epoch 008:    764 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.965, loss=5.05, nll_loss=2.222, ppl=4.67, wps=27523.6, ups=1.85, wpb=14857.6, bsz=497.4, num_updates=17900, lr=0.00023636, gnorm=0.621, train_wall=54, wall=9889
2020-12-19 20:53:54 | INFO | train_inner | epoch 008:    864 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.975, loss=5.045, nll_loss=2.215, ppl=4.64, wps=27513, ups=1.85, wpb=14884.3, bsz=549.7, num_updates=18000, lr=0.000235702, gnorm=0.623, train_wall=54, wall=9943
2020-12-19 20:54:48 | INFO | train_inner | epoch 008:    964 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.001, loss=5.064, nll_loss=2.232, ppl=4.7, wps=27383, ups=1.85, wpb=14793.8, bsz=507.8, num_updates=18100, lr=0.00023505, gnorm=0.61, train_wall=54, wall=9997
2020-12-19 20:55:42 | INFO | train_inner | epoch 008:   1064 / 2448 symm_kl=0.571, self_kl=0, self_cv=8.983, loss=5.082, nll_loss=2.256, ppl=4.78, wps=27325.7, ups=1.85, wpb=14759.6, bsz=488.9, num_updates=18200, lr=0.000234404, gnorm=0.649, train_wall=54, wall=10051
2020-12-19 20:56:36 | INFO | train_inner | epoch 008:   1164 / 2448 symm_kl=0.568, self_kl=0, self_cv=8.983, loss=5.069, nll_loss=2.241, ppl=4.73, wps=27339.4, ups=1.85, wpb=14766.6, bsz=502.7, num_updates=18300, lr=0.000233762, gnorm=0.638, train_wall=54, wall=10105
2020-12-19 20:57:30 | INFO | train_inner | epoch 008:   1264 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.969, loss=5.064, nll_loss=2.238, ppl=4.72, wps=27332.6, ups=1.85, wpb=14812.4, bsz=504.6, num_updates=18400, lr=0.000233126, gnorm=0.621, train_wall=54, wall=10159
2020-12-19 20:58:24 | INFO | train_inner | epoch 008:   1364 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.935, loss=5.051, nll_loss=2.229, ppl=4.69, wps=27513.5, ups=1.85, wpb=14908.4, bsz=541.7, num_updates=18500, lr=0.000232495, gnorm=0.6, train_wall=54, wall=10214
2020-12-19 20:59:18 | INFO | train_inner | epoch 008:   1464 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.957, loss=5.071, nll_loss=2.248, ppl=4.75, wps=27366.7, ups=1.86, wpb=14752.8, bsz=505.8, num_updates=18600, lr=0.000231869, gnorm=0.609, train_wall=54, wall=10267
2020-12-19 21:00:13 | INFO | train_inner | epoch 008:   1564 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.95, loss=5.059, nll_loss=2.235, ppl=4.71, wps=27397.9, ups=1.84, wpb=14903.9, bsz=539, num_updates=18700, lr=0.000231249, gnorm=0.62, train_wall=54, wall=10322
2020-12-19 21:01:07 | INFO | train_inner | epoch 008:   1664 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.941, loss=5.063, nll_loss=2.242, ppl=4.73, wps=27491.7, ups=1.85, wpb=14883.2, bsz=513.4, num_updates=18800, lr=0.000230633, gnorm=0.61, train_wall=54, wall=10376
2020-12-19 21:02:01 | INFO | train_inner | epoch 008:   1764 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.949, loss=5.073, nll_loss=2.252, ppl=4.76, wps=27366.3, ups=1.85, wpb=14808.8, bsz=497.7, num_updates=18900, lr=0.000230022, gnorm=0.618, train_wall=54, wall=10430
2020-12-19 21:02:55 | INFO | train_inner | epoch 008:   1864 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.913, loss=5.056, nll_loss=2.238, ppl=4.72, wps=27343.5, ups=1.85, wpb=14753.4, bsz=519, num_updates=19000, lr=0.000229416, gnorm=0.616, train_wall=54, wall=10484
2020-12-19 21:03:49 | INFO | train_inner | epoch 008:   1964 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.94, loss=5.072, nll_loss=2.252, ppl=4.76, wps=27394.5, ups=1.85, wpb=14832.7, bsz=520, num_updates=19100, lr=0.000228814, gnorm=0.619, train_wall=54, wall=10538
2020-12-19 21:04:43 | INFO | train_inner | epoch 008:   2064 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.942, loss=5.062, nll_loss=2.24, ppl=4.72, wps=27426.7, ups=1.86, wpb=14777.1, bsz=509.1, num_updates=19200, lr=0.000228218, gnorm=0.604, train_wall=54, wall=10592
2020-12-19 21:05:37 | INFO | train_inner | epoch 008:   2164 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.917, loss=5.071, nll_loss=2.255, ppl=4.77, wps=27582.5, ups=1.86, wpb=14867.6, bsz=499.9, num_updates=19300, lr=0.000227626, gnorm=0.603, train_wall=54, wall=10646
2020-12-19 21:06:31 | INFO | train_inner | epoch 008:   2264 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.93, loss=5.073, nll_loss=2.255, ppl=4.77, wps=27523.4, ups=1.85, wpb=14884.4, bsz=517.5, num_updates=19400, lr=0.000227038, gnorm=0.619, train_wall=54, wall=10700
2020-12-19 21:07:25 | INFO | train_inner | epoch 008:   2364 / 2448 symm_kl=0.55, self_kl=0, self_cv=8.864, loss=5.042, nll_loss=2.23, ppl=4.69, wps=27304.6, ups=1.85, wpb=14769.5, bsz=543.8, num_updates=19500, lr=0.000226455, gnorm=0.615, train_wall=54, wall=10754
2020-12-19 21:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 21:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 21:08:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 21:08:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 21:08:25 | INFO | valid | epoch 008 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.974 | nll_loss 7.997 | ppl 255.55 | bleu 15.86 | wps 5421.9 | wpb 7930.2 | bsz 208 | num_updates 19584 | best_bleu 15.86
2020-12-19 21:08:25 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 21:08:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 8 @ 19584 updates, score 15.86) (writing took 8.474358789622784 seconds)
2020-12-19 21:08:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-12-19 21:08:34 | INFO | train | epoch 008 | symm_kl 0.563 | self_kl 0 | self_cv 8.968 | loss 5.06 | nll_loss 2.234 | ppl 4.7 | wps 26774.5 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 19584 | lr 0.000225969 | gnorm 0.62 | train_wall 1318 | wall 10823
2020-12-19 21:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:37 | INFO | fairseq.trainer | begin training epoch 9
2020-12-19 21:08:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:08:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:08:51 | INFO | train_inner | epoch 009:     16 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.972, loss=5.077, nll_loss=2.253, ppl=4.77, wps=17238.7, ups=1.17, wpb=14796.9, bsz=505, num_updates=19600, lr=0.000225877, gnorm=0.628, train_wall=54, wall=10840
2020-12-19 21:09:44 | INFO | train_inner | epoch 009:    116 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.034, loss=5.009, nll_loss=2.165, ppl=4.48, wps=27601.2, ups=1.87, wpb=14760.1, bsz=544.3, num_updates=19700, lr=0.000225303, gnorm=0.604, train_wall=53, wall=10894
2020-12-19 21:10:38 | INFO | train_inner | epoch 009:    216 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.013, loss=5.031, nll_loss=2.194, ppl=4.57, wps=27362.8, ups=1.85, wpb=14799.8, bsz=520.5, num_updates=19800, lr=0.000224733, gnorm=0.622, train_wall=54, wall=10948
2020-12-19 21:11:32 | INFO | train_inner | epoch 009:    316 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.038, loss=5.029, nll_loss=2.187, ppl=4.55, wps=27298.7, ups=1.86, wpb=14706.2, bsz=501, num_updates=19900, lr=0.000224168, gnorm=0.612, train_wall=54, wall=11001
2020-12-19 21:12:26 | INFO | train_inner | epoch 009:    416 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.038, loss=5.034, nll_loss=2.193, ppl=4.57, wps=27367.3, ups=1.86, wpb=14733.2, bsz=475.9, num_updates=20000, lr=0.000223607, gnorm=0.631, train_wall=54, wall=11055
2020-12-19 21:13:20 | INFO | train_inner | epoch 009:    516 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.004, loss=5.026, nll_loss=2.189, ppl=4.56, wps=27528.7, ups=1.86, wpb=14832.1, bsz=526.2, num_updates=20100, lr=0.00022305, gnorm=0.612, train_wall=54, wall=11109
2020-12-19 21:14:14 | INFO | train_inner | epoch 009:    616 / 2448 symm_kl=0.568, self_kl=0, self_cv=9, loss=5.031, nll_loss=2.196, ppl=4.58, wps=27596.2, ups=1.86, wpb=14861.8, bsz=525.7, num_updates=20200, lr=0.000222497, gnorm=0.641, train_wall=54, wall=11163
2020-12-19 21:15:08 | INFO | train_inner | epoch 009:    716 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.018, loss=5.026, nll_loss=2.188, ppl=4.56, wps=27558.4, ups=1.85, wpb=14871.9, bsz=511.1, num_updates=20300, lr=0.000221948, gnorm=0.627, train_wall=54, wall=11217
2020-12-19 21:16:02 | INFO | train_inner | epoch 009:    816 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.004, loss=5.044, nll_loss=2.21, ppl=4.63, wps=27558.1, ups=1.86, wpb=14841, bsz=512.5, num_updates=20400, lr=0.000221404, gnorm=0.628, train_wall=54, wall=11271
2020-12-19 21:16:56 | INFO | train_inner | epoch 009:    916 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.01, loss=5.059, nll_loss=2.226, ppl=4.68, wps=27166.3, ups=1.84, wpb=14785.2, bsz=507, num_updates=20500, lr=0.000220863, gnorm=0.615, train_wall=54, wall=11325
2020-12-19 21:17:50 | INFO | train_inner | epoch 009:   1016 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.027, loss=5.05, nll_loss=2.214, ppl=4.64, wps=27460.8, ups=1.85, wpb=14830.5, bsz=496.7, num_updates=20600, lr=0.000220326, gnorm=0.615, train_wall=54, wall=11379
2020-12-19 21:18:44 | INFO | train_inner | epoch 009:   1116 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.965, loss=5.049, nll_loss=2.222, ppl=4.67, wps=27500.3, ups=1.86, wpb=14813.2, bsz=521.5, num_updates=20700, lr=0.000219793, gnorm=0.609, train_wall=54, wall=11433
2020-12-19 21:19:38 | INFO | train_inner | epoch 009:   1216 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.996, loss=5.042, nll_loss=2.209, ppl=4.62, wps=27296.6, ups=1.84, wpb=14823, bsz=499.4, num_updates=20800, lr=0.000219265, gnorm=0.618, train_wall=54, wall=11487
2020-12-19 21:20:33 | INFO | train_inner | epoch 009:   1316 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.923, loss=5.027, nll_loss=2.204, ppl=4.61, wps=27284.3, ups=1.85, wpb=14781.8, bsz=542.8, num_updates=20900, lr=0.000218739, gnorm=0.632, train_wall=54, wall=11542
2020-12-19 21:21:27 | INFO | train_inner | epoch 009:   1416 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.961, loss=5.053, nll_loss=2.227, ppl=4.68, wps=27418.6, ups=1.84, wpb=14868.3, bsz=504.1, num_updates=21000, lr=0.000218218, gnorm=0.624, train_wall=54, wall=11596
2020-12-19 21:22:21 | INFO | train_inner | epoch 009:   1516 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.948, loss=5.047, nll_loss=2.222, ppl=4.67, wps=27568.1, ups=1.85, wpb=14877.6, bsz=503.8, num_updates=21100, lr=0.0002177, gnorm=0.615, train_wall=54, wall=11650
2020-12-19 21:23:15 | INFO | train_inner | epoch 009:   1616 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.989, loss=5.061, nll_loss=2.232, ppl=4.7, wps=27168.7, ups=1.84, wpb=14786, bsz=506.7, num_updates=21200, lr=0.000217186, gnorm=0.622, train_wall=54, wall=11704
2020-12-19 21:24:09 | INFO | train_inner | epoch 009:   1716 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.97, loss=5.062, nll_loss=2.237, ppl=4.71, wps=27249.4, ups=1.84, wpb=14800.7, bsz=488.2, num_updates=21300, lr=0.000216676, gnorm=0.609, train_wall=54, wall=11759
2020-12-19 21:25:04 | INFO | train_inner | epoch 009:   1816 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.937, loss=5.044, nll_loss=2.221, ppl=4.66, wps=27442.8, ups=1.84, wpb=14879.9, bsz=534.6, num_updates=21400, lr=0.000216169, gnorm=0.621, train_wall=54, wall=11813
2020-12-19 21:25:58 | INFO | train_inner | epoch 009:   1916 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.966, loss=5.074, nll_loss=2.251, ppl=4.76, wps=27118, ups=1.85, wpb=14652.7, bsz=495.4, num_updates=21500, lr=0.000215666, gnorm=0.622, train_wall=54, wall=11867
2020-12-19 21:26:52 | INFO | train_inner | epoch 009:   2016 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.935, loss=5.07, nll_loss=2.251, ppl=4.76, wps=27279.3, ups=1.84, wpb=14803.6, bsz=513.8, num_updates=21600, lr=0.000215166, gnorm=0.621, train_wall=54, wall=11921
2020-12-19 21:27:46 | INFO | train_inner | epoch 009:   2116 / 2448 symm_kl=0.548, self_kl=0, self_cv=8.905, loss=5.024, nll_loss=2.204, ppl=4.61, wps=27537.3, ups=1.84, wpb=14972.9, bsz=550.9, num_updates=21700, lr=0.000214669, gnorm=0.6, train_wall=54, wall=11975
2020-12-19 21:28:40 | INFO | train_inner | epoch 009:   2216 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.97, loss=5.066, nll_loss=2.242, ppl=4.73, wps=27334.9, ups=1.85, wpb=14784.7, bsz=496.8, num_updates=21800, lr=0.000214176, gnorm=0.625, train_wall=54, wall=12030
2020-12-19 21:29:34 | INFO | train_inner | epoch 009:   2316 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.964, loss=5.057, nll_loss=2.232, ppl=4.7, wps=27316.1, ups=1.85, wpb=14764.2, bsz=492.1, num_updates=21900, lr=0.000213687, gnorm=0.629, train_wall=54, wall=12084
2020-12-19 21:30:29 | INFO | train_inner | epoch 009:   2416 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.971, loss=5.043, nll_loss=2.215, ppl=4.64, wps=27466, ups=1.84, wpb=14908, bsz=504.5, num_updates=22000, lr=0.000213201, gnorm=0.604, train_wall=54, wall=12138
2020-12-19 21:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 21:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:30:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 21:30:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 21:30:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 21:31:00 | INFO | valid | epoch 009 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.03 | nll_loss 8.053 | ppl 265.64 | bleu 15.54 | wps 5919.6 | wpb 7930.2 | bsz 208 | num_updates 22032 | best_bleu 15.86
2020-12-19 21:31:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 21:31:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 9 @ 22032 updates, score 15.54) (writing took 5.003429584205151 seconds)
2020-12-19 21:31:05 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-12-19 21:31:05 | INFO | train | epoch 009 | symm_kl 0.563 | self_kl 0 | self_cv 8.982 | loss 5.044 | nll_loss 2.214 | ppl 4.64 | wps 26832.8 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 22032 | lr 0.000213046 | gnorm 0.619 | train_wall 1320 | wall 12174
2020-12-19 21:31:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:31:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:31:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:31:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:31:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:31:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:31:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:31:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:31:08 | INFO | fairseq.trainer | begin training epoch 10
2020-12-19 21:31:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:31:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:31:50 | INFO | train_inner | epoch 010:     68 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.983, loss=5.024, nll_loss=2.191, ppl=4.57, wps=18056.5, ups=1.23, wpb=14685.8, bsz=531.6, num_updates=22100, lr=0.000212718, gnorm=0.613, train_wall=53, wall=12219
2020-12-19 21:32:44 | INFO | train_inner | epoch 010:    168 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.032, loss=4.983, nll_loss=2.136, ppl=4.4, wps=27639.7, ups=1.86, wpb=14877.4, bsz=512.6, num_updates=22200, lr=0.000212238, gnorm=0.612, train_wall=54, wall=12273
2020-12-19 21:33:38 | INFO | train_inner | epoch 010:    268 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.015, loss=5.017, nll_loss=2.178, ppl=4.53, wps=27263.5, ups=1.84, wpb=14783.5, bsz=526.3, num_updates=22300, lr=0.000211762, gnorm=0.617, train_wall=54, wall=12327
2020-12-19 21:34:32 | INFO | train_inner | epoch 010:    368 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.035, loss=5.005, nll_loss=2.161, ppl=4.47, wps=27169.3, ups=1.84, wpb=14740.3, bsz=525.8, num_updates=22400, lr=0.000211289, gnorm=0.654, train_wall=54, wall=12382
2020-12-19 21:35:27 | INFO | train_inner | epoch 010:    468 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.039, loss=5.013, nll_loss=2.169, ppl=4.5, wps=27390.3, ups=1.85, wpb=14819.8, bsz=496.6, num_updates=22500, lr=0.000210819, gnorm=0.618, train_wall=54, wall=12436
2020-12-19 21:36:21 | INFO | train_inner | epoch 010:    568 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.021, loss=4.996, nll_loss=2.154, ppl=4.45, wps=27315, ups=1.84, wpb=14815.7, bsz=521.1, num_updates=22600, lr=0.000210352, gnorm=0.611, train_wall=54, wall=12490
2020-12-19 21:37:15 | INFO | train_inner | epoch 010:    668 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.028, loss=5.028, nll_loss=2.189, ppl=4.56, wps=27421.5, ups=1.85, wpb=14824.2, bsz=490.1, num_updates=22700, lr=0.000209888, gnorm=0.632, train_wall=54, wall=12544
2020-12-19 21:38:09 | INFO | train_inner | epoch 010:    768 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.992, loss=5.014, nll_loss=2.179, ppl=4.53, wps=27450.3, ups=1.85, wpb=14847.3, bsz=513.7, num_updates=22800, lr=0.000209427, gnorm=0.621, train_wall=54, wall=12598
2020-12-19 21:39:03 | INFO | train_inner | epoch 010:    868 / 2448 symm_kl=0.562, self_kl=0, self_cv=9, loss=5.027, nll_loss=2.192, ppl=4.57, wps=27432.4, ups=1.85, wpb=14859.5, bsz=515.7, num_updates=22900, lr=0.000208969, gnorm=0.622, train_wall=54, wall=12652
2020-12-19 21:39:57 | INFO | train_inner | epoch 010:    968 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.019, loss=5.025, nll_loss=2.187, ppl=4.55, wps=27374.7, ups=1.84, wpb=14847.9, bsz=504.6, num_updates=23000, lr=0.000208514, gnorm=0.64, train_wall=54, wall=12706
2020-12-19 21:40:51 | INFO | train_inner | epoch 010:   1068 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.949, loss=5.018, nll_loss=2.19, ppl=4.56, wps=27577.4, ups=1.85, wpb=14867.2, bsz=525.9, num_updates=23100, lr=0.000208063, gnorm=0.612, train_wall=54, wall=12760
2020-12-19 21:41:46 | INFO | train_inner | epoch 010:   1168 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.017, loss=5.031, nll_loss=2.194, ppl=4.58, wps=27367.3, ups=1.84, wpb=14856.9, bsz=521.6, num_updates=23200, lr=0.000207614, gnorm=0.624, train_wall=54, wall=12815
2020-12-19 21:42:41 | INFO | train_inner | epoch 010:   1268 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.98, loss=5.045, nll_loss=2.215, ppl=4.64, wps=26565.2, ups=1.8, wpb=14740.8, bsz=503.2, num_updates=23300, lr=0.000207168, gnorm=0.636, train_wall=55, wall=12870
2020-12-19 21:43:36 | INFO | train_inner | epoch 010:   1368 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.99, loss=5.039, nll_loss=2.207, ppl=4.62, wps=27171.6, ups=1.83, wpb=14832.5, bsz=489.4, num_updates=23400, lr=0.000206725, gnorm=0.601, train_wall=54, wall=12925
2020-12-19 21:44:31 | INFO | train_inner | epoch 010:   1468 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.995, loss=5.039, nll_loss=2.207, ppl=4.62, wps=26880.6, ups=1.81, wpb=14884.1, bsz=516.3, num_updates=23500, lr=0.000206284, gnorm=0.619, train_wall=55, wall=12980
2020-12-19 21:45:26 | INFO | train_inner | epoch 010:   1568 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.97, loss=5.02, nll_loss=2.189, ppl=4.56, wps=26941.8, ups=1.82, wpb=14776, bsz=524.7, num_updates=23600, lr=0.000205847, gnorm=0.619, train_wall=55, wall=13035
2020-12-19 21:46:21 | INFO | train_inner | epoch 010:   1668 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.983, loss=5.043, nll_loss=2.213, ppl=4.64, wps=26810.4, ups=1.82, wpb=14759.4, bsz=514.3, num_updates=23700, lr=0.000205412, gnorm=0.624, train_wall=55, wall=13090
2020-12-19 21:47:15 | INFO | train_inner | epoch 010:   1768 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.975, loss=5.058, nll_loss=2.232, ppl=4.7, wps=27222.6, ups=1.84, wpb=14799.2, bsz=490.6, num_updates=23800, lr=0.00020498, gnorm=0.626, train_wall=54, wall=13144
2020-12-19 21:48:09 | INFO | train_inner | epoch 010:   1868 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.985, loss=5.05, nll_loss=2.221, ppl=4.66, wps=27502.7, ups=1.85, wpb=14834.9, bsz=495.4, num_updates=23900, lr=0.000204551, gnorm=0.634, train_wall=54, wall=13198
2020-12-19 21:49:04 | INFO | train_inner | epoch 010:   1968 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.976, loss=5.058, nll_loss=2.231, ppl=4.69, wps=27027.3, ups=1.83, wpb=14750.4, bsz=480.9, num_updates=24000, lr=0.000204124, gnorm=0.637, train_wall=54, wall=13253
2020-12-19 21:49:59 | INFO | train_inner | epoch 010:   2068 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.985, loss=5.049, nll_loss=2.22, ppl=4.66, wps=26680, ups=1.81, wpb=14756.4, bsz=516.2, num_updates=24100, lr=0.0002037, gnorm=0.646, train_wall=55, wall=13308
2020-12-19 21:50:54 | INFO | train_inner | epoch 010:   2168 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.958, loss=5.044, nll_loss=2.219, ppl=4.66, wps=27138.6, ups=1.83, wpb=14863.5, bsz=502.2, num_updates=24200, lr=0.000203279, gnorm=0.621, train_wall=55, wall=13363
2020-12-19 21:51:49 | INFO | train_inner | epoch 010:   2268 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.959, loss=5.049, nll_loss=2.224, ppl=4.67, wps=27033.8, ups=1.82, wpb=14817, bsz=525.8, num_updates=24300, lr=0.00020286, gnorm=0.633, train_wall=55, wall=13418
2020-12-19 21:52:44 | INFO | train_inner | epoch 010:   2368 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.931, loss=5.034, nll_loss=2.212, ppl=4.63, wps=26780.2, ups=1.81, wpb=14802.1, bsz=543.3, num_updates=24400, lr=0.000202444, gnorm=0.63, train_wall=55, wall=13473
2020-12-19 21:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 21:53:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 21:53:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 21:53:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 21:53:42 | INFO | valid | epoch 010 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.97 | nll_loss 7.995 | ppl 255.07 | bleu 15.78 | wps 5518.7 | wpb 7930.2 | bsz 208 | num_updates 24480 | best_bleu 15.86
2020-12-19 21:53:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 21:53:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 10 @ 24480 updates, score 15.78) (writing took 4.8078981433063745 seconds)
2020-12-19 21:53:47 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-12-19 21:53:47 | INFO | train | epoch 010 | symm_kl 0.563 | self_kl 0 | self_cv 8.991 | loss 5.029 | nll_loss 2.196 | ppl 4.58 | wps 26610.7 | ups 1.8 | wpb 14810.4 | bsz 511.8 | num_updates 24480 | lr 0.000202113 | gnorm 0.625 | train_wall 1329 | wall 13536
2020-12-19 21:53:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:50 | INFO | fairseq.trainer | begin training epoch 11
2020-12-19 21:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:53:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 21:53:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 21:54:07 | INFO | train_inner | epoch 011:     20 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.948, loss=5.019, nll_loss=2.192, ppl=4.57, wps=17761.7, ups=1.21, wpb=14702.2, bsz=506.2, num_updates=24500, lr=0.000202031, gnorm=0.622, train_wall=55, wall=13556
2020-12-19 21:55:00 | INFO | train_inner | epoch 011:    120 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.046, loss=4.984, nll_loss=2.137, ppl=4.4, wps=27821.7, ups=1.87, wpb=14899.7, bsz=507.5, num_updates=24600, lr=0.000201619, gnorm=0.629, train_wall=53, wall=13609
2020-12-19 21:55:54 | INFO | train_inner | epoch 011:    220 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.046, loss=4.996, nll_loss=2.15, ppl=4.44, wps=27693.1, ups=1.86, wpb=14862, bsz=518.1, num_updates=24700, lr=0.000201211, gnorm=0.613, train_wall=53, wall=13663
2020-12-19 21:56:48 | INFO | train_inner | epoch 011:    320 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.049, loss=5.008, nll_loss=2.163, ppl=4.48, wps=27432.1, ups=1.86, wpb=14783.3, bsz=498.8, num_updates=24800, lr=0.000200805, gnorm=0.622, train_wall=54, wall=13717
2020-12-19 21:57:42 | INFO | train_inner | epoch 011:    420 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.028, loss=4.983, nll_loss=2.138, ppl=4.4, wps=27514.9, ups=1.85, wpb=14833.1, bsz=522.4, num_updates=24900, lr=0.000200401, gnorm=0.628, train_wall=54, wall=13771
2020-12-19 21:58:36 | INFO | train_inner | epoch 011:    520 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.037, loss=5, nll_loss=2.156, ppl=4.46, wps=27393.5, ups=1.85, wpb=14788.8, bsz=498, num_updates=25000, lr=0.0002, gnorm=0.613, train_wall=54, wall=13825
2020-12-19 21:59:29 | INFO | train_inner | epoch 011:    620 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.015, loss=5.011, nll_loss=2.172, ppl=4.51, wps=27372.1, ups=1.86, wpb=14727.9, bsz=513.5, num_updates=25100, lr=0.000199601, gnorm=0.616, train_wall=54, wall=13879
2020-12-19 22:00:23 | INFO | train_inner | epoch 011:    720 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.026, loss=5.018, nll_loss=2.178, ppl=4.53, wps=27375.5, ups=1.86, wpb=14756.6, bsz=500.2, num_updates=25200, lr=0.000199205, gnorm=0.632, train_wall=54, wall=13933
2020-12-19 22:01:17 | INFO | train_inner | epoch 011:    820 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.004, loss=5.01, nll_loss=2.172, ppl=4.51, wps=27460.5, ups=1.86, wpb=14733.7, bsz=494.9, num_updates=25300, lr=0.000198811, gnorm=0.624, train_wall=53, wall=13986
2020-12-19 22:02:11 | INFO | train_inner | epoch 011:    920 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.034, loss=5.018, nll_loss=2.177, ppl=4.52, wps=27547.9, ups=1.85, wpb=14882.3, bsz=502.3, num_updates=25400, lr=0.000198419, gnorm=0.633, train_wall=54, wall=14040
2020-12-19 22:03:05 | INFO | train_inner | epoch 011:   1020 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.994, loss=5.025, nll_loss=2.191, ppl=4.57, wps=27382.5, ups=1.86, wpb=14743.3, bsz=508.3, num_updates=25500, lr=0.00019803, gnorm=0.644, train_wall=54, wall=14094
2020-12-19 22:03:59 | INFO | train_inner | epoch 011:   1120 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.025, loss=5.021, nll_loss=2.181, ppl=4.54, wps=27315.8, ups=1.85, wpb=14784.1, bsz=508.4, num_updates=25600, lr=0.000197642, gnorm=0.614, train_wall=54, wall=14148
2020-12-19 22:04:53 | INFO | train_inner | epoch 011:   1220 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.99, loss=5.015, nll_loss=2.18, ppl=4.53, wps=27554.9, ups=1.86, wpb=14839.9, bsz=513.8, num_updates=25700, lr=0.000197257, gnorm=0.642, train_wall=54, wall=14202
2020-12-19 22:05:47 | INFO | train_inner | epoch 011:   1320 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.995, loss=5.006, nll_loss=2.17, ppl=4.5, wps=27557.6, ups=1.85, wpb=14860.2, bsz=513.6, num_updates=25800, lr=0.000196875, gnorm=0.619, train_wall=54, wall=14256
2020-12-19 22:06:41 | INFO | train_inner | epoch 011:   1420 / 2448 symm_kl=0.567, self_kl=0, self_cv=8.997, loss=5.04, nll_loss=2.208, ppl=4.62, wps=27542.1, ups=1.86, wpb=14814.8, bsz=497, num_updates=25900, lr=0.000196494, gnorm=0.64, train_wall=54, wall=14310
2020-12-19 22:07:35 | INFO | train_inner | epoch 011:   1520 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.007, loss=5.026, nll_loss=2.191, ppl=4.57, wps=27525.6, ups=1.85, wpb=14914.4, bsz=512.8, num_updates=26000, lr=0.000196116, gnorm=0.619, train_wall=54, wall=14364
2020-12-19 22:08:29 | INFO | train_inner | epoch 011:   1620 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.98, loss=5.019, nll_loss=2.187, ppl=4.55, wps=27503.4, ups=1.85, wpb=14872.7, bsz=514.5, num_updates=26100, lr=0.00019574, gnorm=0.635, train_wall=54, wall=14418
2020-12-19 22:09:23 | INFO | train_inner | epoch 011:   1720 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.962, loss=5.023, nll_loss=2.194, ppl=4.58, wps=27453.3, ups=1.86, wpb=14788.5, bsz=521.6, num_updates=26200, lr=0.000195366, gnorm=0.625, train_wall=54, wall=14472
2020-12-19 22:10:17 | INFO | train_inner | epoch 011:   1820 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.004, loss=5.046, nll_loss=2.214, ppl=4.64, wps=27367.3, ups=1.85, wpb=14768.2, bsz=502.2, num_updates=26300, lr=0.000194994, gnorm=0.643, train_wall=54, wall=14526
2020-12-19 22:11:11 | INFO | train_inner | epoch 011:   1920 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.942, loss=5.018, nll_loss=2.192, ppl=4.57, wps=27557.2, ups=1.86, wpb=14842.6, bsz=536.2, num_updates=26400, lr=0.000194625, gnorm=0.657, train_wall=54, wall=14580
2020-12-19 22:12:04 | INFO | train_inner | epoch 011:   2020 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.939, loss=5.01, nll_loss=2.183, ppl=4.54, wps=27445.5, ups=1.86, wpb=14793.6, bsz=530.1, num_updates=26500, lr=0.000194257, gnorm=0.631, train_wall=54, wall=14634
2020-12-19 22:12:59 | INFO | train_inner | epoch 011:   2120 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.956, loss=5.017, nll_loss=2.19, ppl=4.56, wps=27532.9, ups=1.85, wpb=14920, bsz=514.1, num_updates=26600, lr=0.000193892, gnorm=0.609, train_wall=54, wall=14688
2020-12-19 22:13:52 | INFO | train_inner | epoch 011:   2220 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.963, loss=5.047, nll_loss=2.222, ppl=4.66, wps=27475.2, ups=1.86, wpb=14778.8, bsz=532.9, num_updates=26700, lr=0.000193528, gnorm=0.646, train_wall=54, wall=14742
2020-12-19 22:14:46 | INFO | train_inner | epoch 011:   2320 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.959, loss=5.039, nll_loss=2.213, ppl=4.64, wps=27333.3, ups=1.85, wpb=14741.1, bsz=504.7, num_updates=26800, lr=0.000193167, gnorm=0.639, train_wall=54, wall=14796
2020-12-19 22:15:40 | INFO | train_inner | epoch 011:   2420 / 2448 symm_kl=0.552, self_kl=0, self_cv=8.952, loss=5.022, nll_loss=2.195, ppl=4.58, wps=27524.7, ups=1.86, wpb=14834.9, bsz=515.4, num_updates=26900, lr=0.000192807, gnorm=0.626, train_wall=54, wall=14849
2020-12-19 22:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 22:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:16:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 22:16:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 22:16:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 22:16:09 | INFO | valid | epoch 011 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.942 | nll_loss 7.957 | ppl 248.49 | bleu 15.85 | wps 5658.6 | wpb 7930.2 | bsz 208 | num_updates 26928 | best_bleu 15.86
2020-12-19 22:16:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 22:16:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 11 @ 26928 updates, score 15.85) (writing took 4.7554371021687984 seconds)
2020-12-19 22:16:14 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-12-19 22:16:14 | INFO | train | epoch 011 | symm_kl 0.562 | self_kl 0 | self_cv 8.998 | loss 5.017 | nll_loss 2.181 | ppl 4.54 | wps 26916 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 26928 | lr 0.000192707 | gnorm 0.629 | train_wall 1315 | wall 14883
2020-12-19 22:16:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:16:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:16:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:16:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:16:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:16:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:16:17 | INFO | fairseq.trainer | begin training epoch 12
2020-12-19 22:16:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:16:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:16:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:16:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:17:02 | INFO | train_inner | epoch 012:     72 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.04, loss=4.988, nll_loss=2.143, ppl=4.42, wps=17934, ups=1.23, wpb=14617.8, bsz=517.2, num_updates=27000, lr=0.00019245, gnorm=0.639, train_wall=53, wall=14931
2020-12-19 22:17:55 | INFO | train_inner | epoch 012:    172 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.05, loss=4.992, nll_loss=2.145, ppl=4.42, wps=27538.9, ups=1.86, wpb=14770.1, bsz=522.2, num_updates=27100, lr=0.000192095, gnorm=0.624, train_wall=53, wall=14985
2020-12-19 22:18:49 | INFO | train_inner | epoch 012:    272 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.052, loss=4.984, nll_loss=2.136, ppl=4.4, wps=27580, ups=1.85, wpb=14898, bsz=525.9, num_updates=27200, lr=0.000191741, gnorm=0.622, train_wall=54, wall=15039
2020-12-19 22:19:43 | INFO | train_inner | epoch 012:    372 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.051, loss=4.974, nll_loss=2.125, ppl=4.36, wps=27684.8, ups=1.86, wpb=14911, bsz=505.4, num_updates=27300, lr=0.00019139, gnorm=0.62, train_wall=54, wall=15092
2020-12-19 22:20:37 | INFO | train_inner | epoch 012:    472 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.042, loss=4.978, nll_loss=2.131, ppl=4.38, wps=27548.2, ups=1.85, wpb=14901.2, bsz=509.2, num_updates=27400, lr=0.00019104, gnorm=0.614, train_wall=54, wall=15147
2020-12-19 22:21:32 | INFO | train_inner | epoch 012:    572 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.013, loss=4.983, nll_loss=2.141, ppl=4.41, wps=27433.2, ups=1.85, wpb=14858.7, bsz=543.3, num_updates=27500, lr=0.000190693, gnorm=0.634, train_wall=54, wall=15201
2020-12-19 22:22:26 | INFO | train_inner | epoch 012:    672 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.031, loss=4.989, nll_loss=2.146, ppl=4.42, wps=27429.8, ups=1.85, wpb=14844.6, bsz=520.6, num_updates=27600, lr=0.000190347, gnorm=0.631, train_wall=54, wall=15255
2020-12-19 22:23:20 | INFO | train_inner | epoch 012:    772 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.039, loss=5.012, nll_loss=2.17, ppl=4.5, wps=27378.5, ups=1.85, wpb=14810.8, bsz=517, num_updates=27700, lr=0.000190003, gnorm=0.634, train_wall=54, wall=15309
2020-12-19 22:24:14 | INFO | train_inner | epoch 012:    872 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.01, loss=5.013, nll_loss=2.176, ppl=4.52, wps=27291.8, ups=1.85, wpb=14741.1, bsz=488.6, num_updates=27800, lr=0.000189661, gnorm=0.639, train_wall=54, wall=15363
2020-12-19 22:25:08 | INFO | train_inner | epoch 012:    972 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.003, loss=4.997, nll_loss=2.159, ppl=4.47, wps=27529.3, ups=1.85, wpb=14904.6, bsz=514.2, num_updates=27900, lr=0.000189321, gnorm=0.61, train_wall=54, wall=15417
2020-12-19 22:26:02 | INFO | train_inner | epoch 012:   1072 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.985, loss=4.986, nll_loss=2.149, ppl=4.44, wps=27343.5, ups=1.85, wpb=14765.6, bsz=546.1, num_updates=28000, lr=0.000188982, gnorm=0.652, train_wall=54, wall=15471
2020-12-19 22:26:56 | INFO | train_inner | epoch 012:   1172 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.978, loss=5.008, nll_loss=2.175, ppl=4.52, wps=27232.5, ups=1.85, wpb=14728.1, bsz=520.4, num_updates=28100, lr=0.000188646, gnorm=0.635, train_wall=54, wall=15525
2020-12-19 22:27:50 | INFO | train_inner | epoch 012:   1272 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.015, loss=5.004, nll_loss=2.165, ppl=4.48, wps=27479.6, ups=1.85, wpb=14845, bsz=507.4, num_updates=28200, lr=0.000188311, gnorm=0.618, train_wall=54, wall=15579
2020-12-19 22:28:44 | INFO | train_inner | epoch 012:   1372 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.017, loss=5.025, nll_loss=2.188, ppl=4.56, wps=27485.2, ups=1.85, wpb=14868.1, bsz=509.9, num_updates=28300, lr=0.000187978, gnorm=0.632, train_wall=54, wall=15633
2020-12-19 22:29:38 | INFO | train_inner | epoch 012:   1472 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.989, loss=5.014, nll_loss=2.18, ppl=4.53, wps=27323.8, ups=1.85, wpb=14768, bsz=505.1, num_updates=28400, lr=0.000187647, gnorm=0.629, train_wall=54, wall=15687
2020-12-19 22:30:32 | INFO | train_inner | epoch 012:   1572 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.995, loss=5.014, nll_loss=2.18, ppl=4.53, wps=27430.1, ups=1.85, wpb=14807.3, bsz=489.3, num_updates=28500, lr=0.000187317, gnorm=0.647, train_wall=54, wall=15741
2020-12-19 22:31:26 | INFO | train_inner | epoch 012:   1672 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.964, loss=5.005, nll_loss=2.175, ppl=4.51, wps=27411.2, ups=1.84, wpb=14876.9, bsz=530.6, num_updates=28600, lr=0.000186989, gnorm=0.631, train_wall=54, wall=15796
2020-12-19 22:32:20 | INFO | train_inner | epoch 012:   1772 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.017, loss=5.017, nll_loss=2.18, ppl=4.53, wps=27347.7, ups=1.85, wpb=14773.9, bsz=508.4, num_updates=28700, lr=0.000186663, gnorm=0.64, train_wall=54, wall=15850
2020-12-19 22:33:15 | INFO | train_inner | epoch 012:   1872 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.021, loss=5.016, nll_loss=2.179, ppl=4.53, wps=27570, ups=1.85, wpb=14921.6, bsz=490.6, num_updates=28800, lr=0.000186339, gnorm=0.638, train_wall=54, wall=15904
2020-12-19 22:34:09 | INFO | train_inner | epoch 012:   1972 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.932, loss=5.009, nll_loss=2.184, ppl=4.54, wps=27371.3, ups=1.85, wpb=14793.3, bsz=505.5, num_updates=28900, lr=0.000186016, gnorm=0.653, train_wall=54, wall=15958
2020-12-19 22:35:03 | INFO | train_inner | epoch 012:   2072 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.944, loss=4.997, nll_loss=2.169, ppl=4.5, wps=27404.7, ups=1.85, wpb=14818.7, bsz=530.6, num_updates=29000, lr=0.000185695, gnorm=0.632, train_wall=54, wall=16012
2020-12-19 22:35:57 | INFO | train_inner | epoch 012:   2172 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.984, loss=5.041, nll_loss=2.212, ppl=4.63, wps=27406, ups=1.86, wpb=14766.2, bsz=473, num_updates=29100, lr=0.000185376, gnorm=0.646, train_wall=54, wall=16066
2020-12-19 22:36:51 | INFO | train_inner | epoch 012:   2272 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.964, loss=5.026, nll_loss=2.198, ppl=4.59, wps=27321.9, ups=1.85, wpb=14760.1, bsz=527, num_updates=29200, lr=0.000185058, gnorm=0.673, train_wall=54, wall=16120
2020-12-19 22:37:44 | INFO | train_inner | epoch 012:   2372 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.99, loss=5.029, nll_loss=2.198, ppl=4.59, wps=27285.4, ups=1.86, wpb=14698.9, bsz=488.9, num_updates=29300, lr=0.000184742, gnorm=0.635, train_wall=54, wall=16174
2020-12-19 22:38:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 22:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 22:38:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 22:38:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 22:38:40 | INFO | valid | epoch 012 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.025 | nll_loss 8.046 | ppl 264.32 | bleu 15.76 | wps 5451.5 | wpb 7930.2 | bsz 208 | num_updates 29376 | best_bleu 15.86
2020-12-19 22:38:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 22:38:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 12 @ 29376 updates, score 15.76) (writing took 4.83415799587965 seconds)
2020-12-19 22:38:45 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-12-19 22:38:45 | INFO | train | epoch 012 | symm_kl 0.562 | self_kl 0 | self_cv 9.005 | loss 5.005 | nll_loss 2.168 | ppl 4.49 | wps 26842.4 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 29376 | lr 0.000184503 | gnorm 0.634 | train_wall 1318 | wall 16234
2020-12-19 22:38:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:48 | INFO | fairseq.trainer | begin training epoch 13
2020-12-19 22:38:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:38:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 22:38:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 22:39:07 | INFO | train_inner | epoch 013:     24 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.006, loss=5.017, nll_loss=2.182, ppl=4.54, wps=17941.2, ups=1.22, wpb=14746.3, bsz=523.3, num_updates=29400, lr=0.000184428, gnorm=0.633, train_wall=54, wall=16256
2020-12-19 22:40:00 | INFO | train_inner | epoch 013:    124 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.055, loss=4.946, nll_loss=2.093, ppl=4.27, wps=27750.9, ups=1.86, wpb=14894.4, bsz=519.3, num_updates=29500, lr=0.000184115, gnorm=0.627, train_wall=53, wall=16309
2020-12-19 22:40:54 | INFO | train_inner | epoch 013:    224 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.045, loss=4.969, nll_loss=2.121, ppl=4.35, wps=27433.7, ups=1.85, wpb=14805.6, bsz=515.8, num_updates=29600, lr=0.000183804, gnorm=0.632, train_wall=54, wall=16363
2020-12-19 22:41:48 | INFO | train_inner | epoch 013:    324 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.007, loss=4.965, nll_loss=2.122, ppl=4.35, wps=27319.7, ups=1.86, wpb=14720.5, bsz=524.7, num_updates=29700, lr=0.000183494, gnorm=0.619, train_wall=54, wall=16417
2020-12-19 22:42:42 | INFO | train_inner | epoch 013:    424 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.047, loss=4.975, nll_loss=2.127, ppl=4.37, wps=27421.2, ups=1.86, wpb=14765.3, bsz=513.1, num_updates=29800, lr=0.000183186, gnorm=0.631, train_wall=54, wall=16471
2020-12-19 22:43:36 | INFO | train_inner | epoch 013:    524 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.079, loss=4.995, nll_loss=2.145, ppl=4.42, wps=27366.5, ups=1.85, wpb=14769.8, bsz=483.5, num_updates=29900, lr=0.000182879, gnorm=0.631, train_wall=54, wall=16525
2020-12-19 22:44:31 | INFO | train_inner | epoch 013:    624 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.038, loss=4.983, nll_loss=2.138, ppl=4.4, wps=27455.9, ups=1.83, wpb=14981.1, bsz=533.1, num_updates=30000, lr=0.000182574, gnorm=0.644, train_wall=54, wall=16580
2020-12-19 22:45:24 | INFO | train_inner | epoch 013:    724 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.984, loss=4.973, nll_loss=2.135, ppl=4.39, wps=27556.5, ups=1.85, wpb=14857.8, bsz=524.5, num_updates=30100, lr=0.000182271, gnorm=0.633, train_wall=54, wall=16634
2020-12-19 22:46:19 | INFO | train_inner | epoch 013:    824 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.008, loss=5.005, nll_loss=2.167, ppl=4.49, wps=27061.7, ups=1.85, wpb=14643, bsz=521.5, num_updates=30200, lr=0.000181969, gnorm=0.633, train_wall=54, wall=16688
2020-12-19 22:47:13 | INFO | train_inner | epoch 013:    924 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.023, loss=5.002, nll_loss=2.162, ppl=4.47, wps=27485.6, ups=1.85, wpb=14834.2, bsz=524.8, num_updates=30300, lr=0.000181668, gnorm=0.629, train_wall=54, wall=16742
2020-12-19 22:48:06 | INFO | train_inner | epoch 013:   1024 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.041, loss=4.993, nll_loss=2.148, ppl=4.43, wps=27550, ups=1.86, wpb=14835.5, bsz=520.2, num_updates=30400, lr=0.000181369, gnorm=0.627, train_wall=54, wall=16796
2020-12-19 22:49:00 | INFO | train_inner | epoch 013:   1124 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.016, loss=5.001, nll_loss=2.162, ppl=4.48, wps=27438.3, ups=1.86, wpb=14756.5, bsz=479.8, num_updates=30500, lr=0.000181071, gnorm=0.662, train_wall=54, wall=16849
2020-12-19 22:49:54 | INFO | train_inner | epoch 013:   1224 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.046, loss=5.014, nll_loss=2.171, ppl=4.5, wps=27453.5, ups=1.85, wpb=14842.9, bsz=489.2, num_updates=30600, lr=0.000180775, gnorm=0.643, train_wall=54, wall=16903
2020-12-19 22:50:48 | INFO | train_inner | epoch 013:   1324 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.985, loss=4.991, nll_loss=2.155, ppl=4.45, wps=27442.2, ups=1.85, wpb=14805.7, bsz=518.9, num_updates=30700, lr=0.000180481, gnorm=0.63, train_wall=54, wall=16957
2020-12-19 22:51:42 | INFO | train_inner | epoch 013:   1424 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.03, loss=5.018, nll_loss=2.179, ppl=4.53, wps=27439.4, ups=1.86, wpb=14791.6, bsz=500.5, num_updates=30800, lr=0.000180187, gnorm=0.677, train_wall=54, wall=17011
2020-12-19 22:52:36 | INFO | train_inner | epoch 013:   1524 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.995, loss=5, nll_loss=2.164, ppl=4.48, wps=27637.4, ups=1.87, wpb=14806, bsz=512.5, num_updates=30900, lr=0.000179896, gnorm=0.664, train_wall=53, wall=17065
2020-12-19 22:53:29 | INFO | train_inner | epoch 013:   1624 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.028, loss=5.013, nll_loss=2.173, ppl=4.51, wps=27834.9, ups=1.87, wpb=14909.3, bsz=481.7, num_updates=31000, lr=0.000179605, gnorm=0.628, train_wall=53, wall=17118
2020-12-19 22:54:23 | INFO | train_inner | epoch 013:   1724 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.953, loss=4.995, nll_loss=2.166, ppl=4.49, wps=27267.9, ups=1.85, wpb=14720.9, bsz=518.8, num_updates=31100, lr=0.000179316, gnorm=0.656, train_wall=54, wall=17172
2020-12-19 22:55:17 | INFO | train_inner | epoch 013:   1824 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.99, loss=4.982, nll_loss=2.145, ppl=4.42, wps=27638.7, ups=1.86, wpb=14894.6, bsz=533.3, num_updates=31200, lr=0.000179029, gnorm=0.631, train_wall=54, wall=17226
2020-12-19 22:56:11 | INFO | train_inner | epoch 013:   1924 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.992, loss=5.016, nll_loss=2.183, ppl=4.54, wps=27535.2, ups=1.86, wpb=14831.3, bsz=503.1, num_updates=31300, lr=0.000178743, gnorm=0.647, train_wall=54, wall=17280
2020-12-19 22:57:05 | INFO | train_inner | epoch 013:   2024 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.988, loss=5.001, nll_loss=2.168, ppl=4.49, wps=27657.1, ups=1.86, wpb=14883.8, bsz=500.4, num_updates=31400, lr=0.000178458, gnorm=0.627, train_wall=54, wall=17334
2020-12-19 22:57:59 | INFO | train_inner | epoch 013:   2124 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.987, loss=5.032, nll_loss=2.202, ppl=4.6, wps=27501.5, ups=1.86, wpb=14779.9, bsz=488.4, num_updates=31500, lr=0.000178174, gnorm=0.65, train_wall=54, wall=17388
2020-12-19 22:58:53 | INFO | train_inner | epoch 013:   2224 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.98, loss=5.015, nll_loss=2.184, ppl=4.54, wps=27384.2, ups=1.85, wpb=14771.4, bsz=528.2, num_updates=31600, lr=0.000177892, gnorm=0.635, train_wall=54, wall=17442
2020-12-19 22:59:47 | INFO | train_inner | epoch 013:   2324 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.963, loss=5.006, nll_loss=2.177, ppl=4.52, wps=27395, ups=1.85, wpb=14802.3, bsz=517, num_updates=31700, lr=0.000177611, gnorm=0.655, train_wall=54, wall=17496
2020-12-19 23:00:40 | INFO | train_inner | epoch 013:   2424 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.953, loss=5.004, nll_loss=2.176, ppl=4.52, wps=27569.9, ups=1.86, wpb=14805.8, bsz=523.8, num_updates=31800, lr=0.000177332, gnorm=0.627, train_wall=54, wall=17549
2020-12-19 23:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 23:00:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:00:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:00:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:00:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:00:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:01:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 23:01:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 23:01:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 23:01:06 | INFO | valid | epoch 013 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.986 | nll_loss 8.008 | ppl 257.48 | bleu 16.16 | wps 6196.4 | wpb 7930.2 | bsz 208 | num_updates 31824 | best_bleu 16.16
2020-12-19 23:01:06 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 23:01:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:01:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:01:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:01:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:01:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:01:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:01:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:01:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:01:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 13 @ 31824 updates, score 16.16) (writing took 8.1361322440207 seconds)
2020-12-19 23:01:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-12-19 23:01:14 | INFO | train | epoch 013 | symm_kl 0.561 | self_kl 0 | self_cv 9.009 | loss 4.995 | nll_loss 2.156 | ppl 4.46 | wps 26865 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 31824 | lr 0.000177265 | gnorm 0.639 | train_wall 1315 | wall 17584
2020-12-19 23:01:17 | INFO | fairseq.trainer | begin training epoch 14
2020-12-19 23:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:02:04 | INFO | train_inner | epoch 014:     76 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.028, loss=4.965, nll_loss=2.12, ppl=4.35, wps=17583.3, ups=1.2, wpb=14638.5, bsz=511.5, num_updates=31900, lr=0.000177054, gnorm=0.656, train_wall=53, wall=17633
2020-12-19 23:02:57 | INFO | train_inner | epoch 014:    176 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.075, loss=4.966, nll_loss=2.113, ppl=4.33, wps=27450.6, ups=1.86, wpb=14747.5, bsz=498.8, num_updates=32000, lr=0.000176777, gnorm=0.658, train_wall=54, wall=17686
2020-12-19 23:03:51 | INFO | train_inner | epoch 014:    276 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.061, loss=4.965, nll_loss=2.114, ppl=4.33, wps=27533.8, ups=1.87, wpb=14762.8, bsz=500.6, num_updates=32100, lr=0.000176501, gnorm=0.632, train_wall=53, wall=17740
2020-12-19 23:04:45 | INFO | train_inner | epoch 014:    376 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.088, loss=4.965, nll_loss=2.11, ppl=4.32, wps=27507.7, ups=1.85, wpb=14889.3, bsz=492.3, num_updates=32200, lr=0.000176227, gnorm=0.624, train_wall=54, wall=17794
2020-12-19 23:05:39 | INFO | train_inner | epoch 014:    476 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.067, loss=4.966, nll_loss=2.115, ppl=4.33, wps=27402.2, ups=1.85, wpb=14843.9, bsz=521.4, num_updates=32300, lr=0.000175954, gnorm=0.662, train_wall=54, wall=17848
2020-12-19 23:06:33 | INFO | train_inner | epoch 014:    576 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.023, loss=4.961, nll_loss=2.116, ppl=4.33, wps=27569.6, ups=1.86, wpb=14858.9, bsz=561.8, num_updates=32400, lr=0.000175682, gnorm=0.638, train_wall=54, wall=17902
2020-12-19 23:07:27 | INFO | train_inner | epoch 014:    676 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.054, loss=4.996, nll_loss=2.151, ppl=4.44, wps=27613.1, ups=1.85, wpb=14949.4, bsz=494.9, num_updates=32500, lr=0.000175412, gnorm=0.637, train_wall=54, wall=17956
2020-12-19 23:08:21 | INFO | train_inner | epoch 014:    776 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.039, loss=4.977, nll_loss=2.132, ppl=4.38, wps=27382.2, ups=1.85, wpb=14831.2, bsz=494.4, num_updates=32600, lr=0.000175142, gnorm=0.645, train_wall=54, wall=18010
2020-12-19 23:09:15 | INFO | train_inner | epoch 014:    876 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.026, loss=4.965, nll_loss=2.12, ppl=4.35, wps=27550.4, ups=1.85, wpb=14887, bsz=517.4, num_updates=32700, lr=0.000174874, gnorm=0.642, train_wall=54, wall=18064
2020-12-19 23:10:09 | INFO | train_inner | epoch 014:    976 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.021, loss=4.995, nll_loss=2.154, ppl=4.45, wps=27430, ups=1.85, wpb=14794.3, bsz=481.7, num_updates=32800, lr=0.000174608, gnorm=0.654, train_wall=54, wall=18118
2020-12-19 23:11:03 | INFO | train_inner | epoch 014:   1076 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.993, loss=4.98, nll_loss=2.142, ppl=4.41, wps=27307.1, ups=1.85, wpb=14792.8, bsz=535.3, num_updates=32900, lr=0.000174342, gnorm=0.639, train_wall=54, wall=18173
2020-12-19 23:11:57 | INFO | train_inner | epoch 014:   1176 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.99, loss=4.983, nll_loss=2.146, ppl=4.43, wps=27374.1, ups=1.85, wpb=14758.6, bsz=532.3, num_updates=33000, lr=0.000174078, gnorm=0.665, train_wall=54, wall=18227
2020-12-19 23:12:51 | INFO | train_inner | epoch 014:   1276 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.025, loss=4.994, nll_loss=2.153, ppl=4.45, wps=27250.1, ups=1.85, wpb=14731.6, bsz=503.4, num_updates=33100, lr=0.000173814, gnorm=0.646, train_wall=54, wall=18281
2020-12-19 23:13:45 | INFO | train_inner | epoch 014:   1376 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.999, loss=5.001, nll_loss=2.164, ppl=4.48, wps=27505.4, ups=1.86, wpb=14814.4, bsz=503.7, num_updates=33200, lr=0.000173553, gnorm=0.636, train_wall=54, wall=18334
2020-12-19 23:14:39 | INFO | train_inner | epoch 014:   1476 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.961, loss=5.003, nll_loss=2.173, ppl=4.51, wps=27333.8, ups=1.86, wpb=14694.6, bsz=532.2, num_updates=33300, lr=0.000173292, gnorm=0.658, train_wall=54, wall=18388
2020-12-19 23:15:33 | INFO | train_inner | epoch 014:   1576 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.98, loss=4.975, nll_loss=2.138, ppl=4.4, wps=27722.8, ups=1.86, wpb=14943, bsz=507.2, num_updates=33400, lr=0.000173032, gnorm=0.63, train_wall=54, wall=18442
2020-12-19 23:16:27 | INFO | train_inner | epoch 014:   1676 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.987, loss=5.004, nll_loss=2.171, ppl=4.5, wps=27208.7, ups=1.86, wpb=14646.3, bsz=514.1, num_updates=33500, lr=0.000172774, gnorm=0.659, train_wall=54, wall=18496
2020-12-19 23:17:21 | INFO | train_inner | epoch 014:   1776 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.994, loss=5.003, nll_loss=2.169, ppl=4.5, wps=27664.5, ups=1.85, wpb=14939.1, bsz=520.4, num_updates=33600, lr=0.000172516, gnorm=0.642, train_wall=54, wall=18550
2020-12-19 23:18:15 | INFO | train_inner | epoch 014:   1876 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.968, loss=4.989, nll_loss=2.156, ppl=4.46, wps=27444.3, ups=1.85, wpb=14821.8, bsz=514.6, num_updates=33700, lr=0.00017226, gnorm=0.649, train_wall=54, wall=18604
2020-12-19 23:19:09 | INFO | train_inner | epoch 014:   1976 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.986, loss=5.002, nll_loss=2.169, ppl=4.5, wps=27551.1, ups=1.86, wpb=14834.5, bsz=505.4, num_updates=33800, lr=0.000172005, gnorm=0.657, train_wall=54, wall=18658
2020-12-19 23:20:02 | INFO | train_inner | epoch 014:   2076 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.018, loss=5.003, nll_loss=2.164, ppl=4.48, wps=27663.1, ups=1.86, wpb=14881.1, bsz=472.9, num_updates=33900, lr=0.000171751, gnorm=0.663, train_wall=54, wall=18712
2020-12-19 23:20:56 | INFO | train_inner | epoch 014:   2176 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.971, loss=4.981, nll_loss=2.148, ppl=4.43, wps=27591.5, ups=1.86, wpb=14851.3, bsz=508.6, num_updates=34000, lr=0.000171499, gnorm=0.628, train_wall=54, wall=18765
2020-12-19 23:21:50 | INFO | train_inner | epoch 014:   2276 / 2448 symm_kl=0.551, self_kl=0, self_cv=8.944, loss=4.987, nll_loss=2.158, ppl=4.46, wps=27509.1, ups=1.86, wpb=14810.3, bsz=531.9, num_updates=34100, lr=0.000171247, gnorm=0.65, train_wall=54, wall=18819
2020-12-19 23:22:44 | INFO | train_inner | epoch 014:   2376 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.968, loss=5, nll_loss=2.17, ppl=4.5, wps=27402.9, ups=1.86, wpb=14724.2, bsz=530.4, num_updates=34200, lr=0.000170996, gnorm=0.664, train_wall=54, wall=18873
2020-12-19 23:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 23:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 23:23:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 23:23:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 23:23:36 | INFO | valid | epoch 014 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.033 | nll_loss 8.061 | ppl 267.08 | bleu 15.62 | wps 5946.8 | wpb 7930.2 | bsz 208 | num_updates 34272 | best_bleu 16.16
2020-12-19 23:23:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 23:23:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 14 @ 34272 updates, score 15.62) (writing took 4.784362211823463 seconds)
2020-12-19 23:23:41 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-12-19 23:23:41 | INFO | train | epoch 014 | symm_kl 0.561 | self_kl 0 | self_cv 9.011 | loss 4.985 | nll_loss 2.145 | ppl 4.42 | wps 26922.6 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 34272 | lr 0.000170817 | gnorm 0.648 | train_wall 1316 | wall 18930
2020-12-19 23:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:44 | INFO | fairseq.trainer | begin training epoch 15
2020-12-19 23:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:23:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:23:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:24:05 | INFO | train_inner | epoch 015:     28 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.015, loss=4.99, nll_loss=2.15, ppl=4.44, wps=18200.8, ups=1.24, wpb=14695.8, bsz=496.4, num_updates=34300, lr=0.000170747, gnorm=0.669, train_wall=54, wall=18954
2020-12-19 23:24:58 | INFO | train_inner | epoch 015:    128 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.054, loss=4.938, nll_loss=2.086, ppl=4.25, wps=27787.5, ups=1.87, wpb=14886.2, bsz=541.8, num_updates=34400, lr=0.000170499, gnorm=0.623, train_wall=53, wall=19007
2020-12-19 23:25:52 | INFO | train_inner | epoch 015:    228 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.075, loss=4.956, nll_loss=2.102, ppl=4.29, wps=27505.9, ups=1.86, wpb=14794.8, bsz=506.4, num_updates=34500, lr=0.000170251, gnorm=0.642, train_wall=54, wall=19061
2020-12-19 23:26:46 | INFO | train_inner | epoch 015:    328 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.069, loss=4.966, nll_loss=2.114, ppl=4.33, wps=27496.7, ups=1.85, wpb=14825.6, bsz=496.6, num_updates=34600, lr=0.000170005, gnorm=0.646, train_wall=54, wall=19115
2020-12-19 23:27:40 | INFO | train_inner | epoch 015:    428 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.078, loss=4.967, nll_loss=2.114, ppl=4.33, wps=27651.2, ups=1.85, wpb=14944.2, bsz=509.2, num_updates=34700, lr=0.00016976, gnorm=0.636, train_wall=54, wall=19169
2020-12-19 23:28:34 | INFO | train_inner | epoch 015:    528 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.012, loss=4.955, nll_loss=2.111, ppl=4.32, wps=27478.5, ups=1.85, wpb=14846.7, bsz=516.1, num_updates=34800, lr=0.000169516, gnorm=0.632, train_wall=54, wall=19223
2020-12-19 23:29:28 | INFO | train_inner | epoch 015:    628 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.035, loss=4.978, nll_loss=2.133, ppl=4.39, wps=27161.6, ups=1.85, wpb=14653.5, bsz=511.3, num_updates=34900, lr=0.000169273, gnorm=0.661, train_wall=54, wall=19277
2020-12-19 23:30:22 | INFO | train_inner | epoch 015:    728 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.058, loss=4.971, nll_loss=2.122, ppl=4.35, wps=27320.5, ups=1.85, wpb=14776.1, bsz=513, num_updates=35000, lr=0.000169031, gnorm=0.646, train_wall=54, wall=19331
2020-12-19 23:31:16 | INFO | train_inner | epoch 015:    828 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.015, loss=4.969, nll_loss=2.126, ppl=4.37, wps=27585.5, ups=1.86, wpb=14815.5, bsz=508.6, num_updates=35100, lr=0.00016879, gnorm=0.657, train_wall=54, wall=19385
2020-12-19 23:32:10 | INFO | train_inner | epoch 015:    928 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.047, loss=4.965, nll_loss=2.117, ppl=4.34, wps=27664.7, ups=1.85, wpb=14918.5, bsz=494.8, num_updates=35200, lr=0.00016855, gnorm=0.644, train_wall=54, wall=19439
2020-12-19 23:33:03 | INFO | train_inner | epoch 015:   1028 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.974, loss=4.982, nll_loss=2.148, ppl=4.43, wps=27435.6, ups=1.86, wpb=14732.4, bsz=512.6, num_updates=35300, lr=0.000168311, gnorm=0.677, train_wall=54, wall=19492
2020-12-19 23:33:57 | INFO | train_inner | epoch 015:   1128 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.037, loss=4.965, nll_loss=2.119, ppl=4.34, wps=27668.4, ups=1.85, wpb=14917.8, bsz=521.5, num_updates=35400, lr=0.000168073, gnorm=0.638, train_wall=54, wall=19546
2020-12-19 23:34:51 | INFO | train_inner | epoch 015:   1228 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.97, loss=4.96, nll_loss=2.123, ppl=4.36, wps=27547, ups=1.86, wpb=14788.9, bsz=527, num_updates=35500, lr=0.000167836, gnorm=0.647, train_wall=54, wall=19600
2020-12-19 23:35:45 | INFO | train_inner | epoch 015:   1328 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.995, loss=4.979, nll_loss=2.141, ppl=4.41, wps=27603.5, ups=1.86, wpb=14860.8, bsz=505.3, num_updates=35600, lr=0.0001676, gnorm=0.648, train_wall=54, wall=19654
2020-12-19 23:36:39 | INFO | train_inner | epoch 015:   1428 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.009, loss=4.996, nll_loss=2.159, ppl=4.46, wps=27220.7, ups=1.86, wpb=14642.5, bsz=495.8, num_updates=35700, lr=0.000167365, gnorm=0.651, train_wall=54, wall=19708
2020-12-19 23:37:33 | INFO | train_inner | epoch 015:   1528 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.009, loss=4.994, nll_loss=2.156, ppl=4.46, wps=27410.8, ups=1.85, wpb=14846.5, bsz=485, num_updates=35800, lr=0.000167132, gnorm=0.655, train_wall=54, wall=19762
2020-12-19 23:38:27 | INFO | train_inner | epoch 015:   1628 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.995, loss=4.986, nll_loss=2.15, ppl=4.44, wps=27423.3, ups=1.85, wpb=14822.4, bsz=494.3, num_updates=35900, lr=0.000166899, gnorm=0.636, train_wall=54, wall=19816
2020-12-19 23:39:21 | INFO | train_inner | epoch 015:   1728 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.001, loss=4.979, nll_loss=2.14, ppl=4.41, wps=27631.3, ups=1.86, wpb=14873.4, bsz=522.9, num_updates=36000, lr=0.000166667, gnorm=0.638, train_wall=54, wall=19870
2020-12-19 23:40:14 | INFO | train_inner | epoch 015:   1828 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.96, loss=4.981, nll_loss=2.149, ppl=4.44, wps=27606.6, ups=1.86, wpb=14839.8, bsz=528.5, num_updates=36100, lr=0.000166436, gnorm=0.654, train_wall=54, wall=19923
2020-12-19 23:41:08 | INFO | train_inner | epoch 015:   1928 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.999, loss=4.986, nll_loss=2.149, ppl=4.44, wps=27438.6, ups=1.85, wpb=14818.9, bsz=541.6, num_updates=36200, lr=0.000166206, gnorm=0.668, train_wall=54, wall=19977
2020-12-19 23:42:02 | INFO | train_inner | epoch 015:   2028 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.98, loss=5.004, nll_loss=2.172, ppl=4.51, wps=27280.2, ups=1.86, wpb=14696.5, bsz=508, num_updates=36300, lr=0.000165977, gnorm=0.668, train_wall=54, wall=20031
2020-12-19 23:42:56 | INFO | train_inner | epoch 015:   2128 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.988, loss=4.992, nll_loss=2.157, ppl=4.46, wps=27417.9, ups=1.85, wpb=14783.4, bsz=509, num_updates=36400, lr=0.000165748, gnorm=0.654, train_wall=54, wall=20085
2020-12-19 23:43:50 | INFO | train_inner | epoch 015:   2228 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.012, loss=5.006, nll_loss=2.17, ppl=4.5, wps=27488.8, ups=1.86, wpb=14816.2, bsz=517, num_updates=36500, lr=0.000165521, gnorm=0.655, train_wall=54, wall=20139
2020-12-19 23:44:44 | INFO | train_inner | epoch 015:   2328 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.006, loss=4.998, nll_loss=2.162, ppl=4.47, wps=27453.6, ups=1.86, wpb=14780.9, bsz=500.2, num_updates=36600, lr=0.000165295, gnorm=0.648, train_wall=54, wall=20193
2020-12-19 23:45:38 | INFO | train_inner | epoch 015:   2428 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.976, loss=4.979, nll_loss=2.145, ppl=4.42, wps=27553.8, ups=1.86, wpb=14841.8, bsz=508.2, num_updates=36700, lr=0.00016507, gnorm=0.664, train_wall=54, wall=20247
2020-12-19 23:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 23:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 23:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 23:46:02 | INFO | valid | epoch 015 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.038 | nll_loss 8.071 | ppl 268.88 | bleu 15.81 | wps 6074 | wpb 7930.2 | bsz 208 | num_updates 36720 | best_bleu 16.16
2020-12-19 23:46:02 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 23:46:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 15 @ 36720 updates, score 15.81) (writing took 4.837531739845872 seconds)
2020-12-19 23:46:07 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-12-19 23:46:07 | INFO | train | epoch 015 | symm_kl 0.561 | self_kl 0 | self_cv 9.014 | loss 4.976 | nll_loss 2.135 | ppl 4.39 | wps 26944.4 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 36720 | lr 0.000165025 | gnorm 0.65 | train_wall 1315 | wall 20276
2020-12-19 23:46:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:46:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:46:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:46:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:46:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:10 | INFO | fairseq.trainer | begin training epoch 16
2020-12-19 23:46:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 23:46:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 23:46:58 | INFO | train_inner | epoch 016:     80 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.072, loss=4.95, nll_loss=2.097, ppl=4.28, wps=18302.7, ups=1.25, wpb=14698.8, bsz=527, num_updates=36800, lr=0.000164845, gnorm=0.657, train_wall=53, wall=20327
2020-12-19 23:47:52 | INFO | train_inner | epoch 016:    180 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.041, loss=4.922, nll_loss=2.07, ppl=4.2, wps=27593.8, ups=1.86, wpb=14846.7, bsz=528.6, num_updates=36900, lr=0.000164622, gnorm=0.635, train_wall=54, wall=20381
2020-12-19 23:48:46 | INFO | train_inner | epoch 016:    280 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.044, loss=4.937, nll_loss=2.087, ppl=4.25, wps=27475, ups=1.85, wpb=14844, bsz=539.5, num_updates=37000, lr=0.000164399, gnorm=0.645, train_wall=54, wall=20435
2020-12-19 23:49:40 | INFO | train_inner | epoch 016:    380 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.049, loss=4.964, nll_loss=2.116, ppl=4.33, wps=27552, ups=1.86, wpb=14830.6, bsz=493.8, num_updates=37100, lr=0.000164177, gnorm=0.658, train_wall=54, wall=20489
2020-12-19 23:50:34 | INFO | train_inner | epoch 016:    480 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.073, loss=4.956, nll_loss=2.102, ppl=4.29, wps=27566.1, ups=1.86, wpb=14823.1, bsz=518.4, num_updates=37200, lr=0.000163956, gnorm=0.647, train_wall=54, wall=20543
2020-12-19 23:51:28 | INFO | train_inner | epoch 016:    580 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.044, loss=4.935, nll_loss=2.084, ppl=4.24, wps=27625.7, ups=1.85, wpb=14917.2, bsz=523.2, num_updates=37300, lr=0.000163737, gnorm=0.647, train_wall=54, wall=20597
2020-12-19 23:52:21 | INFO | train_inner | epoch 016:    680 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.037, loss=4.964, nll_loss=2.118, ppl=4.34, wps=27574, ups=1.86, wpb=14840, bsz=494.3, num_updates=37400, lr=0.000163517, gnorm=0.658, train_wall=54, wall=20650
2020-12-19 23:53:15 | INFO | train_inner | epoch 016:    780 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.032, loss=4.97, nll_loss=2.125, ppl=4.36, wps=27535, ups=1.85, wpb=14867.2, bsz=516.4, num_updates=37500, lr=0.000163299, gnorm=0.642, train_wall=54, wall=20704
2020-12-19 23:54:09 | INFO | train_inner | epoch 016:    880 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.042, loss=4.983, nll_loss=2.139, ppl=4.4, wps=27609, ups=1.86, wpb=14816.4, bsz=494.1, num_updates=37600, lr=0.000163082, gnorm=0.657, train_wall=53, wall=20758
2020-12-19 23:55:03 | INFO | train_inner | epoch 016:    980 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.046, loss=4.969, nll_loss=2.122, ppl=4.35, wps=27430.8, ups=1.85, wpb=14814.4, bsz=506.8, num_updates=37700, lr=0.000162866, gnorm=0.653, train_wall=54, wall=20812
2020-12-19 23:55:57 | INFO | train_inner | epoch 016:   1080 / 2448 symm_kl=0.566, self_kl=0, self_cv=8.999, loss=4.992, nll_loss=2.156, ppl=4.46, wps=27366.8, ups=1.86, wpb=14702.9, bsz=519.7, num_updates=37800, lr=0.00016265, gnorm=0.67, train_wall=54, wall=20866
2020-12-19 23:56:51 | INFO | train_inner | epoch 016:   1180 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.035, loss=4.97, nll_loss=2.125, ppl=4.36, wps=27488.8, ups=1.85, wpb=14879.7, bsz=489, num_updates=37900, lr=0.000162435, gnorm=0.667, train_wall=54, wall=20920
2020-12-19 23:57:45 | INFO | train_inner | epoch 016:   1280 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.019, loss=4.981, nll_loss=2.14, ppl=4.41, wps=27484.1, ups=1.86, wpb=14815.4, bsz=504.1, num_updates=38000, lr=0.000162221, gnorm=0.644, train_wall=54, wall=20974
2020-12-19 23:58:39 | INFO | train_inner | epoch 016:   1380 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.031, loss=4.98, nll_loss=2.137, ppl=4.4, wps=27346.8, ups=1.85, wpb=14745.6, bsz=518.4, num_updates=38100, lr=0.000162008, gnorm=0.646, train_wall=54, wall=21028
2020-12-19 23:59:33 | INFO | train_inner | epoch 016:   1480 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.986, loss=4.975, nll_loss=2.138, ppl=4.4, wps=27448, ups=1.85, wpb=14822.9, bsz=511.5, num_updates=38200, lr=0.000161796, gnorm=0.653, train_wall=54, wall=21082
2020-12-20 00:00:26 | INFO | train_inner | epoch 016:   1580 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.965, loss=4.955, nll_loss=2.12, ppl=4.35, wps=27516.3, ups=1.86, wpb=14788.1, bsz=521.7, num_updates=38300, lr=0.000161585, gnorm=0.648, train_wall=54, wall=21136
2020-12-20 00:01:21 | INFO | train_inner | epoch 016:   1680 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.005, loss=4.972, nll_loss=2.132, ppl=4.38, wps=27425.6, ups=1.84, wpb=14872.5, bsz=506, num_updates=38400, lr=0.000161374, gnorm=0.651, train_wall=54, wall=21190
2020-12-20 00:02:15 | INFO | train_inner | epoch 016:   1780 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.998, loss=4.98, nll_loss=2.143, ppl=4.42, wps=27359.9, ups=1.85, wpb=14829.1, bsz=491.4, num_updates=38500, lr=0.000161165, gnorm=0.652, train_wall=54, wall=21244
2020-12-20 00:03:09 | INFO | train_inner | epoch 016:   1880 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.988, loss=4.984, nll_loss=2.149, ppl=4.44, wps=27543.6, ups=1.86, wpb=14832.8, bsz=501.7, num_updates=38600, lr=0.000160956, gnorm=0.66, train_wall=54, wall=21298
2020-12-20 00:04:02 | INFO | train_inner | epoch 016:   1980 / 2448 symm_kl=0.552, self_kl=0, self_cv=8.971, loss=4.948, nll_loss=2.11, ppl=4.32, wps=27671.1, ups=1.86, wpb=14839.2, bsz=511.4, num_updates=38700, lr=0.000160748, gnorm=0.638, train_wall=53, wall=21351
2020-12-20 00:04:56 | INFO | train_inner | epoch 016:   2080 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.997, loss=4.985, nll_loss=2.15, ppl=4.44, wps=27419.6, ups=1.86, wpb=14781.3, bsz=513.1, num_updates=38800, lr=0.00016054, gnorm=0.673, train_wall=54, wall=21405
2020-12-20 00:05:50 | INFO | train_inner | epoch 016:   2180 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.965, loss=4.983, nll_loss=2.151, ppl=4.44, wps=27363.2, ups=1.86, wpb=14711.3, bsz=528.4, num_updates=38900, lr=0.000160334, gnorm=0.671, train_wall=54, wall=21459
2020-12-20 00:06:44 | INFO | train_inner | epoch 016:   2280 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.945, loss=4.966, nll_loss=2.136, ppl=4.39, wps=27426.4, ups=1.86, wpb=14772.3, bsz=544, num_updates=39000, lr=0.000160128, gnorm=0.653, train_wall=54, wall=21513
2020-12-20 00:07:38 | INFO | train_inner | epoch 016:   2380 / 2448 symm_kl=0.558, self_kl=0, self_cv=9, loss=5.001, nll_loss=2.167, ppl=4.49, wps=27442.4, ups=1.86, wpb=14774.1, bsz=500.3, num_updates=39100, lr=0.000159923, gnorm=0.658, train_wall=54, wall=21567
2020-12-20 00:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 00:08:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 00:08:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 00:08:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 00:08:28 | INFO | valid | epoch 016 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.058 | nll_loss 8.087 | ppl 271.85 | bleu 15.72 | wps 5814.7 | wpb 7930.2 | bsz 208 | num_updates 39168 | best_bleu 16.16
2020-12-20 00:08:28 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 00:08:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 16 @ 39168 updates, score 15.72) (writing took 4.6502183228731155 seconds)
2020-12-20 00:08:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-12-20 00:08:33 | INFO | train | epoch 016 | symm_kl 0.56 | self_kl 0 | self_cv 9.015 | loss 4.968 | nll_loss 2.126 | ppl 4.37 | wps 26931.7 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 39168 | lr 0.000159784 | gnorm 0.654 | train_wall 1315 | wall 21622
2020-12-20 00:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:36 | INFO | fairseq.trainer | begin training epoch 17
2020-12-20 00:08:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:08:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:08:59 | INFO | train_inner | epoch 017:     32 / 2448 symm_kl=0.552, self_kl=0, self_cv=8.987, loss=4.95, nll_loss=2.111, ppl=4.32, wps=18180.1, ups=1.24, wpb=14715.9, bsz=518.2, num_updates=39200, lr=0.000159719, gnorm=0.667, train_wall=54, wall=21648
2020-12-20 00:09:52 | INFO | train_inner | epoch 017:    132 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.06, loss=4.921, nll_loss=2.066, ppl=4.19, wps=27715.2, ups=1.87, wpb=14827.8, bsz=516.6, num_updates=39300, lr=0.000159516, gnorm=0.648, train_wall=53, wall=21701
2020-12-20 00:10:46 | INFO | train_inner | epoch 017:    232 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.057, loss=4.929, nll_loss=2.075, ppl=4.21, wps=27383.7, ups=1.86, wpb=14731.1, bsz=489.4, num_updates=39400, lr=0.000159313, gnorm=0.659, train_wall=54, wall=21755
2020-12-20 00:11:40 | INFO | train_inner | epoch 017:    332 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.032, loss=4.923, nll_loss=2.073, ppl=4.21, wps=27506, ups=1.85, wpb=14835.1, bsz=535.2, num_updates=39500, lr=0.000159111, gnorm=0.642, train_wall=54, wall=21809
2020-12-20 00:12:34 | INFO | train_inner | epoch 017:    432 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.077, loss=4.948, nll_loss=2.093, ppl=4.27, wps=27464, ups=1.85, wpb=14819.2, bsz=525.8, num_updates=39600, lr=0.00015891, gnorm=0.671, train_wall=54, wall=21863
2020-12-20 00:13:28 | INFO | train_inner | epoch 017:    532 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.046, loss=4.936, nll_loss=2.086, ppl=4.25, wps=27674.5, ups=1.85, wpb=14942.4, bsz=517.6, num_updates=39700, lr=0.00015871, gnorm=0.642, train_wall=54, wall=21917
2020-12-20 00:14:21 | INFO | train_inner | epoch 017:    632 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.035, loss=4.967, nll_loss=2.122, ppl=4.35, wps=27478.4, ups=1.86, wpb=14745.6, bsz=495.9, num_updates=39800, lr=0.000158511, gnorm=0.663, train_wall=53, wall=21971
2020-12-20 00:15:15 | INFO | train_inner | epoch 017:    732 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.06, loss=4.977, nll_loss=2.129, ppl=4.38, wps=27149.4, ups=1.85, wpb=14641.2, bsz=496, num_updates=39900, lr=0.000158312, gnorm=0.652, train_wall=54, wall=22025
2020-12-20 00:16:09 | INFO | train_inner | epoch 017:    832 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.987, loss=4.941, nll_loss=2.1, ppl=4.29, wps=27528, ups=1.85, wpb=14881.7, bsz=521.7, num_updates=40000, lr=0.000158114, gnorm=0.651, train_wall=54, wall=22079
2020-12-20 00:17:03 | INFO | train_inner | epoch 017:    932 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.034, loss=4.962, nll_loss=2.117, ppl=4.34, wps=27408.1, ups=1.86, wpb=14741.9, bsz=506.5, num_updates=40100, lr=0.000157917, gnorm=0.652, train_wall=54, wall=22132
2020-12-20 00:17:57 | INFO | train_inner | epoch 017:   1032 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.985, loss=4.945, nll_loss=2.106, ppl=4.3, wps=27470.8, ups=1.85, wpb=14811.1, bsz=495.4, num_updates=40200, lr=0.00015772, gnorm=0.649, train_wall=54, wall=22186
2020-12-20 00:18:51 | INFO | train_inner | epoch 017:   1132 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.019, loss=4.964, nll_loss=2.122, ppl=4.35, wps=27425.2, ups=1.86, wpb=14780.2, bsz=506.5, num_updates=40300, lr=0.000157524, gnorm=0.655, train_wall=54, wall=22240
2020-12-20 00:19:45 | INFO | train_inner | epoch 017:   1232 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.987, loss=4.94, nll_loss=2.1, ppl=4.29, wps=27523.5, ups=1.85, wpb=14873.5, bsz=532.5, num_updates=40400, lr=0.000157329, gnorm=0.652, train_wall=54, wall=22294
2020-12-20 00:20:39 | INFO | train_inner | epoch 017:   1332 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.988, loss=4.967, nll_loss=2.129, ppl=4.38, wps=27369.9, ups=1.85, wpb=14786.2, bsz=508.6, num_updates=40500, lr=0.000157135, gnorm=0.667, train_wall=54, wall=22348
2020-12-20 00:21:33 | INFO | train_inner | epoch 017:   1432 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.04, loss=4.97, nll_loss=2.125, ppl=4.36, wps=27535.3, ups=1.85, wpb=14849.4, bsz=476.7, num_updates=40600, lr=0.000156941, gnorm=0.648, train_wall=54, wall=22402
2020-12-20 00:22:27 | INFO | train_inner | epoch 017:   1532 / 2448 symm_kl=0.553, self_kl=0, self_cv=9.003, loss=4.945, nll_loss=2.103, ppl=4.3, wps=27445.8, ups=1.85, wpb=14865.4, bsz=519.4, num_updates=40700, lr=0.000156748, gnorm=0.661, train_wall=54, wall=22456
2020-12-20 00:23:21 | INFO | train_inner | epoch 017:   1632 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.997, loss=4.977, nll_loss=2.14, ppl=4.41, wps=27358.8, ups=1.86, wpb=14720.1, bsz=509.9, num_updates=40800, lr=0.000156556, gnorm=0.681, train_wall=54, wall=22510
2020-12-20 00:24:15 | INFO | train_inner | epoch 017:   1732 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.009, loss=4.974, nll_loss=2.134, ppl=4.39, wps=27689.6, ups=1.86, wpb=14921.7, bsz=508.4, num_updates=40900, lr=0.000156365, gnorm=0.645, train_wall=54, wall=22564
2020-12-20 00:25:09 | INFO | train_inner | epoch 017:   1832 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.016, loss=4.974, nll_loss=2.134, ppl=4.39, wps=27483.8, ups=1.85, wpb=14832.1, bsz=510.2, num_updates=41000, lr=0.000156174, gnorm=0.674, train_wall=54, wall=22618
2020-12-20 00:26:03 | INFO | train_inner | epoch 017:   1932 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.986, loss=4.977, nll_loss=2.141, ppl=4.41, wps=27402.2, ups=1.85, wpb=14808.9, bsz=530.3, num_updates=41100, lr=0.000155984, gnorm=0.656, train_wall=54, wall=22672
2020-12-20 00:26:57 | INFO | train_inner | epoch 017:   2032 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.981, loss=4.987, nll_loss=2.154, ppl=4.45, wps=27376, ups=1.85, wpb=14775.7, bsz=519.2, num_updates=41200, lr=0.000155794, gnorm=0.667, train_wall=54, wall=22726
2020-12-20 00:27:51 | INFO | train_inner | epoch 017:   2132 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.983, loss=4.977, nll_loss=2.142, ppl=4.41, wps=27508.8, ups=1.86, wpb=14815.1, bsz=531.2, num_updates=41300, lr=0.000155606, gnorm=0.668, train_wall=54, wall=22780
2020-12-20 00:28:44 | INFO | train_inner | epoch 017:   2232 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.996, loss=4.985, nll_loss=2.149, ppl=4.44, wps=27746.1, ups=1.86, wpb=14896.4, bsz=497.4, num_updates=41400, lr=0.000155417, gnorm=0.659, train_wall=54, wall=22834
2020-12-20 00:29:38 | INFO | train_inner | epoch 017:   2332 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.011, loss=5, nll_loss=2.164, ppl=4.48, wps=27559.4, ups=1.86, wpb=14810.8, bsz=504.9, num_updates=41500, lr=0.00015523, gnorm=0.651, train_wall=54, wall=22887
2020-12-20 00:30:32 | INFO | train_inner | epoch 017:   2432 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.975, loss=4.971, nll_loss=2.136, ppl=4.4, wps=27457.7, ups=1.85, wpb=14847.8, bsz=520.6, num_updates=41600, lr=0.000155043, gnorm=0.68, train_wall=54, wall=22941
2020-12-20 00:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 00:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 00:30:54 | INFO | valid | epoch 017 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.026 | nll_loss 8.054 | ppl 265.67 | bleu 15.67 | wps 6097 | wpb 7930.2 | bsz 208 | num_updates 41616 | best_bleu 16.16
2020-12-20 00:30:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 00:30:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 17 @ 41616 updates, score 15.67) (writing took 4.709654152393341 seconds)
2020-12-20 00:30:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-12-20 00:30:59 | INFO | train | epoch 017 | symm_kl 0.56 | self_kl 0 | self_cv 9.016 | loss 4.96 | nll_loss 2.118 | ppl 4.34 | wps 26937.7 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 41616 | lr 0.000155014 | gnorm 0.658 | train_wall 1315 | wall 22968
2020-12-20 00:31:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:31:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:31:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:31:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:31:02 | INFO | fairseq.trainer | begin training epoch 18
2020-12-20 00:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:31:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:31:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:31:53 | INFO | train_inner | epoch 018:     84 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.068, loss=4.935, nll_loss=2.082, ppl=4.23, wps=18202.1, ups=1.24, wpb=14633.2, bsz=510.1, num_updates=41700, lr=0.000154857, gnorm=0.66, train_wall=53, wall=23022
2020-12-20 00:32:47 | INFO | train_inner | epoch 018:    184 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.08, loss=4.913, nll_loss=2.054, ppl=4.15, wps=27484.1, ups=1.86, wpb=14815.5, bsz=522.9, num_updates=41800, lr=0.000154672, gnorm=0.658, train_wall=54, wall=23076
2020-12-20 00:33:40 | INFO | train_inner | epoch 018:    284 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.018, loss=4.941, nll_loss=2.095, ppl=4.27, wps=27379, ups=1.85, wpb=14761.2, bsz=529.1, num_updates=41900, lr=0.000154487, gnorm=0.665, train_wall=54, wall=23130
2020-12-20 00:34:34 | INFO | train_inner | epoch 018:    384 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.037, loss=4.917, nll_loss=2.066, ppl=4.19, wps=27613.8, ups=1.86, wpb=14882.6, bsz=521, num_updates=42000, lr=0.000154303, gnorm=0.652, train_wall=54, wall=23184
2020-12-20 00:35:28 | INFO | train_inner | epoch 018:    484 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.034, loss=4.935, nll_loss=2.087, ppl=4.25, wps=27471.5, ups=1.85, wpb=14863.2, bsz=527.2, num_updates=42100, lr=0.00015412, gnorm=0.684, train_wall=54, wall=23238
2020-12-20 00:36:23 | INFO | train_inner | epoch 018:    584 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.047, loss=4.939, nll_loss=2.088, ppl=4.25, wps=27539.6, ups=1.85, wpb=14884.5, bsz=517.1, num_updates=42200, lr=0.000153937, gnorm=0.674, train_wall=54, wall=23292
2020-12-20 00:37:17 | INFO | train_inner | epoch 018:    684 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.051, loss=4.957, nll_loss=2.109, ppl=4.31, wps=27583.2, ups=1.85, wpb=14895.2, bsz=490.6, num_updates=42300, lr=0.000153755, gnorm=0.656, train_wall=54, wall=23346
2020-12-20 00:38:10 | INFO | train_inner | epoch 018:    784 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.04, loss=4.952, nll_loss=2.104, ppl=4.3, wps=27624.2, ups=1.86, wpb=14863.5, bsz=495.7, num_updates=42400, lr=0.000153574, gnorm=0.663, train_wall=54, wall=23399
2020-12-20 00:39:04 | INFO | train_inner | epoch 018:    884 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.008, loss=4.952, nll_loss=2.109, ppl=4.31, wps=27407.9, ups=1.85, wpb=14795.4, bsz=497.1, num_updates=42500, lr=0.000153393, gnorm=0.674, train_wall=54, wall=23453
2020-12-20 00:39:58 | INFO | train_inner | epoch 018:    984 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.011, loss=4.957, nll_loss=2.115, ppl=4.33, wps=27558.6, ups=1.86, wpb=14791.8, bsz=522.2, num_updates=42600, lr=0.000153213, gnorm=0.686, train_wall=54, wall=23507
2020-12-20 00:40:52 | INFO | train_inner | epoch 018:   1084 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.005, loss=4.958, nll_loss=2.117, ppl=4.34, wps=27392.1, ups=1.86, wpb=14707.5, bsz=510.2, num_updates=42700, lr=0.000153033, gnorm=0.666, train_wall=54, wall=23561
2020-12-20 00:41:46 | INFO | train_inner | epoch 018:   1184 / 2448 symm_kl=0.554, self_kl=0, self_cv=9.005, loss=4.94, nll_loss=2.097, ppl=4.28, wps=27606.9, ups=1.85, wpb=14907.4, bsz=516.6, num_updates=42800, lr=0.000152854, gnorm=0.663, train_wall=54, wall=23615
2020-12-20 00:42:40 | INFO | train_inner | epoch 018:   1284 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.998, loss=4.95, nll_loss=2.109, ppl=4.31, wps=27378.1, ups=1.85, wpb=14767.4, bsz=515.9, num_updates=42900, lr=0.000152676, gnorm=0.677, train_wall=54, wall=23669
2020-12-20 00:43:34 | INFO | train_inner | epoch 018:   1384 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.997, loss=4.951, nll_loss=2.11, ppl=4.32, wps=27472.1, ups=1.85, wpb=14851.7, bsz=512.4, num_updates=43000, lr=0.000152499, gnorm=0.667, train_wall=54, wall=23723
2020-12-20 00:44:27 | INFO | train_inner | epoch 018:   1484 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.016, loss=4.952, nll_loss=2.109, ppl=4.31, wps=27487.5, ups=1.86, wpb=14775.9, bsz=510.9, num_updates=43100, lr=0.000152322, gnorm=0.677, train_wall=54, wall=23777
2020-12-20 00:45:21 | INFO | train_inner | epoch 018:   1584 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.974, loss=4.943, nll_loss=2.106, ppl=4.3, wps=27629.5, ups=1.86, wpb=14869.4, bsz=525.4, num_updates=43200, lr=0.000152145, gnorm=0.655, train_wall=54, wall=23830
2020-12-20 00:46:15 | INFO | train_inner | epoch 018:   1684 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.015, loss=4.98, nll_loss=2.14, ppl=4.41, wps=27537.7, ups=1.87, wpb=14756, bsz=508, num_updates=43300, lr=0.000151969, gnorm=0.669, train_wall=53, wall=23884
2020-12-20 00:47:09 | INFO | train_inner | epoch 018:   1784 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.994, loss=4.978, nll_loss=2.141, ppl=4.41, wps=27449.9, ups=1.86, wpb=14733.4, bsz=514.2, num_updates=43400, lr=0.000151794, gnorm=0.667, train_wall=54, wall=23938
2020-12-20 00:48:02 | INFO | train_inner | epoch 018:   1884 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.985, loss=4.953, nll_loss=2.115, ppl=4.33, wps=27480.7, ups=1.86, wpb=14792.9, bsz=527.3, num_updates=43500, lr=0.00015162, gnorm=0.662, train_wall=54, wall=23991
2020-12-20 00:48:56 | INFO | train_inner | epoch 018:   1984 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.024, loss=4.984, nll_loss=2.145, ppl=4.42, wps=27399.6, ups=1.86, wpb=14751.8, bsz=506.5, num_updates=43600, lr=0.000151446, gnorm=0.682, train_wall=54, wall=24045
2020-12-20 00:49:50 | INFO | train_inner | epoch 018:   2084 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.006, loss=4.958, nll_loss=2.118, ppl=4.34, wps=27376.5, ups=1.86, wpb=14746.2, bsz=498, num_updates=43700, lr=0.000151272, gnorm=0.665, train_wall=54, wall=24099
2020-12-20 00:50:44 | INFO | train_inner | epoch 018:   2184 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.019, loss=4.975, nll_loss=2.135, ppl=4.39, wps=27628, ups=1.85, wpb=14908.2, bsz=487, num_updates=43800, lr=0.000151099, gnorm=0.654, train_wall=54, wall=24153
2020-12-20 00:51:38 | INFO | train_inner | epoch 018:   2284 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.996, loss=4.978, nll_loss=2.141, ppl=4.41, wps=27379.2, ups=1.84, wpb=14850.8, bsz=499.5, num_updates=43900, lr=0.000150927, gnorm=0.667, train_wall=54, wall=24207
2020-12-20 00:52:32 | INFO | train_inner | epoch 018:   2384 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.981, loss=4.971, nll_loss=2.137, ppl=4.4, wps=27379.9, ups=1.85, wpb=14825.6, bsz=527.5, num_updates=44000, lr=0.000150756, gnorm=0.665, train_wall=54, wall=24262
2020-12-20 00:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 00:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 00:53:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 00:53:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 00:53:21 | INFO | valid | epoch 018 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.992 | nll_loss 8.016 | ppl 258.93 | bleu 15.94 | wps 5491.1 | wpb 7930.2 | bsz 208 | num_updates 44064 | best_bleu 16.16
2020-12-20 00:53:21 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 00:53:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 18 @ 44064 updates, score 15.94) (writing took 4.576396107673645 seconds)
2020-12-20 00:53:26 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-12-20 00:53:26 | INFO | train | epoch 018 | symm_kl 0.559 | self_kl 0 | self_cv 9.016 | loss 4.953 | nll_loss 2.11 | ppl 4.32 | wps 26918.1 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 44064 | lr 0.000150646 | gnorm 0.667 | train_wall 1315 | wall 24315
2020-12-20 00:53:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:29 | INFO | fairseq.trainer | begin training epoch 19
2020-12-20 00:53:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 00:53:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 00:53:54 | INFO | train_inner | epoch 019:     36 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.008, loss=4.944, nll_loss=2.101, ppl=4.29, wps=18074.4, ups=1.23, wpb=14680.5, bsz=494.9, num_updates=44100, lr=0.000150585, gnorm=0.684, train_wall=53, wall=24343
2020-12-20 00:54:48 | INFO | train_inner | epoch 019:    136 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.056, loss=4.909, nll_loss=2.054, ppl=4.15, wps=27515.4, ups=1.86, wpb=14826.2, bsz=515.8, num_updates=44200, lr=0.000150414, gnorm=0.653, train_wall=54, wall=24397
2020-12-20 00:55:41 | INFO | train_inner | epoch 019:    236 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.063, loss=4.926, nll_loss=2.072, ppl=4.2, wps=27496.2, ups=1.86, wpb=14805.9, bsz=524.5, num_updates=44300, lr=0.000150244, gnorm=0.665, train_wall=54, wall=24450
2020-12-20 00:56:35 | INFO | train_inner | epoch 019:    336 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.043, loss=4.923, nll_loss=2.072, ppl=4.2, wps=27508.4, ups=1.86, wpb=14825.9, bsz=519.9, num_updates=44400, lr=0.000150075, gnorm=0.66, train_wall=54, wall=24504
2020-12-20 00:57:29 | INFO | train_inner | epoch 019:    436 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.051, loss=4.935, nll_loss=2.084, ppl=4.24, wps=27719.9, ups=1.86, wpb=14892.8, bsz=505.3, num_updates=44500, lr=0.000149906, gnorm=0.675, train_wall=54, wall=24558
2020-12-20 00:58:23 | INFO | train_inner | epoch 019:    536 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.013, loss=4.91, nll_loss=2.062, ppl=4.18, wps=27554, ups=1.86, wpb=14832.5, bsz=517.8, num_updates=44600, lr=0.000149738, gnorm=0.65, train_wall=54, wall=24612
2020-12-20 00:59:17 | INFO | train_inner | epoch 019:    636 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.031, loss=4.937, nll_loss=2.09, ppl=4.26, wps=27662.8, ups=1.86, wpb=14898.5, bsz=526.4, num_updates=44700, lr=0.000149571, gnorm=0.668, train_wall=54, wall=24666
2020-12-20 01:00:10 | INFO | train_inner | epoch 019:    736 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.052, loss=4.941, nll_loss=2.091, ppl=4.26, wps=27469.3, ups=1.86, wpb=14773.4, bsz=503, num_updates=44800, lr=0.000149404, gnorm=0.674, train_wall=54, wall=24720
2020-12-20 01:01:04 | INFO | train_inner | epoch 019:    836 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.032, loss=4.953, nll_loss=2.108, ppl=4.31, wps=27466.9, ups=1.86, wpb=14761.5, bsz=503.4, num_updates=44900, lr=0.000149237, gnorm=0.658, train_wall=54, wall=24773
2020-12-20 01:01:58 | INFO | train_inner | epoch 019:    936 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.017, loss=4.927, nll_loss=2.08, ppl=4.23, wps=27631.5, ups=1.86, wpb=14844.6, bsz=520, num_updates=45000, lr=0.000149071, gnorm=0.659, train_wall=54, wall=24827
2020-12-20 01:02:52 | INFO | train_inner | epoch 019:   1036 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.008, loss=4.946, nll_loss=2.104, ppl=4.3, wps=27524, ups=1.85, wpb=14866.1, bsz=511.8, num_updates=45100, lr=0.000148906, gnorm=0.674, train_wall=54, wall=24881
2020-12-20 01:03:46 | INFO | train_inner | epoch 019:   1136 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.996, loss=4.96, nll_loss=2.121, ppl=4.35, wps=27540.2, ups=1.86, wpb=14797.2, bsz=536.2, num_updates=45200, lr=0.000148741, gnorm=0.675, train_wall=54, wall=24935
2020-12-20 01:04:39 | INFO | train_inner | epoch 019:   1236 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.003, loss=4.947, nll_loss=2.105, ppl=4.3, wps=27564.5, ups=1.86, wpb=14810.2, bsz=527.6, num_updates=45300, lr=0.000148577, gnorm=0.667, train_wall=54, wall=24989
2020-12-20 01:05:33 | INFO | train_inner | epoch 019:   1336 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.011, loss=4.96, nll_loss=2.119, ppl=4.34, wps=27445.8, ups=1.86, wpb=14753.1, bsz=503.2, num_updates=45400, lr=0.000148413, gnorm=0.679, train_wall=54, wall=25042
2020-12-20 01:06:27 | INFO | train_inner | epoch 019:   1436 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.011, loss=4.944, nll_loss=2.101, ppl=4.29, wps=27430.5, ups=1.85, wpb=14794.2, bsz=520.5, num_updates=45500, lr=0.00014825, gnorm=0.669, train_wall=54, wall=25096
2020-12-20 01:07:21 | INFO | train_inner | epoch 019:   1536 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.021, loss=4.963, nll_loss=2.121, ppl=4.35, wps=27496.9, ups=1.86, wpb=14795.4, bsz=499.6, num_updates=45600, lr=0.000148087, gnorm=0.678, train_wall=54, wall=25150
2020-12-20 01:08:15 | INFO | train_inner | epoch 019:   1636 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.008, loss=4.952, nll_loss=2.111, ppl=4.32, wps=27386.8, ups=1.85, wpb=14773.5, bsz=484.2, num_updates=45700, lr=0.000147925, gnorm=0.677, train_wall=54, wall=25204
2020-12-20 01:09:09 | INFO | train_inner | epoch 019:   1736 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.983, loss=4.938, nll_loss=2.098, ppl=4.28, wps=27538.1, ups=1.85, wpb=14878.9, bsz=538.3, num_updates=45800, lr=0.000147764, gnorm=0.67, train_wall=54, wall=25258
2020-12-20 01:10:03 | INFO | train_inner | epoch 019:   1836 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.003, loss=4.966, nll_loss=2.127, ppl=4.37, wps=27224.3, ups=1.85, wpb=14707.3, bsz=509, num_updates=45900, lr=0.000147602, gnorm=0.672, train_wall=54, wall=25312
2020-12-20 01:10:57 | INFO | train_inner | epoch 019:   1936 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.965, loss=4.949, nll_loss=2.114, ppl=4.33, wps=27256.4, ups=1.85, wpb=14705.4, bsz=510.9, num_updates=46000, lr=0.000147442, gnorm=0.677, train_wall=54, wall=25366
2020-12-20 01:11:51 | INFO | train_inner | epoch 019:   2036 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.011, loss=4.975, nll_loss=2.137, ppl=4.4, wps=27442.1, ups=1.85, wpb=14794.6, bsz=478.3, num_updates=46100, lr=0.000147282, gnorm=0.666, train_wall=54, wall=25420
2020-12-20 01:12:45 | INFO | train_inner | epoch 019:   2136 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.979, loss=4.945, nll_loss=2.107, ppl=4.31, wps=27698.2, ups=1.85, wpb=14940.3, bsz=526.1, num_updates=46200, lr=0.000147122, gnorm=0.659, train_wall=54, wall=25474
2020-12-20 01:13:39 | INFO | train_inner | epoch 019:   2236 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.999, loss=4.964, nll_loss=2.127, ppl=4.37, wps=27408, ups=1.85, wpb=14805.8, bsz=494.8, num_updates=46300, lr=0.000146964, gnorm=0.66, train_wall=54, wall=25528
2020-12-20 01:14:33 | INFO | train_inner | epoch 019:   2336 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.97, loss=4.968, nll_loss=2.135, ppl=4.39, wps=27642.6, ups=1.86, wpb=14880.1, bsz=518.4, num_updates=46400, lr=0.000146805, gnorm=0.67, train_wall=54, wall=25582
2020-12-20 01:15:26 | INFO | train_inner | epoch 019:   2436 / 2448 symm_kl=0.557, self_kl=0, self_cv=9, loss=4.971, nll_loss=2.134, ppl=4.39, wps=27612.9, ups=1.86, wpb=14870.7, bsz=508.6, num_updates=46500, lr=0.000146647, gnorm=0.68, train_wall=54, wall=25636
2020-12-20 01:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 01:15:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 01:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 01:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 01:15:47 | INFO | valid | epoch 019 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.014 | nll_loss 8.046 | ppl 264.25 | bleu 15.78 | wps 5396.5 | wpb 7930.2 | bsz 208 | num_updates 46512 | best_bleu 16.16
2020-12-20 01:15:47 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 01:15:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 19 @ 46512 updates, score 15.78) (writing took 4.865392362698913 seconds)
2020-12-20 01:15:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-12-20 01:15:52 | INFO | train | epoch 019 | symm_kl 0.559 | self_kl 0 | self_cv 9.015 | loss 4.946 | nll_loss 2.102 | ppl 4.29 | wps 26927.6 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 46512 | lr 0.000146628 | gnorm 0.668 | train_wall 1314 | wall 25661
2020-12-20 01:15:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:15:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:55 | INFO | fairseq.trainer | begin training epoch 20
2020-12-20 01:15:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:16:48 | INFO | train_inner | epoch 020:     88 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.065, loss=4.943, nll_loss=2.091, ppl=4.26, wps=17936.9, ups=1.23, wpb=14591.6, bsz=498.1, num_updates=46600, lr=0.00014649, gnorm=0.683, train_wall=53, wall=25717
2020-12-20 01:17:42 | INFO | train_inner | epoch 020:    188 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.067, loss=4.914, nll_loss=2.058, ppl=4.16, wps=27501.1, ups=1.86, wpb=14779.4, bsz=511, num_updates=46700, lr=0.000146333, gnorm=0.666, train_wall=54, wall=25771
2020-12-20 01:18:35 | INFO | train_inner | epoch 020:    288 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.999, loss=4.9, nll_loss=2.053, ppl=4.15, wps=27608, ups=1.86, wpb=14852.3, bsz=514.9, num_updates=46800, lr=0.000146176, gnorm=0.656, train_wall=54, wall=25824
2020-12-20 01:19:30 | INFO | train_inner | epoch 020:    388 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.051, loss=4.921, nll_loss=2.069, ppl=4.2, wps=27409.9, ups=1.84, wpb=14862.7, bsz=516.8, num_updates=46900, lr=0.00014602, gnorm=0.677, train_wall=54, wall=25879
2020-12-20 01:20:23 | INFO | train_inner | epoch 020:    488 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.031, loss=4.924, nll_loss=2.075, ppl=4.21, wps=27481.2, ups=1.85, wpb=14822.1, bsz=527.6, num_updates=47000, lr=0.000145865, gnorm=0.668, train_wall=54, wall=25933
2020-12-20 01:21:17 | INFO | train_inner | epoch 020:    588 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.017, loss=4.911, nll_loss=2.063, ppl=4.18, wps=27576.1, ups=1.85, wpb=14870, bsz=529.9, num_updates=47100, lr=0.00014571, gnorm=0.676, train_wall=54, wall=25987
2020-12-20 01:22:11 | INFO | train_inner | epoch 020:    688 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.054, loss=4.936, nll_loss=2.086, ppl=4.24, wps=27502.1, ups=1.86, wpb=14770.2, bsz=497, num_updates=47200, lr=0.000145556, gnorm=0.687, train_wall=54, wall=26040
2020-12-20 01:23:05 | INFO | train_inner | epoch 020:    788 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.054, loss=4.94, nll_loss=2.09, ppl=4.26, wps=27333.6, ups=1.86, wpb=14716.4, bsz=504.6, num_updates=47300, lr=0.000145402, gnorm=0.674, train_wall=54, wall=26094
2020-12-20 01:23:59 | INFO | train_inner | epoch 020:    888 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.006, loss=4.954, nll_loss=2.113, ppl=4.33, wps=27172.3, ups=1.85, wpb=14661.7, bsz=518.5, num_updates=47400, lr=0.000145248, gnorm=0.667, train_wall=54, wall=26148
2020-12-20 01:24:53 | INFO | train_inner | epoch 020:    988 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.016, loss=4.933, nll_loss=2.088, ppl=4.25, wps=27567.5, ups=1.86, wpb=14855.9, bsz=516.6, num_updates=47500, lr=0.000145095, gnorm=0.694, train_wall=54, wall=26202
2020-12-20 01:25:47 | INFO | train_inner | epoch 020:   1088 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.068, loss=4.953, nll_loss=2.102, ppl=4.29, wps=27355.9, ups=1.85, wpb=14820.8, bsz=488.9, num_updates=47600, lr=0.000144943, gnorm=0.664, train_wall=54, wall=26256
2020-12-20 01:26:41 | INFO | train_inner | epoch 020:   1188 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.034, loss=4.946, nll_loss=2.1, ppl=4.29, wps=27749.3, ups=1.86, wpb=14915.1, bsz=515.1, num_updates=47700, lr=0.000144791, gnorm=0.682, train_wall=54, wall=26310
2020-12-20 01:27:34 | INFO | train_inner | epoch 020:   1288 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.021, loss=4.944, nll_loss=2.1, ppl=4.29, wps=27618, ups=1.86, wpb=14832.5, bsz=508.6, num_updates=47800, lr=0.000144639, gnorm=0.686, train_wall=54, wall=26364
2020-12-20 01:28:29 | INFO | train_inner | epoch 020:   1388 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.007, loss=4.953, nll_loss=2.112, ppl=4.32, wps=27493.7, ups=1.85, wpb=14873.8, bsz=513.2, num_updates=47900, lr=0.000144488, gnorm=0.68, train_wall=54, wall=26418
2020-12-20 01:29:22 | INFO | train_inner | epoch 020:   1488 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.023, loss=4.957, nll_loss=2.113, ppl=4.33, wps=27429.9, ups=1.85, wpb=14793.2, bsz=496.4, num_updates=48000, lr=0.000144338, gnorm=0.67, train_wall=54, wall=26472
2020-12-20 01:30:17 | INFO | train_inner | epoch 020:   1588 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.003, loss=4.946, nll_loss=2.105, ppl=4.3, wps=27304.1, ups=1.85, wpb=14772.7, bsz=530.8, num_updates=48100, lr=0.000144187, gnorm=0.674, train_wall=54, wall=26526
2020-12-20 01:31:11 | INFO | train_inner | epoch 020:   1688 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.01, loss=4.94, nll_loss=2.097, ppl=4.28, wps=27634.7, ups=1.85, wpb=14926.7, bsz=517.9, num_updates=48200, lr=0.000144038, gnorm=0.668, train_wall=54, wall=26580
2020-12-20 01:32:05 | INFO | train_inner | epoch 020:   1788 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.991, loss=4.951, nll_loss=2.112, ppl=4.32, wps=27487.9, ups=1.85, wpb=14837.9, bsz=544.4, num_updates=48300, lr=0.000143889, gnorm=0.679, train_wall=54, wall=26634
2020-12-20 01:32:58 | INFO | train_inner | epoch 020:   1888 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.008, loss=4.951, nll_loss=2.11, ppl=4.32, wps=27509.5, ups=1.85, wpb=14831.5, bsz=504.1, num_updates=48400, lr=0.00014374, gnorm=0.674, train_wall=54, wall=26688
2020-12-20 01:33:52 | INFO | train_inner | epoch 020:   1988 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.018, loss=4.95, nll_loss=2.108, ppl=4.31, wps=27543.8, ups=1.86, wpb=14818.9, bsz=478.3, num_updates=48500, lr=0.000143592, gnorm=0.672, train_wall=54, wall=26741
2020-12-20 01:34:46 | INFO | train_inner | epoch 020:   2088 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.012, loss=4.947, nll_loss=2.105, ppl=4.3, wps=27332.4, ups=1.85, wpb=14759.8, bsz=489.4, num_updates=48600, lr=0.000143444, gnorm=0.673, train_wall=54, wall=26795
2020-12-20 01:35:40 | INFO | train_inner | epoch 020:   2188 / 2448 symm_kl=0.553, self_kl=0, self_cv=9.001, loss=4.944, nll_loss=2.103, ppl=4.3, wps=27451.2, ups=1.86, wpb=14785.8, bsz=524.2, num_updates=48700, lr=0.000143296, gnorm=0.661, train_wall=54, wall=26849
2020-12-20 01:36:34 | INFO | train_inner | epoch 020:   2288 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.007, loss=4.951, nll_loss=2.111, ppl=4.32, wps=27474.8, ups=1.85, wpb=14856.1, bsz=499.5, num_updates=48800, lr=0.00014315, gnorm=0.679, train_wall=54, wall=26903
2020-12-20 01:37:28 | INFO | train_inner | epoch 020:   2388 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.974, loss=4.953, nll_loss=2.118, ppl=4.34, wps=27531, ups=1.86, wpb=14785.9, bsz=507.8, num_updates=48900, lr=0.000143003, gnorm=0.667, train_wall=54, wall=26957
2020-12-20 01:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 01:38:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 01:38:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 01:38:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 01:38:13 | INFO | valid | epoch 020 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.009 | nll_loss 8.044 | ppl 263.87 | bleu 15.8 | wps 6078.7 | wpb 7930.2 | bsz 208 | num_updates 48960 | best_bleu 16.16
2020-12-20 01:38:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 01:38:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 20 @ 48960 updates, score 15.8) (writing took 4.8723549246788025 seconds)
2020-12-20 01:38:18 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-12-20 01:38:18 | INFO | train | epoch 020 | symm_kl 0.559 | self_kl 0 | self_cv 9.02 | loss 4.94 | nll_loss 2.095 | ppl 4.27 | wps 26935.1 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 48960 | lr 0.000142915 | gnorm 0.674 | train_wall 1315 | wall 27007
2020-12-20 01:38:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:21 | INFO | fairseq.trainer | begin training epoch 21
2020-12-20 01:38:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 01:38:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 01:38:48 | INFO | train_inner | epoch 021:     40 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.016, loss=4.945, nll_loss=2.101, ppl=4.29, wps=18224.5, ups=1.24, wpb=14649.4, bsz=535.3, num_updates=49000, lr=0.000142857, gnorm=0.691, train_wall=53, wall=27037
2020-12-20 01:39:42 | INFO | train_inner | epoch 021:    140 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.097, loss=4.924, nll_loss=2.065, ppl=4.18, wps=27534, ups=1.86, wpb=14766.4, bsz=510.2, num_updates=49100, lr=0.000142712, gnorm=0.679, train_wall=53, wall=27091
2020-12-20 01:40:36 | INFO | train_inner | epoch 021:    240 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.042, loss=4.902, nll_loss=2.048, ppl=4.14, wps=27531.1, ups=1.85, wpb=14859, bsz=527.8, num_updates=49200, lr=0.000142566, gnorm=0.661, train_wall=54, wall=27145
2020-12-20 01:41:30 | INFO | train_inner | epoch 021:    340 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.079, loss=4.938, nll_loss=2.084, ppl=4.24, wps=27342.3, ups=1.85, wpb=14759.7, bsz=504.4, num_updates=49300, lr=0.000142422, gnorm=0.675, train_wall=54, wall=27199
2020-12-20 01:42:24 | INFO | train_inner | epoch 021:    440 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.037, loss=4.918, nll_loss=2.068, ppl=4.19, wps=27584, ups=1.86, wpb=14863.9, bsz=535.8, num_updates=49400, lr=0.000142278, gnorm=0.668, train_wall=54, wall=27253
2020-12-20 01:43:18 | INFO | train_inner | epoch 021:    540 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.055, loss=4.938, nll_loss=2.088, ppl=4.25, wps=27355.7, ups=1.85, wpb=14759.8, bsz=506.5, num_updates=49500, lr=0.000142134, gnorm=0.678, train_wall=54, wall=27307
2020-12-20 01:44:12 | INFO | train_inner | epoch 021:    640 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.008, loss=4.913, nll_loss=2.067, ppl=4.19, wps=27317.9, ups=1.85, wpb=14732, bsz=520.1, num_updates=49600, lr=0.00014199, gnorm=0.675, train_wall=54, wall=27361
2020-12-20 01:45:06 | INFO | train_inner | epoch 021:    740 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.037, loss=4.912, nll_loss=2.061, ppl=4.17, wps=27561, ups=1.86, wpb=14847, bsz=499, num_updates=49700, lr=0.000141848, gnorm=0.665, train_wall=54, wall=27415
2020-12-20 01:45:59 | INFO | train_inner | epoch 021:    840 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.028, loss=4.916, nll_loss=2.067, ppl=4.19, wps=27703.4, ups=1.86, wpb=14898.2, bsz=520.6, num_updates=49800, lr=0.000141705, gnorm=0.666, train_wall=54, wall=27468
2020-12-20 01:46:53 | INFO | train_inner | epoch 021:    940 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.036, loss=4.919, nll_loss=2.069, ppl=4.2, wps=27621.9, ups=1.86, wpb=14853.5, bsz=507.4, num_updates=49900, lr=0.000141563, gnorm=0.674, train_wall=54, wall=27522
2020-12-20 01:47:47 | INFO | train_inner | epoch 021:   1040 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.038, loss=4.937, nll_loss=2.089, ppl=4.26, wps=27567.5, ups=1.86, wpb=14851.1, bsz=517.2, num_updates=50000, lr=0.000141421, gnorm=0.678, train_wall=54, wall=27576
2020-12-20 01:48:41 | INFO | train_inner | epoch 021:   1140 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.023, loss=4.945, nll_loss=2.101, ppl=4.29, wps=27541.3, ups=1.85, wpb=14889.2, bsz=513.4, num_updates=50100, lr=0.00014128, gnorm=0.694, train_wall=54, wall=27630
2020-12-20 01:49:35 | INFO | train_inner | epoch 021:   1240 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.969, loss=4.907, nll_loss=2.066, ppl=4.19, wps=27653.4, ups=1.86, wpb=14857.9, bsz=521.3, num_updates=50200, lr=0.000141139, gnorm=0.669, train_wall=54, wall=27684
2020-12-20 01:50:28 | INFO | train_inner | epoch 021:   1340 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.998, loss=4.93, nll_loss=2.087, ppl=4.25, wps=27638.5, ups=1.87, wpb=14818.8, bsz=502.1, num_updates=50300, lr=0.000140999, gnorm=0.687, train_wall=53, wall=27737
2020-12-20 01:51:22 | INFO | train_inner | epoch 021:   1440 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.99, loss=4.933, nll_loss=2.093, ppl=4.27, wps=27374.1, ups=1.85, wpb=14817.7, bsz=509.6, num_updates=50400, lr=0.000140859, gnorm=0.67, train_wall=54, wall=27792
2020-12-20 01:52:16 | INFO | train_inner | epoch 021:   1540 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.021, loss=4.946, nll_loss=2.102, ppl=4.29, wps=27411.4, ups=1.85, wpb=14786, bsz=480.5, num_updates=50500, lr=0.00014072, gnorm=0.675, train_wall=54, wall=27846
2020-12-20 01:53:11 | INFO | train_inner | epoch 021:   1640 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.995, loss=4.945, nll_loss=2.105, ppl=4.3, wps=27319, ups=1.85, wpb=14781.8, bsz=514, num_updates=50600, lr=0.00014058, gnorm=0.683, train_wall=54, wall=27900
2020-12-20 01:54:05 | INFO | train_inner | epoch 021:   1740 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.974, loss=4.933, nll_loss=2.095, ppl=4.27, wps=27317.2, ups=1.85, wpb=14779.9, bsz=516.2, num_updates=50700, lr=0.000140442, gnorm=0.666, train_wall=54, wall=27954
2020-12-20 01:54:59 | INFO | train_inner | epoch 021:   1840 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.038, loss=4.96, nll_loss=2.116, ppl=4.33, wps=27414.5, ups=1.85, wpb=14783.4, bsz=494.4, num_updates=50800, lr=0.000140303, gnorm=0.667, train_wall=54, wall=28008
2020-12-20 01:55:52 | INFO | train_inner | epoch 021:   1940 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.982, loss=4.947, nll_loss=2.109, ppl=4.32, wps=27445.6, ups=1.86, wpb=14790.6, bsz=528.6, num_updates=50900, lr=0.000140165, gnorm=0.68, train_wall=54, wall=28062
2020-12-20 01:56:46 | INFO | train_inner | epoch 021:   2040 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.017, loss=4.955, nll_loss=2.114, ppl=4.33, wps=27571.2, ups=1.86, wpb=14829.5, bsz=509.9, num_updates=51000, lr=0.000140028, gnorm=0.686, train_wall=54, wall=28115
2020-12-20 01:57:40 | INFO | train_inner | epoch 021:   2140 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.978, loss=4.947, nll_loss=2.111, ppl=4.32, wps=27376.2, ups=1.85, wpb=14814.2, bsz=512.1, num_updates=51100, lr=0.000139891, gnorm=0.679, train_wall=54, wall=28169
2020-12-20 01:58:34 | INFO | train_inner | epoch 021:   2240 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.998, loss=4.952, nll_loss=2.113, ppl=4.33, wps=27572, ups=1.86, wpb=14860.4, bsz=510.6, num_updates=51200, lr=0.000139754, gnorm=0.68, train_wall=54, wall=28223
2020-12-20 01:59:28 | INFO | train_inner | epoch 021:   2340 / 2448 symm_kl=0.552, self_kl=0, self_cv=8.975, loss=4.936, nll_loss=2.099, ppl=4.28, wps=27652.9, ups=1.87, wpb=14823.5, bsz=507.4, num_updates=51300, lr=0.000139618, gnorm=0.685, train_wall=53, wall=28277
2020-12-20 02:00:22 | INFO | train_inner | epoch 021:   2440 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.998, loss=4.954, nll_loss=2.115, ppl=4.33, wps=27400.1, ups=1.85, wpb=14815.3, bsz=519.2, num_updates=51400, lr=0.000139482, gnorm=0.675, train_wall=54, wall=28331
2020-12-20 02:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 02:00:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 02:00:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 02:00:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 02:00:41 | INFO | valid | epoch 021 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.998 | nll_loss 8.024 | ppl 260.38 | bleu 15.83 | wps 5450.7 | wpb 7930.2 | bsz 208 | num_updates 51408 | best_bleu 16.16
2020-12-20 02:00:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 02:00:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 21 @ 51408 updates, score 15.83) (writing took 4.8703038692474365 seconds)
2020-12-20 02:00:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-12-20 02:00:46 | INFO | train | epoch 021 | symm_kl 0.559 | self_kl 0 | self_cv 9.019 | loss 4.934 | nll_loss 2.089 | ppl 4.25 | wps 26910.5 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 51408 | lr 0.000139471 | gnorm 0.676 | train_wall 1315 | wall 28355
2020-12-20 02:00:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:00:49 | INFO | fairseq.trainer | begin training epoch 22
2020-12-20 02:00:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:00:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:01:44 | INFO | train_inner | epoch 022:     92 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.105, loss=4.905, nll_loss=2.042, ppl=4.12, wps=18021.3, ups=1.22, wpb=14715, bsz=495.1, num_updates=51500, lr=0.000139347, gnorm=0.668, train_wall=53, wall=28413
2020-12-20 02:02:37 | INFO | train_inner | epoch 022:    192 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.078, loss=4.914, nll_loss=2.057, ppl=4.16, wps=27505.6, ups=1.86, wpb=14808.5, bsz=515.9, num_updates=51600, lr=0.000139212, gnorm=0.676, train_wall=54, wall=28467
2020-12-20 02:03:31 | INFO | train_inner | epoch 022:    292 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.032, loss=4.9, nll_loss=2.049, ppl=4.14, wps=27456, ups=1.85, wpb=14824.8, bsz=562.4, num_updates=51700, lr=0.000139077, gnorm=0.687, train_wall=54, wall=28521
2020-12-20 02:04:25 | INFO | train_inner | epoch 022:    392 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.074, loss=4.909, nll_loss=2.052, ppl=4.15, wps=27471.1, ups=1.86, wpb=14807.2, bsz=501.4, num_updates=51800, lr=0.000138943, gnorm=0.67, train_wall=54, wall=28574
2020-12-20 02:05:19 | INFO | train_inner | epoch 022:    492 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.032, loss=4.899, nll_loss=2.047, ppl=4.13, wps=27451, ups=1.85, wpb=14850.4, bsz=522.6, num_updates=51900, lr=0.000138809, gnorm=0.686, train_wall=54, wall=28629
2020-12-20 02:06:13 | INFO | train_inner | epoch 022:    592 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.044, loss=4.914, nll_loss=2.063, ppl=4.18, wps=27568.1, ups=1.86, wpb=14838.9, bsz=515.3, num_updates=52000, lr=0.000138675, gnorm=0.682, train_wall=54, wall=28682
2020-12-20 02:07:07 | INFO | train_inner | epoch 022:    692 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.023, loss=4.92, nll_loss=2.073, ppl=4.21, wps=27406, ups=1.85, wpb=14790, bsz=526, num_updates=52100, lr=0.000138542, gnorm=0.68, train_wall=54, wall=28736
2020-12-20 02:08:01 | INFO | train_inner | epoch 022:    792 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.027, loss=4.919, nll_loss=2.07, ppl=4.2, wps=27497.4, ups=1.85, wpb=14865.5, bsz=504.2, num_updates=52200, lr=0.000138409, gnorm=0.668, train_wall=54, wall=28790
2020-12-20 02:08:55 | INFO | train_inner | epoch 022:    892 / 2448 symm_kl=0.566, self_kl=0, self_cv=9, loss=4.924, nll_loss=2.08, ppl=4.23, wps=27205, ups=1.85, wpb=14683, bsz=508.5, num_updates=52300, lr=0.000138277, gnorm=0.672, train_wall=54, wall=28844
2020-12-20 02:09:49 | INFO | train_inner | epoch 022:    992 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.032, loss=4.931, nll_loss=2.084, ppl=4.24, wps=27308.7, ups=1.85, wpb=14801.3, bsz=506.2, num_updates=52400, lr=0.000138145, gnorm=0.682, train_wall=54, wall=28899
2020-12-20 02:10:44 | INFO | train_inner | epoch 022:   1092 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.002, loss=4.935, nll_loss=2.093, ppl=4.27, wps=27291.6, ups=1.85, wpb=14781.9, bsz=499, num_updates=52500, lr=0.000138013, gnorm=0.675, train_wall=54, wall=28953
2020-12-20 02:11:37 | INFO | train_inner | epoch 022:   1192 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.019, loss=4.936, nll_loss=2.091, ppl=4.26, wps=27737.8, ups=1.86, wpb=14879.2, bsz=511.2, num_updates=52600, lr=0.000137882, gnorm=0.672, train_wall=53, wall=29006
2020-12-20 02:12:31 | INFO | train_inner | epoch 022:   1292 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.049, loss=4.934, nll_loss=2.085, ppl=4.24, wps=27441.5, ups=1.86, wpb=14790.9, bsz=509.3, num_updates=52700, lr=0.000137751, gnorm=0.673, train_wall=54, wall=29060
2020-12-20 02:13:25 | INFO | train_inner | epoch 022:   1392 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.005, loss=4.923, nll_loss=2.079, ppl=4.23, wps=27453.9, ups=1.86, wpb=14763.5, bsz=506.2, num_updates=52800, lr=0.00013762, gnorm=0.688, train_wall=54, wall=29114
2020-12-20 02:14:19 | INFO | train_inner | epoch 022:   1492 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.018, loss=4.955, nll_loss=2.113, ppl=4.33, wps=27284.6, ups=1.85, wpb=14738.8, bsz=479.4, num_updates=52900, lr=0.00013749, gnorm=0.688, train_wall=54, wall=29168
2020-12-20 02:15:13 | INFO | train_inner | epoch 022:   1592 / 2448 symm_kl=0.551, self_kl=0, self_cv=8.974, loss=4.909, nll_loss=2.068, ppl=4.19, wps=27549.5, ups=1.85, wpb=14866.5, bsz=539, num_updates=53000, lr=0.000137361, gnorm=0.673, train_wall=54, wall=29222
2020-12-20 02:16:07 | INFO | train_inner | epoch 022:   1692 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.99, loss=4.944, nll_loss=2.105, ppl=4.3, wps=27513.9, ups=1.85, wpb=14852.5, bsz=494.6, num_updates=53100, lr=0.000137231, gnorm=0.682, train_wall=54, wall=29276
2020-12-20 02:17:01 | INFO | train_inner | epoch 022:   1792 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.984, loss=4.946, nll_loss=2.108, ppl=4.31, wps=27398.1, ups=1.85, wpb=14832.6, bsz=522.9, num_updates=53200, lr=0.000137102, gnorm=0.679, train_wall=54, wall=29330
2020-12-20 02:17:55 | INFO | train_inner | epoch 022:   1892 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.024, loss=4.953, nll_loss=2.111, ppl=4.32, wps=27509.7, ups=1.86, wpb=14812.6, bsz=483.4, num_updates=53300, lr=0.000136973, gnorm=0.705, train_wall=54, wall=29384
2020-12-20 02:18:49 | INFO | train_inner | epoch 022:   1992 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.97, loss=4.936, nll_loss=2.1, ppl=4.29, wps=27416.6, ups=1.85, wpb=14816.9, bsz=529.3, num_updates=53400, lr=0.000136845, gnorm=0.68, train_wall=54, wall=29438
2020-12-20 02:19:43 | INFO | train_inner | epoch 022:   2092 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.985, loss=4.931, nll_loss=2.092, ppl=4.26, wps=27552.4, ups=1.85, wpb=14876.3, bsz=534.2, num_updates=53500, lr=0.000136717, gnorm=0.682, train_wall=54, wall=29492
2020-12-20 02:20:37 | INFO | train_inner | epoch 022:   2192 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.007, loss=4.936, nll_loss=2.094, ppl=4.27, wps=27538.3, ups=1.86, wpb=14823.3, bsz=502.2, num_updates=53600, lr=0.00013659, gnorm=0.705, train_wall=54, wall=29546
2020-12-20 02:21:30 | INFO | train_inner | epoch 022:   2292 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.991, loss=4.951, nll_loss=2.113, ppl=4.33, wps=27557.8, ups=1.86, wpb=14804.3, bsz=498.2, num_updates=53700, lr=0.000136462, gnorm=0.69, train_wall=54, wall=29600
2020-12-20 02:22:25 | INFO | train_inner | epoch 022:   2392 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.017, loss=4.944, nll_loss=2.101, ppl=4.29, wps=27382.7, ups=1.84, wpb=14877.6, bsz=518.2, num_updates=53800, lr=0.000136335, gnorm=0.682, train_wall=54, wall=29654
2020-12-20 02:22:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 02:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 02:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 02:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 02:23:09 | INFO | valid | epoch 022 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.066 | nll_loss 8.102 | ppl 274.84 | bleu 15.95 | wps 5726.9 | wpb 7930.2 | bsz 208 | num_updates 53856 | best_bleu 16.16
2020-12-20 02:23:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 02:23:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 22 @ 53856 updates, score 15.95) (writing took 4.984547505155206 seconds)
2020-12-20 02:23:14 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-12-20 02:23:14 | INFO | train | epoch 022 | symm_kl 0.559 | self_kl 0 | self_cv 9.02 | loss 4.928 | nll_loss 2.083 | ppl 4.24 | wps 26887.4 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 53856 | lr 0.000136265 | gnorm 0.681 | train_wall 1317 | wall 29703
2020-12-20 02:23:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:23:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:23:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:23:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:23:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:17 | INFO | fairseq.trainer | begin training epoch 23
2020-12-20 02:23:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:23:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:23:46 | INFO | train_inner | epoch 023:     44 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.031, loss=4.915, nll_loss=2.066, ppl=4.19, wps=18075.4, ups=1.23, wpb=14680.1, bsz=506.2, num_updates=53900, lr=0.000136209, gnorm=0.676, train_wall=54, wall=29735
2020-12-20 02:24:40 | INFO | train_inner | epoch 023:    144 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.1, loss=4.906, nll_loss=2.045, ppl=4.13, wps=27545.8, ups=1.86, wpb=14824.6, bsz=502.5, num_updates=54000, lr=0.000136083, gnorm=0.671, train_wall=54, wall=29789
2020-12-20 02:25:34 | INFO | train_inner | epoch 023:    244 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.08, loss=4.901, nll_loss=2.042, ppl=4.12, wps=27599, ups=1.85, wpb=14893.1, bsz=517.1, num_updates=54100, lr=0.000135957, gnorm=0.688, train_wall=54, wall=29843
2020-12-20 02:26:28 | INFO | train_inner | epoch 023:    344 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.05, loss=4.91, nll_loss=2.057, ppl=4.16, wps=27420.8, ups=1.85, wpb=14793, bsz=511.3, num_updates=54200, lr=0.000135831, gnorm=0.697, train_wall=54, wall=29897
2020-12-20 02:27:22 | INFO | train_inner | epoch 023:    444 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.054, loss=4.887, nll_loss=2.031, ppl=4.09, wps=27592.1, ups=1.85, wpb=14927.3, bsz=527.4, num_updates=54300, lr=0.000135706, gnorm=0.68, train_wall=54, wall=29951
2020-12-20 02:28:16 | INFO | train_inner | epoch 023:    544 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.04, loss=4.898, nll_loss=2.045, ppl=4.13, wps=27473.7, ups=1.85, wpb=14873, bsz=508.2, num_updates=54400, lr=0.000135582, gnorm=0.674, train_wall=54, wall=30005
2020-12-20 02:29:10 | INFO | train_inner | epoch 023:    644 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.024, loss=4.919, nll_loss=2.071, ppl=4.2, wps=27194.4, ups=1.84, wpb=14749.8, bsz=520.6, num_updates=54500, lr=0.000135457, gnorm=0.694, train_wall=54, wall=30059
2020-12-20 02:30:04 | INFO | train_inner | epoch 023:    744 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.022, loss=4.918, nll_loss=2.071, ppl=4.2, wps=27459.3, ups=1.85, wpb=14861.4, bsz=487.7, num_updates=54600, lr=0.000135333, gnorm=0.677, train_wall=54, wall=30113
2020-12-20 02:30:59 | INFO | train_inner | epoch 023:    844 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.041, loss=4.922, nll_loss=2.072, ppl=4.21, wps=27300.9, ups=1.84, wpb=14824.3, bsz=519.2, num_updates=54700, lr=0.000135209, gnorm=0.684, train_wall=54, wall=30168
2020-12-20 02:31:52 | INFO | train_inner | epoch 023:    944 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.009, loss=4.913, nll_loss=2.068, ppl=4.19, wps=27659, ups=1.86, wpb=14882, bsz=514.2, num_updates=54800, lr=0.000135086, gnorm=0.685, train_wall=54, wall=30222
2020-12-20 02:32:46 | INFO | train_inner | epoch 023:   1044 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.025, loss=4.905, nll_loss=2.056, ppl=4.16, wps=27689.2, ups=1.85, wpb=14932.3, bsz=518.9, num_updates=54900, lr=0.000134963, gnorm=0.669, train_wall=54, wall=30276
2020-12-20 02:33:40 | INFO | train_inner | epoch 023:   1144 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.002, loss=4.933, nll_loss=2.091, ppl=4.26, wps=27207.7, ups=1.85, wpb=14685.7, bsz=515.4, num_updates=55000, lr=0.00013484, gnorm=0.689, train_wall=54, wall=30329
2020-12-20 02:34:34 | INFO | train_inner | epoch 023:   1244 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.03, loss=4.933, nll_loss=2.087, ppl=4.25, wps=27171.3, ups=1.85, wpb=14701, bsz=485.8, num_updates=55100, lr=0.000134718, gnorm=0.683, train_wall=54, wall=30384
2020-12-20 02:35:28 | INFO | train_inner | epoch 023:   1344 / 2448 symm_kl=0.559, self_kl=0, self_cv=9, loss=4.917, nll_loss=2.073, ppl=4.21, wps=27395.3, ups=1.86, wpb=14766.5, bsz=525.3, num_updates=55200, lr=0.000134595, gnorm=0.688, train_wall=54, wall=30437
2020-12-20 02:36:22 | INFO | train_inner | epoch 023:   1444 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.97, loss=4.906, nll_loss=2.065, ppl=4.19, wps=27487.8, ups=1.85, wpb=14820.6, bsz=554, num_updates=55300, lr=0.000134474, gnorm=0.704, train_wall=54, wall=30491
2020-12-20 02:37:16 | INFO | train_inner | epoch 023:   1544 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.023, loss=4.96, nll_loss=2.118, ppl=4.34, wps=27401.9, ups=1.86, wpb=14761.6, bsz=497.6, num_updates=55400, lr=0.000134352, gnorm=0.691, train_wall=54, wall=30545
2020-12-20 02:38:10 | INFO | train_inner | epoch 023:   1644 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.997, loss=4.938, nll_loss=2.097, ppl=4.28, wps=27301.4, ups=1.86, wpb=14715.9, bsz=509.4, num_updates=55500, lr=0.000134231, gnorm=0.701, train_wall=54, wall=30599
2020-12-20 02:39:04 | INFO | train_inner | epoch 023:   1744 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.013, loss=4.943, nll_loss=2.101, ppl=4.29, wps=27382.1, ups=1.85, wpb=14781.5, bsz=496.7, num_updates=55600, lr=0.00013411, gnorm=0.702, train_wall=54, wall=30653
2020-12-20 02:39:58 | INFO | train_inner | epoch 023:   1844 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.005, loss=4.937, nll_loss=2.096, ppl=4.27, wps=27568.8, ups=1.86, wpb=14827.9, bsz=504, num_updates=55700, lr=0.00013399, gnorm=0.674, train_wall=54, wall=30707
2020-12-20 02:40:52 | INFO | train_inner | epoch 023:   1944 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.99, loss=4.925, nll_loss=2.084, ppl=4.24, wps=27606, ups=1.86, wpb=14880.6, bsz=527.4, num_updates=55800, lr=0.00013387, gnorm=0.676, train_wall=54, wall=30761
2020-12-20 02:41:46 | INFO | train_inner | epoch 023:   2044 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.007, loss=4.929, nll_loss=2.087, ppl=4.25, wps=27485.8, ups=1.85, wpb=14845.4, bsz=524.1, num_updates=55900, lr=0.00013375, gnorm=0.699, train_wall=54, wall=30815
2020-12-20 02:42:40 | INFO | train_inner | epoch 023:   2144 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.996, loss=4.942, nll_loss=2.102, ppl=4.29, wps=27377.1, ups=1.85, wpb=14838.1, bsz=496.5, num_updates=56000, lr=0.000133631, gnorm=0.695, train_wall=54, wall=30869
2020-12-20 02:43:34 | INFO | train_inner | epoch 023:   2244 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.994, loss=4.943, nll_loss=2.104, ppl=4.3, wps=27519.4, ups=1.86, wpb=14802, bsz=512.6, num_updates=56100, lr=0.000133511, gnorm=0.699, train_wall=54, wall=30923
2020-12-20 02:44:28 | INFO | train_inner | epoch 023:   2344 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.986, loss=4.937, nll_loss=2.099, ppl=4.28, wps=27333.7, ups=1.86, wpb=14725.5, bsz=513.1, num_updates=56200, lr=0.000133393, gnorm=0.694, train_wall=54, wall=30977
2020-12-20 02:45:22 | INFO | train_inner | epoch 023:   2444 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.013, loss=4.945, nll_loss=2.104, ppl=4.3, wps=27400.6, ups=1.85, wpb=14810.4, bsz=497.6, num_updates=56300, lr=0.000133274, gnorm=0.689, train_wall=54, wall=31031
2020-12-20 02:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 02:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 02:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 02:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 02:45:38 | INFO | valid | epoch 023 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.077 | nll_loss 8.107 | ppl 275.67 | bleu 15.88 | wps 5554.1 | wpb 7930.2 | bsz 208 | num_updates 56304 | best_bleu 16.16
2020-12-20 02:45:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 02:45:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 23 @ 56304 updates, score 15.88) (writing took 5.098420947790146 seconds)
2020-12-20 02:45:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-12-20 02:45:43 | INFO | train | epoch 023 | symm_kl 0.559 | self_kl 0 | self_cv 9.02 | loss 4.923 | nll_loss 2.076 | ppl 4.22 | wps 26872.3 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 56304 | lr 0.000133269 | gnorm 0.687 | train_wall 1317 | wall 31052
2020-12-20 02:45:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:45:46 | INFO | fairseq.trainer | begin training epoch 24
2020-12-20 02:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 02:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 02:46:43 | INFO | train_inner | epoch 024:     96 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.044, loss=4.89, nll_loss=2.036, ppl=4.1, wps=18049.3, ups=1.23, wpb=14728.4, bsz=524.2, num_updates=56400, lr=0.000133156, gnorm=0.689, train_wall=53, wall=31112
2020-12-20 02:47:37 | INFO | train_inner | epoch 024:    196 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.081, loss=4.911, nll_loss=2.053, ppl=4.15, wps=27254.5, ups=1.85, wpb=14743.2, bsz=524.5, num_updates=56500, lr=0.000133038, gnorm=0.687, train_wall=54, wall=31166
2020-12-20 02:48:32 | INFO | train_inner | epoch 024:    296 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.037, loss=4.882, nll_loss=2.028, ppl=4.08, wps=27309, ups=1.84, wpb=14805.1, bsz=547, num_updates=56600, lr=0.00013292, gnorm=0.69, train_wall=54, wall=31221
2020-12-20 02:49:25 | INFO | train_inner | epoch 024:    396 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.052, loss=4.897, nll_loss=2.043, ppl=4.12, wps=27543, ups=1.86, wpb=14815.2, bsz=527.4, num_updates=56700, lr=0.000132803, gnorm=0.681, train_wall=54, wall=31274
2020-12-20 02:50:19 | INFO | train_inner | epoch 024:    496 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.057, loss=4.903, nll_loss=2.049, ppl=4.14, wps=27466.7, ups=1.85, wpb=14820, bsz=511, num_updates=56800, lr=0.000132686, gnorm=0.682, train_wall=54, wall=31328
2020-12-20 02:51:13 | INFO | train_inner | epoch 024:    596 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.073, loss=4.927, nll_loss=2.073, ppl=4.21, wps=27436.3, ups=1.86, wpb=14743.5, bsz=490.8, num_updates=56900, lr=0.00013257, gnorm=0.701, train_wall=54, wall=31382
2020-12-20 02:52:07 | INFO | train_inner | epoch 024:    696 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.028, loss=4.915, nll_loss=2.066, ppl=4.19, wps=27533.5, ups=1.86, wpb=14839.2, bsz=511.3, num_updates=57000, lr=0.000132453, gnorm=0.687, train_wall=54, wall=31436
2020-12-20 02:53:01 | INFO | train_inner | epoch 024:    796 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.036, loss=4.929, nll_loss=2.081, ppl=4.23, wps=27408.8, ups=1.86, wpb=14722.4, bsz=510.1, num_updates=57100, lr=0.000132337, gnorm=0.708, train_wall=54, wall=31490
2020-12-20 02:53:55 | INFO | train_inner | epoch 024:    896 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.043, loss=4.91, nll_loss=2.059, ppl=4.17, wps=27548.1, ups=1.85, wpb=14864.9, bsz=543.1, num_updates=57200, lr=0.000132221, gnorm=0.697, train_wall=54, wall=31544
2020-12-20 02:54:49 | INFO | train_inner | epoch 024:    996 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.016, loss=4.918, nll_loss=2.072, ppl=4.2, wps=27305.8, ups=1.85, wpb=14726.8, bsz=501.6, num_updates=57300, lr=0.000132106, gnorm=0.677, train_wall=54, wall=31598
2020-12-20 02:55:42 | INFO | train_inner | epoch 024:   1096 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.992, loss=4.906, nll_loss=2.062, ppl=4.18, wps=27321.6, ups=1.85, wpb=14730, bsz=501.5, num_updates=57400, lr=0.000131991, gnorm=0.69, train_wall=54, wall=31652
2020-12-20 02:56:37 | INFO | train_inner | epoch 024:   1196 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.025, loss=4.929, nll_loss=2.083, ppl=4.24, wps=27636.1, ups=1.85, wpb=14946.8, bsz=520.1, num_updates=57500, lr=0.000131876, gnorm=0.686, train_wall=54, wall=31706
2020-12-20 02:57:31 | INFO | train_inner | epoch 024:   1296 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.016, loss=4.918, nll_loss=2.072, ppl=4.2, wps=27395.3, ups=1.85, wpb=14828.4, bsz=510.6, num_updates=57600, lr=0.000131762, gnorm=0.703, train_wall=54, wall=31760
2020-12-20 02:58:25 | INFO | train_inner | epoch 024:   1396 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.034, loss=4.943, nll_loss=2.097, ppl=4.28, wps=27143.3, ups=1.84, wpb=14713.5, bsz=495.2, num_updates=57700, lr=0.000131647, gnorm=0.694, train_wall=54, wall=31814
2020-12-20 02:59:19 | INFO | train_inner | epoch 024:   1496 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.046, loss=4.92, nll_loss=2.069, ppl=4.2, wps=27496.9, ups=1.85, wpb=14828.9, bsz=478.9, num_updates=57800, lr=0.000131533, gnorm=0.691, train_wall=54, wall=31868
2020-12-20 03:00:13 | INFO | train_inner | epoch 024:   1596 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.032, loss=4.927, nll_loss=2.08, ppl=4.23, wps=27540.2, ups=1.85, wpb=14884.6, bsz=490, num_updates=57900, lr=0.00013142, gnorm=0.686, train_wall=54, wall=31922
2020-12-20 03:01:07 | INFO | train_inner | epoch 024:   1696 / 2448 symm_kl=0.551, self_kl=0, self_cv=8.971, loss=4.903, nll_loss=2.063, ppl=4.18, wps=27460.3, ups=1.86, wpb=14798.2, bsz=510.9, num_updates=58000, lr=0.000131306, gnorm=0.678, train_wall=54, wall=31976
2020-12-20 03:02:01 | INFO | train_inner | epoch 024:   1796 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.984, loss=4.917, nll_loss=2.076, ppl=4.22, wps=27652.3, ups=1.86, wpb=14892.3, bsz=516.2, num_updates=58100, lr=0.000131193, gnorm=0.672, train_wall=54, wall=32030
2020-12-20 03:02:54 | INFO | train_inner | epoch 024:   1896 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.011, loss=4.941, nll_loss=2.1, ppl=4.29, wps=27599.6, ups=1.86, wpb=14840.4, bsz=499.6, num_updates=58200, lr=0.000131081, gnorm=0.697, train_wall=54, wall=32084
2020-12-20 03:03:48 | INFO | train_inner | epoch 024:   1996 / 2448 symm_kl=0.552, self_kl=0, self_cv=8.968, loss=4.911, nll_loss=2.073, ppl=4.21, wps=27672.7, ups=1.86, wpb=14891.9, bsz=537, num_updates=58300, lr=0.000130968, gnorm=0.69, train_wall=54, wall=32137
2020-12-20 03:04:42 | INFO | train_inner | epoch 024:   2096 / 2448 symm_kl=0.55, self_kl=0, self_cv=8.97, loss=4.899, nll_loss=2.059, ppl=4.17, wps=27603, ups=1.86, wpb=14857.3, bsz=512.2, num_updates=58400, lr=0.000130856, gnorm=0.7, train_wall=54, wall=32191
2020-12-20 03:05:36 | INFO | train_inner | epoch 024:   2196 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.994, loss=4.923, nll_loss=2.082, ppl=4.23, wps=27449.7, ups=1.85, wpb=14852.5, bsz=493.3, num_updates=58500, lr=0.000130744, gnorm=0.687, train_wall=54, wall=32245
2020-12-20 03:06:30 | INFO | train_inner | epoch 024:   2296 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.015, loss=4.946, nll_loss=2.104, ppl=4.3, wps=27535.6, ups=1.86, wpb=14804.7, bsz=516.4, num_updates=58600, lr=0.000130632, gnorm=0.707, train_wall=54, wall=32299
2020-12-20 03:07:24 | INFO | train_inner | epoch 024:   2396 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.015, loss=4.948, nll_loss=2.107, ppl=4.31, wps=27389.2, ups=1.85, wpb=14787.1, bsz=491.2, num_updates=58700, lr=0.000130521, gnorm=0.705, train_wall=54, wall=32353
2020-12-20 03:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 03:07:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:07:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:07:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:07:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:07:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:07:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:07:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:07:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:07:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:07:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 03:08:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 03:08:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 03:08:06 | INFO | valid | epoch 024 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.075 | nll_loss 8.105 | ppl 275.35 | bleu 15.81 | wps 5439.1 | wpb 7930.2 | bsz 208 | num_updates 58752 | best_bleu 16.16
2020-12-20 03:08:06 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 03:08:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 24 @ 58752 updates, score 15.81) (writing took 5.08089261315763 seconds)
2020-12-20 03:08:12 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-12-20 03:08:12 | INFO | train | epoch 024 | symm_kl 0.56 | self_kl 0 | self_cv 9.021 | loss 4.917 | nll_loss 2.071 | ppl 4.2 | wps 26888.6 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 58752 | lr 0.000130463 | gnorm 0.691 | train_wall 1316 | wall 32401
2020-12-20 03:08:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:08:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:08:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:08:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:08:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:14 | INFO | fairseq.trainer | begin training epoch 25
2020-12-20 03:08:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:08:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:08:46 | INFO | train_inner | epoch 025:     48 / 2448 symm_kl=0.551, self_kl=0, self_cv=9.001, loss=4.894, nll_loss=2.048, ppl=4.13, wps=17940.6, ups=1.22, wpb=14722.9, bsz=532.3, num_updates=58800, lr=0.00013041, gnorm=0.695, train_wall=54, wall=32435
2020-12-20 03:09:40 | INFO | train_inner | epoch 025:    148 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.1, loss=4.879, nll_loss=2.014, ppl=4.04, wps=27635.2, ups=1.86, wpb=14821.4, bsz=495, num_updates=58900, lr=0.000130299, gnorm=0.676, train_wall=53, wall=32489
2020-12-20 03:10:34 | INFO | train_inner | epoch 025:    248 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.075, loss=4.9, nll_loss=2.042, ppl=4.12, wps=27351.7, ups=1.84, wpb=14845.7, bsz=501.5, num_updates=59000, lr=0.000130189, gnorm=0.695, train_wall=54, wall=32543
2020-12-20 03:11:28 | INFO | train_inner | epoch 025:    348 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.065, loss=4.903, nll_loss=2.047, ppl=4.13, wps=27406.8, ups=1.85, wpb=14847.5, bsz=504.2, num_updates=59100, lr=0.000130079, gnorm=0.691, train_wall=54, wall=32597
2020-12-20 03:12:22 | INFO | train_inner | epoch 025:    448 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.006, loss=4.88, nll_loss=2.031, ppl=4.09, wps=27578.1, ups=1.85, wpb=14931.9, bsz=528.6, num_updates=59200, lr=0.000129969, gnorm=0.676, train_wall=54, wall=32651
2020-12-20 03:13:16 | INFO | train_inner | epoch 025:    548 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.079, loss=4.918, nll_loss=2.062, ppl=4.17, wps=27406.5, ups=1.85, wpb=14798.6, bsz=480.2, num_updates=59300, lr=0.000129859, gnorm=0.694, train_wall=54, wall=32705
2020-12-20 03:14:10 | INFO | train_inner | epoch 025:    648 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.038, loss=4.893, nll_loss=2.041, ppl=4.12, wps=27519.9, ups=1.85, wpb=14897.2, bsz=514.4, num_updates=59400, lr=0.00012975, gnorm=0.697, train_wall=54, wall=32759
2020-12-20 03:15:04 | INFO | train_inner | epoch 025:    748 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.025, loss=4.898, nll_loss=2.049, ppl=4.14, wps=27412.9, ups=1.86, wpb=14760.3, bsz=517.1, num_updates=59500, lr=0.000129641, gnorm=0.702, train_wall=54, wall=32813
2020-12-20 03:15:58 | INFO | train_inner | epoch 025:    848 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.049, loss=4.917, nll_loss=2.066, ppl=4.19, wps=27650.3, ups=1.86, wpb=14883.3, bsz=504.2, num_updates=59600, lr=0.000129532, gnorm=0.71, train_wall=54, wall=32867
2020-12-20 03:16:52 | INFO | train_inner | epoch 025:    948 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.036, loss=4.899, nll_loss=2.048, ppl=4.13, wps=27765.2, ups=1.86, wpb=14922.1, bsz=523.9, num_updates=59700, lr=0.000129423, gnorm=0.695, train_wall=54, wall=32921
2020-12-20 03:17:46 | INFO | train_inner | epoch 025:   1048 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.005, loss=4.919, nll_loss=2.075, ppl=4.21, wps=27344.1, ups=1.85, wpb=14756.9, bsz=520.4, num_updates=59800, lr=0.000129315, gnorm=0.702, train_wall=54, wall=32975
2020-12-20 03:18:40 | INFO | train_inner | epoch 025:   1148 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.994, loss=4.897, nll_loss=2.052, ppl=4.15, wps=27530.3, ups=1.85, wpb=14870.6, bsz=524.2, num_updates=59900, lr=0.000129207, gnorm=0.698, train_wall=54, wall=33029
2020-12-20 03:19:34 | INFO | train_inner | epoch 025:   1248 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.027, loss=4.936, nll_loss=2.09, ppl=4.26, wps=27344.6, ups=1.86, wpb=14728.6, bsz=484.5, num_updates=60000, lr=0.000129099, gnorm=0.71, train_wall=54, wall=33083
2020-12-20 03:20:27 | INFO | train_inner | epoch 025:   1348 / 2448 symm_kl=0.549, self_kl=0, self_cv=8.968, loss=4.883, nll_loss=2.04, ppl=4.11, wps=27518.2, ups=1.86, wpb=14821.4, bsz=566.2, num_updates=60100, lr=0.000128992, gnorm=0.694, train_wall=54, wall=33137
2020-12-20 03:21:21 | INFO | train_inner | epoch 025:   1448 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.024, loss=4.932, nll_loss=2.087, ppl=4.25, wps=27444, ups=1.85, wpb=14832, bsz=497, num_updates=60200, lr=0.000128885, gnorm=0.689, train_wall=54, wall=33191
2020-12-20 03:22:15 | INFO | train_inner | epoch 025:   1548 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.016, loss=4.911, nll_loss=2.065, ppl=4.18, wps=27638.1, ups=1.85, wpb=14922.2, bsz=510.7, num_updates=60300, lr=0.000128778, gnorm=0.696, train_wall=54, wall=33245
2020-12-20 03:23:10 | INFO | train_inner | epoch 025:   1648 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.02, loss=4.924, nll_loss=2.079, ppl=4.22, wps=27441.5, ups=1.84, wpb=14885.9, bsz=544.6, num_updates=60400, lr=0.000128671, gnorm=0.702, train_wall=54, wall=33299
2020-12-20 03:24:04 | INFO | train_inner | epoch 025:   1748 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.035, loss=4.929, nll_loss=2.082, ppl=4.23, wps=27229.9, ups=1.85, wpb=14755.9, bsz=494.4, num_updates=60500, lr=0.000128565, gnorm=0.7, train_wall=54, wall=33353
2020-12-20 03:24:58 | INFO | train_inner | epoch 025:   1848 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.007, loss=4.931, nll_loss=2.089, ppl=4.25, wps=27258.5, ups=1.85, wpb=14756.5, bsz=506.7, num_updates=60600, lr=0.000128459, gnorm=0.699, train_wall=54, wall=33407
2020-12-20 03:25:52 | INFO | train_inner | epoch 025:   1948 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.021, loss=4.924, nll_loss=2.078, ppl=4.22, wps=27436, ups=1.86, wpb=14765.7, bsz=504.3, num_updates=60700, lr=0.000128353, gnorm=0.698, train_wall=54, wall=33461
2020-12-20 03:26:46 | INFO | train_inner | epoch 025:   2048 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.002, loss=4.934, nll_loss=2.093, ppl=4.27, wps=27326.2, ups=1.86, wpb=14725.3, bsz=508.3, num_updates=60800, lr=0.000128247, gnorm=0.693, train_wall=54, wall=33515
2020-12-20 03:27:40 | INFO | train_inner | epoch 025:   2148 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.003, loss=4.933, nll_loss=2.091, ppl=4.26, wps=27288.1, ups=1.84, wpb=14803.9, bsz=496.9, num_updates=60900, lr=0.000128142, gnorm=0.686, train_wall=54, wall=33569
2020-12-20 03:28:34 | INFO | train_inner | epoch 025:   2248 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.983, loss=4.941, nll_loss=2.104, ppl=4.3, wps=27365.3, ups=1.85, wpb=14755.3, bsz=523.9, num_updates=61000, lr=0.000128037, gnorm=0.695, train_wall=54, wall=33623
2020-12-20 03:29:28 | INFO | train_inner | epoch 025:   2348 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.998, loss=4.94, nll_loss=2.1, ppl=4.29, wps=27216.9, ups=1.86, wpb=14669.5, bsz=493.2, num_updates=61100, lr=0.000127932, gnorm=0.691, train_wall=54, wall=33677
2020-12-20 03:30:22 | INFO | train_inner | epoch 025:   2448 / 2448 symm_kl=0.553, self_kl=0, self_cv=8.957, loss=4.915, nll_loss=2.079, ppl=4.23, wps=27112.9, ups=1.85, wpb=14663.8, bsz=533.9, num_updates=61200, lr=0.000127827, gnorm=0.704, train_wall=54, wall=33731
2020-12-20 03:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 03:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 03:30:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 03:30:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 03:30:36 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.052 | nll_loss 8.084 | ppl 271.27 | bleu 16.06 | wps 5717.9 | wpb 7930.2 | bsz 208 | num_updates 61200 | best_bleu 16.16
2020-12-20 03:30:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 03:30:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 25 @ 61200 updates, score 16.06) (writing took 5.2096066530793905 seconds)
2020-12-20 03:30:41 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-12-20 03:30:41 | INFO | train | epoch 025 | symm_kl 0.56 | self_kl 0 | self_cv 9.023 | loss 4.913 | nll_loss 2.066 | ppl 4.19 | wps 26865 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 61200 | lr 0.000127827 | gnorm 0.695 | train_wall 1318 | wall 33750
2020-12-20 03:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:44 | INFO | fairseq.trainer | begin training epoch 26
2020-12-20 03:30:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:30:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:30:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:31:43 | INFO | train_inner | epoch 026:    100 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.05, loss=4.881, nll_loss=2.025, ppl=4.07, wps=18205.8, ups=1.23, wpb=14847.9, bsz=527.1, num_updates=61300, lr=0.000127723, gnorm=0.7, train_wall=53, wall=33813
2020-12-20 03:32:37 | INFO | train_inner | epoch 026:    200 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.058, loss=4.891, nll_loss=2.035, ppl=4.1, wps=27389.5, ups=1.85, wpb=14776.7, bsz=504.7, num_updates=61400, lr=0.000127619, gnorm=0.689, train_wall=54, wall=33867
2020-12-20 03:33:31 | INFO | train_inner | epoch 026:    300 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.022, loss=4.873, nll_loss=2.02, ppl=4.06, wps=27335.8, ups=1.85, wpb=14741.1, bsz=527.9, num_updates=61500, lr=0.000127515, gnorm=0.713, train_wall=54, wall=33920
2020-12-20 03:34:25 | INFO | train_inner | epoch 026:    400 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.068, loss=4.886, nll_loss=2.028, ppl=4.08, wps=27425.3, ups=1.85, wpb=14837.3, bsz=498.6, num_updates=61600, lr=0.000127412, gnorm=0.697, train_wall=54, wall=33975
2020-12-20 03:35:19 | INFO | train_inner | epoch 026:    500 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.062, loss=4.903, nll_loss=2.048, ppl=4.13, wps=27516.5, ups=1.85, wpb=14859.7, bsz=530.4, num_updates=61700, lr=0.000127309, gnorm=0.707, train_wall=54, wall=34029
2020-12-20 03:36:13 | INFO | train_inner | epoch 026:    600 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.033, loss=4.903, nll_loss=2.053, ppl=4.15, wps=27390.2, ups=1.85, wpb=14794.7, bsz=507.9, num_updates=61800, lr=0.000127205, gnorm=0.709, train_wall=54, wall=34083
2020-12-20 03:37:07 | INFO | train_inner | epoch 026:    700 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.05, loss=4.901, nll_loss=2.048, ppl=4.14, wps=27572.7, ups=1.85, wpb=14885.8, bsz=539, num_updates=61900, lr=0.000127103, gnorm=0.701, train_wall=54, wall=34137
2020-12-20 03:38:01 | INFO | train_inner | epoch 026:    800 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.032, loss=4.899, nll_loss=2.048, ppl=4.14, wps=27327.1, ups=1.85, wpb=14757, bsz=509.8, num_updates=62000, lr=0.000127, gnorm=0.694, train_wall=54, wall=34191
2020-12-20 03:38:55 | INFO | train_inner | epoch 026:    900 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.039, loss=4.905, nll_loss=2.054, ppl=4.15, wps=27737, ups=1.86, wpb=14874.9, bsz=510.9, num_updates=62100, lr=0.000126898, gnorm=0.691, train_wall=53, wall=34244
2020-12-20 03:39:49 | INFO | train_inner | epoch 026:   1000 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.004, loss=4.896, nll_loss=2.049, ppl=4.14, wps=27700.5, ups=1.86, wpb=14867.7, bsz=532.6, num_updates=62200, lr=0.000126796, gnorm=0.69, train_wall=54, wall=34298
2020-12-20 03:40:43 | INFO | train_inner | epoch 026:   1100 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.029, loss=4.909, nll_loss=2.061, ppl=4.17, wps=27387.8, ups=1.85, wpb=14781.7, bsz=498.2, num_updates=62300, lr=0.000126694, gnorm=0.693, train_wall=54, wall=34352
2020-12-20 03:41:37 | INFO | train_inner | epoch 026:   1200 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.035, loss=4.904, nll_loss=2.054, ppl=4.15, wps=27531.1, ups=1.85, wpb=14851, bsz=511.4, num_updates=62400, lr=0.000126592, gnorm=0.7, train_wall=54, wall=34406
2020-12-20 03:42:31 | INFO | train_inner | epoch 026:   1300 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.032, loss=4.918, nll_loss=2.07, ppl=4.2, wps=27534.2, ups=1.86, wpb=14835.7, bsz=485.8, num_updates=62500, lr=0.000126491, gnorm=0.688, train_wall=54, wall=34460
2020-12-20 03:43:25 | INFO | train_inner | epoch 026:   1400 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.989, loss=4.908, nll_loss=2.066, ppl=4.19, wps=27360.2, ups=1.85, wpb=14777, bsz=534.6, num_updates=62600, lr=0.00012639, gnorm=0.701, train_wall=54, wall=34514
2020-12-20 03:44:19 | INFO | train_inner | epoch 026:   1500 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.029, loss=4.91, nll_loss=2.061, ppl=4.17, wps=27540.8, ups=1.85, wpb=14897.4, bsz=496.7, num_updates=62700, lr=0.000126289, gnorm=0.698, train_wall=54, wall=34568
2020-12-20 03:45:13 | INFO | train_inner | epoch 026:   1600 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.995, loss=4.894, nll_loss=2.049, ppl=4.14, wps=27514.9, ups=1.85, wpb=14902.7, bsz=518.1, num_updates=62800, lr=0.000126189, gnorm=0.696, train_wall=54, wall=34622
2020-12-20 03:46:07 | INFO | train_inner | epoch 026:   1700 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.023, loss=4.909, nll_loss=2.061, ppl=4.17, wps=27480.7, ups=1.85, wpb=14857.1, bsz=500.9, num_updates=62900, lr=0.000126088, gnorm=0.692, train_wall=54, wall=34676
2020-12-20 03:47:01 | INFO | train_inner | epoch 026:   1800 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.039, loss=4.925, nll_loss=2.077, ppl=4.22, wps=27386.1, ups=1.85, wpb=14801.8, bsz=507.4, num_updates=63000, lr=0.000125988, gnorm=0.692, train_wall=54, wall=34730
2020-12-20 03:47:55 | INFO | train_inner | epoch 026:   1900 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.021, loss=4.932, nll_loss=2.088, ppl=4.25, wps=27371.6, ups=1.85, wpb=14797, bsz=519.4, num_updates=63100, lr=0.000125888, gnorm=0.699, train_wall=54, wall=34784
2020-12-20 03:48:49 | INFO | train_inner | epoch 026:   2000 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.022, loss=4.936, nll_loss=2.092, ppl=4.26, wps=27445.1, ups=1.85, wpb=14819, bsz=484.7, num_updates=63200, lr=0.000125789, gnorm=0.702, train_wall=54, wall=34838
2020-12-20 03:49:43 | INFO | train_inner | epoch 026:   2100 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.003, loss=4.942, nll_loss=2.102, ppl=4.29, wps=27386.4, ups=1.86, wpb=14714.9, bsz=488.1, num_updates=63300, lr=0.000125689, gnorm=0.725, train_wall=54, wall=34892
2020-12-20 03:50:37 | INFO | train_inner | epoch 026:   2200 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.039, loss=4.93, nll_loss=2.083, ppl=4.24, wps=27466.6, ups=1.85, wpb=14826.4, bsz=485.4, num_updates=63400, lr=0.00012559, gnorm=0.707, train_wall=54, wall=34946
2020-12-20 03:51:31 | INFO | train_inner | epoch 026:   2300 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.942, loss=4.913, nll_loss=2.079, ppl=4.22, wps=27256.9, ups=1.85, wpb=14693.8, bsz=548.6, num_updates=63500, lr=0.000125491, gnorm=0.711, train_wall=54, wall=35000
2020-12-20 03:52:25 | INFO | train_inner | epoch 026:   2400 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.99, loss=4.932, nll_loss=2.093, ppl=4.27, wps=27381.2, ups=1.85, wpb=14762.7, bsz=527.4, num_updates=63600, lr=0.000125392, gnorm=0.689, train_wall=54, wall=35054
2020-12-20 03:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 03:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 03:53:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 03:53:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 03:53:05 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.013 | nll_loss 8.049 | ppl 264.83 | bleu 16.1 | wps 5471.9 | wpb 7930.2 | bsz 208 | num_updates 63648 | best_bleu 16.16
2020-12-20 03:53:05 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 03:53:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 26 @ 63648 updates, score 16.1) (writing took 4.763426901772618 seconds)
2020-12-20 03:53:09 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-12-20 03:53:09 | INFO | train | epoch 026 | symm_kl 0.56 | self_kl 0 | self_cv 9.025 | loss 4.908 | nll_loss 2.06 | ppl 4.17 | wps 26891.3 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 63648 | lr 0.000125345 | gnorm 0.7 | train_wall 1316 | wall 35098
2020-12-20 03:53:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:53:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:53:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:53:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:12 | INFO | fairseq.trainer | begin training epoch 27
2020-12-20 03:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 03:53:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 03:53:46 | INFO | train_inner | epoch 027:     52 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.039, loss=4.888, nll_loss=2.036, ppl=4.1, wps=18140.5, ups=1.23, wpb=14740.4, bsz=516.3, num_updates=63700, lr=0.000125294, gnorm=0.707, train_wall=53, wall=35135
2020-12-20 03:54:40 | INFO | train_inner | epoch 027:    152 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.06, loss=4.884, nll_loss=2.027, ppl=4.08, wps=27522.1, ups=1.86, wpb=14788.7, bsz=482.7, num_updates=63800, lr=0.000125196, gnorm=0.7, train_wall=54, wall=35189
2020-12-20 03:55:34 | INFO | train_inner | epoch 027:    252 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.053, loss=4.876, nll_loss=2.02, ppl=4.05, wps=27432.1, ups=1.85, wpb=14817.8, bsz=512, num_updates=63900, lr=0.000125098, gnorm=0.684, train_wall=54, wall=35243
2020-12-20 03:56:27 | INFO | train_inner | epoch 027:    352 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.052, loss=4.894, nll_loss=2.039, ppl=4.11, wps=27530.2, ups=1.86, wpb=14840.8, bsz=514.8, num_updates=64000, lr=0.000125, gnorm=0.699, train_wall=54, wall=35297
2020-12-20 03:57:21 | INFO | train_inner | epoch 027:    452 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.011, loss=4.891, nll_loss=2.043, ppl=4.12, wps=27443.3, ups=1.85, wpb=14827.2, bsz=520.1, num_updates=64100, lr=0.000124902, gnorm=0.707, train_wall=54, wall=35351
2020-12-20 03:58:15 | INFO | train_inner | epoch 027:    552 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.052, loss=4.895, nll_loss=2.041, ppl=4.11, wps=27429.8, ups=1.85, wpb=14788.7, bsz=499.7, num_updates=64200, lr=0.000124805, gnorm=0.698, train_wall=54, wall=35405
2020-12-20 03:59:09 | INFO | train_inner | epoch 027:    652 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.06, loss=4.914, nll_loss=2.061, ppl=4.17, wps=27257.2, ups=1.86, wpb=14683.5, bsz=506.8, num_updates=64300, lr=0.000124708, gnorm=0.721, train_wall=54, wall=35458
2020-12-20 04:00:03 | INFO | train_inner | epoch 027:    752 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.05, loss=4.924, nll_loss=2.074, ppl=4.21, wps=27176.8, ups=1.85, wpb=14695.5, bsz=513.6, num_updates=64400, lr=0.000124611, gnorm=0.707, train_wall=54, wall=35512
2020-12-20 04:00:57 | INFO | train_inner | epoch 027:    852 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.996, loss=4.883, nll_loss=2.036, ppl=4.1, wps=27612.2, ups=1.85, wpb=14918.7, bsz=562.5, num_updates=64500, lr=0.000124515, gnorm=0.688, train_wall=54, wall=35566
2020-12-20 04:01:52 | INFO | train_inner | epoch 027:    952 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.019, loss=4.887, nll_loss=2.037, ppl=4.11, wps=27351.1, ups=1.84, wpb=14830, bsz=519.2, num_updates=64600, lr=0.000124418, gnorm=0.712, train_wall=54, wall=35621
2020-12-20 04:02:45 | INFO | train_inner | epoch 027:   1052 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.041, loss=4.913, nll_loss=2.063, ppl=4.18, wps=27466.7, ups=1.86, wpb=14757.7, bsz=489.7, num_updates=64700, lr=0.000124322, gnorm=0.708, train_wall=54, wall=35674
2020-12-20 04:03:39 | INFO | train_inner | epoch 027:   1152 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.039, loss=4.918, nll_loss=2.07, ppl=4.2, wps=27488.9, ups=1.86, wpb=14814.7, bsz=518.2, num_updates=64800, lr=0.000124226, gnorm=0.711, train_wall=54, wall=35728
2020-12-20 04:04:33 | INFO | train_inner | epoch 027:   1252 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.024, loss=4.906, nll_loss=2.058, ppl=4.16, wps=27573.5, ups=1.86, wpb=14848.8, bsz=499.3, num_updates=64900, lr=0.00012413, gnorm=0.689, train_wall=54, wall=35782
2020-12-20 04:05:27 | INFO | train_inner | epoch 027:   1352 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.044, loss=4.91, nll_loss=2.06, ppl=4.17, wps=27555.6, ups=1.85, wpb=14871.1, bsz=501.1, num_updates=65000, lr=0.000124035, gnorm=0.71, train_wall=54, wall=35836
2020-12-20 04:06:21 | INFO | train_inner | epoch 027:   1452 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.025, loss=4.918, nll_loss=2.071, ppl=4.2, wps=27518.5, ups=1.86, wpb=14807.2, bsz=496, num_updates=65100, lr=0.000123939, gnorm=0.713, train_wall=54, wall=35890
2020-12-20 04:07:15 | INFO | train_inner | epoch 027:   1552 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.024, loss=4.922, nll_loss=2.076, ppl=4.22, wps=27391.8, ups=1.86, wpb=14731.6, bsz=500.4, num_updates=65200, lr=0.000123844, gnorm=0.72, train_wall=54, wall=35944
2020-12-20 04:08:09 | INFO | train_inner | epoch 027:   1652 / 2448 symm_kl=0.556, self_kl=0, self_cv=9.028, loss=4.898, nll_loss=2.048, ppl=4.14, wps=27249.1, ups=1.84, wpb=14840.1, bsz=528.6, num_updates=65300, lr=0.000123749, gnorm=0.697, train_wall=54, wall=35998
2020-12-20 04:09:03 | INFO | train_inner | epoch 027:   1752 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.991, loss=4.905, nll_loss=2.062, ppl=4.17, wps=27466.8, ups=1.85, wpb=14853.9, bsz=497.4, num_updates=65400, lr=0.000123655, gnorm=0.696, train_wall=54, wall=36052
2020-12-20 04:09:57 | INFO | train_inner | epoch 027:   1852 / 2448 symm_kl=0.554, self_kl=0, self_cv=9.009, loss=4.89, nll_loss=2.043, ppl=4.12, wps=27468.9, ups=1.85, wpb=14832.7, bsz=522.3, num_updates=65500, lr=0.00012356, gnorm=0.719, train_wall=54, wall=36106
2020-12-20 04:10:51 | INFO | train_inner | epoch 027:   1952 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.033, loss=4.916, nll_loss=2.068, ppl=4.19, wps=27412, ups=1.85, wpb=14802.2, bsz=502.2, num_updates=65600, lr=0.000123466, gnorm=0.703, train_wall=54, wall=36160
2020-12-20 04:11:45 | INFO | train_inner | epoch 027:   2052 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.032, loss=4.919, nll_loss=2.072, ppl=4.21, wps=27496, ups=1.85, wpb=14834.5, bsz=478.2, num_updates=65700, lr=0.000123372, gnorm=0.699, train_wall=54, wall=36214
2020-12-20 04:12:39 | INFO | train_inner | epoch 027:   2152 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.005, loss=4.907, nll_loss=2.063, ppl=4.18, wps=27418.1, ups=1.85, wpb=14805.3, bsz=519.9, num_updates=65800, lr=0.000123278, gnorm=0.701, train_wall=54, wall=36268
2020-12-20 04:13:33 | INFO | train_inner | epoch 027:   2252 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.998, loss=4.912, nll_loss=2.069, ppl=4.2, wps=27620.7, ups=1.86, wpb=14854.9, bsz=513.5, num_updates=65900, lr=0.000123185, gnorm=0.717, train_wall=54, wall=36322
2020-12-20 04:14:27 | INFO | train_inner | epoch 027:   2352 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.985, loss=4.91, nll_loss=2.069, ppl=4.2, wps=27538.1, ups=1.86, wpb=14842.3, bsz=550.5, num_updates=66000, lr=0.000123091, gnorm=0.713, train_wall=54, wall=36376
2020-12-20 04:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 04:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 04:15:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 04:15:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 04:15:33 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.04 | nll_loss 8.077 | ppl 269.96 | bleu 15.88 | wps 5304.2 | wpb 7930.2 | bsz 208 | num_updates 66096 | best_bleu 16.16
2020-12-20 04:15:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 04:15:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 27 @ 66096 updates, score 15.88) (writing took 5.016165301203728 seconds)
2020-12-20 04:15:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-12-20 04:15:38 | INFO | train | epoch 027 | symm_kl 0.56 | self_kl 0 | self_cv 9.026 | loss 4.904 | nll_loss 2.055 | ppl 4.16 | wps 26877.2 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 66096 | lr 0.000123002 | gnorm 0.706 | train_wall 1316 | wall 36447
2020-12-20 04:15:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:41 | INFO | fairseq.trainer | begin training epoch 28
2020-12-20 04:15:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:15:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:15:49 | INFO | train_inner | epoch 028:      4 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.995, loss=4.914, nll_loss=2.072, ppl=4.2, wps=17890.6, ups=1.21, wpb=14739.6, bsz=513.6, num_updates=66100, lr=0.000122998, gnorm=0.723, train_wall=54, wall=36458
2020-12-20 04:16:43 | INFO | train_inner | epoch 028:    104 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.063, loss=4.858, nll_loss=1.998, ppl=3.99, wps=27877.2, ups=1.87, wpb=14899.8, bsz=500.3, num_updates=66200, lr=0.000122905, gnorm=0.697, train_wall=53, wall=36512
2020-12-20 04:17:36 | INFO | train_inner | epoch 028:    204 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.054, loss=4.876, nll_loss=2.02, ppl=4.05, wps=27441.3, ups=1.86, wpb=14761.7, bsz=509.8, num_updates=66300, lr=0.000122813, gnorm=0.701, train_wall=54, wall=36566
2020-12-20 04:18:30 | INFO | train_inner | epoch 028:    304 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.038, loss=4.88, nll_loss=2.026, ppl=4.07, wps=27480, ups=1.85, wpb=14834.2, bsz=528.1, num_updates=66400, lr=0.00012272, gnorm=0.699, train_wall=54, wall=36620
2020-12-20 04:19:25 | INFO | train_inner | epoch 028:    404 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.05, loss=4.879, nll_loss=2.024, ppl=4.07, wps=27204, ups=1.84, wpb=14778.6, bsz=515.8, num_updates=66500, lr=0.000122628, gnorm=0.707, train_wall=54, wall=36674
2020-12-20 04:20:19 | INFO | train_inner | epoch 028:    504 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.058, loss=4.895, nll_loss=2.04, ppl=4.11, wps=27384.6, ups=1.85, wpb=14812.2, bsz=519.6, num_updates=66600, lr=0.000122536, gnorm=0.725, train_wall=54, wall=36728
2020-12-20 04:21:13 | INFO | train_inner | epoch 028:    604 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.059, loss=4.911, nll_loss=2.058, ppl=4.16, wps=27409.7, ups=1.86, wpb=14715.4, bsz=508.3, num_updates=66700, lr=0.000122444, gnorm=0.725, train_wall=54, wall=36782
2020-12-20 04:22:06 | INFO | train_inner | epoch 028:    704 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.056, loss=4.908, nll_loss=2.056, ppl=4.16, wps=27582.2, ups=1.86, wpb=14864.2, bsz=498.8, num_updates=66800, lr=0.000122352, gnorm=0.711, train_wall=54, wall=36836
2020-12-20 04:23:00 | INFO | train_inner | epoch 028:    804 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.052, loss=4.908, nll_loss=2.056, ppl=4.16, wps=27407.9, ups=1.86, wpb=14728.9, bsz=492, num_updates=66900, lr=0.000122261, gnorm=0.705, train_wall=54, wall=36889
2020-12-20 04:23:54 | INFO | train_inner | epoch 028:    904 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.056, loss=4.896, nll_loss=2.041, ppl=4.12, wps=27373.9, ups=1.85, wpb=14805.4, bsz=505.1, num_updates=67000, lr=0.000122169, gnorm=0.697, train_wall=54, wall=36943
2020-12-20 04:24:48 | INFO | train_inner | epoch 028:   1004 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.039, loss=4.902, nll_loss=2.051, ppl=4.14, wps=27447.3, ups=1.85, wpb=14827.8, bsz=499.8, num_updates=67100, lr=0.000122078, gnorm=0.705, train_wall=54, wall=36997
2020-12-20 04:25:42 | INFO | train_inner | epoch 028:   1104 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.024, loss=4.887, nll_loss=2.036, ppl=4.1, wps=27573.2, ups=1.85, wpb=14880.8, bsz=546.9, num_updates=67200, lr=0.000121988, gnorm=0.701, train_wall=54, wall=37051
2020-12-20 04:26:36 | INFO | train_inner | epoch 028:   1204 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.031, loss=4.911, nll_loss=2.062, ppl=4.18, wps=27332.8, ups=1.85, wpb=14776.3, bsz=525, num_updates=67300, lr=0.000121897, gnorm=0.701, train_wall=54, wall=37105
2020-12-20 04:27:30 | INFO | train_inner | epoch 028:   1304 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.032, loss=4.924, nll_loss=2.078, ppl=4.22, wps=27395, ups=1.85, wpb=14771.4, bsz=514.3, num_updates=67400, lr=0.000121806, gnorm=0.707, train_wall=54, wall=37159
2020-12-20 04:28:24 | INFO | train_inner | epoch 028:   1404 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.036, loss=4.894, nll_loss=2.043, ppl=4.12, wps=27485.2, ups=1.85, wpb=14851.5, bsz=520.5, num_updates=67500, lr=0.000121716, gnorm=0.703, train_wall=54, wall=37213
2020-12-20 04:29:18 | INFO | train_inner | epoch 028:   1504 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.032, loss=4.912, nll_loss=2.063, ppl=4.18, wps=27442.8, ups=1.85, wpb=14836.4, bsz=491, num_updates=67600, lr=0.000121626, gnorm=0.724, train_wall=54, wall=37267
2020-12-20 04:30:12 | INFO | train_inner | epoch 028:   1604 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.994, loss=4.894, nll_loss=2.05, ppl=4.14, wps=27443.9, ups=1.85, wpb=14836.4, bsz=510.1, num_updates=67700, lr=0.000121536, gnorm=0.714, train_wall=54, wall=37321
2020-12-20 04:31:06 | INFO | train_inner | epoch 028:   1704 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.001, loss=4.912, nll_loss=2.069, ppl=4.2, wps=27343.9, ups=1.86, wpb=14684.2, bsz=511.2, num_updates=67800, lr=0.000121447, gnorm=0.709, train_wall=54, wall=37375
2020-12-20 04:32:00 | INFO | train_inner | epoch 028:   1804 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.007, loss=4.906, nll_loss=2.061, ppl=4.17, wps=27372.4, ups=1.85, wpb=14771.4, bsz=501.4, num_updates=67900, lr=0.000121357, gnorm=0.729, train_wall=54, wall=37429
2020-12-20 04:32:54 | INFO | train_inner | epoch 028:   1904 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.985, loss=4.889, nll_loss=2.045, ppl=4.13, wps=27517.5, ups=1.85, wpb=14857.1, bsz=539.6, num_updates=68000, lr=0.000121268, gnorm=0.707, train_wall=54, wall=37483
2020-12-20 04:33:48 | INFO | train_inner | epoch 028:   2004 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.003, loss=4.906, nll_loss=2.062, ppl=4.18, wps=27476, ups=1.85, wpb=14876.5, bsz=515.9, num_updates=68100, lr=0.000121179, gnorm=0.7, train_wall=54, wall=37537
2020-12-20 04:34:42 | INFO | train_inner | epoch 028:   2104 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.008, loss=4.919, nll_loss=2.075, ppl=4.21, wps=27482.8, ups=1.85, wpb=14877, bsz=489.4, num_updates=68200, lr=0.00012109, gnorm=0.706, train_wall=54, wall=37591
2020-12-20 04:35:36 | INFO | train_inner | epoch 028:   2204 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.032, loss=4.906, nll_loss=2.058, ppl=4.16, wps=27618.2, ups=1.85, wpb=14902.5, bsz=508.8, num_updates=68300, lr=0.000121001, gnorm=0.71, train_wall=54, wall=37645
2020-12-20 04:36:30 | INFO | train_inner | epoch 028:   2304 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.984, loss=4.898, nll_loss=2.056, ppl=4.16, wps=27377, ups=1.84, wpb=14844.5, bsz=508.9, num_updates=68400, lr=0.000120913, gnorm=0.713, train_wall=54, wall=37700
2020-12-20 04:37:24 | INFO | train_inner | epoch 028:   2404 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.001, loss=4.925, nll_loss=2.084, ppl=4.24, wps=27433.9, ups=1.86, wpb=14753.8, bsz=509.5, num_updates=68500, lr=0.000120824, gnorm=0.716, train_wall=54, wall=37753
2020-12-20 04:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 04:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 04:38:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 04:38:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 04:38:02 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.015 | nll_loss 8.046 | ppl 264.38 | bleu 16.09 | wps 6001.4 | wpb 7930.2 | bsz 208 | num_updates 68544 | best_bleu 16.16
2020-12-20 04:38:02 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 04:38:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 28 @ 68544 updates, score 16.09) (writing took 5.074002992361784 seconds)
2020-12-20 04:38:07 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-12-20 04:38:07 | INFO | train | epoch 028 | symm_kl 0.561 | self_kl 0 | self_cv 9.028 | loss 4.9 | nll_loss 2.05 | ppl 4.14 | wps 26890 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 68544 | lr 0.000120786 | gnorm 0.709 | train_wall 1317 | wall 37796
2020-12-20 04:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:38:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:10 | INFO | fairseq.trainer | begin training epoch 29
2020-12-20 04:38:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 04:38:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 04:38:45 | INFO | train_inner | epoch 029:     56 / 2448 symm_kl=0.555, self_kl=0, self_cv=9.019, loss=4.876, nll_loss=2.025, ppl=4.07, wps=18107.9, ups=1.23, wpb=14703.2, bsz=530.3, num_updates=68600, lr=0.000120736, gnorm=0.697, train_wall=54, wall=37835
2020-12-20 04:39:39 | INFO | train_inner | epoch 029:    156 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.072, loss=4.862, nll_loss=2.001, ppl=4, wps=27440.8, ups=1.86, wpb=14772.6, bsz=519.8, num_updates=68700, lr=0.000120648, gnorm=0.703, train_wall=54, wall=37888
2020-12-20 04:40:33 | INFO | train_inner | epoch 029:    256 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.077, loss=4.877, nll_loss=2.016, ppl=4.05, wps=27562.2, ups=1.85, wpb=14858.8, bsz=504.5, num_updates=68800, lr=0.000120561, gnorm=0.716, train_wall=54, wall=37942
2020-12-20 04:41:27 | INFO | train_inner | epoch 029:    356 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.025, loss=4.879, nll_loss=2.027, ppl=4.07, wps=27400, ups=1.85, wpb=14830.4, bsz=553.4, num_updates=68900, lr=0.000120473, gnorm=0.697, train_wall=54, wall=37996
2020-12-20 04:42:22 | INFO | train_inner | epoch 029:    456 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.068, loss=4.885, nll_loss=2.028, ppl=4.08, wps=27366.6, ups=1.84, wpb=14842.8, bsz=530.5, num_updates=69000, lr=0.000120386, gnorm=0.703, train_wall=54, wall=38051
2020-12-20 04:43:16 | INFO | train_inner | epoch 029:    556 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.113, loss=4.893, nll_loss=2.03, ppl=4.08, wps=27316.8, ups=1.84, wpb=14826.7, bsz=478.3, num_updates=69100, lr=0.000120299, gnorm=0.712, train_wall=54, wall=38105
2020-12-20 04:44:10 | INFO | train_inner | epoch 029:    656 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.015, loss=4.894, nll_loss=2.046, ppl=4.13, wps=27355.5, ups=1.85, wpb=14790, bsz=514.8, num_updates=69200, lr=0.000120212, gnorm=0.728, train_wall=54, wall=38159
2020-12-20 04:45:04 | INFO | train_inner | epoch 029:    756 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.036, loss=4.887, nll_loss=2.035, ppl=4.1, wps=27498.7, ups=1.85, wpb=14861, bsz=527, num_updates=69300, lr=0.000120125, gnorm=0.714, train_wall=54, wall=38213
2020-12-20 04:45:58 | INFO | train_inner | epoch 029:    856 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.052, loss=4.895, nll_loss=2.041, ppl=4.11, wps=27366.7, ups=1.85, wpb=14793.4, bsz=499.4, num_updates=69400, lr=0.000120038, gnorm=0.716, train_wall=54, wall=38267
2020-12-20 04:46:52 | INFO | train_inner | epoch 029:    956 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.022, loss=4.904, nll_loss=2.056, ppl=4.16, wps=27261.8, ups=1.85, wpb=14715.3, bsz=520, num_updates=69500, lr=0.000119952, gnorm=0.72, train_wall=54, wall=38321
2020-12-20 04:47:46 | INFO | train_inner | epoch 029:   1056 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.028, loss=4.926, nll_loss=2.081, ppl=4.23, wps=27310.6, ups=1.86, wpb=14689.8, bsz=492.3, num_updates=69600, lr=0.000119866, gnorm=0.744, train_wall=54, wall=38375
2020-12-20 04:48:40 | INFO | train_inner | epoch 029:   1156 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.021, loss=4.899, nll_loss=2.051, ppl=4.14, wps=27403.5, ups=1.84, wpb=14854.2, bsz=524.6, num_updates=69700, lr=0.00011978, gnorm=0.715, train_wall=54, wall=38429
2020-12-20 04:49:34 | INFO | train_inner | epoch 029:   1256 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.03, loss=4.902, nll_loss=2.053, ppl=4.15, wps=27176, ups=1.84, wpb=14736.8, bsz=517.2, num_updates=69800, lr=0.000119694, gnorm=0.705, train_wall=54, wall=38483
2020-12-20 04:50:28 | INFO | train_inner | epoch 029:   1356 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.974, loss=4.885, nll_loss=2.042, ppl=4.12, wps=27460.4, ups=1.84, wpb=14884.3, bsz=514.1, num_updates=69900, lr=0.000119608, gnorm=0.706, train_wall=54, wall=38538
2020-12-20 04:51:22 | INFO | train_inner | epoch 029:   1456 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.032, loss=4.89, nll_loss=2.039, ppl=4.11, wps=27483.8, ups=1.85, wpb=14827.5, bsz=474.4, num_updates=70000, lr=0.000119523, gnorm=0.701, train_wall=54, wall=38591
2020-12-20 04:52:16 | INFO | train_inner | epoch 029:   1556 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.022, loss=4.894, nll_loss=2.045, ppl=4.13, wps=27387.2, ups=1.85, wpb=14789.3, bsz=523.2, num_updates=70100, lr=0.000119438, gnorm=0.726, train_wall=54, wall=38645
2020-12-20 04:53:10 | INFO | train_inner | epoch 029:   1656 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.056, loss=4.903, nll_loss=2.05, ppl=4.14, wps=27592.8, ups=1.85, wpb=14901.4, bsz=508.9, num_updates=70200, lr=0.000119352, gnorm=0.72, train_wall=54, wall=38699
2020-12-20 04:54:04 | INFO | train_inner | epoch 029:   1756 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.023, loss=4.889, nll_loss=2.04, ppl=4.11, wps=27528.3, ups=1.85, wpb=14861.8, bsz=516.6, num_updates=70300, lr=0.000119268, gnorm=0.72, train_wall=54, wall=38753
2020-12-20 04:54:58 | INFO | train_inner | epoch 029:   1856 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.037, loss=4.92, nll_loss=2.072, ppl=4.21, wps=27711.7, ups=1.87, wpb=14848.6, bsz=491.7, num_updates=70400, lr=0.000119183, gnorm=0.723, train_wall=53, wall=38807
2020-12-20 04:55:52 | INFO | train_inner | epoch 029:   1956 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.026, loss=4.914, nll_loss=2.067, ppl=4.19, wps=27509.1, ups=1.86, wpb=14812.7, bsz=492.2, num_updates=70500, lr=0.000119098, gnorm=0.709, train_wall=54, wall=38861
2020-12-20 04:56:46 | INFO | train_inner | epoch 029:   2056 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.021, loss=4.917, nll_loss=2.072, ppl=4.2, wps=27332.2, ups=1.85, wpb=14767.5, bsz=507.4, num_updates=70600, lr=0.000119014, gnorm=0.718, train_wall=54, wall=38915
2020-12-20 04:57:40 | INFO | train_inner | epoch 029:   2156 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.983, loss=4.902, nll_loss=2.06, ppl=4.17, wps=27343, ups=1.84, wpb=14828.1, bsz=536, num_updates=70700, lr=0.00011893, gnorm=0.702, train_wall=54, wall=38969
2020-12-20 04:58:34 | INFO | train_inner | epoch 029:   2256 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.004, loss=4.903, nll_loss=2.058, ppl=4.16, wps=27326.7, ups=1.85, wpb=14807.4, bsz=496.1, num_updates=70800, lr=0.000118846, gnorm=0.721, train_wall=54, wall=39023
2020-12-20 04:59:28 | INFO | train_inner | epoch 029:   2356 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.979, loss=4.887, nll_loss=2.044, ppl=4.12, wps=27588.9, ups=1.85, wpb=14893.1, bsz=520.9, num_updates=70900, lr=0.000118762, gnorm=0.722, train_wall=54, wall=39077
2020-12-20 05:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 05:00:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 05:00:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 05:00:33 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.072 | nll_loss 8.109 | ppl 276.06 | bleu 16.02 | wps 5302.7 | wpb 7930.2 | bsz 208 | num_updates 70992 | best_bleu 16.16
2020-12-20 05:00:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 05:00:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 29 @ 70992 updates, score 16.02) (writing took 5.128633189946413 seconds)
2020-12-20 05:00:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-12-20 05:00:38 | INFO | train | epoch 029 | symm_kl 0.562 | self_kl 0 | self_cv 9.031 | loss 4.896 | nll_loss 2.045 | ppl 4.13 | wps 26834.5 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 70992 | lr 0.000118685 | gnorm 0.716 | train_wall 1318 | wall 39147
2020-12-20 05:00:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:41 | INFO | fairseq.trainer | begin training epoch 30
2020-12-20 05:00:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:00:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:00:51 | INFO | train_inner | epoch 030:      8 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.019, loss=4.905, nll_loss=2.059, ppl=4.17, wps=17749.6, ups=1.21, wpb=14661.8, bsz=526.3, num_updates=71000, lr=0.000118678, gnorm=0.751, train_wall=54, wall=39160
2020-12-20 05:01:45 | INFO | train_inner | epoch 030:    108 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.074, loss=4.849, nll_loss=1.986, ppl=3.96, wps=27500.3, ups=1.86, wpb=14780.8, bsz=546.4, num_updates=71100, lr=0.000118595, gnorm=0.709, train_wall=54, wall=39214
2020-12-20 05:02:39 | INFO | train_inner | epoch 030:    208 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.069, loss=4.868, nll_loss=2.008, ppl=4.02, wps=27552.9, ups=1.85, wpb=14909, bsz=516.2, num_updates=71200, lr=0.000118511, gnorm=0.733, train_wall=54, wall=39268
2020-12-20 05:03:33 | INFO | train_inner | epoch 030:    308 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.056, loss=4.88, nll_loss=2.024, ppl=4.07, wps=27369.1, ups=1.85, wpb=14762.8, bsz=516.6, num_updates=71300, lr=0.000118428, gnorm=0.719, train_wall=54, wall=39322
2020-12-20 05:04:26 | INFO | train_inner | epoch 030:    408 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.026, loss=4.881, nll_loss=2.029, ppl=4.08, wps=27564.2, ups=1.86, wpb=14817.8, bsz=529.7, num_updates=71400, lr=0.000118345, gnorm=0.723, train_wall=54, wall=39375
2020-12-20 05:05:20 | INFO | train_inner | epoch 030:    508 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.122, loss=4.895, nll_loss=2.03, ppl=4.09, wps=27635.8, ups=1.86, wpb=14848.2, bsz=473.6, num_updates=71500, lr=0.000118262, gnorm=0.719, train_wall=54, wall=39429
2020-12-20 05:06:14 | INFO | train_inner | epoch 030:    608 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.058, loss=4.894, nll_loss=2.039, ppl=4.11, wps=27248.4, ups=1.85, wpb=14746.7, bsz=499.9, num_updates=71600, lr=0.00011818, gnorm=0.726, train_wall=54, wall=39483
2020-12-20 05:07:08 | INFO | train_inner | epoch 030:    708 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.038, loss=4.88, nll_loss=2.027, ppl=4.08, wps=27564.4, ups=1.85, wpb=14864.8, bsz=527.4, num_updates=71700, lr=0.000118097, gnorm=0.702, train_wall=54, wall=39537
2020-12-20 05:08:02 | INFO | train_inner | epoch 030:    808 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.045, loss=4.893, nll_loss=2.041, ppl=4.11, wps=27545.5, ups=1.86, wpb=14843.8, bsz=521.7, num_updates=71800, lr=0.000118015, gnorm=0.717, train_wall=54, wall=39591
2020-12-20 05:08:56 | INFO | train_inner | epoch 030:    908 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.037, loss=4.885, nll_loss=2.033, ppl=4.09, wps=27347.2, ups=1.85, wpb=14820.8, bsz=527.4, num_updates=71900, lr=0.000117933, gnorm=0.706, train_wall=54, wall=39645
2020-12-20 05:09:50 | INFO | train_inner | epoch 030:   1008 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.018, loss=4.888, nll_loss=2.038, ppl=4.11, wps=27385.7, ups=1.85, wpb=14819.8, bsz=504.8, num_updates=72000, lr=0.000117851, gnorm=0.72, train_wall=54, wall=39699
2020-12-20 05:10:44 | INFO | train_inner | epoch 030:   1108 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.045, loss=4.894, nll_loss=2.042, ppl=4.12, wps=27600.8, ups=1.86, wpb=14877.9, bsz=491.4, num_updates=72100, lr=0.000117769, gnorm=0.716, train_wall=54, wall=39753
2020-12-20 05:11:38 | INFO | train_inner | epoch 030:   1208 / 2448 symm_kl=0.558, self_kl=0, self_cv=8.97, loss=4.881, nll_loss=2.038, ppl=4.11, wps=27354.2, ups=1.85, wpb=14756.1, bsz=544.7, num_updates=72200, lr=0.000117688, gnorm=0.724, train_wall=54, wall=39807
2020-12-20 05:12:32 | INFO | train_inner | epoch 030:   1308 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.059, loss=4.904, nll_loss=2.051, ppl=4.14, wps=27507.8, ups=1.85, wpb=14832.9, bsz=499.8, num_updates=72300, lr=0.000117606, gnorm=0.721, train_wall=54, wall=39861
2020-12-20 05:13:26 | INFO | train_inner | epoch 030:   1408 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.044, loss=4.898, nll_loss=2.046, ppl=4.13, wps=27599, ups=1.85, wpb=14918.4, bsz=507.1, num_updates=72400, lr=0.000117525, gnorm=0.709, train_wall=54, wall=39915
2020-12-20 05:14:20 | INFO | train_inner | epoch 030:   1508 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.043, loss=4.896, nll_loss=2.044, ppl=4.12, wps=27485.7, ups=1.85, wpb=14851.3, bsz=486.5, num_updates=72500, lr=0.000117444, gnorm=0.703, train_wall=54, wall=39969
2020-12-20 05:15:14 | INFO | train_inner | epoch 030:   1608 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.985, loss=4.887, nll_loss=2.043, ppl=4.12, wps=27344.5, ups=1.85, wpb=14752, bsz=544.2, num_updates=72600, lr=0.000117363, gnorm=0.713, train_wall=54, wall=40023
2020-12-20 05:16:08 | INFO | train_inner | epoch 030:   1708 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.043, loss=4.924, nll_loss=2.075, ppl=4.21, wps=27328.9, ups=1.85, wpb=14748.3, bsz=479.8, num_updates=72700, lr=0.000117282, gnorm=0.732, train_wall=54, wall=40077
2020-12-20 05:17:02 | INFO | train_inner | epoch 030:   1808 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.037, loss=4.906, nll_loss=2.057, ppl=4.16, wps=27293, ups=1.86, wpb=14670.8, bsz=484.7, num_updates=72800, lr=0.000117202, gnorm=0.724, train_wall=54, wall=40131
2020-12-20 05:17:56 | INFO | train_inner | epoch 030:   1908 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.994, loss=4.894, nll_loss=2.05, ppl=4.14, wps=27397.9, ups=1.85, wpb=14813.5, bsz=522.7, num_updates=72900, lr=0.000117121, gnorm=0.712, train_wall=54, wall=40185
2020-12-20 05:18:50 | INFO | train_inner | epoch 030:   2008 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.985, loss=4.889, nll_loss=2.046, ppl=4.13, wps=27537.8, ups=1.85, wpb=14864.9, bsz=518.9, num_updates=73000, lr=0.000117041, gnorm=0.723, train_wall=54, wall=40239
2020-12-20 05:19:44 | INFO | train_inner | epoch 030:   2108 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.041, loss=4.914, nll_loss=2.065, ppl=4.19, wps=27333.2, ups=1.86, wpb=14728.6, bsz=468, num_updates=73100, lr=0.000116961, gnorm=0.723, train_wall=54, wall=40293
2020-12-20 05:20:38 | INFO | train_inner | epoch 030:   2208 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.989, loss=4.901, nll_loss=2.058, ppl=4.16, wps=27733.7, ups=1.86, wpb=14898.2, bsz=523.8, num_updates=73200, lr=0.000116881, gnorm=0.728, train_wall=54, wall=40347
2020-12-20 05:21:31 | INFO | train_inner | epoch 030:   2308 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.983, loss=4.898, nll_loss=2.057, ppl=4.16, wps=27548.4, ups=1.86, wpb=14805.9, bsz=538.5, num_updates=73300, lr=0.000116801, gnorm=0.718, train_wall=54, wall=40400
2020-12-20 05:22:25 | INFO | train_inner | epoch 030:   2408 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.013, loss=4.907, nll_loss=2.062, ppl=4.18, wps=27604.9, ups=1.86, wpb=14809.7, bsz=504.1, num_updates=73400, lr=0.000116722, gnorm=0.727, train_wall=53, wall=40454
2020-12-20 05:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 05:22:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:22:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:22:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:22:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:22:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:22:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:22:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:22:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:22:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:22:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:22:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 05:22:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 05:22:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 05:23:00 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.033 | nll_loss 8.072 | ppl 269.02 | bleu 15.99 | wps 6117.1 | wpb 7930.2 | bsz 208 | num_updates 73440 | best_bleu 16.16
2020-12-20 05:23:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 05:23:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 30 @ 73440 updates, score 15.99) (writing took 5.076361894607544 seconds)
2020-12-20 05:23:05 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-12-20 05:23:05 | INFO | train | epoch 030 | symm_kl 0.562 | self_kl 0 | self_cv 9.031 | loss 4.892 | nll_loss 2.041 | ppl 4.12 | wps 26913.9 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 73440 | lr 0.00011669 | gnorm 0.719 | train_wall 1316 | wall 40494
2020-12-20 05:23:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:23:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:23:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:23:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:23:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:23:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:23:08 | INFO | fairseq.trainer | begin training epoch 31
2020-12-20 05:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:23:46 | INFO | train_inner | epoch 031:     60 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.054, loss=4.876, nll_loss=2.02, ppl=4.06, wps=18128.8, ups=1.24, wpb=14636.2, bsz=491.4, num_updates=73500, lr=0.000116642, gnorm=0.716, train_wall=53, wall=40535
2020-12-20 05:24:40 | INFO | train_inner | epoch 031:    160 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.101, loss=4.858, nll_loss=1.992, ppl=3.98, wps=27639.1, ups=1.86, wpb=14899.6, bsz=497.3, num_updates=73600, lr=0.000116563, gnorm=0.708, train_wall=54, wall=40589
2020-12-20 05:25:34 | INFO | train_inner | epoch 031:    260 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.052, loss=4.864, nll_loss=2.006, ppl=4.02, wps=27329.5, ups=1.85, wpb=14745.3, bsz=514.4, num_updates=73700, lr=0.000116484, gnorm=0.718, train_wall=54, wall=40643
2020-12-20 05:26:28 | INFO | train_inner | epoch 031:    360 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.073, loss=4.879, nll_loss=2.02, ppl=4.06, wps=27372.3, ups=1.85, wpb=14784.4, bsz=515.4, num_updates=73800, lr=0.000116405, gnorm=0.714, train_wall=54, wall=40697
2020-12-20 05:27:22 | INFO | train_inner | epoch 031:    460 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.064, loss=4.869, nll_loss=2.011, ppl=4.03, wps=27345.2, ups=1.85, wpb=14793.1, bsz=524.9, num_updates=73900, lr=0.000116326, gnorm=0.711, train_wall=54, wall=40751
2020-12-20 05:28:16 | INFO | train_inner | epoch 031:    560 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.075, loss=4.885, nll_loss=2.027, ppl=4.08, wps=27538, ups=1.85, wpb=14915.2, bsz=482.6, num_updates=74000, lr=0.000116248, gnorm=0.712, train_wall=54, wall=40805
2020-12-20 05:29:10 | INFO | train_inner | epoch 031:    660 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.08, loss=4.901, nll_loss=2.044, ppl=4.12, wps=27360.9, ups=1.85, wpb=14755.1, bsz=466.3, num_updates=74100, lr=0.000116169, gnorm=0.722, train_wall=54, wall=40859
2020-12-20 05:30:04 | INFO | train_inner | epoch 031:    760 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.033, loss=4.872, nll_loss=2.019, ppl=4.05, wps=27383.8, ups=1.86, wpb=14740.6, bsz=536.8, num_updates=74200, lr=0.000116091, gnorm=0.717, train_wall=54, wall=40913
2020-12-20 05:30:57 | INFO | train_inner | epoch 031:    860 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.061, loss=4.897, nll_loss=2.042, ppl=4.12, wps=27424.7, ups=1.85, wpb=14792.7, bsz=497.7, num_updates=74300, lr=0.000116013, gnorm=0.76, train_wall=54, wall=40967
2020-12-20 05:31:51 | INFO | train_inner | epoch 031:    960 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.069, loss=4.894, nll_loss=2.038, ppl=4.11, wps=27780.8, ups=1.87, wpb=14848.2, bsz=477.8, num_updates=74400, lr=0.000115935, gnorm=0.709, train_wall=53, wall=41020
2020-12-20 05:32:45 | INFO | train_inner | epoch 031:   1060 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.033, loss=4.882, nll_loss=2.03, ppl=4.08, wps=27423.4, ups=1.86, wpb=14764.3, bsz=549.8, num_updates=74500, lr=0.000115857, gnorm=0.719, train_wall=54, wall=41074
2020-12-20 05:33:39 | INFO | train_inner | epoch 031:   1160 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.046, loss=4.891, nll_loss=2.038, ppl=4.11, wps=27641.7, ups=1.86, wpb=14884, bsz=499.4, num_updates=74600, lr=0.000115779, gnorm=0.725, train_wall=54, wall=41128
2020-12-20 05:34:32 | INFO | train_inner | epoch 031:   1260 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.002, loss=4.888, nll_loss=2.042, ppl=4.12, wps=27562.2, ups=1.86, wpb=14817.7, bsz=500.8, num_updates=74700, lr=0.000115702, gnorm=0.721, train_wall=54, wall=41182
2020-12-20 05:35:26 | INFO | train_inner | epoch 031:   1360 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.038, loss=4.897, nll_loss=2.046, ppl=4.13, wps=27429.7, ups=1.86, wpb=14750.6, bsz=487, num_updates=74800, lr=0.000115624, gnorm=0.726, train_wall=54, wall=41235
2020-12-20 05:36:20 | INFO | train_inner | epoch 031:   1460 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.993, loss=4.865, nll_loss=2.017, ppl=4.05, wps=27296.4, ups=1.84, wpb=14796.2, bsz=530.8, num_updates=74900, lr=0.000115547, gnorm=0.706, train_wall=54, wall=41289
2020-12-20 05:37:14 | INFO | train_inner | epoch 031:   1560 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.018, loss=4.89, nll_loss=2.042, ppl=4.12, wps=27463.9, ups=1.85, wpb=14834, bsz=501, num_updates=75000, lr=0.00011547, gnorm=0.719, train_wall=54, wall=41344
2020-12-20 05:38:08 | INFO | train_inner | epoch 031:   1660 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.009, loss=4.904, nll_loss=2.059, ppl=4.17, wps=27413.5, ups=1.85, wpb=14830.1, bsz=515.8, num_updates=75100, lr=0.000115393, gnorm=0.722, train_wall=54, wall=41398
2020-12-20 05:39:03 | INFO | train_inner | epoch 031:   1760 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.008, loss=4.889, nll_loss=2.042, ppl=4.12, wps=27276.5, ups=1.85, wpb=14758.6, bsz=538.4, num_updates=75200, lr=0.000115316, gnorm=0.732, train_wall=54, wall=41452
2020-12-20 05:39:56 | INFO | train_inner | epoch 031:   1860 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.023, loss=4.92, nll_loss=2.075, ppl=4.21, wps=27573.5, ups=1.86, wpb=14856.4, bsz=510.4, num_updates=75300, lr=0.00011524, gnorm=0.717, train_wall=54, wall=41506
2020-12-20 05:40:50 | INFO | train_inner | epoch 031:   1960 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.014, loss=4.891, nll_loss=2.044, ppl=4.12, wps=27629.3, ups=1.86, wpb=14845.9, bsz=525.1, num_updates=75400, lr=0.000115163, gnorm=0.713, train_wall=54, wall=41559
2020-12-20 05:41:44 | INFO | train_inner | epoch 031:   2060 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.981, loss=4.884, nll_loss=2.041, ppl=4.11, wps=27718.8, ups=1.86, wpb=14904.8, bsz=509.9, num_updates=75500, lr=0.000115087, gnorm=0.722, train_wall=54, wall=41613
2020-12-20 05:42:38 | INFO | train_inner | epoch 031:   2160 / 2448 symm_kl=0.554, self_kl=0, self_cv=8.971, loss=4.89, nll_loss=2.049, ppl=4.14, wps=27538.2, ups=1.85, wpb=14887.2, bsz=547.5, num_updates=75600, lr=0.000115011, gnorm=0.714, train_wall=54, wall=41667
2020-12-20 05:43:32 | INFO | train_inner | epoch 031:   2260 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.007, loss=4.915, nll_loss=2.072, ppl=4.2, wps=27397.3, ups=1.85, wpb=14810.1, bsz=548.3, num_updates=75700, lr=0.000114935, gnorm=0.732, train_wall=54, wall=41721
2020-12-20 05:44:26 | INFO | train_inner | epoch 031:   2360 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.014, loss=4.899, nll_loss=2.053, ppl=4.15, wps=27456.4, ups=1.86, wpb=14759.8, bsz=523.9, num_updates=75800, lr=0.000114859, gnorm=0.747, train_wall=54, wall=41775
2020-12-20 05:45:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 05:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 05:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 05:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 05:45:27 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.069 | nll_loss 8.108 | ppl 275.84 | bleu 15.83 | wps 6169.8 | wpb 7930.2 | bsz 208 | num_updates 75888 | best_bleu 16.16
2020-12-20 05:45:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 05:45:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 31 @ 75888 updates, score 15.83) (writing took 5.206029541790485 seconds)
2020-12-20 05:45:32 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-12-20 05:45:32 | INFO | train | epoch 031 | symm_kl 0.562 | self_kl 0 | self_cv 9.034 | loss 4.888 | nll_loss 2.037 | ppl 4.1 | wps 26916.3 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 75888 | lr 0.000114792 | gnorm 0.721 | train_wall 1316 | wall 41841
2020-12-20 05:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:35 | INFO | fairseq.trainer | begin training epoch 32
2020-12-20 05:45:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 05:45:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 05:45:47 | INFO | train_inner | epoch 032:     12 / 2448 symm_kl=0.554, self_kl=0, self_cv=9, loss=4.882, nll_loss=2.036, ppl=4.1, wps=18220, ups=1.23, wpb=14776, bsz=503.7, num_updates=75900, lr=0.000114783, gnorm=0.731, train_wall=54, wall=41856
2020-12-20 05:46:41 | INFO | train_inner | epoch 032:    112 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.056, loss=4.863, nll_loss=2.004, ppl=4.01, wps=27646.2, ups=1.86, wpb=14842.2, bsz=503.3, num_updates=76000, lr=0.000114708, gnorm=0.72, train_wall=54, wall=41910
2020-12-20 05:47:35 | INFO | train_inner | epoch 032:    212 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.066, loss=4.849, nll_loss=1.988, ppl=3.97, wps=27235.6, ups=1.84, wpb=14797.9, bsz=521.2, num_updates=76100, lr=0.000114632, gnorm=0.716, train_wall=54, wall=41964
2020-12-20 05:48:29 | INFO | train_inner | epoch 032:    312 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.057, loss=4.855, nll_loss=1.996, ppl=3.99, wps=27392.5, ups=1.85, wpb=14841.4, bsz=518.7, num_updates=76200, lr=0.000114557, gnorm=0.708, train_wall=54, wall=42018
2020-12-20 05:49:23 | INFO | train_inner | epoch 032:    412 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.024, loss=4.873, nll_loss=2.021, ppl=4.06, wps=27351.2, ups=1.86, wpb=14705.6, bsz=536, num_updates=76300, lr=0.000114482, gnorm=0.717, train_wall=54, wall=42072
2020-12-20 05:50:17 | INFO | train_inner | epoch 032:    512 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.025, loss=4.859, nll_loss=2.005, ppl=4.01, wps=27444.2, ups=1.85, wpb=14861.6, bsz=535.9, num_updates=76400, lr=0.000114407, gnorm=0.711, train_wall=54, wall=42126
2020-12-20 05:51:11 | INFO | train_inner | epoch 032:    612 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.058, loss=4.892, nll_loss=2.037, ppl=4.1, wps=27544.4, ups=1.86, wpb=14834.1, bsz=512.7, num_updates=76500, lr=0.000114332, gnorm=0.724, train_wall=54, wall=42180
2020-12-20 05:52:05 | INFO | train_inner | epoch 032:    712 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.044, loss=4.877, nll_loss=2.023, ppl=4.06, wps=27276.8, ups=1.85, wpb=14717.4, bsz=511.4, num_updates=76600, lr=0.000114258, gnorm=0.711, train_wall=54, wall=42234
2020-12-20 05:52:59 | INFO | train_inner | epoch 032:    812 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.06, loss=4.884, nll_loss=2.028, ppl=4.08, wps=27478.1, ups=1.86, wpb=14776.3, bsz=506.7, num_updates=76700, lr=0.000114183, gnorm=0.728, train_wall=54, wall=42288
2020-12-20 05:53:53 | INFO | train_inner | epoch 032:    912 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.051, loss=4.874, nll_loss=2.018, ppl=4.05, wps=27477, ups=1.85, wpb=14863.7, bsz=528.6, num_updates=76800, lr=0.000114109, gnorm=0.716, train_wall=54, wall=42342
2020-12-20 05:54:47 | INFO | train_inner | epoch 032:   1012 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.042, loss=4.885, nll_loss=2.032, ppl=4.09, wps=27401.5, ups=1.85, wpb=14811.7, bsz=514.8, num_updates=76900, lr=0.000114035, gnorm=0.719, train_wall=54, wall=42396
2020-12-20 05:55:41 | INFO | train_inner | epoch 032:   1112 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.07, loss=4.889, nll_loss=2.032, ppl=4.09, wps=27513.6, ups=1.85, wpb=14848.1, bsz=498.1, num_updates=77000, lr=0.000113961, gnorm=0.712, train_wall=54, wall=42450
2020-12-20 05:56:35 | INFO | train_inner | epoch 032:   1212 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.023, loss=4.879, nll_loss=2.028, ppl=4.08, wps=27322.8, ups=1.85, wpb=14780.4, bsz=516.8, num_updates=77100, lr=0.000113887, gnorm=0.746, train_wall=54, wall=42504
2020-12-20 05:57:29 | INFO | train_inner | epoch 032:   1312 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.031, loss=4.887, nll_loss=2.036, ppl=4.1, wps=27568.2, ups=1.85, wpb=14903.7, bsz=496.7, num_updates=77200, lr=0.000113813, gnorm=0.721, train_wall=54, wall=42558
2020-12-20 05:58:23 | INFO | train_inner | epoch 032:   1412 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.053, loss=4.907, nll_loss=2.056, ppl=4.16, wps=27384.7, ups=1.85, wpb=14821.6, bsz=495, num_updates=77300, lr=0.000113739, gnorm=0.719, train_wall=54, wall=42612
2020-12-20 05:59:17 | INFO | train_inner | epoch 032:   1512 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.054, loss=4.891, nll_loss=2.037, ppl=4.1, wps=27518.9, ups=1.85, wpb=14894.1, bsz=503.8, num_updates=77400, lr=0.000113666, gnorm=0.73, train_wall=54, wall=42666
2020-12-20 06:00:11 | INFO | train_inner | epoch 032:   1612 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.027, loss=4.884, nll_loss=2.034, ppl=4.1, wps=27377.6, ups=1.85, wpb=14773.8, bsz=520.8, num_updates=77500, lr=0.000113592, gnorm=0.74, train_wall=54, wall=42720
2020-12-20 06:01:05 | INFO | train_inner | epoch 032:   1712 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.021, loss=4.888, nll_loss=2.039, ppl=4.11, wps=27350.2, ups=1.85, wpb=14792.9, bsz=515.8, num_updates=77600, lr=0.000113519, gnorm=0.757, train_wall=54, wall=42774
2020-12-20 06:01:59 | INFO | train_inner | epoch 032:   1812 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.065, loss=4.907, nll_loss=2.053, ppl=4.15, wps=27307.5, ups=1.85, wpb=14724.9, bsz=479.4, num_updates=77700, lr=0.000113446, gnorm=0.748, train_wall=54, wall=42828
2020-12-20 06:02:53 | INFO | train_inner | epoch 032:   1912 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.02, loss=4.906, nll_loss=2.06, ppl=4.17, wps=27547.6, ups=1.85, wpb=14906.8, bsz=501.7, num_updates=77800, lr=0.000113373, gnorm=0.723, train_wall=54, wall=42882
2020-12-20 06:03:47 | INFO | train_inner | epoch 032:   2012 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.006, loss=4.904, nll_loss=2.06, ppl=4.17, wps=27337.4, ups=1.85, wpb=14806.7, bsz=523.1, num_updates=77900, lr=0.0001133, gnorm=0.734, train_wall=54, wall=42937
2020-12-20 06:04:41 | INFO | train_inner | epoch 032:   2112 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.994, loss=4.879, nll_loss=2.033, ppl=4.09, wps=27558.8, ups=1.85, wpb=14876.9, bsz=523.9, num_updates=78000, lr=0.000113228, gnorm=0.734, train_wall=54, wall=42991
2020-12-20 06:05:35 | INFO | train_inner | epoch 032:   2212 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.047, loss=4.917, nll_loss=2.068, ppl=4.19, wps=27251.8, ups=1.85, wpb=14692.3, bsz=479.7, num_updates=78100, lr=0.000113155, gnorm=0.722, train_wall=54, wall=43044
2020-12-20 06:06:29 | INFO | train_inner | epoch 032:   2312 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.034, loss=4.91, nll_loss=2.062, ppl=4.18, wps=27485.8, ups=1.85, wpb=14848.2, bsz=504.4, num_updates=78200, lr=0.000113083, gnorm=0.747, train_wall=54, wall=43098
2020-12-20 06:07:23 | INFO | train_inner | epoch 032:   2412 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.014, loss=4.901, nll_loss=2.055, ppl=4.15, wps=27456.5, ups=1.85, wpb=14848.2, bsz=519.8, num_updates=78300, lr=0.000113011, gnorm=0.747, train_wall=54, wall=43153
2020-12-20 06:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 06:07:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:07:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:07:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:07:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:07:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:07:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:07:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:07:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:07:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:07:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:07:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 06:07:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 06:07:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 06:07:56 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.04 | nll_loss 8.072 | ppl 269.02 | bleu 15.76 | wps 5953.6 | wpb 7930.2 | bsz 208 | num_updates 78336 | best_bleu 16.16
2020-12-20 06:07:56 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 06:08:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 32 @ 78336 updates, score 15.76) (writing took 5.174515716731548 seconds)
2020-12-20 06:08:02 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-12-20 06:08:02 | INFO | train | epoch 032 | symm_kl 0.563 | self_kl 0 | self_cv 9.036 | loss 4.885 | nll_loss 2.033 | ppl 4.09 | wps 26859.3 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 78336 | lr 0.000112985 | gnorm 0.727 | train_wall 1318 | wall 43191
2020-12-20 06:08:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:08:05 | INFO | fairseq.trainer | begin training epoch 33
2020-12-20 06:08:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:08:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:08:44 | INFO | train_inner | epoch 033:     64 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.01, loss=4.855, nll_loss=2.003, ppl=4.01, wps=18082.5, ups=1.23, wpb=14652.3, bsz=532.4, num_updates=78400, lr=0.000112938, gnorm=0.742, train_wall=53, wall=43234
2020-12-20 06:09:38 | INFO | train_inner | epoch 033:    164 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.051, loss=4.834, nll_loss=1.974, ppl=3.93, wps=27607.3, ups=1.85, wpb=14891.7, bsz=517.1, num_updates=78500, lr=0.000112867, gnorm=0.707, train_wall=54, wall=43288
2020-12-20 06:10:32 | INFO | train_inner | epoch 033:    264 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.084, loss=4.866, nll_loss=2.004, ppl=4.01, wps=27514.1, ups=1.86, wpb=14783.9, bsz=478.7, num_updates=78600, lr=0.000112795, gnorm=0.711, train_wall=54, wall=43341
2020-12-20 06:11:26 | INFO | train_inner | epoch 033:    364 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.054, loss=4.845, nll_loss=1.986, ppl=3.96, wps=27642.5, ups=1.85, wpb=14955.4, bsz=527.6, num_updates=78700, lr=0.000112723, gnorm=0.704, train_wall=54, wall=43395
2020-12-20 06:12:20 | INFO | train_inner | epoch 033:    464 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.013, loss=4.87, nll_loss=2.019, ppl=4.05, wps=27418.7, ups=1.86, wpb=14774.2, bsz=548.1, num_updates=78800, lr=0.000112651, gnorm=0.72, train_wall=54, wall=43449
2020-12-20 06:13:14 | INFO | train_inner | epoch 033:    564 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.056, loss=4.885, nll_loss=2.03, ppl=4.08, wps=27112.1, ups=1.85, wpb=14691.8, bsz=539.2, num_updates=78900, lr=0.00011258, gnorm=0.751, train_wall=54, wall=43503
2020-12-20 06:14:08 | INFO | train_inner | epoch 033:    664 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.08, loss=4.895, nll_loss=2.038, ppl=4.11, wps=27238.3, ups=1.85, wpb=14739.8, bsz=486.6, num_updates=79000, lr=0.000112509, gnorm=0.742, train_wall=54, wall=43558
2020-12-20 06:15:03 | INFO | train_inner | epoch 033:    764 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.052, loss=4.866, nll_loss=2.009, ppl=4.03, wps=27378.9, ups=1.84, wpb=14854.8, bsz=515.7, num_updates=79100, lr=0.000112438, gnorm=0.721, train_wall=54, wall=43612
2020-12-20 06:15:57 | INFO | train_inner | epoch 033:    864 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.047, loss=4.883, nll_loss=2.029, ppl=4.08, wps=27385.2, ups=1.85, wpb=14818.6, bsz=526.7, num_updates=79200, lr=0.000112367, gnorm=0.729, train_wall=54, wall=43666
2020-12-20 06:16:51 | INFO | train_inner | epoch 033:    964 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.034, loss=4.882, nll_loss=2.031, ppl=4.09, wps=27259.9, ups=1.85, wpb=14717, bsz=516.8, num_updates=79300, lr=0.000112296, gnorm=0.749, train_wall=54, wall=43720
2020-12-20 06:17:45 | INFO | train_inner | epoch 033:   1064 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.047, loss=4.88, nll_loss=2.026, ppl=4.07, wps=27276.8, ups=1.85, wpb=14737.2, bsz=503.3, num_updates=79400, lr=0.000112225, gnorm=0.72, train_wall=54, wall=43774
2020-12-20 06:18:39 | INFO | train_inner | epoch 033:   1164 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.038, loss=4.881, nll_loss=2.029, ppl=4.08, wps=27323, ups=1.85, wpb=14737.9, bsz=490.4, num_updates=79500, lr=0.000112154, gnorm=0.731, train_wall=54, wall=43828
2020-12-20 06:19:33 | INFO | train_inner | epoch 033:   1264 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.076, loss=4.89, nll_loss=2.032, ppl=4.09, wps=27528.2, ups=1.86, wpb=14839.1, bsz=498.9, num_updates=79600, lr=0.000112084, gnorm=0.733, train_wall=54, wall=43882
2020-12-20 06:20:27 | INFO | train_inner | epoch 033:   1364 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.041, loss=4.878, nll_loss=2.025, ppl=4.07, wps=27532.4, ups=1.85, wpb=14845.6, bsz=517, num_updates=79700, lr=0.000112014, gnorm=0.719, train_wall=54, wall=43936
2020-12-20 06:21:21 | INFO | train_inner | epoch 033:   1464 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.002, loss=4.881, nll_loss=2.034, ppl=4.1, wps=27417.5, ups=1.85, wpb=14802.2, bsz=537.4, num_updates=79800, lr=0.000111943, gnorm=0.741, train_wall=54, wall=43990
2020-12-20 06:22:15 | INFO | train_inner | epoch 033:   1564 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.013, loss=4.869, nll_loss=2.019, ppl=4.05, wps=27648.4, ups=1.85, wpb=14927.5, bsz=503, num_updates=79900, lr=0.000111873, gnorm=0.721, train_wall=54, wall=44044
2020-12-20 06:23:09 | INFO | train_inner | epoch 033:   1664 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.012, loss=4.887, nll_loss=2.039, ppl=4.11, wps=27293, ups=1.85, wpb=14767.2, bsz=511.5, num_updates=80000, lr=0.000111803, gnorm=0.75, train_wall=54, wall=44098
2020-12-20 06:24:03 | INFO | train_inner | epoch 033:   1764 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.019, loss=4.878, nll_loss=2.028, ppl=4.08, wps=27649.7, ups=1.84, wpb=14997.5, bsz=513.5, num_updates=80100, lr=0.000111734, gnorm=0.724, train_wall=54, wall=44152
2020-12-20 06:24:57 | INFO | train_inner | epoch 033:   1864 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.018, loss=4.9, nll_loss=2.053, ppl=4.15, wps=27281.1, ups=1.86, wpb=14699.7, bsz=508.6, num_updates=80200, lr=0.000111664, gnorm=0.75, train_wall=54, wall=44206
2020-12-20 06:25:51 | INFO | train_inner | epoch 033:   1964 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.006, loss=4.902, nll_loss=2.057, ppl=4.16, wps=27437.5, ups=1.85, wpb=14818.6, bsz=514.9, num_updates=80300, lr=0.000111594, gnorm=0.726, train_wall=54, wall=44260
2020-12-20 06:26:45 | INFO | train_inner | epoch 033:   2064 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.065, loss=4.909, nll_loss=2.056, ppl=4.16, wps=27519.7, ups=1.85, wpb=14888.1, bsz=481.4, num_updates=80400, lr=0.000111525, gnorm=0.73, train_wall=54, wall=44314
2020-12-20 06:27:39 | INFO | train_inner | epoch 033:   2164 / 2448 symm_kl=0.563, self_kl=0, self_cv=8.987, loss=4.893, nll_loss=2.05, ppl=4.14, wps=27400, ups=1.85, wpb=14805, bsz=513.7, num_updates=80500, lr=0.000111456, gnorm=0.725, train_wall=54, wall=44368
2020-12-20 06:28:33 | INFO | train_inner | epoch 033:   2264 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.017, loss=4.89, nll_loss=2.043, ppl=4.12, wps=27402, ups=1.85, wpb=14791.5, bsz=507.8, num_updates=80600, lr=0.000111386, gnorm=0.731, train_wall=54, wall=44422
2020-12-20 06:29:27 | INFO | train_inner | epoch 033:   2364 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.057, loss=4.9, nll_loss=2.047, ppl=4.13, wps=27480.1, ups=1.85, wpb=14856.8, bsz=491, num_updates=80700, lr=0.000111317, gnorm=0.73, train_wall=54, wall=44476
2020-12-20 06:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 06:30:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 06:30:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 06:30:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 06:30:27 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.05 | nll_loss 8.088 | ppl 272.09 | bleu 15.86 | wps 5333.4 | wpb 7930.2 | bsz 208 | num_updates 80784 | best_bleu 16.16
2020-12-20 06:30:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 06:30:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 33 @ 80784 updates, score 15.86) (writing took 5.178628634661436 seconds)
2020-12-20 06:30:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-12-20 06:30:32 | INFO | train | epoch 033 | symm_kl 0.564 | self_kl 0 | self_cv 9.038 | loss 4.881 | nll_loss 2.029 | ppl 4.08 | wps 26844.7 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 80784 | lr 0.00011126 | gnorm 0.73 | train_wall 1318 | wall 44541
2020-12-20 06:30:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:35 | INFO | fairseq.trainer | begin training epoch 34
2020-12-20 06:30:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:30:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:30:50 | INFO | train_inner | epoch 034:     16 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.027, loss=4.897, nll_loss=2.049, ppl=4.14, wps=17830.3, ups=1.21, wpb=14714.4, bsz=529.1, num_updates=80800, lr=0.000111249, gnorm=0.758, train_wall=54, wall=44559
2020-12-20 06:31:43 | INFO | train_inner | epoch 034:    116 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.071, loss=4.832, nll_loss=1.968, ppl=3.91, wps=27768.8, ups=1.87, wpb=14874, bsz=510.2, num_updates=80900, lr=0.00011118, gnorm=0.711, train_wall=53, wall=44612
2020-12-20 06:32:37 | INFO | train_inner | epoch 034:    216 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.085, loss=4.855, nll_loss=1.991, ppl=3.98, wps=27482.5, ups=1.86, wpb=14797, bsz=518.5, num_updates=81000, lr=0.000111111, gnorm=0.758, train_wall=54, wall=44666
2020-12-20 06:33:31 | INFO | train_inner | epoch 034:    316 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.08, loss=4.868, nll_loss=2.007, ppl=4.02, wps=27475.1, ups=1.85, wpb=14848.7, bsz=505.9, num_updates=81100, lr=0.000111043, gnorm=0.724, train_wall=54, wall=44720
2020-12-20 06:34:25 | INFO | train_inner | epoch 034:    416 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.075, loss=4.87, nll_loss=2.01, ppl=4.03, wps=27259.7, ups=1.84, wpb=14807.1, bsz=509.6, num_updates=81200, lr=0.000110974, gnorm=0.739, train_wall=54, wall=44774
2020-12-20 06:35:19 | INFO | train_inner | epoch 034:    516 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.043, loss=4.843, nll_loss=1.985, ppl=3.96, wps=27579.8, ups=1.86, wpb=14859.2, bsz=531.6, num_updates=81300, lr=0.000110906, gnorm=0.729, train_wall=54, wall=44828
2020-12-20 06:36:13 | INFO | train_inner | epoch 034:    616 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.068, loss=4.876, nll_loss=2.018, ppl=4.05, wps=27564.5, ups=1.86, wpb=14780.3, bsz=514.6, num_updates=81400, lr=0.000110838, gnorm=0.74, train_wall=53, wall=44882
2020-12-20 06:37:07 | INFO | train_inner | epoch 034:    716 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.08, loss=4.861, nll_loss=1.999, ppl=4, wps=27518.7, ups=1.85, wpb=14863, bsz=543.3, num_updates=81500, lr=0.00011077, gnorm=0.73, train_wall=54, wall=44936
2020-12-20 06:38:01 | INFO | train_inner | epoch 034:    816 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.078, loss=4.882, nll_loss=2.024, ppl=4.07, wps=27559.5, ups=1.86, wpb=14840.6, bsz=486.7, num_updates=81600, lr=0.000110702, gnorm=0.728, train_wall=54, wall=44990
2020-12-20 06:38:55 | INFO | train_inner | epoch 034:    916 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.059, loss=4.893, nll_loss=2.039, ppl=4.11, wps=27282.2, ups=1.85, wpb=14783.5, bsz=500, num_updates=81700, lr=0.000110634, gnorm=0.723, train_wall=54, wall=45044
2020-12-20 06:39:49 | INFO | train_inner | epoch 034:   1016 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.037, loss=4.867, nll_loss=2.013, ppl=4.04, wps=27394.9, ups=1.85, wpb=14782.5, bsz=514.4, num_updates=81800, lr=0.000110566, gnorm=0.729, train_wall=54, wall=45098
2020-12-20 06:40:43 | INFO | train_inner | epoch 034:   1116 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.061, loss=4.891, nll_loss=2.036, ppl=4.1, wps=27284, ups=1.85, wpb=14757.5, bsz=495.3, num_updates=81900, lr=0.000110499, gnorm=0.739, train_wall=54, wall=45152
2020-12-20 06:41:37 | INFO | train_inner | epoch 034:   1216 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.052, loss=4.884, nll_loss=2.03, ppl=4.08, wps=27453.8, ups=1.85, wpb=14810.2, bsz=499.5, num_updates=82000, lr=0.000110432, gnorm=0.743, train_wall=54, wall=45206
2020-12-20 06:42:31 | INFO | train_inner | epoch 034:   1316 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.036, loss=4.874, nll_loss=2.021, ppl=4.06, wps=27488.1, ups=1.86, wpb=14801, bsz=515.9, num_updates=82100, lr=0.000110364, gnorm=0.726, train_wall=54, wall=45260
2020-12-20 06:43:25 | INFO | train_inner | epoch 034:   1416 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.039, loss=4.887, nll_loss=2.035, ppl=4.1, wps=27441.1, ups=1.86, wpb=14780.4, bsz=508.7, num_updates=82200, lr=0.000110297, gnorm=0.723, train_wall=54, wall=45314
2020-12-20 06:44:18 | INFO | train_inner | epoch 034:   1516 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.05, loss=4.894, nll_loss=2.042, ppl=4.12, wps=27387.6, ups=1.86, wpb=14750.4, bsz=492.7, num_updates=82300, lr=0.00011023, gnorm=0.739, train_wall=54, wall=45368
2020-12-20 06:45:13 | INFO | train_inner | epoch 034:   1616 / 2448 symm_kl=0.556, self_kl=0, self_cv=8.976, loss=4.866, nll_loss=2.021, ppl=4.06, wps=27456.3, ups=1.84, wpb=14905.9, bsz=516.2, num_updates=82400, lr=0.000110163, gnorm=0.724, train_wall=54, wall=45422
2020-12-20 06:46:07 | INFO | train_inner | epoch 034:   1716 / 2448 symm_kl=0.561, self_kl=0, self_cv=8.999, loss=4.886, nll_loss=2.04, ppl=4.11, wps=27409.1, ups=1.85, wpb=14836.1, bsz=535.7, num_updates=82500, lr=0.000110096, gnorm=0.723, train_wall=54, wall=45476
2020-12-20 06:47:01 | INFO | train_inner | epoch 034:   1816 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.028, loss=4.888, nll_loss=2.038, ppl=4.11, wps=27353.4, ups=1.85, wpb=14777.9, bsz=499, num_updates=82600, lr=0.00011003, gnorm=0.734, train_wall=54, wall=45530
2020-12-20 06:47:55 | INFO | train_inner | epoch 034:   1916 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.022, loss=4.886, nll_loss=2.037, ppl=4.1, wps=27419.8, ups=1.85, wpb=14820.3, bsz=511.8, num_updates=82700, lr=0.000109963, gnorm=0.738, train_wall=54, wall=45584
2020-12-20 06:48:49 | INFO | train_inner | epoch 034:   2016 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.022, loss=4.897, nll_loss=2.05, ppl=4.14, wps=27351.9, ups=1.85, wpb=14764.5, bsz=496.5, num_updates=82800, lr=0.000109897, gnorm=0.732, train_wall=54, wall=45638
2020-12-20 06:49:43 | INFO | train_inner | epoch 034:   2116 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.015, loss=4.891, nll_loss=2.044, ppl=4.12, wps=27398.4, ups=1.84, wpb=14870.8, bsz=509.8, num_updates=82900, lr=0.00010983, gnorm=0.752, train_wall=54, wall=45692
2020-12-20 06:50:37 | INFO | train_inner | epoch 034:   2216 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.989, loss=4.883, nll_loss=2.039, ppl=4.11, wps=27379.2, ups=1.85, wpb=14790.7, bsz=537.8, num_updates=83000, lr=0.000109764, gnorm=0.729, train_wall=54, wall=45746
2020-12-20 06:51:31 | INFO | train_inner | epoch 034:   2316 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.994, loss=4.894, nll_loss=2.05, ppl=4.14, wps=27254.6, ups=1.85, wpb=14740.6, bsz=499, num_updates=83100, lr=0.000109698, gnorm=0.744, train_wall=54, wall=45800
2020-12-20 06:52:26 | INFO | train_inner | epoch 034:   2416 / 2448 symm_kl=0.557, self_kl=0, self_cv=8.989, loss=4.879, nll_loss=2.035, ppl=4.1, wps=27538.5, ups=1.84, wpb=14946.5, bsz=548.6, num_updates=83200, lr=0.000109632, gnorm=0.729, train_wall=54, wall=45855
2020-12-20 06:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 06:52:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:52:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:52:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:52:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:52:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:52:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:52:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:52:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:52:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:52:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 06:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 06:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 06:52:57 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.069 | nll_loss 8.11 | ppl 276.31 | bleu 15.66 | wps 5451.7 | wpb 7930.2 | bsz 208 | num_updates 83232 | best_bleu 16.16
2020-12-20 06:52:57 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 06:53:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 34 @ 83232 updates, score 15.66) (writing took 5.140315750613809 seconds)
2020-12-20 06:53:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-12-20 06:53:02 | INFO | train | epoch 034 | symm_kl 0.564 | self_kl 0 | self_cv 9.04 | loss 4.877 | nll_loss 2.024 | ppl 4.07 | wps 26856.7 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 83232 | lr 0.000109611 | gnorm 0.733 | train_wall 1318 | wall 45891
2020-12-20 06:53:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:53:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:53:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:53:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:53:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:53:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:53:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:53:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:53:05 | INFO | fairseq.trainer | begin training epoch 35
2020-12-20 06:53:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 06:53:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 06:53:47 | INFO | train_inner | epoch 035:     68 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.051, loss=4.863, nll_loss=2.006, ppl=4.02, wps=17996.7, ups=1.22, wpb=14735.5, bsz=511.4, num_updates=83300, lr=0.000109566, gnorm=0.745, train_wall=53, wall=45937
2020-12-20 06:54:41 | INFO | train_inner | epoch 035:    168 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.114, loss=4.871, nll_loss=2.005, ppl=4.01, wps=27400.4, ups=1.86, wpb=14716.4, bsz=484.2, num_updates=83400, lr=0.000109501, gnorm=0.737, train_wall=54, wall=45990
2020-12-20 06:55:35 | INFO | train_inner | epoch 035:    268 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.055, loss=4.84, nll_loss=1.98, ppl=3.94, wps=27519.6, ups=1.86, wpb=14804.9, bsz=532.4, num_updates=83500, lr=0.000109435, gnorm=0.73, train_wall=54, wall=46044
2020-12-20 06:56:29 | INFO | train_inner | epoch 035:    368 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.05, loss=4.857, nll_loss=2, ppl=4, wps=27487.5, ups=1.85, wpb=14830.3, bsz=508.8, num_updates=83600, lr=0.00010937, gnorm=0.728, train_wall=54, wall=46098
2020-12-20 06:57:23 | INFO | train_inner | epoch 035:    468 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.051, loss=4.86, nll_loss=2.003, ppl=4.01, wps=27407.8, ups=1.85, wpb=14819.5, bsz=522.7, num_updates=83700, lr=0.000109304, gnorm=0.723, train_wall=54, wall=46152
2020-12-20 06:58:17 | INFO | train_inner | epoch 035:    568 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.08, loss=4.868, nll_loss=2.008, ppl=4.02, wps=27450.1, ups=1.85, wpb=14800.2, bsz=483, num_updates=83800, lr=0.000109239, gnorm=0.728, train_wall=54, wall=46206
2020-12-20 06:59:11 | INFO | train_inner | epoch 035:    668 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.09, loss=4.875, nll_loss=2.014, ppl=4.04, wps=27429.8, ups=1.85, wpb=14798.4, bsz=499.5, num_updates=83900, lr=0.000109174, gnorm=0.733, train_wall=54, wall=46260
2020-12-20 07:00:05 | INFO | train_inner | epoch 035:    768 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.079, loss=4.872, nll_loss=2.012, ppl=4.03, wps=27437.4, ups=1.86, wpb=14789, bsz=493.6, num_updates=84000, lr=0.000109109, gnorm=0.749, train_wall=54, wall=46314
2020-12-20 07:00:59 | INFO | train_inner | epoch 035:    868 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.052, loss=4.885, nll_loss=2.031, ppl=4.09, wps=27374.3, ups=1.86, wpb=14748.8, bsz=507, num_updates=84100, lr=0.000109044, gnorm=0.726, train_wall=54, wall=46368
2020-12-20 07:01:52 | INFO | train_inner | epoch 035:    968 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.045, loss=4.894, nll_loss=2.042, ppl=4.12, wps=27378.9, ups=1.86, wpb=14722.3, bsz=498.2, num_updates=84200, lr=0.000108979, gnorm=0.746, train_wall=54, wall=46421
2020-12-20 07:02:46 | INFO | train_inner | epoch 035:   1068 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.039, loss=4.877, nll_loss=2.024, ppl=4.07, wps=27324.3, ups=1.86, wpb=14726.9, bsz=524.4, num_updates=84300, lr=0.000108915, gnorm=0.756, train_wall=54, wall=46475
2020-12-20 07:03:40 | INFO | train_inner | epoch 035:   1168 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.035, loss=4.863, nll_loss=2.008, ppl=4.02, wps=27438.3, ups=1.85, wpb=14812.1, bsz=522.9, num_updates=84400, lr=0.00010885, gnorm=0.735, train_wall=54, wall=46529
2020-12-20 07:04:34 | INFO | train_inner | epoch 035:   1268 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.06, loss=4.881, nll_loss=2.026, ppl=4.07, wps=27482.7, ups=1.86, wpb=14756.1, bsz=465.5, num_updates=84500, lr=0.000108786, gnorm=0.749, train_wall=54, wall=46583
2020-12-20 07:05:28 | INFO | train_inner | epoch 035:   1368 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.008, loss=4.857, nll_loss=2.007, ppl=4.02, wps=27398.4, ups=1.85, wpb=14840.5, bsz=534.2, num_updates=84600, lr=0.000108721, gnorm=0.725, train_wall=54, wall=46637
2020-12-20 07:06:22 | INFO | train_inner | epoch 035:   1468 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.031, loss=4.871, nll_loss=2.019, ppl=4.05, wps=27352.6, ups=1.85, wpb=14802, bsz=517.9, num_updates=84700, lr=0.000108657, gnorm=0.738, train_wall=54, wall=46691
2020-12-20 07:07:16 | INFO | train_inner | epoch 035:   1568 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.031, loss=4.892, nll_loss=2.042, ppl=4.12, wps=27461.6, ups=1.85, wpb=14824.3, bsz=501, num_updates=84800, lr=0.000108593, gnorm=0.73, train_wall=54, wall=46745
2020-12-20 07:08:10 | INFO | train_inner | epoch 035:   1668 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.029, loss=4.881, nll_loss=2.03, ppl=4.08, wps=27460.6, ups=1.85, wpb=14851.7, bsz=513.8, num_updates=84900, lr=0.000108529, gnorm=0.721, train_wall=54, wall=46799
2020-12-20 07:09:04 | INFO | train_inner | epoch 035:   1768 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.031, loss=4.87, nll_loss=2.017, ppl=4.05, wps=27553.7, ups=1.85, wpb=14926.7, bsz=523.5, num_updates=85000, lr=0.000108465, gnorm=0.734, train_wall=54, wall=46854
2020-12-20 07:09:58 | INFO | train_inner | epoch 035:   1868 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.005, loss=4.881, nll_loss=2.035, ppl=4.1, wps=27591.6, ups=1.85, wpb=14904, bsz=536.6, num_updates=85100, lr=0.000108401, gnorm=0.738, train_wall=54, wall=46908
2020-12-20 07:10:52 | INFO | train_inner | epoch 035:   1968 / 2448 symm_kl=0.557, self_kl=0, self_cv=9.014, loss=4.869, nll_loss=2.019, ppl=4.05, wps=27764.6, ups=1.86, wpb=14898.1, bsz=511.8, num_updates=85200, lr=0.000108338, gnorm=0.727, train_wall=54, wall=46961
2020-12-20 07:11:46 | INFO | train_inner | epoch 035:   2068 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.002, loss=4.878, nll_loss=2.032, ppl=4.09, wps=27550.5, ups=1.85, wpb=14859.4, bsz=522, num_updates=85300, lr=0.000108274, gnorm=0.743, train_wall=54, wall=47015
2020-12-20 07:12:40 | INFO | train_inner | epoch 035:   2168 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.038, loss=4.901, nll_loss=2.051, ppl=4.14, wps=27560.1, ups=1.86, wpb=14835.3, bsz=523.7, num_updates=85400, lr=0.000108211, gnorm=0.733, train_wall=54, wall=47069
2020-12-20 07:13:34 | INFO | train_inner | epoch 035:   2268 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.032, loss=4.905, nll_loss=2.057, ppl=4.16, wps=27372.7, ups=1.85, wpb=14802.5, bsz=483.9, num_updates=85500, lr=0.000108148, gnorm=0.746, train_wall=54, wall=47123
2020-12-20 07:14:28 | INFO | train_inner | epoch 035:   2368 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.986, loss=4.883, nll_loss=2.04, ppl=4.11, wps=27415.2, ups=1.85, wpb=14826.1, bsz=529.7, num_updates=85600, lr=0.000108084, gnorm=0.729, train_wall=54, wall=47177
2020-12-20 07:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 07:15:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 07:15:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 07:15:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 07:15:25 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.021 | nll_loss 8.058 | ppl 266.5 | bleu 15.5 | wps 5690 | wpb 7930.2 | bsz 208 | num_updates 85680 | best_bleu 16.16
2020-12-20 07:15:25 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 07:15:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 35 @ 85680 updates, score 15.5) (writing took 5.197211168706417 seconds)
2020-12-20 07:15:30 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-12-20 07:15:30 | INFO | train | epoch 035 | symm_kl 0.565 | self_kl 0 | self_cv 9.041 | loss 4.875 | nll_loss 2.021 | ppl 4.06 | wps 26898.4 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 85680 | lr 0.000108034 | gnorm 0.736 | train_wall 1316 | wall 47239
2020-12-20 07:15:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:33 | INFO | fairseq.trainer | begin training epoch 36
2020-12-20 07:15:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:15:50 | INFO | train_inner | epoch 036:     20 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.022, loss=4.879, nll_loss=2.03, ppl=4.08, wps=18051.4, ups=1.23, wpb=14706.7, bsz=529, num_updates=85700, lr=0.000108021, gnorm=0.804, train_wall=53, wall=47259
2020-12-20 07:16:43 | INFO | train_inner | epoch 036:    120 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.096, loss=4.863, nll_loss=1.999, ppl=4, wps=27489.4, ups=1.87, wpb=14711.2, bsz=504.6, num_updates=85800, lr=0.000107958, gnorm=0.732, train_wall=53, wall=47312
2020-12-20 07:17:37 | INFO | train_inner | epoch 036:    220 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.093, loss=4.848, nll_loss=1.982, ppl=3.95, wps=27471.9, ups=1.86, wpb=14778.5, bsz=492.9, num_updates=85900, lr=0.000107896, gnorm=0.727, train_wall=54, wall=47366
2020-12-20 07:18:31 | INFO | train_inner | epoch 036:    320 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.099, loss=4.844, nll_loss=1.978, ppl=3.94, wps=27639.6, ups=1.86, wpb=14894.7, bsz=523, num_updates=86000, lr=0.000107833, gnorm=0.732, train_wall=54, wall=47420
2020-12-20 07:19:25 | INFO | train_inner | epoch 036:    420 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.059, loss=4.852, nll_loss=1.992, ppl=3.98, wps=27555.1, ups=1.86, wpb=14851.5, bsz=524.9, num_updates=86100, lr=0.00010777, gnorm=0.748, train_wall=54, wall=47474
2020-12-20 07:20:19 | INFO | train_inner | epoch 036:    520 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.08, loss=4.876, nll_loss=2.016, ppl=4.05, wps=27349.6, ups=1.85, wpb=14752.3, bsz=490, num_updates=86200, lr=0.000107708, gnorm=0.748, train_wall=54, wall=47528
2020-12-20 07:21:12 | INFO | train_inner | epoch 036:    620 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.063, loss=4.851, nll_loss=1.991, ppl=3.98, wps=27582.2, ups=1.87, wpb=14788.8, bsz=510.7, num_updates=86300, lr=0.000107645, gnorm=0.734, train_wall=53, wall=47581
2020-12-20 07:22:06 | INFO | train_inner | epoch 036:    720 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.012, loss=4.843, nll_loss=1.99, ppl=3.97, wps=27438.4, ups=1.85, wpb=14796, bsz=552.8, num_updates=86400, lr=0.000107583, gnorm=0.73, train_wall=54, wall=47635
2020-12-20 07:23:00 | INFO | train_inner | epoch 036:    820 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.038, loss=4.859, nll_loss=2.004, ppl=4.01, wps=27354.5, ups=1.85, wpb=14766.1, bsz=515.4, num_updates=86500, lr=0.000107521, gnorm=0.753, train_wall=54, wall=47689
2020-12-20 07:23:54 | INFO | train_inner | epoch 036:    920 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.067, loss=4.877, nll_loss=2.02, ppl=4.05, wps=27475.4, ups=1.85, wpb=14881.8, bsz=513.2, num_updates=86600, lr=0.000107459, gnorm=0.736, train_wall=54, wall=47743
2020-12-20 07:24:48 | INFO | train_inner | epoch 036:   1020 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.043, loss=4.871, nll_loss=2.017, ppl=4.05, wps=27456.6, ups=1.86, wpb=14800.2, bsz=514.7, num_updates=86700, lr=0.000107397, gnorm=0.738, train_wall=54, wall=47797
2020-12-20 07:25:42 | INFO | train_inner | epoch 036:   1120 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.008, loss=4.864, nll_loss=2.015, ppl=4.04, wps=27452.7, ups=1.85, wpb=14799.4, bsz=533.7, num_updates=86800, lr=0.000107335, gnorm=0.75, train_wall=54, wall=47851
2020-12-20 07:26:36 | INFO | train_inner | epoch 036:   1220 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.054, loss=4.875, nll_loss=2.02, ppl=4.05, wps=27467, ups=1.85, wpb=14865.8, bsz=520.7, num_updates=86900, lr=0.000107273, gnorm=0.73, train_wall=54, wall=47905
2020-12-20 07:27:30 | INFO | train_inner | epoch 036:   1320 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.028, loss=4.872, nll_loss=2.02, ppl=4.06, wps=27546.1, ups=1.85, wpb=14854.7, bsz=523.9, num_updates=87000, lr=0.000107211, gnorm=0.734, train_wall=54, wall=47959
2020-12-20 07:28:24 | INFO | train_inner | epoch 036:   1420 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.041, loss=4.9, nll_loss=2.05, ppl=4.14, wps=27457.3, ups=1.86, wpb=14769.8, bsz=525.8, num_updates=87100, lr=0.00010715, gnorm=0.764, train_wall=54, wall=48013
2020-12-20 07:29:18 | INFO | train_inner | epoch 036:   1520 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.036, loss=4.889, nll_loss=2.038, ppl=4.11, wps=27447.3, ups=1.85, wpb=14828.3, bsz=517.4, num_updates=87200, lr=0.000107088, gnorm=0.752, train_wall=54, wall=48067
2020-12-20 07:30:12 | INFO | train_inner | epoch 036:   1620 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.029, loss=4.881, nll_loss=2.03, ppl=4.09, wps=27642.6, ups=1.86, wpb=14841.9, bsz=500.6, num_updates=87300, lr=0.000107027, gnorm=0.772, train_wall=54, wall=48121
2020-12-20 07:31:06 | INFO | train_inner | epoch 036:   1720 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.027, loss=4.876, nll_loss=2.025, ppl=4.07, wps=27424.6, ups=1.85, wpb=14833.6, bsz=520.2, num_updates=87400, lr=0.000106966, gnorm=0.761, train_wall=54, wall=48175
2020-12-20 07:32:00 | INFO | train_inner | epoch 036:   1820 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.014, loss=4.886, nll_loss=2.039, ppl=4.11, wps=27421.7, ups=1.85, wpb=14793.9, bsz=522.1, num_updates=87500, lr=0.000106904, gnorm=0.746, train_wall=54, wall=48229
2020-12-20 07:32:53 | INFO | train_inner | epoch 036:   1920 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.03, loss=4.872, nll_loss=2.021, ppl=4.06, wps=27525.4, ups=1.86, wpb=14810.4, bsz=500.3, num_updates=87600, lr=0.000106843, gnorm=0.736, train_wall=54, wall=48283
2020-12-20 07:33:47 | INFO | train_inner | epoch 036:   2020 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.066, loss=4.89, nll_loss=2.035, ppl=4.1, wps=27393.5, ups=1.85, wpb=14782.5, bsz=473.3, num_updates=87700, lr=0.000106783, gnorm=0.749, train_wall=54, wall=48337
2020-12-20 07:34:42 | INFO | train_inner | epoch 036:   2120 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.003, loss=4.883, nll_loss=2.037, ppl=4.1, wps=27440.6, ups=1.85, wpb=14864.4, bsz=511.1, num_updates=87800, lr=0.000106722, gnorm=0.733, train_wall=54, wall=48391
2020-12-20 07:35:36 | INFO | train_inner | epoch 036:   2220 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.004, loss=4.877, nll_loss=2.03, ppl=4.08, wps=27482.7, ups=1.85, wpb=14823.8, bsz=509.4, num_updates=87900, lr=0.000106661, gnorm=0.741, train_wall=54, wall=48445
2020-12-20 07:36:29 | INFO | train_inner | epoch 036:   2320 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.008, loss=4.878, nll_loss=2.03, ppl=4.09, wps=27566.1, ups=1.86, wpb=14831.2, bsz=486, num_updates=88000, lr=0.0001066, gnorm=0.747, train_wall=54, wall=48498
2020-12-20 07:37:23 | INFO | train_inner | epoch 036:   2420 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.019, loss=4.886, nll_loss=2.038, ppl=4.11, wps=27489.3, ups=1.86, wpb=14780.9, bsz=489.1, num_updates=88100, lr=0.00010654, gnorm=0.751, train_wall=54, wall=48552
2020-12-20 07:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 07:37:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:37:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 07:37:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 07:37:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 07:37:53 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.06 | nll_loss 8.097 | ppl 273.87 | bleu 15.95 | wps 5439.7 | wpb 7930.2 | bsz 208 | num_updates 88128 | best_bleu 16.16
2020-12-20 07:37:53 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 07:37:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 36 @ 88128 updates, score 15.95) (writing took 5.062455320730805 seconds)
2020-12-20 07:37:58 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-12-20 07:37:58 | INFO | train | epoch 036 | symm_kl 0.565 | self_kl 0 | self_cv 9.043 | loss 4.871 | nll_loss 2.017 | ppl 4.05 | wps 26900.3 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 88128 | lr 0.000106523 | gnorm 0.745 | train_wall 1315 | wall 48587
2020-12-20 07:37:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:37:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:38:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:38:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:38:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:38:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:38:01 | INFO | fairseq.trainer | begin training epoch 37
2020-12-20 07:38:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 07:38:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 07:38:45 | INFO | train_inner | epoch 037:     72 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.018, loss=4.828, nll_loss=1.972, ppl=3.92, wps=17972.5, ups=1.22, wpb=14715.5, bsz=534, num_updates=88200, lr=0.000106479, gnorm=0.743, train_wall=53, wall=48634
2020-12-20 07:39:39 | INFO | train_inner | epoch 037:    172 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.089, loss=4.846, nll_loss=1.981, ppl=3.95, wps=27356.4, ups=1.85, wpb=14758.1, bsz=497.6, num_updates=88300, lr=0.000106419, gnorm=0.732, train_wall=54, wall=48688
2020-12-20 07:40:33 | INFO | train_inner | epoch 037:    272 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.04, loss=4.852, nll_loss=1.995, ppl=3.99, wps=27642, ups=1.86, wpb=14869.9, bsz=541.7, num_updates=88400, lr=0.000106359, gnorm=0.739, train_wall=54, wall=48742
2020-12-20 07:41:27 | INFO | train_inner | epoch 037:    372 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.087, loss=4.869, nll_loss=2.007, ppl=4.02, wps=27331.3, ups=1.85, wpb=14783.8, bsz=482.2, num_updates=88500, lr=0.000106299, gnorm=0.742, train_wall=54, wall=48796
2020-12-20 07:42:21 | INFO | train_inner | epoch 037:    472 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.076, loss=4.865, nll_loss=2.004, ppl=4.01, wps=27508.4, ups=1.85, wpb=14848.3, bsz=497.3, num_updates=88600, lr=0.000106239, gnorm=0.742, train_wall=54, wall=48850
2020-12-20 07:43:15 | INFO | train_inner | epoch 037:    572 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.052, loss=4.86, nll_loss=2.003, ppl=4.01, wps=27411.4, ups=1.86, wpb=14770.8, bsz=509.9, num_updates=88700, lr=0.000106179, gnorm=0.727, train_wall=54, wall=48904
2020-12-20 07:44:09 | INFO | train_inner | epoch 037:    672 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.053, loss=4.863, nll_loss=2.006, ppl=4.02, wps=27448.2, ups=1.86, wpb=14773.9, bsz=503.8, num_updates=88800, lr=0.000106119, gnorm=0.751, train_wall=54, wall=48958
2020-12-20 07:45:02 | INFO | train_inner | epoch 037:    772 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.022, loss=4.863, nll_loss=2.01, ppl=4.03, wps=27468.5, ups=1.86, wpb=14801.6, bsz=528.4, num_updates=88900, lr=0.000106059, gnorm=0.747, train_wall=54, wall=49012
2020-12-20 07:45:56 | INFO | train_inner | epoch 037:    872 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.021, loss=4.849, nll_loss=1.995, ppl=3.99, wps=27565.7, ups=1.86, wpb=14822.5, bsz=528.3, num_updates=89000, lr=0.000106, gnorm=0.758, train_wall=54, wall=49065
2020-12-20 07:46:50 | INFO | train_inner | epoch 037:    972 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.084, loss=4.875, nll_loss=2.016, ppl=4.04, wps=27552.8, ups=1.86, wpb=14783.1, bsz=495.2, num_updates=89100, lr=0.00010594, gnorm=0.734, train_wall=53, wall=49119
2020-12-20 07:47:44 | INFO | train_inner | epoch 037:   1072 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.042, loss=4.862, nll_loss=2.007, ppl=4.02, wps=27431.7, ups=1.85, wpb=14839.5, bsz=513.3, num_updates=89200, lr=0.000105881, gnorm=0.754, train_wall=54, wall=49173
2020-12-20 07:48:38 | INFO | train_inner | epoch 037:   1172 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.057, loss=4.873, nll_loss=2.016, ppl=4.05, wps=27564.4, ups=1.85, wpb=14870.4, bsz=498.4, num_updates=89300, lr=0.000105822, gnorm=0.752, train_wall=54, wall=49227
2020-12-20 07:49:32 | INFO | train_inner | epoch 037:   1272 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.04, loss=4.888, nll_loss=2.036, ppl=4.1, wps=27246.9, ups=1.84, wpb=14772.5, bsz=538.6, num_updates=89400, lr=0.000105762, gnorm=0.749, train_wall=54, wall=49281
2020-12-20 07:50:26 | INFO | train_inner | epoch 037:   1372 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.041, loss=4.858, nll_loss=2.003, ppl=4.01, wps=27367.6, ups=1.85, wpb=14788.8, bsz=518, num_updates=89500, lr=0.000105703, gnorm=0.731, train_wall=54, wall=49335
2020-12-20 07:51:20 | INFO | train_inner | epoch 037:   1472 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.019, loss=4.872, nll_loss=2.021, ppl=4.06, wps=27554.5, ups=1.86, wpb=14804.5, bsz=532.7, num_updates=89600, lr=0.000105644, gnorm=0.738, train_wall=54, wall=49389
2020-12-20 07:52:14 | INFO | train_inner | epoch 037:   1572 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.053, loss=4.869, nll_loss=2.013, ppl=4.04, wps=27426.2, ups=1.85, wpb=14826.1, bsz=505.6, num_updates=89700, lr=0.000105585, gnorm=0.731, train_wall=54, wall=49443
2020-12-20 07:53:08 | INFO | train_inner | epoch 037:   1672 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.061, loss=4.884, nll_loss=2.029, ppl=4.08, wps=27387.1, ups=1.84, wpb=14851.9, bsz=491.7, num_updates=89800, lr=0.000105527, gnorm=0.755, train_wall=54, wall=49497
2020-12-20 07:54:02 | INFO | train_inner | epoch 037:   1772 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.038, loss=4.863, nll_loss=2.009, ppl=4.03, wps=27733.1, ups=1.85, wpb=14955.2, bsz=534.2, num_updates=89900, lr=0.000105468, gnorm=0.727, train_wall=54, wall=49551
2020-12-20 07:54:56 | INFO | train_inner | epoch 037:   1872 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.034, loss=4.894, nll_loss=2.044, ppl=4.12, wps=27329.1, ups=1.86, wpb=14702.8, bsz=486.2, num_updates=90000, lr=0.000105409, gnorm=0.78, train_wall=54, wall=49605
2020-12-20 07:55:50 | INFO | train_inner | epoch 037:   1972 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.052, loss=4.894, nll_loss=2.041, ppl=4.12, wps=27462.3, ups=1.85, wpb=14862.4, bsz=526, num_updates=90100, lr=0.000105351, gnorm=0.744, train_wall=54, wall=49659
2020-12-20 07:56:44 | INFO | train_inner | epoch 037:   2072 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.01, loss=4.872, nll_loss=2.023, ppl=4.06, wps=27503.1, ups=1.86, wpb=14819.9, bsz=526.5, num_updates=90200, lr=0.000105292, gnorm=0.734, train_wall=54, wall=49713
2020-12-20 07:57:38 | INFO | train_inner | epoch 037:   2172 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.047, loss=4.889, nll_loss=2.037, ppl=4.1, wps=27324.7, ups=1.85, wpb=14804.4, bsz=497.8, num_updates=90300, lr=0.000105234, gnorm=0.745, train_wall=54, wall=49767
2020-12-20 07:58:32 | INFO | train_inner | epoch 037:   2272 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.031, loss=4.876, nll_loss=2.025, ppl=4.07, wps=27549.7, ups=1.87, wpb=14764.5, bsz=507.5, num_updates=90400, lr=0.000105176, gnorm=0.762, train_wall=53, wall=49821
2020-12-20 07:59:26 | INFO | train_inner | epoch 037:   2372 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.011, loss=4.873, nll_loss=2.025, ppl=4.07, wps=27540.6, ups=1.85, wpb=14847.8, bsz=511.8, num_updates=90500, lr=0.000105118, gnorm=0.739, train_wall=54, wall=49875
2020-12-20 08:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 08:00:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 08:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 08:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 08:00:20 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.053 | nll_loss 8.099 | ppl 274.23 | bleu 15.73 | wps 5967 | wpb 7930.2 | bsz 208 | num_updates 90576 | best_bleu 16.16
2020-12-20 08:00:20 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 08:00:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 37 @ 90576 updates, score 15.73) (writing took 5.240537662059069 seconds)
2020-12-20 08:00:25 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-12-20 08:00:25 | INFO | train | epoch 037 | symm_kl 0.566 | self_kl 0 | self_cv 9.045 | loss 4.869 | nll_loss 2.014 | ppl 4.04 | wps 26909.2 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 90576 | lr 0.000105074 | gnorm 0.745 | train_wall 1316 | wall 49934
2020-12-20 08:00:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:28 | INFO | fairseq.trainer | begin training epoch 38
2020-12-20 08:00:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:00:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:00:47 | INFO | train_inner | epoch 038:     24 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.046, loss=4.871, nll_loss=2.017, ppl=4.05, wps=18138.2, ups=1.23, wpb=14769.8, bsz=496.1, num_updates=90600, lr=0.00010506, gnorm=0.76, train_wall=54, wall=49956
2020-12-20 08:01:41 | INFO | train_inner | epoch 038:    124 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.094, loss=4.835, nll_loss=1.968, ppl=3.91, wps=27698.7, ups=1.86, wpb=14859.5, bsz=516.6, num_updates=90700, lr=0.000105002, gnorm=0.742, train_wall=53, wall=50010
2020-12-20 08:02:35 | INFO | train_inner | epoch 038:    224 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.091, loss=4.848, nll_loss=1.984, ppl=3.96, wps=27137.8, ups=1.84, wpb=14746.1, bsz=495.8, num_updates=90800, lr=0.000104944, gnorm=0.738, train_wall=54, wall=50064
2020-12-20 08:03:29 | INFO | train_inner | epoch 038:    324 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.067, loss=4.843, nll_loss=1.982, ppl=3.95, wps=27456, ups=1.85, wpb=14876.8, bsz=513.4, num_updates=90900, lr=0.000104886, gnorm=0.737, train_wall=54, wall=50118
2020-12-20 08:04:23 | INFO | train_inner | epoch 038:    424 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.08, loss=4.855, nll_loss=1.993, ppl=3.98, wps=27368, ups=1.85, wpb=14820.6, bsz=529.9, num_updates=91000, lr=0.000104828, gnorm=0.735, train_wall=54, wall=50172
2020-12-20 08:05:18 | INFO | train_inner | epoch 038:    524 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.109, loss=4.862, nll_loss=1.997, ppl=3.99, wps=27245, ups=1.84, wpb=14783, bsz=496.2, num_updates=91100, lr=0.000104771, gnorm=0.748, train_wall=54, wall=50227
2020-12-20 08:06:12 | INFO | train_inner | epoch 038:    624 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.054, loss=4.856, nll_loss=1.999, ppl=4, wps=27189.9, ups=1.84, wpb=14766.8, bsz=545.8, num_updates=91200, lr=0.000104713, gnorm=0.741, train_wall=54, wall=50281
2020-12-20 08:07:06 | INFO | train_inner | epoch 038:    724 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.088, loss=4.881, nll_loss=2.021, ppl=4.06, wps=27262.1, ups=1.86, wpb=14678.5, bsz=482.2, num_updates=91300, lr=0.000104656, gnorm=0.755, train_wall=54, wall=50335
2020-12-20 08:08:00 | INFO | train_inner | epoch 038:    824 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.047, loss=4.855, nll_loss=1.998, ppl=3.99, wps=27186.3, ups=1.84, wpb=14763.6, bsz=553.5, num_updates=91400, lr=0.000104599, gnorm=0.758, train_wall=54, wall=50389
2020-12-20 08:08:54 | INFO | train_inner | epoch 038:    924 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.033, loss=4.846, nll_loss=1.99, ppl=3.97, wps=27399.6, ups=1.84, wpb=14873.9, bsz=516, num_updates=91500, lr=0.000104542, gnorm=0.741, train_wall=54, wall=50443
2020-12-20 08:09:48 | INFO | train_inner | epoch 038:   1024 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.044, loss=4.874, nll_loss=2.02, ppl=4.06, wps=27422.1, ups=1.85, wpb=14809.6, bsz=484.9, num_updates=91600, lr=0.000104485, gnorm=0.744, train_wall=54, wall=50497
2020-12-20 08:10:42 | INFO | train_inner | epoch 038:   1124 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.029, loss=4.861, nll_loss=2.008, ppl=4.02, wps=27421.7, ups=1.85, wpb=14813.7, bsz=540.8, num_updates=91700, lr=0.000104428, gnorm=0.744, train_wall=54, wall=50551
2020-12-20 08:11:36 | INFO | train_inner | epoch 038:   1224 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.07, loss=4.86, nll_loss=2.001, ppl=4, wps=27675.3, ups=1.86, wpb=14893.5, bsz=522.6, num_updates=91800, lr=0.000104371, gnorm=0.747, train_wall=54, wall=50605
2020-12-20 08:12:30 | INFO | train_inner | epoch 038:   1324 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.016, loss=4.878, nll_loss=2.029, ppl=4.08, wps=27592.9, ups=1.87, wpb=14785.4, bsz=534.3, num_updates=91900, lr=0.000104314, gnorm=0.764, train_wall=53, wall=50659
2020-12-20 08:13:23 | INFO | train_inner | epoch 038:   1424 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.037, loss=4.869, nll_loss=2.016, ppl=4.04, wps=27918.5, ups=1.86, wpb=14995.6, bsz=537.1, num_updates=92000, lr=0.000104257, gnorm=0.733, train_wall=54, wall=50713
2020-12-20 08:14:17 | INFO | train_inner | epoch 038:   1524 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.035, loss=4.875, nll_loss=2.022, ppl=4.06, wps=27681.9, ups=1.86, wpb=14847.4, bsz=481.8, num_updates=92100, lr=0.000104201, gnorm=0.76, train_wall=53, wall=50766
2020-12-20 08:15:11 | INFO | train_inner | epoch 038:   1624 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.038, loss=4.871, nll_loss=2.017, ppl=4.05, wps=27674.4, ups=1.85, wpb=14927.1, bsz=492.6, num_updates=92200, lr=0.000104144, gnorm=0.738, train_wall=54, wall=50820
2020-12-20 08:16:05 | INFO | train_inner | epoch 038:   1724 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.047, loss=4.877, nll_loss=2.024, ppl=4.07, wps=27412.8, ups=1.85, wpb=14848.6, bsz=509.1, num_updates=92300, lr=0.000104088, gnorm=0.743, train_wall=54, wall=50874
2020-12-20 08:16:59 | INFO | train_inner | epoch 038:   1824 / 2448 symm_kl=0.555, self_kl=0, self_cv=8.962, loss=4.844, nll_loss=2, ppl=4, wps=27458, ups=1.85, wpb=14837.6, bsz=538, num_updates=92400, lr=0.000104031, gnorm=0.733, train_wall=54, wall=50928
2020-12-20 08:17:53 | INFO | train_inner | epoch 038:   1924 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.044, loss=4.888, nll_loss=2.036, ppl=4.1, wps=27384.6, ups=1.85, wpb=14807.6, bsz=496.6, num_updates=92500, lr=0.000103975, gnorm=0.75, train_wall=54, wall=50982
2020-12-20 08:18:47 | INFO | train_inner | epoch 038:   2024 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.023, loss=4.874, nll_loss=2.024, ppl=4.07, wps=27449.5, ups=1.85, wpb=14819.8, bsz=503.1, num_updates=92600, lr=0.000103919, gnorm=0.74, train_wall=54, wall=51036
2020-12-20 08:19:41 | INFO | train_inner | epoch 038:   2124 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.057, loss=4.89, nll_loss=2.036, ppl=4.1, wps=27391.1, ups=1.86, wpb=14759.2, bsz=488.9, num_updates=92700, lr=0.000103863, gnorm=0.764, train_wall=54, wall=51090
2020-12-20 08:20:35 | INFO | train_inner | epoch 038:   2224 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.011, loss=4.869, nll_loss=2.02, ppl=4.06, wps=27616.6, ups=1.87, wpb=14766.4, bsz=516.5, num_updates=92800, lr=0.000103807, gnorm=0.757, train_wall=53, wall=51144
2020-12-20 08:21:28 | INFO | train_inner | epoch 038:   2324 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.014, loss=4.868, nll_loss=2.019, ppl=4.05, wps=27407.4, ups=1.86, wpb=14747.6, bsz=509.4, num_updates=92900, lr=0.000103751, gnorm=0.748, train_wall=54, wall=51198
2020-12-20 08:22:22 | INFO | train_inner | epoch 038:   2424 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.009, loss=4.892, nll_loss=2.046, ppl=4.13, wps=27323.3, ups=1.86, wpb=14726.2, bsz=495.2, num_updates=93000, lr=0.000103695, gnorm=0.751, train_wall=54, wall=51251
2020-12-20 08:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 08:22:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 08:22:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 08:22:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 08:22:49 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.06 | nll_loss 8.096 | ppl 273.67 | bleu 15.81 | wps 6047.3 | wpb 7930.2 | bsz 208 | num_updates 93024 | best_bleu 16.16
2020-12-20 08:22:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 08:22:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 38 @ 93024 updates, score 15.81) (writing took 5.275237414985895 seconds)
2020-12-20 08:22:54 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-12-20 08:22:54 | INFO | train | epoch 038 | symm_kl 0.567 | self_kl 0 | self_cv 9.046 | loss 4.865 | nll_loss 2.01 | ppl 4.03 | wps 26884.4 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 93024 | lr 0.000103682 | gnorm 0.747 | train_wall 1317 | wall 51283
2020-12-20 08:22:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:22:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:22:57 | INFO | fairseq.trainer | begin training epoch 39
2020-12-20 08:23:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:23:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:23:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:23:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:23:43 | INFO | train_inner | epoch 039:     76 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.09, loss=4.86, nll_loss=1.997, ppl=3.99, wps=18116.3, ups=1.23, wpb=14686.5, bsz=509.8, num_updates=93100, lr=0.000103639, gnorm=0.76, train_wall=53, wall=51333
2020-12-20 08:24:37 | INFO | train_inner | epoch 039:    176 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.096, loss=4.837, nll_loss=1.971, ppl=3.92, wps=27519.8, ups=1.86, wpb=14808.9, bsz=498.5, num_updates=93200, lr=0.000103584, gnorm=0.762, train_wall=54, wall=51386
2020-12-20 08:25:31 | INFO | train_inner | epoch 039:    276 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.086, loss=4.837, nll_loss=1.972, ppl=3.92, wps=27441.5, ups=1.85, wpb=14820.1, bsz=501.5, num_updates=93300, lr=0.000103528, gnorm=0.725, train_wall=54, wall=51440
2020-12-20 08:26:25 | INFO | train_inner | epoch 039:    376 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.08, loss=4.835, nll_loss=1.971, ppl=3.92, wps=27493.7, ups=1.85, wpb=14858.8, bsz=485.4, num_updates=93400, lr=0.000103473, gnorm=0.722, train_wall=54, wall=51494
2020-12-20 08:27:20 | INFO | train_inner | epoch 039:    476 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.079, loss=4.848, nll_loss=1.985, ppl=3.96, wps=27386.2, ups=1.84, wpb=14873.7, bsz=536.1, num_updates=93500, lr=0.000103418, gnorm=0.738, train_wall=54, wall=51549
2020-12-20 08:28:14 | INFO | train_inner | epoch 039:    576 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.114, loss=4.879, nll_loss=2.015, ppl=4.04, wps=27307.2, ups=1.85, wpb=14724.7, bsz=472, num_updates=93600, lr=0.000103362, gnorm=0.747, train_wall=54, wall=51603
2020-12-20 08:29:07 | INFO | train_inner | epoch 039:    676 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.075, loss=4.87, nll_loss=2.011, ppl=4.03, wps=27471.1, ups=1.86, wpb=14734.6, bsz=517.2, num_updates=93700, lr=0.000103307, gnorm=0.742, train_wall=53, wall=51656
2020-12-20 08:30:01 | INFO | train_inner | epoch 039:    776 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.082, loss=4.863, nll_loss=2.002, ppl=4.01, wps=27627.4, ups=1.86, wpb=14840.6, bsz=518.9, num_updates=93800, lr=0.000103252, gnorm=0.75, train_wall=54, wall=51710
2020-12-20 08:30:55 | INFO | train_inner | epoch 039:    876 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.07, loss=4.876, nll_loss=2.018, ppl=4.05, wps=27520.8, ups=1.86, wpb=14810.5, bsz=512.6, num_updates=93900, lr=0.000103197, gnorm=0.758, train_wall=54, wall=51764
2020-12-20 08:31:49 | INFO | train_inner | epoch 039:    976 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.056, loss=4.855, nll_loss=1.997, ppl=3.99, wps=27476.2, ups=1.85, wpb=14826.5, bsz=515.8, num_updates=94000, lr=0.000103142, gnorm=0.739, train_wall=54, wall=51818
2020-12-20 08:32:43 | INFO | train_inner | epoch 039:   1076 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.065, loss=4.867, nll_loss=2.009, ppl=4.03, wps=27536, ups=1.85, wpb=14859.4, bsz=498.1, num_updates=94100, lr=0.000103087, gnorm=0.736, train_wall=54, wall=51872
2020-12-20 08:33:36 | INFO | train_inner | epoch 039:   1176 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.058, loss=4.876, nll_loss=2.021, ppl=4.06, wps=27528.2, ups=1.86, wpb=14809, bsz=516.2, num_updates=94200, lr=0.000103033, gnorm=0.763, train_wall=54, wall=51926
2020-12-20 08:34:30 | INFO | train_inner | epoch 039:   1276 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.042, loss=4.867, nll_loss=2.012, ppl=4.03, wps=27488.5, ups=1.85, wpb=14852.7, bsz=517.5, num_updates=94300, lr=0.000102978, gnorm=0.75, train_wall=54, wall=51980
2020-12-20 08:35:25 | INFO | train_inner | epoch 039:   1376 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.032, loss=4.867, nll_loss=2.015, ppl=4.04, wps=27156, ups=1.85, wpb=14674.7, bsz=531.8, num_updates=94400, lr=0.000102923, gnorm=0.753, train_wall=54, wall=52034
2020-12-20 08:36:19 | INFO | train_inner | epoch 039:   1476 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.011, loss=4.848, nll_loss=1.996, ppl=3.99, wps=27626.6, ups=1.85, wpb=14916, bsz=497.4, num_updates=94500, lr=0.000102869, gnorm=0.745, train_wall=54, wall=52088
2020-12-20 08:37:12 | INFO | train_inner | epoch 039:   1576 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.054, loss=4.877, nll_loss=2.023, ppl=4.06, wps=27440.3, ups=1.86, wpb=14755.3, bsz=510, num_updates=94600, lr=0.000102815, gnorm=0.749, train_wall=54, wall=52141
2020-12-20 08:38:06 | INFO | train_inner | epoch 039:   1676 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.005, loss=4.849, nll_loss=1.999, ppl=4, wps=27455.6, ups=1.86, wpb=14793.5, bsz=545.6, num_updates=94700, lr=0.00010276, gnorm=0.768, train_wall=54, wall=52195
2020-12-20 08:39:00 | INFO | train_inner | epoch 039:   1776 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.027, loss=4.864, nll_loss=2.011, ppl=4.03, wps=27484.9, ups=1.85, wpb=14833.7, bsz=510.3, num_updates=94800, lr=0.000102706, gnorm=0.751, train_wall=54, wall=52249
2020-12-20 08:39:54 | INFO | train_inner | epoch 039:   1876 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.007, loss=4.87, nll_loss=2.022, ppl=4.06, wps=27526.4, ups=1.85, wpb=14849.6, bsz=523.8, num_updates=94900, lr=0.000102652, gnorm=0.758, train_wall=54, wall=52303
2020-12-20 08:40:48 | INFO | train_inner | epoch 039:   1976 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.014, loss=4.863, nll_loss=2.013, ppl=4.04, wps=27465.8, ups=1.86, wpb=14744.8, bsz=525.6, num_updates=95000, lr=0.000102598, gnorm=0.767, train_wall=54, wall=52357
2020-12-20 08:41:42 | INFO | train_inner | epoch 039:   2076 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.046, loss=4.89, nll_loss=2.039, ppl=4.11, wps=27300.8, ups=1.85, wpb=14774.6, bsz=510.6, num_updates=95100, lr=0.000102544, gnorm=0.754, train_wall=54, wall=52411
2020-12-20 08:42:36 | INFO | train_inner | epoch 039:   2176 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.015, loss=4.875, nll_loss=2.026, ppl=4.07, wps=27596.3, ups=1.86, wpb=14814.3, bsz=516.1, num_updates=95200, lr=0.00010249, gnorm=0.758, train_wall=54, wall=52465
2020-12-20 08:43:29 | INFO | train_inner | epoch 039:   2276 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.058, loss=4.884, nll_loss=2.029, ppl=4.08, wps=27497, ups=1.85, wpb=14830.8, bsz=475.2, num_updates=95300, lr=0.000102436, gnorm=0.741, train_wall=54, wall=52519
2020-12-20 08:44:23 | INFO | train_inner | epoch 039:   2376 / 2448 symm_kl=0.558, self_kl=0, self_cv=9.011, loss=4.86, nll_loss=2.01, ppl=4.03, wps=27923, ups=1.87, wpb=14970.1, bsz=518.2, num_updates=95400, lr=0.000102383, gnorm=0.744, train_wall=53, wall=52572
2020-12-20 08:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 08:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 08:45:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 08:45:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 08:45:16 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.041 | nll_loss 8.078 | ppl 270.31 | bleu 15.77 | wps 5584.7 | wpb 7930.2 | bsz 208 | num_updates 95472 | best_bleu 16.16
2020-12-20 08:45:16 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 08:45:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 39 @ 95472 updates, score 15.77) (writing took 5.239432662725449 seconds)
2020-12-20 08:45:21 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-12-20 08:45:21 | INFO | train | epoch 039 | symm_kl 0.567 | self_kl 0 | self_cv 9.05 | loss 4.863 | nll_loss 2.007 | ppl 4.02 | wps 26905.7 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 95472 | lr 0.000102344 | gnorm 0.75 | train_wall 1315 | wall 52630
2020-12-20 08:45:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:24 | INFO | fairseq.trainer | begin training epoch 40
2020-12-20 08:45:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 08:45:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 08:45:45 | INFO | train_inner | epoch 040:     28 / 2448 symm_kl=0.564, self_kl=0, self_cv=8.992, loss=4.862, nll_loss=2.015, ppl=4.04, wps=17849.7, ups=1.22, wpb=14623.6, bsz=507.9, num_updates=95500, lr=0.000102329, gnorm=0.78, train_wall=54, wall=52654
2020-12-20 08:46:39 | INFO | train_inner | epoch 040:    128 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.096, loss=4.829, nll_loss=1.961, ppl=3.89, wps=27603.8, ups=1.87, wpb=14762.2, bsz=510, num_updates=95600, lr=0.000102275, gnorm=0.738, train_wall=53, wall=52708
2020-12-20 08:47:32 | INFO | train_inner | epoch 040:    228 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.089, loss=4.84, nll_loss=1.975, ppl=3.93, wps=27514.3, ups=1.85, wpb=14833.6, bsz=521.2, num_updates=95700, lr=0.000102222, gnorm=0.752, train_wall=54, wall=52762
2020-12-20 08:48:27 | INFO | train_inner | epoch 040:    328 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.105, loss=4.844, nll_loss=1.977, ppl=3.94, wps=27465.9, ups=1.85, wpb=14858.1, bsz=491.1, num_updates=95800, lr=0.000102169, gnorm=0.737, train_wall=54, wall=52816
2020-12-20 08:49:20 | INFO | train_inner | epoch 040:    428 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.06, loss=4.844, nll_loss=1.983, ppl=3.95, wps=27586.2, ups=1.86, wpb=14821.5, bsz=506, num_updates=95900, lr=0.000102115, gnorm=0.759, train_wall=54, wall=52869
2020-12-20 08:50:14 | INFO | train_inner | epoch 040:    528 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.056, loss=4.842, nll_loss=1.983, ppl=3.95, wps=27369.9, ups=1.85, wpb=14828.8, bsz=544.8, num_updates=96000, lr=0.000102062, gnorm=0.743, train_wall=54, wall=52924
2020-12-20 08:51:08 | INFO | train_inner | epoch 040:    628 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.052, loss=4.839, nll_loss=1.98, ppl=3.94, wps=27378.2, ups=1.85, wpb=14801.4, bsz=520.6, num_updates=96100, lr=0.000102009, gnorm=0.743, train_wall=54, wall=52978
2020-12-20 08:52:02 | INFO | train_inner | epoch 040:    728 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.048, loss=4.878, nll_loss=2.025, ppl=4.07, wps=27255.7, ups=1.86, wpb=14681.1, bsz=536.2, num_updates=96200, lr=0.000101956, gnorm=0.789, train_wall=54, wall=53031
2020-12-20 08:52:57 | INFO | train_inner | epoch 040:    828 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.087, loss=4.873, nll_loss=2.012, ppl=4.03, wps=27251.6, ups=1.84, wpb=14772.1, bsz=482.7, num_updates=96300, lr=0.000101903, gnorm=0.752, train_wall=54, wall=53086
2020-12-20 08:53:51 | INFO | train_inner | epoch 040:    928 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.068, loss=4.855, nll_loss=1.996, ppl=3.99, wps=27678, ups=1.85, wpb=14965.9, bsz=518.6, num_updates=96400, lr=0.00010185, gnorm=0.756, train_wall=54, wall=53140
2020-12-20 08:54:44 | INFO | train_inner | epoch 040:   1028 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.03, loss=4.849, nll_loss=1.995, ppl=3.99, wps=27660.7, ups=1.86, wpb=14880, bsz=514.7, num_updates=96500, lr=0.000101797, gnorm=0.744, train_wall=54, wall=53194
2020-12-20 08:55:38 | INFO | train_inner | epoch 040:   1128 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.053, loss=4.859, nll_loss=2.002, ppl=4, wps=27422.3, ups=1.86, wpb=14781.5, bsz=495, num_updates=96600, lr=0.000101745, gnorm=0.755, train_wall=54, wall=53247
2020-12-20 08:56:32 | INFO | train_inner | epoch 040:   1228 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.055, loss=4.861, nll_loss=2.004, ppl=4.01, wps=27550, ups=1.85, wpb=14868.6, bsz=519.7, num_updates=96700, lr=0.000101692, gnorm=0.759, train_wall=54, wall=53301
2020-12-20 08:57:26 | INFO | train_inner | epoch 040:   1328 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.059, loss=4.87, nll_loss=2.013, ppl=4.04, wps=27631.8, ups=1.86, wpb=14866.9, bsz=516.6, num_updates=96800, lr=0.000101639, gnorm=0.772, train_wall=54, wall=53355
2020-12-20 08:58:20 | INFO | train_inner | epoch 040:   1428 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.009, loss=4.853, nll_loss=2.002, ppl=4.01, wps=27534.4, ups=1.86, wpb=14834.6, bsz=543.8, num_updates=96900, lr=0.000101587, gnorm=0.742, train_wall=54, wall=53409
2020-12-20 08:59:14 | INFO | train_inner | epoch 040:   1528 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.082, loss=4.868, nll_loss=2.007, ppl=4.02, wps=27551.4, ups=1.86, wpb=14838, bsz=483.9, num_updates=97000, lr=0.000101535, gnorm=0.755, train_wall=54, wall=53463
2020-12-20 09:00:08 | INFO | train_inner | epoch 040:   1628 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.018, loss=4.881, nll_loss=2.032, ppl=4.09, wps=27562.7, ups=1.86, wpb=14824.1, bsz=505.6, num_updates=97100, lr=0.000101482, gnorm=0.763, train_wall=54, wall=53517
2020-12-20 09:01:01 | INFO | train_inner | epoch 040:   1728 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.05, loss=4.863, nll_loss=2.008, ppl=4.02, wps=27482.8, ups=1.86, wpb=14768.8, bsz=500, num_updates=97200, lr=0.00010143, gnorm=0.755, train_wall=54, wall=53570
2020-12-20 09:01:55 | INFO | train_inner | epoch 040:   1828 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.063, loss=4.889, nll_loss=2.034, ppl=4.1, wps=27321.5, ups=1.85, wpb=14754, bsz=495.2, num_updates=97300, lr=0.000101378, gnorm=0.758, train_wall=54, wall=53624
2020-12-20 09:02:49 | INFO | train_inner | epoch 040:   1928 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.031, loss=4.862, nll_loss=2.009, ppl=4.03, wps=27563.9, ups=1.85, wpb=14897.9, bsz=499, num_updates=97400, lr=0.000101326, gnorm=0.752, train_wall=54, wall=53679
2020-12-20 09:03:43 | INFO | train_inner | epoch 040:   2028 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.01, loss=4.864, nll_loss=2.015, ppl=4.04, wps=27467.9, ups=1.86, wpb=14785.5, bsz=537.3, num_updates=97500, lr=0.000101274, gnorm=0.759, train_wall=54, wall=53732
2020-12-20 09:04:37 | INFO | train_inner | epoch 040:   2128 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.058, loss=4.882, nll_loss=2.028, ppl=4.08, wps=27533.4, ups=1.86, wpb=14802.7, bsz=509.1, num_updates=97600, lr=0.000101222, gnorm=0.762, train_wall=54, wall=53786
2020-12-20 09:05:31 | INFO | train_inner | epoch 040:   2228 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.05, loss=4.864, nll_loss=2.009, ppl=4.02, wps=27704.1, ups=1.86, wpb=14865.5, bsz=523.8, num_updates=97700, lr=0.00010117, gnorm=0.738, train_wall=53, wall=53840
2020-12-20 09:06:25 | INFO | train_inner | epoch 040:   2328 / 2448 symm_kl=0.564, self_kl=0, self_cv=9.005, loss=4.869, nll_loss=2.021, ppl=4.06, wps=27448.3, ups=1.85, wpb=14822.2, bsz=524.3, num_updates=97800, lr=0.000101118, gnorm=0.754, train_wall=54, wall=53894
2020-12-20 09:07:19 | INFO | train_inner | epoch 040:   2428 / 2448 symm_kl=0.562, self_kl=0, self_cv=8.973, loss=4.859, nll_loss=2.015, ppl=4.04, wps=27328.6, ups=1.86, wpb=14730.7, bsz=517.5, num_updates=97900, lr=0.000101067, gnorm=0.76, train_wall=54, wall=53948
2020-12-20 09:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 09:07:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 09:07:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 09:07:43 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.077 | nll_loss 8.117 | ppl 277.58 | bleu 15.91 | wps 5710.5 | wpb 7930.2 | bsz 208 | num_updates 97920 | best_bleu 16.16
2020-12-20 09:07:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 09:07:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 40 @ 97920 updates, score 15.91) (writing took 5.212602656334639 seconds)
2020-12-20 09:07:49 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-12-20 09:07:49 | INFO | train | epoch 040 | symm_kl 0.568 | self_kl 0 | self_cv 9.051 | loss 4.86 | nll_loss 2.004 | ppl 4.01 | wps 26911 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 97920 | lr 0.000101057 | gnorm 0.754 | train_wall 1315 | wall 53978
2020-12-20 09:07:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:51 | INFO | fairseq.trainer | begin training epoch 41
2020-12-20 09:07:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:07:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:07:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:08:40 | INFO | train_inner | epoch 041:     80 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.118, loss=4.842, nll_loss=1.972, ppl=3.92, wps=17945, ups=1.23, wpb=14633.5, bsz=493.8, num_updates=98000, lr=0.000101015, gnorm=0.774, train_wall=53, wall=54029
2020-12-20 09:09:34 | INFO | train_inner | epoch 041:    180 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.067, loss=4.822, nll_loss=1.958, ppl=3.89, wps=27390.9, ups=1.85, wpb=14785.6, bsz=517, num_updates=98100, lr=0.000100964, gnorm=0.753, train_wall=54, wall=54083
2020-12-20 09:10:28 | INFO | train_inner | epoch 041:    280 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.096, loss=4.837, nll_loss=1.971, ppl=3.92, wps=27716.2, ups=1.86, wpb=14900.9, bsz=499.2, num_updates=98200, lr=0.000100912, gnorm=0.76, train_wall=54, wall=54137
2020-12-20 09:11:22 | INFO | train_inner | epoch 041:    380 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.068, loss=4.836, nll_loss=1.974, ppl=3.93, wps=27575.3, ups=1.86, wpb=14847.4, bsz=533.4, num_updates=98300, lr=0.000100861, gnorm=0.75, train_wall=54, wall=54191
2020-12-20 09:12:16 | INFO | train_inner | epoch 041:    480 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.046, loss=4.865, nll_loss=2.009, ppl=4.02, wps=27412.4, ups=1.86, wpb=14767.6, bsz=538.1, num_updates=98400, lr=0.00010081, gnorm=0.756, train_wall=54, wall=54245
2020-12-20 09:13:09 | INFO | train_inner | epoch 041:    580 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.034, loss=4.846, nll_loss=1.99, ppl=3.97, wps=27582.7, ups=1.86, wpb=14832, bsz=509, num_updates=98500, lr=0.000100759, gnorm=0.743, train_wall=54, wall=54298
2020-12-20 09:14:03 | INFO | train_inner | epoch 041:    680 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.095, loss=4.863, nll_loss=1.999, ppl=4, wps=27475, ups=1.86, wpb=14748.1, bsz=492.2, num_updates=98600, lr=0.000100707, gnorm=0.784, train_wall=54, wall=54352
2020-12-20 09:14:57 | INFO | train_inner | epoch 041:    780 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.04, loss=4.832, nll_loss=1.974, ppl=3.93, wps=27681.2, ups=1.86, wpb=14868.8, bsz=527.2, num_updates=98700, lr=0.000100656, gnorm=0.758, train_wall=54, wall=54406
2020-12-20 09:15:51 | INFO | train_inner | epoch 041:    880 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.073, loss=4.879, nll_loss=2.022, ppl=4.06, wps=27295.4, ups=1.85, wpb=14746.7, bsz=508.8, num_updates=98800, lr=0.000100605, gnorm=0.771, train_wall=54, wall=54460
2020-12-20 09:16:45 | INFO | train_inner | epoch 041:    980 / 2448 symm_kl=0.577, self_kl=0, self_cv=9.073, loss=4.883, nll_loss=2.026, ppl=4.07, wps=27284.5, ups=1.85, wpb=14734.2, bsz=501.8, num_updates=98900, lr=0.000100555, gnorm=0.778, train_wall=54, wall=54514
2020-12-20 09:17:39 | INFO | train_inner | epoch 041:   1080 / 2448 symm_kl=0.559, self_kl=0, self_cv=8.998, loss=4.834, nll_loss=1.982, ppl=3.95, wps=27593.5, ups=1.86, wpb=14842.8, bsz=540.6, num_updates=99000, lr=0.000100504, gnorm=0.767, train_wall=54, wall=54568
2020-12-20 09:18:33 | INFO | train_inner | epoch 041:   1180 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.073, loss=4.86, nll_loss=2.001, ppl=4, wps=27521.7, ups=1.85, wpb=14869.9, bsz=491.5, num_updates=99100, lr=0.000100453, gnorm=0.76, train_wall=54, wall=54622
2020-12-20 09:19:26 | INFO | train_inner | epoch 041:   1280 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.046, loss=4.875, nll_loss=2.022, ppl=4.06, wps=27607.4, ups=1.86, wpb=14874.5, bsz=515.5, num_updates=99200, lr=0.000100402, gnorm=0.765, train_wall=54, wall=54676
2020-12-20 09:20:21 | INFO | train_inner | epoch 041:   1380 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.056, loss=4.855, nll_loss=1.997, ppl=3.99, wps=27534.5, ups=1.85, wpb=14912.2, bsz=523.5, num_updates=99300, lr=0.000100352, gnorm=0.747, train_wall=54, wall=54730
2020-12-20 09:21:15 | INFO | train_inner | epoch 041:   1480 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.049, loss=4.863, nll_loss=2.007, ppl=4.02, wps=27363.8, ups=1.85, wpb=14755.2, bsz=485.8, num_updates=99400, lr=0.000100301, gnorm=0.761, train_wall=54, wall=54784
2020-12-20 09:22:08 | INFO | train_inner | epoch 041:   1580 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.073, loss=4.867, nll_loss=2.008, ppl=4.02, wps=27637.7, ups=1.86, wpb=14877.8, bsz=492, num_updates=99500, lr=0.000100251, gnorm=0.762, train_wall=54, wall=54838
2020-12-20 09:23:02 | INFO | train_inner | epoch 041:   1680 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.05, loss=4.864, nll_loss=2.009, ppl=4.02, wps=27357, ups=1.85, wpb=14779.3, bsz=518.3, num_updates=99600, lr=0.000100201, gnorm=0.768, train_wall=54, wall=54892
2020-12-20 09:23:56 | INFO | train_inner | epoch 041:   1780 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.039, loss=4.858, nll_loss=2.003, ppl=4.01, wps=27652.6, ups=1.85, wpb=14912.5, bsz=492.2, num_updates=99700, lr=0.00010015, gnorm=0.757, train_wall=54, wall=54945
2020-12-20 09:24:50 | INFO | train_inner | epoch 041:   1880 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.046, loss=4.877, nll_loss=2.023, ppl=4.07, wps=27397.3, ups=1.85, wpb=14781.7, bsz=527.3, num_updates=99800, lr=0.0001001, gnorm=0.773, train_wall=54, wall=54999
2020-12-20 09:25:44 | INFO | train_inner | epoch 041:   1980 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.028, loss=4.859, nll_loss=2.007, ppl=4.02, wps=27295.4, ups=1.85, wpb=14779.1, bsz=498.2, num_updates=99900, lr=0.00010005, gnorm=0.76, train_wall=54, wall=55054
2020-12-20 09:26:39 | INFO | train_inner | epoch 041:   2080 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.028, loss=4.858, nll_loss=2.005, ppl=4.01, wps=27403.2, ups=1.85, wpb=14816.9, bsz=523, num_updates=100000, lr=0.0001, gnorm=0.773, train_wall=54, wall=55108
2020-12-20 09:27:32 | INFO | train_inner | epoch 041:   2180 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.009, loss=4.881, nll_loss=2.034, ppl=4.09, wps=27300.9, ups=1.86, wpb=14685.9, bsz=526.2, num_updates=100100, lr=9.995e-05, gnorm=0.767, train_wall=54, wall=55161
2020-12-20 09:28:26 | INFO | train_inner | epoch 041:   2280 / 2448 symm_kl=0.561, self_kl=0, self_cv=9.03, loss=4.847, nll_loss=1.993, ppl=3.98, wps=27542.8, ups=1.85, wpb=14904.9, bsz=504.6, num_updates=100200, lr=9.99001e-05, gnorm=0.772, train_wall=54, wall=55216
2020-12-20 09:29:21 | INFO | train_inner | epoch 041:   2380 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.038, loss=4.884, nll_loss=2.033, ppl=4.09, wps=27275.8, ups=1.85, wpb=14760.6, bsz=519, num_updates=100300, lr=9.98503e-05, gnorm=0.776, train_wall=54, wall=55270
2020-12-20 09:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 09:29:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:29:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:29:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:29:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:29:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 09:30:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 09:30:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 09:30:12 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.089 | nll_loss 8.138 | ppl 281.68 | bleu 15.51 | wps 5301.1 | wpb 7930.2 | bsz 208 | num_updates 100368 | best_bleu 16.16
2020-12-20 09:30:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 09:30:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 41 @ 100368 updates, score 15.51) (writing took 5.310694471001625 seconds)
2020-12-20 09:30:17 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2020-12-20 09:30:17 | INFO | train | epoch 041 | symm_kl 0.568 | self_kl 0 | self_cv 9.052 | loss 4.857 | nll_loss 2.001 | ppl 4 | wps 26887.6 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 100368 | lr 9.98165e-05 | gnorm 0.763 | train_wall 1316 | wall 55326
2020-12-20 09:30:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:20 | INFO | fairseq.trainer | begin training epoch 42
2020-12-20 09:30:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:30:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:30:43 | INFO | train_inner | epoch 042:     32 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.07, loss=4.854, nll_loss=1.994, ppl=3.98, wps=17881.5, ups=1.21, wpb=14720.5, bsz=490.6, num_updates=100400, lr=9.98006e-05, gnorm=0.762, train_wall=53, wall=55352
2020-12-20 09:31:37 | INFO | train_inner | epoch 042:    132 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.076, loss=4.832, nll_loss=1.968, ppl=3.91, wps=27617.4, ups=1.86, wpb=14823.5, bsz=532.1, num_updates=100500, lr=9.97509e-05, gnorm=0.755, train_wall=54, wall=55406
2020-12-20 09:32:30 | INFO | train_inner | epoch 042:    232 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.12, loss=4.817, nll_loss=1.944, ppl=3.85, wps=27715.6, ups=1.86, wpb=14932.3, bsz=489.3, num_updates=100600, lr=9.97013e-05, gnorm=0.749, train_wall=54, wall=55460
2020-12-20 09:33:25 | INFO | train_inner | epoch 042:    332 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.067, loss=4.814, nll_loss=1.949, ppl=3.86, wps=27491.3, ups=1.84, wpb=14915.4, bsz=527, num_updates=100700, lr=9.96518e-05, gnorm=0.75, train_wall=54, wall=55514
2020-12-20 09:34:19 | INFO | train_inner | epoch 042:    432 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.055, loss=4.834, nll_loss=1.973, ppl=3.93, wps=27394.5, ups=1.84, wpb=14882.1, bsz=545.9, num_updates=100800, lr=9.96024e-05, gnorm=0.748, train_wall=54, wall=55568
2020-12-20 09:35:13 | INFO | train_inner | epoch 042:    532 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.04, loss=4.847, nll_loss=1.99, ppl=3.97, wps=27169.9, ups=1.85, wpb=14691, bsz=504.5, num_updates=100900, lr=9.9553e-05, gnorm=0.746, train_wall=54, wall=55622
2020-12-20 09:36:07 | INFO | train_inner | epoch 042:    632 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.105, loss=4.861, nll_loss=1.997, ppl=3.99, wps=27283.9, ups=1.85, wpb=14758.7, bsz=497.7, num_updates=101000, lr=9.95037e-05, gnorm=0.782, train_wall=54, wall=55676
2020-12-20 09:37:01 | INFO | train_inner | epoch 042:    732 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.082, loss=4.85, nll_loss=1.988, ppl=3.97, wps=27369.4, ups=1.85, wpb=14801.5, bsz=502.6, num_updates=101100, lr=9.94545e-05, gnorm=0.773, train_wall=54, wall=55730
2020-12-20 09:37:55 | INFO | train_inner | epoch 042:    832 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.08, loss=4.863, nll_loss=2.003, ppl=4.01, wps=27569.7, ups=1.86, wpb=14797.1, bsz=497.8, num_updates=101200, lr=9.94053e-05, gnorm=0.764, train_wall=54, wall=55784
2020-12-20 09:38:49 | INFO | train_inner | epoch 042:    932 / 2448 symm_kl=0.577, self_kl=0, self_cv=9.073, loss=4.872, nll_loss=2.013, ppl=4.04, wps=27367.9, ups=1.85, wpb=14799.6, bsz=500.2, num_updates=101300, lr=9.93563e-05, gnorm=0.791, train_wall=54, wall=55838
2020-12-20 09:39:43 | INFO | train_inner | epoch 042:   1032 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.046, loss=4.846, nll_loss=1.988, ppl=3.97, wps=27471.1, ups=1.85, wpb=14846.1, bsz=501.4, num_updates=101400, lr=9.93073e-05, gnorm=0.759, train_wall=54, wall=55892
2020-12-20 09:40:37 | INFO | train_inner | epoch 042:   1132 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.056, loss=4.871, nll_loss=2.015, ppl=4.04, wps=27301.6, ups=1.85, wpb=14729, bsz=494.7, num_updates=101500, lr=9.92583e-05, gnorm=0.772, train_wall=54, wall=55946
2020-12-20 09:41:31 | INFO | train_inner | epoch 042:   1232 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.059, loss=4.858, nll_loss=2.001, ppl=4, wps=27478.3, ups=1.85, wpb=14823.2, bsz=523.3, num_updates=101600, lr=9.92095e-05, gnorm=0.764, train_wall=54, wall=56000
2020-12-20 09:42:25 | INFO | train_inner | epoch 042:   1332 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.031, loss=4.85, nll_loss=1.995, ppl=3.99, wps=27328.2, ups=1.85, wpb=14755, bsz=497.6, num_updates=101700, lr=9.91607e-05, gnorm=0.76, train_wall=54, wall=56054
2020-12-20 09:43:19 | INFO | train_inner | epoch 042:   1432 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.076, loss=4.872, nll_loss=2.014, ppl=4.04, wps=27416.6, ups=1.86, wpb=14759.5, bsz=494.6, num_updates=101800, lr=9.9112e-05, gnorm=0.775, train_wall=54, wall=56108
2020-12-20 09:44:13 | INFO | train_inner | epoch 042:   1532 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.043, loss=4.865, nll_loss=2.011, ppl=4.03, wps=27416, ups=1.84, wpb=14877.5, bsz=502.4, num_updates=101900, lr=9.90633e-05, gnorm=0.746, train_wall=54, wall=56162
2020-12-20 09:45:07 | INFO | train_inner | epoch 042:   1632 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.036, loss=4.856, nll_loss=2.002, ppl=4.01, wps=27228, ups=1.84, wpb=14810.7, bsz=538.2, num_updates=102000, lr=9.90148e-05, gnorm=0.771, train_wall=54, wall=56217
2020-12-20 09:46:01 | INFO | train_inner | epoch 042:   1732 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.044, loss=4.871, nll_loss=2.017, ppl=4.05, wps=27372.8, ups=1.85, wpb=14777.1, bsz=527.6, num_updates=102100, lr=9.89663e-05, gnorm=0.773, train_wall=54, wall=56271
2020-12-20 09:46:56 | INFO | train_inner | epoch 042:   1832 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.026, loss=4.854, nll_loss=2.002, ppl=4, wps=27469.3, ups=1.85, wpb=14859.4, bsz=532.2, num_updates=102200, lr=9.89178e-05, gnorm=0.787, train_wall=54, wall=56325
2020-12-20 09:47:50 | INFO | train_inner | epoch 042:   1932 / 2448 symm_kl=0.56, self_kl=0, self_cv=9.015, loss=4.841, nll_loss=1.988, ppl=3.97, wps=27448, ups=1.85, wpb=14849.1, bsz=539.1, num_updates=102300, lr=9.88695e-05, gnorm=0.761, train_wall=54, wall=56379
2020-12-20 09:48:44 | INFO | train_inner | epoch 042:   2032 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.017, loss=4.865, nll_loss=2.015, ppl=4.04, wps=27312.9, ups=1.85, wpb=14780.8, bsz=518.3, num_updates=102400, lr=9.88212e-05, gnorm=0.758, train_wall=54, wall=56433
2020-12-20 09:49:38 | INFO | train_inner | epoch 042:   2132 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.051, loss=4.874, nll_loss=2.02, ppl=4.06, wps=27423.8, ups=1.85, wpb=14840.2, bsz=500.6, num_updates=102500, lr=9.8773e-05, gnorm=0.767, train_wall=54, wall=56487
2020-12-20 09:50:32 | INFO | train_inner | epoch 042:   2232 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.051, loss=4.877, nll_loss=2.023, ppl=4.06, wps=27552.4, ups=1.85, wpb=14860.3, bsz=491.6, num_updates=102600, lr=9.87248e-05, gnorm=0.768, train_wall=54, wall=56541
2020-12-20 09:51:26 | INFO | train_inner | epoch 042:   2332 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.033, loss=4.871, nll_loss=2.02, ppl=4.06, wps=27423, ups=1.85, wpb=14804.7, bsz=516.3, num_updates=102700, lr=9.86767e-05, gnorm=0.775, train_wall=54, wall=56595
2020-12-20 09:52:19 | INFO | train_inner | epoch 042:   2432 / 2448 symm_kl=0.565, self_kl=0, self_cv=8.994, loss=4.865, nll_loss=2.018, ppl=4.05, wps=27523.8, ups=1.86, wpb=14769, bsz=515.3, num_updates=102800, lr=9.86287e-05, gnorm=0.764, train_wall=53, wall=56649
2020-12-20 09:52:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 09:52:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 09:52:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 09:52:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 09:52:42 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.07 | nll_loss 8.107 | ppl 275.71 | bleu 16.18 | wps 5720 | wpb 7930.2 | bsz 208 | num_updates 102816 | best_bleu 16.18
2020-12-20 09:52:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 09:52:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:52:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_best.pt (epoch 42 @ 102816 updates, score 16.18) (writing took 8.12023788318038 seconds)
2020-12-20 09:52:50 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2020-12-20 09:52:50 | INFO | train | epoch 042 | symm_kl 0.569 | self_kl 0 | self_cv 9.054 | loss 4.855 | nll_loss 1.998 | ppl 3.99 | wps 26794.5 | ups 1.81 | wpb 14810.4 | bsz 511.8 | num_updates 102816 | lr 9.86211e-05 | gnorm 0.766 | train_wall 1318 | wall 56679
2020-12-20 09:52:53 | INFO | fairseq.trainer | begin training epoch 43
2020-12-20 09:52:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 09:52:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 09:53:44 | INFO | train_inner | epoch 043:     84 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.103, loss=4.829, nll_loss=1.961, ppl=3.89, wps=17408, ups=1.18, wpb=14691.5, bsz=503, num_updates=102900, lr=9.85808e-05, gnorm=0.772, train_wall=53, wall=56733
2020-12-20 09:54:38 | INFO | train_inner | epoch 043:    184 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.112, loss=4.835, nll_loss=1.966, ppl=3.91, wps=27651.8, ups=1.86, wpb=14891.6, bsz=516.7, num_updates=103000, lr=9.85329e-05, gnorm=0.759, train_wall=54, wall=56787
2020-12-20 09:55:32 | INFO | train_inner | epoch 043:    284 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.073, loss=4.834, nll_loss=1.971, ppl=3.92, wps=27409.7, ups=1.85, wpb=14780.7, bsz=514.7, num_updates=103100, lr=9.84851e-05, gnorm=0.763, train_wall=54, wall=56841
2020-12-20 09:56:25 | INFO | train_inner | epoch 043:    384 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.084, loss=4.831, nll_loss=1.966, ppl=3.91, wps=27479.6, ups=1.86, wpb=14744.9, bsz=481.8, num_updates=103200, lr=9.84374e-05, gnorm=0.757, train_wall=53, wall=56894
2020-12-20 09:57:19 | INFO | train_inner | epoch 043:    484 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.049, loss=4.843, nll_loss=1.984, ppl=3.96, wps=27708.3, ups=1.86, wpb=14918.5, bsz=541, num_updates=103300, lr=9.83897e-05, gnorm=0.749, train_wall=54, wall=56948
2020-12-20 09:58:13 | INFO | train_inner | epoch 043:    584 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.037, loss=4.828, nll_loss=1.97, ppl=3.92, wps=27751.1, ups=1.86, wpb=14956.5, bsz=535.1, num_updates=103400, lr=9.83422e-05, gnorm=0.763, train_wall=54, wall=57002
2020-12-20 09:59:07 | INFO | train_inner | epoch 043:    684 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.03, loss=4.834, nll_loss=1.977, ppl=3.94, wps=27371.6, ups=1.85, wpb=14774, bsz=518.2, num_updates=103500, lr=9.82946e-05, gnorm=0.771, train_wall=54, wall=57056
2020-12-20 10:00:01 | INFO | train_inner | epoch 043:    784 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.071, loss=4.85, nll_loss=1.989, ppl=3.97, wps=27487.3, ups=1.85, wpb=14863.2, bsz=507.3, num_updates=103600, lr=9.82472e-05, gnorm=0.765, train_wall=54, wall=57110
2020-12-20 10:00:55 | INFO | train_inner | epoch 043:    884 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.038, loss=4.827, nll_loss=1.968, ppl=3.91, wps=27615.1, ups=1.85, wpb=14941.5, bsz=523.7, num_updates=103700, lr=9.81998e-05, gnorm=0.761, train_wall=54, wall=57164
2020-12-20 10:01:49 | INFO | train_inner | epoch 043:    984 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.078, loss=4.84, nll_loss=1.977, ppl=3.94, wps=27601.5, ups=1.86, wpb=14824.1, bsz=498.9, num_updates=103800, lr=9.81525e-05, gnorm=0.79, train_wall=54, wall=57218
2020-12-20 10:02:43 | INFO | train_inner | epoch 043:   1084 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.061, loss=4.848, nll_loss=1.99, ppl=3.97, wps=27432, ups=1.85, wpb=14854.6, bsz=509.3, num_updates=103900, lr=9.81052e-05, gnorm=0.757, train_wall=54, wall=57272
2020-12-20 10:03:37 | INFO | train_inner | epoch 043:   1184 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.056, loss=4.853, nll_loss=1.995, ppl=3.99, wps=27487.8, ups=1.85, wpb=14860.6, bsz=521.4, num_updates=104000, lr=9.80581e-05, gnorm=0.799, train_wall=54, wall=57326
2020-12-20 10:04:31 | INFO | train_inner | epoch 043:   1284 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.071, loss=4.871, nll_loss=2.014, ppl=4.04, wps=27486.8, ups=1.85, wpb=14833.2, bsz=509, num_updates=104100, lr=9.8011e-05, gnorm=0.755, train_wall=54, wall=57380
2020-12-20 10:05:25 | INFO | train_inner | epoch 043:   1384 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.039, loss=4.853, nll_loss=1.998, ppl=4, wps=27551.7, ups=1.85, wpb=14855.5, bsz=516.2, num_updates=104200, lr=9.79639e-05, gnorm=0.77, train_wall=54, wall=57434
2020-12-20 10:06:19 | INFO | train_inner | epoch 043:   1484 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.051, loss=4.86, nll_loss=2.004, ppl=4.01, wps=27398.5, ups=1.85, wpb=14794.4, bsz=491.4, num_updates=104300, lr=9.79169e-05, gnorm=0.761, train_wall=54, wall=57488
2020-12-20 10:07:13 | INFO | train_inner | epoch 043:   1584 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.056, loss=4.862, nll_loss=2.005, ppl=4.01, wps=27274.2, ups=1.86, wpb=14687.2, bsz=497.7, num_updates=104400, lr=9.787e-05, gnorm=0.781, train_wall=54, wall=57542
2020-12-20 10:08:07 | INFO | train_inner | epoch 043:   1684 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.076, loss=4.866, nll_loss=2.006, ppl=4.02, wps=27646, ups=1.86, wpb=14859.5, bsz=496.8, num_updates=104500, lr=9.78232e-05, gnorm=0.77, train_wall=54, wall=57596
2020-12-20 10:09:01 | INFO | train_inner | epoch 043:   1784 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.059, loss=4.878, nll_loss=2.023, ppl=4.07, wps=27474.9, ups=1.85, wpb=14829.6, bsz=499.1, num_updates=104600, lr=9.77764e-05, gnorm=0.769, train_wall=54, wall=57650
2020-12-20 10:09:54 | INFO | train_inner | epoch 043:   1884 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.013, loss=4.869, nll_loss=2.021, ppl=4.06, wps=27281.7, ups=1.85, wpb=14721.4, bsz=514.2, num_updates=104700, lr=9.77297e-05, gnorm=0.789, train_wall=54, wall=57704
2020-12-20 10:10:48 | INFO | train_inner | epoch 043:   1984 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.032, loss=4.878, nll_loss=2.027, ppl=4.08, wps=27318.9, ups=1.85, wpb=14755.4, bsz=508.2, num_updates=104800, lr=9.76831e-05, gnorm=0.769, train_wall=54, wall=57758
2020-12-20 10:11:42 | INFO | train_inner | epoch 043:   2084 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.036, loss=4.869, nll_loss=2.016, ppl=4.05, wps=27362.4, ups=1.86, wpb=14735.7, bsz=475.5, num_updates=104900, lr=9.76365e-05, gnorm=0.79, train_wall=54, wall=57811
2020-12-20 10:12:36 | INFO | train_inner | epoch 043:   2184 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.06, loss=4.885, nll_loss=2.031, ppl=4.09, wps=27329.7, ups=1.86, wpb=14708.8, bsz=489.3, num_updates=105000, lr=9.759e-05, gnorm=0.778, train_wall=54, wall=57865
2020-12-20 10:13:30 | INFO | train_inner | epoch 043:   2284 / 2448 symm_kl=0.56, self_kl=0, self_cv=8.995, loss=4.837, nll_loss=1.987, ppl=3.96, wps=27624.2, ups=1.87, wpb=14797.4, bsz=561.3, num_updates=105100, lr=9.75436e-05, gnorm=0.768, train_wall=53, wall=57919
2020-12-20 10:14:24 | INFO | train_inner | epoch 043:   2384 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.011, loss=4.869, nll_loss=2.021, ppl=4.06, wps=27336.6, ups=1.85, wpb=14749.6, bsz=553.8, num_updates=105200, lr=9.74972e-05, gnorm=0.775, train_wall=54, wall=57973
2020-12-20 10:14:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 10:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 10:15:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 10:15:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 10:15:12 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.073 | nll_loss 8.117 | ppl 277.57 | bleu 15.76 | wps 5424.7 | wpb 7930.2 | bsz 208 | num_updates 105264 | best_bleu 16.18
2020-12-20 10:15:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 10:15:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 43 @ 105264 updates, score 15.76) (writing took 5.000595571473241 seconds)
2020-12-20 10:15:17 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2020-12-20 10:15:17 | INFO | train | epoch 043 | symm_kl 0.569 | self_kl 0 | self_cv 9.054 | loss 4.852 | nll_loss 1.994 | ppl 3.98 | wps 26909.1 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 105264 | lr 9.74676e-05 | gnorm 0.769 | train_wall 1315 | wall 58027
2020-12-20 10:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:20 | INFO | fairseq.trainer | begin training epoch 44
2020-12-20 10:15:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:15:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:15:45 | INFO | train_inner | epoch 044:     36 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.079, loss=4.839, nll_loss=1.976, ppl=3.94, wps=18072.2, ups=1.22, wpb=14761.2, bsz=512.6, num_updates=105300, lr=9.74509e-05, gnorm=0.765, train_wall=53, wall=58054
2020-12-20 10:16:39 | INFO | train_inner | epoch 044:    136 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.143, loss=4.817, nll_loss=1.941, ppl=3.84, wps=27539.3, ups=1.85, wpb=14881.8, bsz=517, num_updates=105400, lr=9.74047e-05, gnorm=0.764, train_wall=54, wall=58109
2020-12-20 10:17:33 | INFO | train_inner | epoch 044:    236 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.108, loss=4.844, nll_loss=1.977, ppl=3.94, wps=27421, ups=1.86, wpb=14779.1, bsz=519, num_updates=105500, lr=9.73585e-05, gnorm=0.754, train_wall=54, wall=58162
2020-12-20 10:18:27 | INFO | train_inner | epoch 044:    336 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.051, loss=4.815, nll_loss=1.953, ppl=3.87, wps=27515.9, ups=1.85, wpb=14858.1, bsz=525.7, num_updates=105600, lr=9.73124e-05, gnorm=0.759, train_wall=54, wall=58216
2020-12-20 10:19:21 | INFO | train_inner | epoch 044:    436 / 2448 symm_kl=0.576, self_kl=0, self_cv=9.134, loss=4.849, nll_loss=1.978, ppl=3.94, wps=27472.4, ups=1.85, wpb=14854.6, bsz=489, num_updates=105700, lr=9.72663e-05, gnorm=0.761, train_wall=54, wall=58271
2020-12-20 10:20:15 | INFO | train_inner | epoch 044:    536 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.041, loss=4.832, nll_loss=1.974, ppl=3.93, wps=27579.6, ups=1.85, wpb=14908.8, bsz=532, num_updates=105800, lr=9.72203e-05, gnorm=0.763, train_wall=54, wall=58325
2020-12-20 10:21:09 | INFO | train_inner | epoch 044:    636 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.057, loss=4.85, nll_loss=1.992, ppl=3.98, wps=27310.1, ups=1.85, wpb=14733, bsz=515.3, num_updates=105900, lr=9.71744e-05, gnorm=0.771, train_wall=54, wall=58379
2020-12-20 10:22:03 | INFO | train_inner | epoch 044:    736 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.089, loss=4.846, nll_loss=1.982, ppl=3.95, wps=27405.7, ups=1.85, wpb=14818.6, bsz=500.6, num_updates=106000, lr=9.71286e-05, gnorm=0.776, train_wall=54, wall=58433
2020-12-20 10:22:57 | INFO | train_inner | epoch 044:    836 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.068, loss=4.84, nll_loss=1.978, ppl=3.94, wps=27583.9, ups=1.86, wpb=14866.7, bsz=513.1, num_updates=106100, lr=9.70828e-05, gnorm=0.762, train_wall=54, wall=58486
2020-12-20 10:23:51 | INFO | train_inner | epoch 044:    936 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.08, loss=4.847, nll_loss=1.985, ppl=3.96, wps=27302.1, ups=1.86, wpb=14715.6, bsz=505.9, num_updates=106200, lr=9.70371e-05, gnorm=0.767, train_wall=54, wall=58540
2020-12-20 10:24:45 | INFO | train_inner | epoch 044:   1036 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.034, loss=4.842, nll_loss=1.986, ppl=3.96, wps=27592.3, ups=1.85, wpb=14897.6, bsz=524.2, num_updates=106300, lr=9.69914e-05, gnorm=0.775, train_wall=54, wall=58594
2020-12-20 10:25:39 | INFO | train_inner | epoch 044:   1136 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.041, loss=4.858, nll_loss=2.003, ppl=4.01, wps=27268.7, ups=1.85, wpb=14736.4, bsz=505.8, num_updates=106400, lr=9.69458e-05, gnorm=0.768, train_wall=54, wall=58648
2020-12-20 10:26:33 | INFO | train_inner | epoch 044:   1236 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.083, loss=4.849, nll_loss=1.986, ppl=3.96, wps=27728.7, ups=1.85, wpb=14960.1, bsz=493.4, num_updates=106500, lr=9.69003e-05, gnorm=0.766, train_wall=54, wall=58702
2020-12-20 10:27:27 | INFO | train_inner | epoch 044:   1336 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.037, loss=4.852, nll_loss=1.997, ppl=3.99, wps=27620.3, ups=1.86, wpb=14868.8, bsz=526, num_updates=106600, lr=9.68549e-05, gnorm=0.763, train_wall=54, wall=58756
2020-12-20 10:28:21 | INFO | train_inner | epoch 044:   1436 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.029, loss=4.857, nll_loss=2.004, ppl=4.01, wps=27507.8, ups=1.86, wpb=14818.2, bsz=513, num_updates=106700, lr=9.68095e-05, gnorm=0.768, train_wall=54, wall=58810
2020-12-20 10:29:15 | INFO | train_inner | epoch 044:   1536 / 2448 symm_kl=0.571, self_kl=0, self_cv=9.059, loss=4.859, nll_loss=2.002, ppl=4, wps=27402.4, ups=1.85, wpb=14827.2, bsz=523.3, num_updates=106800, lr=9.67641e-05, gnorm=0.768, train_wall=54, wall=58864
2020-12-20 10:30:09 | INFO | train_inner | epoch 044:   1636 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.027, loss=4.859, nll_loss=2.007, ppl=4.02, wps=27474.7, ups=1.87, wpb=14684.3, bsz=484.6, num_updates=106900, lr=9.67189e-05, gnorm=0.792, train_wall=53, wall=58918
2020-12-20 10:31:02 | INFO | train_inner | epoch 044:   1736 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.061, loss=4.878, nll_loss=2.023, ppl=4.06, wps=27304.5, ups=1.86, wpb=14715.1, bsz=505.4, num_updates=107000, lr=9.66736e-05, gnorm=0.776, train_wall=54, wall=58972
2020-12-20 10:31:56 | INFO | train_inner | epoch 044:   1836 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.051, loss=4.86, nll_loss=2.004, ppl=4.01, wps=27533.3, ups=1.85, wpb=14856.3, bsz=514.9, num_updates=107100, lr=9.66285e-05, gnorm=0.779, train_wall=54, wall=59025
2020-12-20 10:32:50 | INFO | train_inner | epoch 044:   1936 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.034, loss=4.853, nll_loss=1.999, ppl=4, wps=27428.5, ups=1.86, wpb=14758.6, bsz=532.3, num_updates=107200, lr=9.65834e-05, gnorm=0.781, train_wall=54, wall=59079
2020-12-20 10:33:44 | INFO | train_inner | epoch 044:   2036 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.014, loss=4.844, nll_loss=1.992, ppl=3.98, wps=27581.6, ups=1.86, wpb=14836, bsz=520.6, num_updates=107300, lr=9.65384e-05, gnorm=0.774, train_wall=54, wall=59133
2020-12-20 10:34:38 | INFO | train_inner | epoch 044:   2136 / 2448 symm_kl=0.568, self_kl=0, self_cv=9.034, loss=4.857, nll_loss=2.004, ppl=4.01, wps=27502.9, ups=1.86, wpb=14815.6, bsz=497.4, num_updates=107400, lr=9.64935e-05, gnorm=0.77, train_wall=54, wall=59187
2020-12-20 10:35:31 | INFO | train_inner | epoch 044:   2236 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.053, loss=4.878, nll_loss=2.025, ppl=4.07, wps=27441.5, ups=1.87, wpb=14706.8, bsz=495.8, num_updates=107500, lr=9.64486e-05, gnorm=0.786, train_wall=53, wall=59241
2020-12-20 10:36:25 | INFO | train_inner | epoch 044:   2336 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.024, loss=4.851, nll_loss=1.999, ppl=4, wps=27471.9, ups=1.85, wpb=14850.7, bsz=515.5, num_updates=107600, lr=9.64037e-05, gnorm=0.778, train_wall=54, wall=59295
2020-12-20 10:37:20 | INFO | train_inner | epoch 044:   2436 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.015, loss=4.873, nll_loss=2.025, ppl=4.07, wps=27370.6, ups=1.85, wpb=14799.5, bsz=521.8, num_updates=107700, lr=9.6359e-05, gnorm=0.778, train_wall=54, wall=59349
2020-12-20 10:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 10:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 10:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 10:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 10:37:40 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.037 | nll_loss 8.076 | ppl 269.81 | bleu 15.96 | wps 5606.1 | wpb 7930.2 | bsz 208 | num_updates 107712 | best_bleu 16.18
2020-12-20 10:37:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 10:37:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/cv/checkpoint_last.pt (epoch 44 @ 107712 updates, score 15.96) (writing took 4.960642484948039 seconds)
2020-12-20 10:37:45 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2020-12-20 10:37:45 | INFO | train | epoch 044 | symm_kl 0.57 | self_kl 0 | self_cv 9.058 | loss 4.85 | nll_loss 1.992 | ppl 3.98 | wps 26904 | ups 1.82 | wpb 14810.4 | bsz 511.8 | num_updates 107712 | lr 9.63536e-05 | gnorm 0.771 | train_wall 1316 | wall 59374
2020-12-20 10:37:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:48 | INFO | fairseq.trainer | begin training epoch 45
2020-12-20 10:37:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:37:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 10:37:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 10:38:41 | INFO | train_inner | epoch 045:     88 / 2448 symm_kl=0.563, self_kl=0, self_cv=9.056, loss=4.809, nll_loss=1.945, ppl=3.85, wps=18075.6, ups=1.23, wpb=14730.9, bsz=514.2, num_updates=107800, lr=9.63143e-05, gnorm=0.777, train_wall=53, wall=59430
2020-12-20 10:39:35 | INFO | train_inner | epoch 045:    188 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.08, loss=4.829, nll_loss=1.964, ppl=3.9, wps=27679.9, ups=1.86, wpb=14861.1, bsz=530.4, num_updates=107900, lr=9.62696e-05, gnorm=0.767, train_wall=54, wall=59484
2020-12-20 10:40:29 | INFO | train_inner | epoch 045:    288 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.088, loss=4.82, nll_loss=1.953, ppl=3.87, wps=27267.8, ups=1.85, wpb=14705.4, bsz=497.6, num_updates=108000, lr=9.6225e-05, gnorm=0.755, train_wall=54, wall=59538
2020-12-20 10:41:22 | INFO | train_inner | epoch 045:    388 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.087, loss=4.824, nll_loss=1.958, ppl=3.89, wps=27679.1, ups=1.86, wpb=14901.5, bsz=495.5, num_updates=108100, lr=9.61805e-05, gnorm=0.766, train_wall=54, wall=59592
2020-12-20 10:42:17 | INFO | train_inner | epoch 045:    488 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.084, loss=4.823, nll_loss=1.957, ppl=3.88, wps=27385.2, ups=1.84, wpb=14871, bsz=505.6, num_updates=108200, lr=9.61361e-05, gnorm=0.766, train_wall=54, wall=59646
2020-12-20 10:43:11 | INFO | train_inner | epoch 045:    588 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.086, loss=4.85, nll_loss=1.987, ppl=3.97, wps=27353.8, ups=1.85, wpb=14822, bsz=510.2, num_updates=108300, lr=9.60917e-05, gnorm=0.782, train_wall=54, wall=59700
2020-12-20 10:44:05 | INFO | train_inner | epoch 045:    688 / 2448 symm_kl=0.57, self_kl=0, self_cv=9.067, loss=4.843, nll_loss=1.983, ppl=3.95, wps=27488.7, ups=1.85, wpb=14869.8, bsz=521.8, num_updates=108400, lr=9.60473e-05, gnorm=0.774, train_wall=54, wall=59754
2020-12-20 10:44:59 | INFO | train_inner | epoch 045:    788 / 2448 symm_kl=0.573, self_kl=0, self_cv=9.066, loss=4.844, nll_loss=1.983, ppl=3.95, wps=27421.2, ups=1.86, wpb=14776.3, bsz=512.3, num_updates=108500, lr=9.60031e-05, gnorm=0.792, train_wall=54, wall=59808
2020-12-20 10:45:53 | INFO | train_inner | epoch 045:    888 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.035, loss=4.853, nll_loss=1.999, ppl=4, wps=27339.2, ups=1.85, wpb=14755.8, bsz=531.2, num_updates=108600, lr=9.59589e-05, gnorm=0.788, train_wall=54, wall=59862
2020-12-20 10:46:47 | INFO | train_inner | epoch 045:    988 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.085, loss=4.835, nll_loss=1.971, ppl=3.92, wps=27767, ups=1.86, wpb=14889.6, bsz=494.9, num_updates=108700, lr=9.59147e-05, gnorm=0.776, train_wall=53, wall=59916
2020-12-20 10:47:41 | INFO | train_inner | epoch 045:   1088 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.064, loss=4.851, nll_loss=1.991, ppl=3.98, wps=27200.4, ups=1.85, wpb=14684.5, bsz=493.3, num_updates=108800, lr=9.58706e-05, gnorm=0.776, train_wall=54, wall=59970
2020-12-20 10:48:34 | INFO | train_inner | epoch 045:   1188 / 2448 symm_kl=0.575, self_kl=0, self_cv=9.059, loss=4.858, nll_loss=2, ppl=4, wps=27548.8, ups=1.86, wpb=14833, bsz=506.5, num_updates=108900, lr=9.58266e-05, gnorm=0.773, train_wall=54, wall=60024
2020-12-20 10:49:28 | INFO | train_inner | epoch 045:   1288 / 2448 symm_kl=0.577, self_kl=0, self_cv=9.071, loss=4.866, nll_loss=2.007, ppl=4.02, wps=27375.3, ups=1.85, wpb=14800.4, bsz=504.2, num_updates=109000, lr=9.57826e-05, gnorm=0.77, train_wall=54, wall=60078
2020-12-20 10:50:23 | INFO | train_inner | epoch 045:   1388 / 2448 symm_kl=0.566, self_kl=0, self_cv=9.041, loss=4.84, nll_loss=1.983, ppl=3.95, wps=27449.7, ups=1.85, wpb=14871.2, bsz=515.7, num_updates=109100, lr=9.57387e-05, gnorm=0.772, train_wall=54, wall=60132
2020-12-20 10:51:17 | INFO | train_inner | epoch 045:   1488 / 2448 symm_kl=0.567, self_kl=0, self_cv=9.033, loss=4.837, nll_loss=1.981, ppl=3.95, wps=27394, ups=1.84, wpb=14856.7, bsz=553.6, num_updates=109200, lr=9.56949e-05, gnorm=0.78, train_wall=54, wall=60186
2020-12-20 10:52:11 | INFO | train_inner | epoch 045:   1588 / 2448 symm_kl=0.565, self_kl=0, self_cv=9.044, loss=4.837, nll_loss=1.98, ppl=3.94, wps=27644.6, ups=1.85, wpb=14918.2, bsz=513.5, num_updates=109300, lr=9.56511e-05, gnorm=0.763, train_wall=54, wall=60240
2020-12-20 10:53:05 | INFO | train_inner | epoch 045:   1688 / 2448 symm_kl=0.574, self_kl=0, self_cv=9.073, loss=4.87, nll_loss=2.012, ppl=4.03, wps=27349.7, ups=1.86, wpb=14697.7, bsz=481.3, num_updates=109400, lr=9.56074e-05, gnorm=0.774, train_wall=54, wall=60294
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 500 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
