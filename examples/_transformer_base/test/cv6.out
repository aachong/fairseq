nohup: ignoring input
save_dir=./examples/_transformer_base/bash/../checkpoints/kl
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=4000
max_epoch=100
r3f_lambda=1
extr='--noised-no-grad --cv --cv-lambda 0'
2020-12-21 19:38:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:16286
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:16286
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:16286
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:16286
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | distributed init (rank 4): tcp://localhost:16286
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 4
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-21 19:38:14 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-21 19:38:18 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=True, cv_lambda=0.0, data='./examples/_transformer_base/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:16286', distributed_no_spawn=False, distributed_num_procs=5, distributed_port=-1, distributed_rank=0, distributed_world_size=5, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3200, max_tokens_valid=3200, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=5, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/_transformer_base/bash/../checkpoints/kl', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-21 19:38:18 | INFO | fairseq.tasks.translation | [ch] dictionary: 41952 types
2020-12-21 19:38:18 | INFO | fairseq.tasks.translation | [en] dictionary: 31264 types
2020-12-21 19:38:18 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.ch
2020-12-21 19:38:18 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.en
2020-12-21 19:38:18 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin valid ch-en 1664 examples
2020-12-21 19:38:20 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(41952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31264, bias=False)
  )
)
2020-12-21 19:38:20 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-21 19:38:20 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2020-12-21 19:38:20 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2020-12-21 19:38:20 | INFO | fairseq_cli.train | num. model params: 97632256 (num. trained: 97632256)
2020-12-21 19:38:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-21 19:38:20 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 19:38:20 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 19:38:20 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 19:38:20 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 19:38:20 | INFO | fairseq.utils | rank   4: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 19:38:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-21 19:38:20 | INFO | fairseq_cli.train | training on 5 devices (GPUs/TPUs)
2020-12-21 19:38:20 | INFO | fairseq_cli.train | max tokens per GPU = 3200 and max sentences per GPU = None
2020-12-21 19:38:20 | INFO | fairseq.checkpoint_utils | loading pretrained model from ./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2020-12-21 19:38:22 | INFO | fairseq.trainer | loaded checkpoint ./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt (epoch 80 @ 0 updates)
2020-12-21 19:38:22 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-21 19:38:22 | INFO | fairseq.trainer | loading train data for epoch 1
2020-12-21 19:38:22 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.ch
2020-12-21 19:38:22 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.en
2020-12-21 19:38:22 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin train ch-en 1252977 examples
2020-12-21 19:38:27 | INFO | fairseq.trainer | begin training epoch 1
2020-12-21 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:39:25 | INFO | train_inner | epoch 001:    100 / 2448 symm_kl=0.787, self_kl=0, self_cv=10.037, loss=4.504, nll_loss=1.662, ppl=3.17, wps=28843.4, ups=1.96, wpb=14735.4, bsz=497.5, num_updates=100, lr=1.0975e-06, gnorm=1.576, train_wall=52, wall=65
2020-12-21 19:40:16 | INFO | train_inner | epoch 001:    200 / 2448 symm_kl=0.729, self_kl=0, self_cv=9.88, loss=4.39, nll_loss=1.636, ppl=3.11, wps=28986.1, ups=1.95, wpb=14861, bsz=508.2, num_updates=200, lr=2.095e-06, gnorm=1.389, train_wall=51, wall=116
2020-12-21 19:41:08 | INFO | train_inner | epoch 001:    300 / 2448 symm_kl=0.687, self_kl=0, self_cv=9.694, loss=4.331, nll_loss=1.649, ppl=3.14, wps=28639.6, ups=1.93, wpb=14835.7, bsz=534.3, num_updates=300, lr=3.0925e-06, gnorm=1.286, train_wall=52, wall=168
2020-12-21 19:42:00 | INFO | train_inner | epoch 001:    400 / 2448 symm_kl=0.667, self_kl=0, self_cv=9.584, loss=4.328, nll_loss=1.685, ppl=3.22, wps=28484.7, ups=1.92, wpb=14836, bsz=520.4, num_updates=400, lr=4.09e-06, gnorm=1.261, train_wall=52, wall=220
2020-12-21 19:42:52 | INFO | train_inner | epoch 001:    500 / 2448 symm_kl=0.648, self_kl=0, self_cv=9.542, loss=4.313, nll_loss=1.7, ppl=3.25, wps=28211.3, ups=1.92, wpb=14706.6, bsz=513.4, num_updates=500, lr=5.0875e-06, gnorm=1.234, train_wall=52, wall=272
2020-12-21 19:43:44 | INFO | train_inner | epoch 001:    600 / 2448 symm_kl=0.629, self_kl=0, self_cv=9.538, loss=4.273, nll_loss=1.688, ppl=3.22, wps=28425.7, ups=1.91, wpb=14844.7, bsz=519, num_updates=600, lr=6.085e-06, gnorm=1.203, train_wall=52, wall=324
2020-12-21 19:44:37 | INFO | train_inner | epoch 001:    700 / 2448 symm_kl=0.619, self_kl=0, self_cv=9.542, loss=4.259, nll_loss=1.688, ppl=3.22, wps=28397.9, ups=1.91, wpb=14832.9, bsz=540.2, num_updates=700, lr=7.0825e-06, gnorm=1.195, train_wall=52, wall=376
2020-12-21 19:45:29 | INFO | train_inner | epoch 001:    800 / 2448 symm_kl=0.609, self_kl=0, self_cv=9.541, loss=4.266, nll_loss=1.712, ppl=3.28, wps=28279, ups=1.91, wpb=14814.1, bsz=508, num_updates=800, lr=8.08e-06, gnorm=1.176, train_wall=52, wall=429
2020-12-21 19:46:22 | INFO | train_inner | epoch 001:    900 / 2448 symm_kl=0.607, self_kl=0, self_cv=9.575, loss=4.253, nll_loss=1.7, ppl=3.25, wps=28023.6, ups=1.9, wpb=14741, bsz=498.3, num_updates=900, lr=9.0775e-06, gnorm=1.191, train_wall=52, wall=481
2020-12-21 19:47:14 | INFO | train_inner | epoch 001:   1000 / 2448 symm_kl=0.588, self_kl=0, self_cv=9.537, loss=4.22, nll_loss=1.694, ppl=3.24, wps=28158.5, ups=1.9, wpb=14834.9, bsz=533.9, num_updates=1000, lr=1.0075e-05, gnorm=1.142, train_wall=53, wall=534
2020-12-21 19:48:07 | INFO | train_inner | epoch 001:   1100 / 2448 symm_kl=0.588, self_kl=0, self_cv=9.564, loss=4.227, nll_loss=1.702, ppl=3.25, wps=28113.1, ups=1.91, wpb=14733.3, bsz=519.7, num_updates=1100, lr=1.10725e-05, gnorm=1.164, train_wall=52, wall=586
2020-12-21 19:48:59 | INFO | train_inner | epoch 001:   1200 / 2448 symm_kl=0.584, self_kl=0, self_cv=9.529, loss=4.235, nll_loss=1.719, ppl=3.29, wps=28145, ups=1.92, wpb=14678.3, bsz=487.4, num_updates=1200, lr=1.207e-05, gnorm=1.151, train_wall=52, wall=638
2020-12-21 19:49:51 | INFO | train_inner | epoch 001:   1300 / 2448 symm_kl=0.572, self_kl=0, self_cv=9.542, loss=4.191, nll_loss=1.687, ppl=3.22, wps=28154.8, ups=1.9, wpb=14811.5, bsz=513.1, num_updates=1300, lr=1.30675e-05, gnorm=1.133, train_wall=52, wall=691
2020-12-21 19:50:44 | INFO | train_inner | epoch 001:   1400 / 2448 symm_kl=0.569, self_kl=0, self_cv=9.528, loss=4.196, nll_loss=1.698, ppl=3.24, wps=28342.9, ups=1.91, wpb=14867.5, bsz=527.4, num_updates=1400, lr=1.4065e-05, gnorm=1.13, train_wall=52, wall=744
2020-12-21 19:51:37 | INFO | train_inner | epoch 001:   1500 / 2448 symm_kl=0.559, self_kl=0, self_cv=9.522, loss=4.185, nll_loss=1.702, ppl=3.25, wps=28205.4, ups=1.9, wpb=14841.8, bsz=533.8, num_updates=1500, lr=1.50625e-05, gnorm=1.119, train_wall=52, wall=796
2020-12-21 19:52:29 | INFO | train_inner | epoch 001:   1600 / 2448 symm_kl=0.562, self_kl=0, self_cv=9.541, loss=4.199, nll_loss=1.713, ppl=3.28, wps=28256.1, ups=1.91, wpb=14788.4, bsz=498.9, num_updates=1600, lr=1.606e-05, gnorm=1.119, train_wall=52, wall=849
2020-12-21 19:53:21 | INFO | train_inner | epoch 001:   1700 / 2448 symm_kl=0.554, self_kl=0, self_cv=9.521, loss=4.178, nll_loss=1.702, ppl=3.25, wps=28119.4, ups=1.9, wpb=14798.4, bsz=510.6, num_updates=1700, lr=1.70575e-05, gnorm=1.121, train_wall=52, wall=901
2020-12-21 19:54:14 | INFO | train_inner | epoch 001:   1800 / 2448 symm_kl=0.549, self_kl=0, self_cv=9.567, loss=4.153, nll_loss=1.681, ppl=3.21, wps=28382.8, ups=1.91, wpb=14891.2, bsz=509.1, num_updates=1800, lr=1.8055e-05, gnorm=1.094, train_wall=52, wall=954
2020-12-21 19:55:06 | INFO | train_inner | epoch 001:   1900 / 2448 symm_kl=0.548, self_kl=0, self_cv=9.547, loss=4.176, nll_loss=1.709, ppl=3.27, wps=28280.5, ups=1.91, wpb=14838.8, bsz=504.4, num_updates=1900, lr=1.90525e-05, gnorm=1.1, train_wall=52, wall=1006
2020-12-21 19:55:59 | INFO | train_inner | epoch 001:   2000 / 2448 symm_kl=0.548, self_kl=0, self_cv=9.5, loss=4.185, nll_loss=1.721, ppl=3.3, wps=28278.5, ups=1.9, wpb=14863.1, bsz=483.1, num_updates=2000, lr=2.005e-05, gnorm=1.1, train_wall=52, wall=1059
2020-12-21 19:56:51 | INFO | train_inner | epoch 001:   2100 / 2448 symm_kl=0.541, self_kl=0, self_cv=9.548, loss=4.161, nll_loss=1.704, ppl=3.26, wps=28448.2, ups=1.92, wpb=14827.9, bsz=487.8, num_updates=2100, lr=2.10475e-05, gnorm=1.091, train_wall=52, wall=1111
2020-12-21 19:57:44 | INFO | train_inner | epoch 001:   2200 / 2448 symm_kl=0.531, self_kl=0, self_cv=9.528, loss=4.128, nll_loss=1.681, ppl=3.21, wps=28387, ups=1.9, wpb=14906.9, bsz=537.7, num_updates=2200, lr=2.2045e-05, gnorm=1.077, train_wall=52, wall=1163
2020-12-21 19:58:36 | INFO | train_inner | epoch 001:   2300 / 2448 symm_kl=0.54, self_kl=0, self_cv=9.511, loss=4.179, nll_loss=1.726, ppl=3.31, wps=28112, ups=1.91, wpb=14731.3, bsz=497.8, num_updates=2300, lr=2.30425e-05, gnorm=1.096, train_wall=52, wall=1216
2020-12-21 19:59:28 | INFO | train_inner | epoch 001:   2400 / 2448 symm_kl=0.525, self_kl=0, self_cv=9.522, loss=4.123, nll_loss=1.685, ppl=3.22, wps=28460.7, ups=1.91, wpb=14928.9, bsz=508.3, num_updates=2400, lr=2.404e-05, gnorm=1.069, train_wall=52, wall=1268
2020-12-21 19:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 19:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 19:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 19:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 20:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 20:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 20:00:07 | INFO | valid | epoch 001 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.071 | nll_loss 8.047 | ppl 264.46 | bleu 16.25 | wps 5860.2 | wpb 7930.2 | bsz 208 | num_updates 2448
2020-12-21 20:00:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 20:00:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 1 @ 2448 updates, score 16.25) (writing took 3.517969448119402 seconds)
2020-12-21 20:00:11 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-12-21 20:00:11 | INFO | train | epoch 001 | symm_kl 0.596 | self_kl 0 | self_cv 9.58 | loss 4.233 | nll_loss 1.693 | ppl 3.23 | wps 27953.5 | ups 1.89 | wpb 14810.4 | bsz 511.8 | num_updates 2448 | lr 2.45188e-05 | gnorm 1.175 | train_wall 1276 | wall 1310
2020-12-21 20:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:00:14 | INFO | fairseq.trainer | begin training epoch 2
2020-12-21 20:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:00:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:00:46 | INFO | train_inner | epoch 002:     52 / 2448 symm_kl=0.52, self_kl=0, self_cv=9.527, loss=4.095, nll_loss=1.664, ppl=3.17, wps=18964.3, ups=1.29, wpb=14718.1, bsz=493.5, num_updates=2500, lr=2.50375e-05, gnorm=1.095, train_wall=52, wall=1346
2020-12-21 20:01:39 | INFO | train_inner | epoch 002:    152 / 2448 symm_kl=0.524, self_kl=0, self_cv=9.504, loss=4.124, nll_loss=1.688, ppl=3.22, wps=28329, ups=1.9, wpb=14903.9, bsz=536.5, num_updates=2600, lr=2.6035e-05, gnorm=1.069, train_wall=52, wall=1398
2020-12-21 20:02:31 | INFO | train_inner | epoch 002:    252 / 2448 symm_kl=0.526, self_kl=0, self_cv=9.479, loss=4.15, nll_loss=1.716, ppl=3.28, wps=28284.2, ups=1.91, wpb=14786.3, bsz=496.6, num_updates=2700, lr=2.70325e-05, gnorm=1.079, train_wall=52, wall=1451
2020-12-21 20:03:23 | INFO | train_inner | epoch 002:    352 / 2448 symm_kl=0.518, self_kl=0, self_cv=9.518, loss=4.123, nll_loss=1.698, ppl=3.24, wps=28204.1, ups=1.91, wpb=14754.5, bsz=531.4, num_updates=2800, lr=2.803e-05, gnorm=1.075, train_wall=52, wall=1503
2020-12-21 20:04:16 | INFO | train_inner | epoch 002:    452 / 2448 symm_kl=0.513, self_kl=0, self_cv=9.496, loss=4.102, nll_loss=1.682, ppl=3.21, wps=28405.9, ups=1.91, wpb=14892.2, bsz=530.4, num_updates=2900, lr=2.90275e-05, gnorm=1.051, train_wall=52, wall=1555
2020-12-21 20:05:08 | INFO | train_inner | epoch 002:    552 / 2448 symm_kl=0.516, self_kl=0, self_cv=9.485, loss=4.123, nll_loss=1.7, ppl=3.25, wps=28285.9, ups=1.91, wpb=14814.2, bsz=496.6, num_updates=3000, lr=3.0025e-05, gnorm=1.069, train_wall=52, wall=1608
2020-12-21 20:06:01 | INFO | train_inner | epoch 002:    652 / 2448 symm_kl=0.52, self_kl=0, self_cv=9.502, loss=4.153, nll_loss=1.729, ppl=3.31, wps=28113.1, ups=1.9, wpb=14826.5, bsz=496.3, num_updates=3100, lr=3.10225e-05, gnorm=1.071, train_wall=53, wall=1660
2020-12-21 20:06:53 | INFO | train_inner | epoch 002:    752 / 2448 symm_kl=0.511, self_kl=0, self_cv=9.499, loss=4.121, nll_loss=1.707, ppl=3.27, wps=28485.4, ups=1.91, wpb=14916.4, bsz=490.2, num_updates=3200, lr=3.202e-05, gnorm=1.053, train_wall=52, wall=1713
2020-12-21 20:07:46 | INFO | train_inner | epoch 002:    852 / 2448 symm_kl=0.514, self_kl=0, self_cv=9.475, loss=4.145, nll_loss=1.728, ppl=3.31, wps=28110.4, ups=1.91, wpb=14744.7, bsz=515.6, num_updates=3300, lr=3.30175e-05, gnorm=1.081, train_wall=52, wall=1765
2020-12-21 20:08:38 | INFO | train_inner | epoch 002:    952 / 2448 symm_kl=0.509, self_kl=0, self_cv=9.489, loss=4.135, nll_loss=1.726, ppl=3.31, wps=28319, ups=1.91, wpb=14830, bsz=505, num_updates=3400, lr=3.4015e-05, gnorm=1.064, train_wall=52, wall=1818
2020-12-21 20:09:30 | INFO | train_inner | epoch 002:   1052 / 2448 symm_kl=0.502, self_kl=0, self_cv=9.456, loss=4.109, nll_loss=1.708, ppl=3.27, wps=28371.5, ups=1.91, wpb=14880.4, bsz=520.4, num_updates=3500, lr=3.50125e-05, gnorm=1.047, train_wall=52, wall=1870
2020-12-21 20:10:23 | INFO | train_inner | epoch 002:   1152 / 2448 symm_kl=0.511, self_kl=0, self_cv=9.447, loss=4.149, nll_loss=1.738, ppl=3.34, wps=28004.8, ups=1.9, wpb=14722.8, bsz=519.4, num_updates=3600, lr=3.601e-05, gnorm=1.073, train_wall=52, wall=1923
2020-12-21 20:11:15 | INFO | train_inner | epoch 002:   1252 / 2448 symm_kl=0.502, self_kl=0, self_cv=9.463, loss=4.121, nll_loss=1.721, ppl=3.3, wps=28485.6, ups=1.91, wpb=14883.6, bsz=513.5, num_updates=3700, lr=3.70075e-05, gnorm=1.048, train_wall=52, wall=1975
2020-12-21 20:12:08 | INFO | train_inner | epoch 002:   1352 / 2448 symm_kl=0.496, self_kl=0, self_cv=9.474, loss=4.103, nll_loss=1.71, ppl=3.27, wps=28138.2, ups=1.9, wpb=14819.3, bsz=529.4, num_updates=3800, lr=3.8005e-05, gnorm=1.051, train_wall=52, wall=2028
2020-12-21 20:13:01 | INFO | train_inner | epoch 002:   1452 / 2448 symm_kl=0.501, self_kl=0, self_cv=9.463, loss=4.131, nll_loss=1.734, ppl=3.33, wps=28111.8, ups=1.9, wpb=14815.2, bsz=497.8, num_updates=3900, lr=3.90025e-05, gnorm=1.053, train_wall=53, wall=2080
2020-12-21 20:13:53 | INFO | train_inner | epoch 002:   1552 / 2448 symm_kl=0.499, self_kl=0, self_cv=9.458, loss=4.129, nll_loss=1.735, ppl=3.33, wps=28133.5, ups=1.91, wpb=14767.3, bsz=489.6, num_updates=4000, lr=4e-05, gnorm=1.056, train_wall=52, wall=2133
2020-12-21 20:14:46 | INFO | train_inner | epoch 002:   1652 / 2448 symm_kl=0.492, self_kl=0, self_cv=9.443, loss=4.115, nll_loss=1.73, ppl=3.32, wps=28108.3, ups=1.9, wpb=14765.8, bsz=520.9, num_updates=4100, lr=3.95092e-05, gnorm=1.046, train_wall=52, wall=2185
2020-12-21 20:15:38 | INFO | train_inner | epoch 002:   1752 / 2448 symm_kl=0.493, self_kl=0, self_cv=9.454, loss=4.128, nll_loss=1.743, ppl=3.35, wps=28233.8, ups=1.9, wpb=14850.1, bsz=502.4, num_updates=4200, lr=3.9036e-05, gnorm=1.044, train_wall=52, wall=2238
2020-12-21 20:16:31 | INFO | train_inner | epoch 002:   1852 / 2448 symm_kl=0.495, self_kl=0, self_cv=9.45, loss=4.131, nll_loss=1.745, ppl=3.35, wps=28224.6, ups=1.9, wpb=14873.6, bsz=524.6, num_updates=4300, lr=3.85794e-05, gnorm=1.056, train_wall=53, wall=2291
2020-12-21 20:17:23 | INFO | train_inner | epoch 002:   1952 / 2448 symm_kl=0.49, self_kl=0, self_cv=9.422, loss=4.115, nll_loss=1.734, ppl=3.33, wps=28397.3, ups=1.91, wpb=14877, bsz=529.3, num_updates=4400, lr=3.81385e-05, gnorm=1.032, train_wall=52, wall=2343
2020-12-21 20:18:16 | INFO | train_inner | epoch 002:   2052 / 2448 symm_kl=0.492, self_kl=0, self_cv=9.451, loss=4.136, nll_loss=1.755, ppl=3.37, wps=27943.4, ups=1.91, wpb=14645.1, bsz=531.5, num_updates=4500, lr=3.77124e-05, gnorm=1.067, train_wall=52, wall=2395
2020-12-21 20:19:08 | INFO | train_inner | epoch 002:   2152 / 2448 symm_kl=0.485, self_kl=0, self_cv=9.425, loss=4.109, nll_loss=1.735, ppl=3.33, wps=28229.3, ups=1.91, wpb=14806.2, bsz=505.9, num_updates=4600, lr=3.73002e-05, gnorm=1.034, train_wall=52, wall=2448
2020-12-21 20:20:01 | INFO | train_inner | epoch 002:   2252 / 2448 symm_kl=0.484, self_kl=0, self_cv=9.449, loss=4.11, nll_loss=1.737, ppl=3.33, wps=28210.7, ups=1.9, wpb=14822.8, bsz=512.5, num_updates=4700, lr=3.69012e-05, gnorm=1.03, train_wall=52, wall=2500
2020-12-21 20:20:53 | INFO | train_inner | epoch 002:   2352 / 2448 symm_kl=0.49, self_kl=0, self_cv=9.454, loss=4.134, nll_loss=1.756, ppl=3.38, wps=28039, ups=1.91, wpb=14716.2, bsz=493.3, num_updates=4800, lr=3.65148e-05, gnorm=1.054, train_wall=52, wall=2553
2020-12-21 20:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 20:21:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:21:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:21:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:21:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:21:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:21:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:21:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:21:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:21:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:21:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:21:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 20:21:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 20:21:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 20:21:58 | INFO | valid | epoch 002 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 9.024 | nll_loss 7.991 | ppl 254.48 | bleu 16.35 | wps 5483.7 | wpb 7930.2 | bsz 208 | num_updates 4896 | best_bleu 16.35
2020-12-21 20:21:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 20:22:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:22:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:22:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:22:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:22:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 2 @ 4896 updates, score 16.35) (writing took 8.147509770467877 seconds)
2020-12-21 20:22:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-12-21 20:22:06 | INFO | train | epoch 002 | symm_kl 0.503 | self_kl 0 | self_cv 9.467 | loss 4.125 | nll_loss 1.723 | ppl 3.3 | wps 27562.2 | ups 1.86 | wpb 14810.4 | bsz 511.8 | num_updates 4896 | lr 3.61551e-05 | gnorm 1.056 | train_wall 1280 | wall 2626
2020-12-21 20:22:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:22:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:22:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:22:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:22:09 | INFO | fairseq.trainer | begin training epoch 3
2020-12-21 20:22:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:22:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:22:17 | INFO | train_inner | epoch 003:      4 / 2448 symm_kl=0.483, self_kl=0, self_cv=9.423, loss=4.113, nll_loss=1.743, ppl=3.35, wps=17597.3, ups=1.19, wpb=14748, bsz=504.4, num_updates=4900, lr=3.61403e-05, gnorm=1.042, train_wall=52, wall=2637
2020-12-21 20:23:09 | INFO | train_inner | epoch 003:    104 / 2448 symm_kl=0.484, self_kl=0, self_cv=9.463, loss=4.102, nll_loss=1.729, ppl=3.32, wps=28289.4, ups=1.92, wpb=14719.6, bsz=509.2, num_updates=5000, lr=3.57771e-05, gnorm=1.035, train_wall=52, wall=2689
2020-12-21 20:24:02 | INFO | train_inner | epoch 003:    204 / 2448 symm_kl=0.479, self_kl=0, self_cv=9.436, loss=4.09, nll_loss=1.723, ppl=3.3, wps=28234.4, ups=1.9, wpb=14833.1, bsz=523.8, num_updates=5100, lr=3.54246e-05, gnorm=1.033, train_wall=52, wall=2741
2020-12-21 20:24:54 | INFO | train_inner | epoch 003:    304 / 2448 symm_kl=0.478, self_kl=0, self_cv=9.451, loss=4.082, nll_loss=1.716, ppl=3.29, wps=28200.8, ups=1.89, wpb=14882.1, bsz=521.8, num_updates=5200, lr=3.50823e-05, gnorm=1.018, train_wall=53, wall=2794
2020-12-21 20:25:47 | INFO | train_inner | epoch 003:    404 / 2448 symm_kl=0.476, self_kl=0, self_cv=9.462, loss=4.071, nll_loss=1.707, ppl=3.26, wps=28206, ups=1.91, wpb=14782.1, bsz=523.8, num_updates=5300, lr=3.47498e-05, gnorm=1.028, train_wall=52, wall=2846
2020-12-21 20:26:39 | INFO | train_inner | epoch 003:    504 / 2448 symm_kl=0.47, self_kl=0, self_cv=9.452, loss=4.05, nll_loss=1.693, ppl=3.23, wps=28154.1, ups=1.9, wpb=14793.1, bsz=539.2, num_updates=5400, lr=3.44265e-05, gnorm=1.016, train_wall=52, wall=2899
2020-12-21 20:27:32 | INFO | train_inner | epoch 003:    604 / 2448 symm_kl=0.477, self_kl=0, self_cv=9.454, loss=4.103, nll_loss=1.741, ppl=3.34, wps=27967.2, ups=1.89, wpb=14765.4, bsz=519.6, num_updates=5500, lr=3.41121e-05, gnorm=1.021, train_wall=53, wall=2952
2020-12-21 20:28:25 | INFO | train_inner | epoch 003:    704 / 2448 symm_kl=0.477, self_kl=0, self_cv=9.451, loss=4.083, nll_loss=1.719, ppl=3.29, wps=28173, ups=1.9, wpb=14828.9, bsz=514.6, num_updates=5600, lr=3.38062e-05, gnorm=1.023, train_wall=52, wall=3004
2020-12-21 20:29:17 | INFO | train_inner | epoch 003:    804 / 2448 symm_kl=0.477, self_kl=0, self_cv=9.487, loss=4.091, nll_loss=1.727, ppl=3.31, wps=28028.5, ups=1.91, wpb=14692.9, bsz=491.5, num_updates=5700, lr=3.35083e-05, gnorm=1.042, train_wall=52, wall=3057
2020-12-21 20:30:10 | INFO | train_inner | epoch 003:    904 / 2448 symm_kl=0.474, self_kl=0, self_cv=9.434, loss=4.106, nll_loss=1.749, ppl=3.36, wps=28146.3, ups=1.91, wpb=14763.3, bsz=499.7, num_updates=5800, lr=3.32182e-05, gnorm=1.032, train_wall=52, wall=3109
2020-12-21 20:31:02 | INFO | train_inner | epoch 003:   1004 / 2448 symm_kl=0.476, self_kl=0, self_cv=9.474, loss=4.094, nll_loss=1.734, ppl=3.33, wps=28134.5, ups=1.9, wpb=14815.8, bsz=498.2, num_updates=5900, lr=3.29355e-05, gnorm=1.032, train_wall=52, wall=3162
2020-12-21 20:31:55 | INFO | train_inner | epoch 003:   1104 / 2448 symm_kl=0.469, self_kl=0, self_cv=9.47, loss=4.061, nll_loss=1.705, ppl=3.26, wps=28114.7, ups=1.9, wpb=14777.6, bsz=529.6, num_updates=6000, lr=3.26599e-05, gnorm=1.032, train_wall=52, wall=3215
2020-12-21 20:32:48 | INFO | train_inner | epoch 003:   1204 / 2448 symm_kl=0.47, self_kl=0, self_cv=9.456, loss=4.079, nll_loss=1.725, ppl=3.31, wps=28097.3, ups=1.9, wpb=14799.9, bsz=532.1, num_updates=6100, lr=3.23911e-05, gnorm=1.029, train_wall=53, wall=3267
2020-12-21 20:33:40 | INFO | train_inner | epoch 003:   1304 / 2448 symm_kl=0.465, self_kl=0, self_cv=9.445, loss=4.061, nll_loss=1.713, ppl=3.28, wps=28179.8, ups=1.89, wpb=14891.4, bsz=524.6, num_updates=6200, lr=3.21288e-05, gnorm=1.011, train_wall=53, wall=3320
2020-12-21 20:34:33 | INFO | train_inner | epoch 003:   1404 / 2448 symm_kl=0.472, self_kl=0, self_cv=9.436, loss=4.103, nll_loss=1.749, ppl=3.36, wps=28095.6, ups=1.91, wpb=14741.1, bsz=513.4, num_updates=6300, lr=3.18728e-05, gnorm=1.029, train_wall=52, wall=3373
2020-12-21 20:35:25 | INFO | train_inner | epoch 003:   1504 / 2448 symm_kl=0.471, self_kl=0, self_cv=9.429, loss=4.106, nll_loss=1.754, ppl=3.37, wps=28039.8, ups=1.9, wpb=14729.6, bsz=507.7, num_updates=6400, lr=3.16228e-05, gnorm=1.028, train_wall=52, wall=3425
2020-12-21 20:36:18 | INFO | train_inner | epoch 003:   1604 / 2448 symm_kl=0.464, self_kl=0, self_cv=9.43, loss=4.066, nll_loss=1.72, ppl=3.29, wps=28218.7, ups=1.9, wpb=14885.7, bsz=515.7, num_updates=6500, lr=3.13786e-05, gnorm=1.011, train_wall=53, wall=3478
2020-12-21 20:37:11 | INFO | train_inner | epoch 003:   1704 / 2448 symm_kl=0.462, self_kl=0, self_cv=9.433, loss=4.05, nll_loss=1.706, ppl=3.26, wps=28210, ups=1.9, wpb=14879.5, bsz=505.6, num_updates=6600, lr=3.114e-05, gnorm=1.007, train_wall=53, wall=3531
2020-12-21 20:38:03 | INFO | train_inner | epoch 003:   1804 / 2448 symm_kl=0.468, self_kl=0, self_cv=9.439, loss=4.081, nll_loss=1.73, ppl=3.32, wps=28211.4, ups=1.91, wpb=14804.8, bsz=493.1, num_updates=6700, lr=3.09067e-05, gnorm=1.022, train_wall=52, wall=3583
2020-12-21 20:38:56 | INFO | train_inner | epoch 003:   1904 / 2448 symm_kl=0.464, self_kl=0, self_cv=9.435, loss=4.066, nll_loss=1.72, ppl=3.3, wps=28278.5, ups=1.9, wpb=14873.8, bsz=499.4, num_updates=6800, lr=3.06786e-05, gnorm=1.013, train_wall=52, wall=3636
2020-12-21 20:39:48 | INFO | train_inner | epoch 003:   2004 / 2448 symm_kl=0.465, self_kl=0, self_cv=9.4, loss=4.087, nll_loss=1.744, ppl=3.35, wps=28264.9, ups=1.91, wpb=14828.8, bsz=504.4, num_updates=6900, lr=3.04555e-05, gnorm=1.016, train_wall=52, wall=3688
2020-12-21 20:40:41 | INFO | train_inner | epoch 003:   2104 / 2448 symm_kl=0.461, self_kl=0, self_cv=9.456, loss=4.061, nll_loss=1.72, ppl=3.29, wps=28437.8, ups=1.9, wpb=14940.1, bsz=493.8, num_updates=7000, lr=3.02372e-05, gnorm=1.001, train_wall=52, wall=3741
2020-12-21 20:41:34 | INFO | train_inner | epoch 003:   2204 / 2448 symm_kl=0.466, self_kl=0, self_cv=9.425, loss=4.095, nll_loss=1.749, ppl=3.36, wps=28027.7, ups=1.9, wpb=14744.5, bsz=503.5, num_updates=7100, lr=3.00235e-05, gnorm=1.019, train_wall=52, wall=3793
2020-12-21 20:42:26 | INFO | train_inner | epoch 003:   2304 / 2448 symm_kl=0.461, self_kl=0, self_cv=9.418, loss=4.07, nll_loss=1.73, ppl=3.32, wps=28210, ups=1.9, wpb=14880.4, bsz=522.7, num_updates=7200, lr=2.98142e-05, gnorm=1.008, train_wall=53, wall=3846
2020-12-21 20:43:19 | INFO | train_inner | epoch 003:   2404 / 2448 symm_kl=0.463, self_kl=0, self_cv=9.427, loss=4.081, nll_loss=1.74, ppl=3.34, wps=28102.1, ups=1.89, wpb=14844, bsz=512.8, num_updates=7300, lr=2.96093e-05, gnorm=1.01, train_wall=53, wall=3899
2020-12-21 20:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 20:43:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:43:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:43:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:43:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:43:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:43:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:43:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:43:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:43:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:43:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:43:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 20:43:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 20:43:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 20:43:56 | INFO | valid | epoch 003 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.981 | nll_loss 7.946 | ppl 246.55 | bleu 16.45 | wps 6047 | wpb 7930.2 | bsz 208 | num_updates 7344 | best_bleu 16.45
2020-12-21 20:43:56 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 20:44:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:44:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:44:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:44:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:44:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:44:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:44:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:44:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:44:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 3 @ 7344 updates, score 16.45) (writing took 9.529953250661492 seconds)
2020-12-21 20:44:05 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-12-21 20:44:05 | INFO | train | epoch 003 | symm_kl 0.47 | self_kl 0 | self_cv 9.444 | loss 4.081 | nll_loss 1.727 | ppl 3.31 | wps 27485.3 | ups 1.86 | wpb 14810.4 | bsz 511.8 | num_updates 7344 | lr 2.95205e-05 | gnorm 1.022 | train_wall 1283 | wall 3945
2020-12-21 20:44:08 | INFO | fairseq.trainer | begin training epoch 4
2020-12-21 20:44:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 20:44:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 20:44:43 | INFO | train_inner | epoch 004:     56 / 2448 symm_kl=0.454, self_kl=0, self_cv=9.425, loss=4.034, nll_loss=1.699, ppl=3.25, wps=17751.2, ups=1.2, wpb=14826.9, bsz=515.9, num_updates=7400, lr=2.94086e-05, gnorm=1.01, train_wall=52, wall=3982
2020-12-21 20:45:36 | INFO | train_inner | epoch 004:    156 / 2448 symm_kl=0.457, self_kl=0, self_cv=9.476, loss=4.038, nll_loss=1.699, ppl=3.25, wps=27953.1, ups=1.88, wpb=14886.2, bsz=523.3, num_updates=7500, lr=2.92119e-05, gnorm=1.007, train_wall=53, wall=4036
2020-12-21 20:46:30 | INFO | train_inner | epoch 004:    256 / 2448 symm_kl=0.458, self_kl=0, self_cv=9.467, loss=4.047, nll_loss=1.707, ppl=3.26, wps=27587.6, ups=1.86, wpb=14807.9, bsz=521, num_updates=7600, lr=2.90191e-05, gnorm=1.008, train_wall=53, wall=4089
2020-12-21 20:47:24 | INFO | train_inner | epoch 004:    356 / 2448 symm_kl=0.461, self_kl=0, self_cv=9.485, loss=4.062, nll_loss=1.719, ppl=3.29, wps=27469.2, ups=1.85, wpb=14812.2, bsz=514.7, num_updates=7700, lr=2.883e-05, gnorm=1.015, train_wall=54, wall=4143
2020-12-21 20:48:16 | INFO | train_inner | epoch 004:    456 / 2448 symm_kl=0.464, self_kl=0, self_cv=9.426, loss=4.081, nll_loss=1.738, ppl=3.33, wps=28168.2, ups=1.9, wpb=14799.4, bsz=518.9, num_updates=7800, lr=2.86446e-05, gnorm=1.034, train_wall=52, wall=4196
2020-12-21 20:49:09 | INFO | train_inner | epoch 004:    556 / 2448 symm_kl=0.458, self_kl=0, self_cv=9.462, loss=4.054, nll_loss=1.716, ppl=3.29, wps=28186.6, ups=1.9, wpb=14804, bsz=516.2, num_updates=7900, lr=2.84627e-05, gnorm=1.012, train_wall=52, wall=4248
2020-12-21 20:50:01 | INFO | train_inner | epoch 004:    656 / 2448 symm_kl=0.456, self_kl=0, self_cv=9.448, loss=4.055, nll_loss=1.72, ppl=3.29, wps=28227.2, ups=1.9, wpb=14871.8, bsz=522.1, num_updates=8000, lr=2.82843e-05, gnorm=1.003, train_wall=53, wall=4301
2020-12-21 20:50:54 | INFO | train_inner | epoch 004:    756 / 2448 symm_kl=0.455, self_kl=0, self_cv=9.448, loss=4.043, nll_loss=1.708, ppl=3.27, wps=28108.9, ups=1.9, wpb=14830.7, bsz=512.3, num_updates=8100, lr=2.81091e-05, gnorm=1.008, train_wall=53, wall=4354
2020-12-21 20:51:46 | INFO | train_inner | epoch 004:    856 / 2448 symm_kl=0.458, self_kl=0, self_cv=9.49, loss=4.054, nll_loss=1.717, ppl=3.29, wps=28161.3, ups=1.91, wpb=14750.9, bsz=489.8, num_updates=8200, lr=2.79372e-05, gnorm=1.011, train_wall=52, wall=4406
2020-12-21 20:52:39 | INFO | train_inner | epoch 004:    956 / 2448 symm_kl=0.454, self_kl=0, self_cv=9.431, loss=4.045, nll_loss=1.713, ppl=3.28, wps=28192.1, ups=1.9, wpb=14831.4, bsz=553.3, num_updates=8300, lr=2.77684e-05, gnorm=1.009, train_wall=52, wall=4459
2020-12-21 20:53:32 | INFO | train_inner | epoch 004:   1056 / 2448 symm_kl=0.458, self_kl=0, self_cv=9.454, loss=4.059, nll_loss=1.722, ppl=3.3, wps=27748, ups=1.88, wpb=14783.5, bsz=498.4, num_updates=8400, lr=2.76026e-05, gnorm=1.015, train_wall=53, wall=4512
2020-12-21 20:54:25 | INFO | train_inner | epoch 004:   1156 / 2448 symm_kl=0.457, self_kl=0, self_cv=9.479, loss=4.06, nll_loss=1.726, ppl=3.31, wps=27801.5, ups=1.89, wpb=14731.6, bsz=493.6, num_updates=8500, lr=2.74398e-05, gnorm=1.019, train_wall=53, wall=4565
2020-12-21 20:55:18 | INFO | train_inner | epoch 004:   1256 / 2448 symm_kl=0.454, self_kl=0, self_cv=9.449, loss=4.046, nll_loss=1.714, ppl=3.28, wps=27943.3, ups=1.88, wpb=14836.8, bsz=498.2, num_updates=8600, lr=2.72798e-05, gnorm=1, train_wall=53, wall=4618
2020-12-21 20:56:11 | INFO | train_inner | epoch 004:   1356 / 2448 symm_kl=0.458, self_kl=0, self_cv=9.448, loss=4.064, nll_loss=1.728, ppl=3.31, wps=28301.6, ups=1.91, wpb=14806.1, bsz=472.4, num_updates=8700, lr=2.71225e-05, gnorm=1.014, train_wall=52, wall=4670
2020-12-21 20:57:03 | INFO | train_inner | epoch 004:   1456 / 2448 symm_kl=0.456, self_kl=0, self_cv=9.415, loss=4.067, nll_loss=1.735, ppl=3.33, wps=28147.1, ups=1.91, wpb=14745.1, bsz=513, num_updates=8800, lr=2.6968e-05, gnorm=1.011, train_wall=52, wall=4723
2020-12-21 20:57:56 | INFO | train_inner | epoch 004:   1556 / 2448 symm_kl=0.454, self_kl=0, self_cv=9.438, loss=4.063, nll_loss=1.733, ppl=3.32, wps=28085.6, ups=1.9, wpb=14744.6, bsz=513.3, num_updates=8900, lr=2.68161e-05, gnorm=1.021, train_wall=52, wall=4775
2020-12-21 20:58:48 | INFO | train_inner | epoch 004:   1656 / 2448 symm_kl=0.45, self_kl=0, self_cv=9.425, loss=4.046, nll_loss=1.722, ppl=3.3, wps=28358.2, ups=1.9, wpb=14907.2, bsz=504.9, num_updates=9000, lr=2.66667e-05, gnorm=0.996, train_wall=52, wall=4828
2020-12-21 20:59:41 | INFO | train_inner | epoch 004:   1756 / 2448 symm_kl=0.454, self_kl=0, self_cv=9.43, loss=4.065, nll_loss=1.735, ppl=3.33, wps=28087.6, ups=1.9, wpb=14787.2, bsz=485.7, num_updates=9100, lr=2.65197e-05, gnorm=1.005, train_wall=52, wall=4880
2020-12-21 21:00:33 | INFO | train_inner | epoch 004:   1856 / 2448 symm_kl=0.447, self_kl=0, self_cv=9.46, loss=4.03, nll_loss=1.707, ppl=3.26, wps=28115.6, ups=1.9, wpb=14803.6, bsz=530.8, num_updates=9200, lr=2.63752e-05, gnorm=1.006, train_wall=52, wall=4933
2020-12-21 21:01:26 | INFO | train_inner | epoch 004:   1956 / 2448 symm_kl=0.449, self_kl=0, self_cv=9.453, loss=4.037, nll_loss=1.712, ppl=3.28, wps=28187.7, ups=1.9, wpb=14847.9, bsz=522.2, num_updates=9300, lr=2.6233e-05, gnorm=1.001, train_wall=53, wall=4986
2020-12-21 21:02:19 | INFO | train_inner | epoch 004:   2056 / 2448 symm_kl=0.446, self_kl=0, self_cv=9.429, loss=4.021, nll_loss=1.7, ppl=3.25, wps=28408.5, ups=1.9, wpb=14929.1, bsz=541.4, num_updates=9400, lr=2.60931e-05, gnorm=0.996, train_wall=52, wall=5038
2020-12-21 21:03:11 | INFO | train_inner | epoch 004:   2156 / 2448 symm_kl=0.452, self_kl=0, self_cv=9.408, loss=4.073, nll_loss=1.749, ppl=3.36, wps=28399.2, ups=1.91, wpb=14846.1, bsz=504.6, num_updates=9500, lr=2.59554e-05, gnorm=1.001, train_wall=52, wall=5091
2020-12-21 21:04:04 | INFO | train_inner | epoch 004:   2256 / 2448 symm_kl=0.452, self_kl=0, self_cv=9.43, loss=4.07, nll_loss=1.745, ppl=3.35, wps=28174.5, ups=1.9, wpb=14827.1, bsz=513.1, num_updates=9600, lr=2.58199e-05, gnorm=1.002, train_wall=52, wall=5143
2020-12-21 21:04:56 | INFO | train_inner | epoch 004:   2356 / 2448 symm_kl=0.452, self_kl=0, self_cv=9.441, loss=4.064, nll_loss=1.737, ppl=3.33, wps=28148.3, ups=1.9, wpb=14788.5, bsz=488.6, num_updates=9700, lr=2.56865e-05, gnorm=1.007, train_wall=52, wall=5196
2020-12-21 21:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 21:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:05:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 21:05:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 21:05:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 21:05:58 | INFO | valid | epoch 004 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.973 | nll_loss 7.941 | ppl 245.67 | bleu 16.28 | wps 6048.3 | wpb 7930.2 | bsz 208 | num_updates 9792 | best_bleu 16.45
2020-12-21 21:05:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 21:06:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 4 @ 9792 updates, score 16.28) (writing took 5.218970935791731 seconds)
2020-12-21 21:06:03 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-12-21 21:06:03 | INFO | train | epoch 004 | symm_kl 0.454 | self_kl 0 | self_cv 9.445 | loss 4.053 | nll_loss 1.721 | ppl 3.3 | wps 27513.6 | ups 1.86 | wpb 14810.4 | bsz 511.8 | num_updates 9792 | lr 2.55655e-05 | gnorm 1.008 | train_wall 1286 | wall 5263
2020-12-21 21:06:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:06:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:06:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:06:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:06:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:06:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:06:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:06:06 | INFO | fairseq.trainer | begin training epoch 5
2020-12-21 21:06:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:06:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:06:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:06:16 | INFO | train_inner | epoch 005:      8 / 2448 symm_kl=0.448, self_kl=0, self_cv=9.412, loss=4.065, nll_loss=1.745, ppl=3.35, wps=18169.9, ups=1.25, wpb=14573.8, bsz=516.2, num_updates=9800, lr=2.55551e-05, gnorm=1.007, train_wall=52, wall=5276
2020-12-21 21:07:08 | INFO | train_inner | epoch 005:    108 / 2448 symm_kl=0.449, self_kl=0, self_cv=9.453, loss=4.053, nll_loss=1.73, ppl=3.32, wps=28370.3, ups=1.93, wpb=14697.8, bsz=524.2, num_updates=9900, lr=2.54257e-05, gnorm=1.008, train_wall=52, wall=5328
2020-12-21 21:08:01 | INFO | train_inner | epoch 005:    208 / 2448 symm_kl=0.448, self_kl=0, self_cv=9.451, loss=4.032, nll_loss=1.707, ppl=3.26, wps=28322.8, ups=1.91, wpb=14839.8, bsz=501.9, num_updates=10000, lr=2.52982e-05, gnorm=1.003, train_wall=52, wall=5380
2020-12-21 21:08:53 | INFO | train_inner | epoch 005:    308 / 2448 symm_kl=0.446, self_kl=0, self_cv=9.464, loss=4.024, nll_loss=1.7, ppl=3.25, wps=28400.4, ups=1.91, wpb=14890.2, bsz=503.4, num_updates=10100, lr=2.51727e-05, gnorm=0.995, train_wall=52, wall=5433
2020-12-21 21:09:45 | INFO | train_inner | epoch 005:    408 / 2448 symm_kl=0.445, self_kl=0, self_cv=9.439, loss=4.035, nll_loss=1.716, ppl=3.29, wps=28179.9, ups=1.91, wpb=14768.8, bsz=539.9, num_updates=10200, lr=2.5049e-05, gnorm=0.997, train_wall=52, wall=5485
2020-12-21 21:10:38 | INFO | train_inner | epoch 005:    508 / 2448 symm_kl=0.448, self_kl=0, self_cv=9.436, loss=4.039, nll_loss=1.716, ppl=3.29, wps=28271.3, ups=1.91, wpb=14809.5, bsz=504.6, num_updates=10300, lr=2.49271e-05, gnorm=1.004, train_wall=52, wall=5537
2020-12-21 21:11:30 | INFO | train_inner | epoch 005:    608 / 2448 symm_kl=0.447, self_kl=0, self_cv=9.45, loss=4.039, nll_loss=1.717, ppl=3.29, wps=28317.4, ups=1.91, wpb=14826.2, bsz=504.6, num_updates=10400, lr=2.48069e-05, gnorm=1.007, train_wall=52, wall=5590
2020-12-21 21:12:22 | INFO | train_inner | epoch 005:    708 / 2448 symm_kl=0.447, self_kl=0, self_cv=9.439, loss=4.037, nll_loss=1.714, ppl=3.28, wps=28408, ups=1.91, wpb=14854.3, bsz=517.1, num_updates=10500, lr=2.46885e-05, gnorm=1.001, train_wall=52, wall=5642
2020-12-21 21:13:15 | INFO | train_inner | epoch 005:    808 / 2448 symm_kl=0.448, self_kl=0, self_cv=9.437, loss=4.048, nll_loss=1.728, ppl=3.31, wps=28062.3, ups=1.91, wpb=14696.7, bsz=496, num_updates=10600, lr=2.45718e-05, gnorm=1.005, train_wall=52, wall=5694
2020-12-21 21:14:07 | INFO | train_inner | epoch 005:    908 / 2448 symm_kl=0.445, self_kl=0, self_cv=9.441, loss=4.031, nll_loss=1.712, ppl=3.28, wps=28269.1, ups=1.9, wpb=14845.6, bsz=508.5, num_updates=10700, lr=2.44567e-05, gnorm=0.999, train_wall=52, wall=5747
2020-12-21 21:14:59 | INFO | train_inner | epoch 005:   1008 / 2448 symm_kl=0.443, self_kl=0, self_cv=9.457, loss=4.015, nll_loss=1.696, ppl=3.24, wps=28571, ups=1.92, wpb=14868.2, bsz=520.3, num_updates=10800, lr=2.43432e-05, gnorm=0.995, train_wall=52, wall=5799
2020-12-21 21:15:52 | INFO | train_inner | epoch 005:   1108 / 2448 symm_kl=0.446, self_kl=0, self_cv=9.463, loss=4.036, nll_loss=1.715, ppl=3.28, wps=28264.9, ups=1.91, wpb=14770, bsz=497.5, num_updates=10900, lr=2.42313e-05, gnorm=1.024, train_wall=52, wall=5851
2020-12-21 21:16:44 | INFO | train_inner | epoch 005:   1208 / 2448 symm_kl=0.44, self_kl=0, self_cv=9.448, loss=4.01, nll_loss=1.696, ppl=3.24, wps=28390.5, ups=1.91, wpb=14855, bsz=541.4, num_updates=11000, lr=2.41209e-05, gnorm=0.992, train_wall=52, wall=5904
2020-12-21 21:17:37 | INFO | train_inner | epoch 005:   1308 / 2448 symm_kl=0.444, self_kl=0, self_cv=9.447, loss=4.033, nll_loss=1.715, ppl=3.28, wps=27822.9, ups=1.88, wpb=14827.2, bsz=525.8, num_updates=11100, lr=2.4012e-05, gnorm=1.005, train_wall=53, wall=5957
2020-12-21 21:18:30 | INFO | train_inner | epoch 005:   1408 / 2448 symm_kl=0.445, self_kl=0, self_cv=9.436, loss=4.036, nll_loss=1.717, ppl=3.29, wps=28194.4, ups=1.9, wpb=14866.6, bsz=516.5, num_updates=11200, lr=2.39046e-05, gnorm=0.995, train_wall=53, wall=6010
2020-12-21 21:19:23 | INFO | train_inner | epoch 005:   1508 / 2448 symm_kl=0.443, self_kl=0, self_cv=9.446, loss=4.034, nll_loss=1.719, ppl=3.29, wps=28144, ups=1.9, wpb=14794.1, bsz=518.6, num_updates=11300, lr=2.37986e-05, gnorm=1.005, train_wall=52, wall=6062
2020-12-21 21:20:15 | INFO | train_inner | epoch 005:   1608 / 2448 symm_kl=0.444, self_kl=0, self_cv=9.451, loss=4.044, nll_loss=1.728, ppl=3.31, wps=28157.9, ups=1.91, wpb=14752.4, bsz=502.6, num_updates=11400, lr=2.3694e-05, gnorm=1.001, train_wall=52, wall=6115
2020-12-21 21:21:08 | INFO | train_inner | epoch 005:   1708 / 2448 symm_kl=0.442, self_kl=0, self_cv=9.452, loss=4.031, nll_loss=1.717, ppl=3.29, wps=27683.2, ups=1.87, wpb=14766.5, bsz=511.4, num_updates=11500, lr=2.35907e-05, gnorm=1.007, train_wall=53, wall=6168
2020-12-21 21:22:02 | INFO | train_inner | epoch 005:   1808 / 2448 symm_kl=0.443, self_kl=0, self_cv=9.463, loss=4.038, nll_loss=1.724, ppl=3.3, wps=27818.2, ups=1.88, wpb=14831.5, bsz=508.2, num_updates=11600, lr=2.34888e-05, gnorm=1.002, train_wall=53, wall=6221
2020-12-21 21:22:54 | INFO | train_inner | epoch 005:   1908 / 2448 symm_kl=0.441, self_kl=0, self_cv=9.444, loss=4.031, nll_loss=1.718, ppl=3.29, wps=28376.8, ups=1.91, wpb=14842.2, bsz=514.8, num_updates=11700, lr=2.33882e-05, gnorm=0.991, train_wall=52, wall=6274
2020-12-21 21:23:46 | INFO | train_inner | epoch 005:   2008 / 2448 symm_kl=0.446, self_kl=0, self_cv=9.44, loss=4.058, nll_loss=1.741, ppl=3.34, wps=28234.6, ups=1.91, wpb=14797.9, bsz=481.1, num_updates=11800, lr=2.32889e-05, gnorm=1.008, train_wall=52, wall=6326
2020-12-21 21:24:39 | INFO | train_inner | epoch 005:   2108 / 2448 symm_kl=0.444, self_kl=0, self_cv=9.426, loss=4.049, nll_loss=1.735, ppl=3.33, wps=28207.4, ups=1.91, wpb=14754.8, bsz=509.2, num_updates=11900, lr=2.31908e-05, gnorm=0.998, train_wall=52, wall=6378
2020-12-21 21:25:31 | INFO | train_inner | epoch 005:   2208 / 2448 symm_kl=0.435, self_kl=0, self_cv=9.446, loss=4.006, nll_loss=1.7, ppl=3.25, wps=28458.4, ups=1.91, wpb=14919, bsz=532.6, num_updates=12000, lr=2.3094e-05, gnorm=0.984, train_wall=52, wall=6431
2020-12-21 21:26:23 | INFO | train_inner | epoch 005:   2308 / 2448 symm_kl=0.44, self_kl=0, self_cv=9.449, loss=4.035, nll_loss=1.725, ppl=3.3, wps=28467.7, ups=1.92, wpb=14862.6, bsz=500.4, num_updates=12100, lr=2.29984e-05, gnorm=0.993, train_wall=52, wall=6483
2020-12-21 21:27:15 | INFO | train_inner | epoch 005:   2408 / 2448 symm_kl=0.438, self_kl=0, self_cv=9.419, loss=4.031, nll_loss=1.724, ppl=3.3, wps=28442.9, ups=1.91, wpb=14856.5, bsz=525, num_updates=12200, lr=2.29039e-05, gnorm=0.996, train_wall=52, wall=6535
2020-12-21 21:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 21:27:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 21:27:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 21:27:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 21:27:50 | INFO | valid | epoch 005 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.939 | nll_loss 7.902 | ppl 239.24 | bleu 16.25 | wps 6016.8 | wpb 7930.2 | bsz 208 | num_updates 12240 | best_bleu 16.45
2020-12-21 21:27:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 21:27:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 5 @ 12240 updates, score 16.25) (writing took 4.652979908511043 seconds)
2020-12-21 21:27:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-12-21 21:27:54 | INFO | train | epoch 005 | symm_kl 0.444 | self_kl 0 | self_cv 9.447 | loss 4.035 | nll_loss 1.718 | ppl 3.29 | wps 27647.8 | ups 1.87 | wpb 14810.4 | bsz 511.8 | num_updates 12240 | lr 2.28665e-05 | gnorm 1.001 | train_wall 1280 | wall 6574
2020-12-21 21:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:27:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:57 | INFO | fairseq.trainer | begin training epoch 6
2020-12-21 21:27:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:27:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:28:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:28:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:28:34 | INFO | train_inner | epoch 006:     60 / 2448 symm_kl=0.442, self_kl=0, self_cv=9.461, loss=4.037, nll_loss=1.723, ppl=3.3, wps=18703.9, ups=1.27, wpb=14682.4, bsz=490.5, num_updates=12300, lr=2.28106e-05, gnorm=1.007, train_wall=52, wall=6614
2020-12-21 21:29:26 | INFO | train_inner | epoch 006:    160 / 2448 symm_kl=0.435, self_kl=0, self_cv=9.467, loss=3.988, nll_loss=1.679, ppl=3.2, wps=28385.1, ups=1.91, wpb=14892, bsz=513, num_updates=12400, lr=2.27185e-05, gnorm=0.984, train_wall=52, wall=6666
2020-12-21 21:30:19 | INFO | train_inner | epoch 006:    260 / 2448 symm_kl=0.441, self_kl=0, self_cv=9.477, loss=4.03, nll_loss=1.716, ppl=3.28, wps=28213, ups=1.91, wpb=14782.4, bsz=517.8, num_updates=12500, lr=2.26274e-05, gnorm=1.005, train_wall=52, wall=6718
2020-12-21 21:31:11 | INFO | train_inner | epoch 006:    360 / 2448 symm_kl=0.441, self_kl=0, self_cv=9.441, loss=4.036, nll_loss=1.724, ppl=3.3, wps=28055.9, ups=1.91, wpb=14702.3, bsz=519, num_updates=12600, lr=2.25374e-05, gnorm=1.007, train_wall=52, wall=6771
2020-12-21 21:32:05 | INFO | train_inner | epoch 006:    460 / 2448 symm_kl=0.441, self_kl=0, self_cv=9.454, loss=4.037, nll_loss=1.725, ppl=3.3, wps=27788.4, ups=1.88, wpb=14813.6, bsz=488.2, num_updates=12700, lr=2.24485e-05, gnorm=1.001, train_wall=53, wall=6824
2020-12-21 21:32:57 | INFO | train_inner | epoch 006:    560 / 2448 symm_kl=0.44, self_kl=0, self_cv=9.445, loss=4.023, nll_loss=1.712, ppl=3.28, wps=28259.6, ups=1.91, wpb=14790.8, bsz=527.1, num_updates=12800, lr=2.23607e-05, gnorm=1.001, train_wall=52, wall=6877
2020-12-21 21:33:50 | INFO | train_inner | epoch 006:    660 / 2448 symm_kl=0.438, self_kl=0, self_cv=9.456, loss=4.018, nll_loss=1.708, ppl=3.27, wps=27739.7, ups=1.88, wpb=14770.2, bsz=518.4, num_updates=12900, lr=2.22738e-05, gnorm=0.999, train_wall=53, wall=6930
2020-12-21 21:34:44 | INFO | train_inner | epoch 006:    760 / 2448 symm_kl=0.436, self_kl=0, self_cv=9.448, loss=4.009, nll_loss=1.701, ppl=3.25, wps=27910.4, ups=1.87, wpb=14899, bsz=523.6, num_updates=13000, lr=2.2188e-05, gnorm=0.987, train_wall=53, wall=6983
2020-12-21 21:35:36 | INFO | train_inner | epoch 006:    860 / 2448 symm_kl=0.438, self_kl=0, self_cv=9.459, loss=4.017, nll_loss=1.707, ppl=3.26, wps=28034.5, ups=1.89, wpb=14843.6, bsz=507.2, num_updates=13100, lr=2.21032e-05, gnorm=0.988, train_wall=53, wall=7036
2020-12-21 21:36:29 | INFO | train_inner | epoch 006:    960 / 2448 symm_kl=0.443, self_kl=0, self_cv=9.402, loss=4.067, nll_loss=1.756, ppl=3.38, wps=27880.2, ups=1.89, wpb=14743.9, bsz=520.9, num_updates=13200, lr=2.20193e-05, gnorm=1.001, train_wall=53, wall=7089
2020-12-21 21:37:22 | INFO | train_inner | epoch 006:   1060 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.436, loss=4.01, nll_loss=1.705, ppl=3.26, wps=28102.6, ups=1.89, wpb=14895.4, bsz=532.6, num_updates=13300, lr=2.19363e-05, gnorm=0.982, train_wall=53, wall=7142
2020-12-21 21:38:15 | INFO | train_inner | epoch 006:   1160 / 2448 symm_kl=0.438, self_kl=0, self_cv=9.439, loss=4.034, nll_loss=1.727, ppl=3.31, wps=28049.3, ups=1.88, wpb=14890, bsz=508.2, num_updates=13400, lr=2.18543e-05, gnorm=0.988, train_wall=53, wall=7195
2020-12-21 21:39:08 | INFO | train_inner | epoch 006:   1260 / 2448 symm_kl=0.439, self_kl=0, self_cv=9.456, loss=4.028, nll_loss=1.719, ppl=3.29, wps=28054.8, ups=1.9, wpb=14797.8, bsz=512.2, num_updates=13500, lr=2.17732e-05, gnorm=0.997, train_wall=53, wall=7248
2020-12-21 21:40:01 | INFO | train_inner | epoch 006:   1360 / 2448 symm_kl=0.439, self_kl=0, self_cv=9.448, loss=4.042, nll_loss=1.734, ppl=3.33, wps=27823, ups=1.89, wpb=14751.1, bsz=505.4, num_updates=13600, lr=2.1693e-05, gnorm=1.005, train_wall=53, wall=7301
2020-12-21 21:40:54 | INFO | train_inner | epoch 006:   1460 / 2448 symm_kl=0.436, self_kl=0, self_cv=9.482, loss=4.013, nll_loss=1.706, ppl=3.26, wps=28204.6, ups=1.91, wpb=14791.3, bsz=499, num_updates=13700, lr=2.16137e-05, gnorm=0.995, train_wall=52, wall=7353
2020-12-21 21:41:46 | INFO | train_inner | epoch 006:   1560 / 2448 symm_kl=0.437, self_kl=0, self_cv=9.449, loss=4.021, nll_loss=1.714, ppl=3.28, wps=28410.2, ups=1.91, wpb=14849.9, bsz=483.7, num_updates=13800, lr=2.15353e-05, gnorm=0.995, train_wall=52, wall=7406
2020-12-21 21:42:38 | INFO | train_inner | epoch 006:   1660 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.438, loss=4.014, nll_loss=1.713, ppl=3.28, wps=28097.1, ups=1.91, wpb=14734.3, bsz=537.7, num_updates=13900, lr=2.14577e-05, gnorm=0.992, train_wall=52, wall=7458
2020-12-21 21:43:31 | INFO | train_inner | epoch 006:   1760 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.466, loss=4.003, nll_loss=1.7, ppl=3.25, wps=28295.5, ups=1.91, wpb=14847.5, bsz=494.6, num_updates=14000, lr=2.13809e-05, gnorm=0.984, train_wall=52, wall=7510
2020-12-21 21:44:23 | INFO | train_inner | epoch 006:   1860 / 2448 symm_kl=0.437, self_kl=0, self_cv=9.463, loss=4.025, nll_loss=1.718, ppl=3.29, wps=28095.2, ups=1.9, wpb=14762.9, bsz=487.8, num_updates=14100, lr=2.13049e-05, gnorm=1.005, train_wall=52, wall=7563
2020-12-21 21:45:16 | INFO | train_inner | epoch 006:   1960 / 2448 symm_kl=0.435, self_kl=0, self_cv=9.445, loss=4.02, nll_loss=1.715, ppl=3.28, wps=28182.4, ups=1.9, wpb=14794, bsz=515.3, num_updates=14200, lr=2.12298e-05, gnorm=1, train_wall=52, wall=7616
2020-12-21 21:46:08 | INFO | train_inner | epoch 006:   2060 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.467, loss=4.018, nll_loss=1.715, ppl=3.28, wps=28310.3, ups=1.91, wpb=14857.1, bsz=496, num_updates=14300, lr=2.11554e-05, gnorm=0.996, train_wall=52, wall=7668
2020-12-21 21:47:01 | INFO | train_inner | epoch 006:   2160 / 2448 symm_kl=0.435, self_kl=0, self_cv=9.443, loss=4.031, nll_loss=1.728, ppl=3.31, wps=28199.1, ups=1.9, wpb=14875.9, bsz=511.6, num_updates=14400, lr=2.10819e-05, gnorm=0.998, train_wall=53, wall=7721
2020-12-21 21:47:54 | INFO | train_inner | epoch 006:   2260 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.422, loss=4.026, nll_loss=1.726, ppl=3.31, wps=28178.8, ups=1.9, wpb=14819.5, bsz=527.4, num_updates=14500, lr=2.1009e-05, gnorm=0.994, train_wall=52, wall=7773
2020-12-21 21:48:46 | INFO | train_inner | epoch 006:   2360 / 2448 symm_kl=0.429, self_kl=0, self_cv=9.439, loss=4, nll_loss=1.702, ppl=3.25, wps=28228.3, ups=1.9, wpb=14845.1, bsz=519, num_updates=14600, lr=2.0937e-05, gnorm=0.987, train_wall=52, wall=7826
2020-12-21 21:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 21:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 21:49:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 21:49:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 21:49:46 | INFO | valid | epoch 006 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.95 | nll_loss 7.915 | ppl 241.28 | bleu 16.43 | wps 6108.1 | wpb 7930.2 | bsz 208 | num_updates 14688 | best_bleu 16.45
2020-12-21 21:49:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 21:49:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 6 @ 14688 updates, score 16.43) (writing took 4.728374740108848 seconds)
2020-12-21 21:49:51 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-12-21 21:49:51 | INFO | train | epoch 006 | symm_kl 0.437 | self_kl 0 | self_cv 9.449 | loss 4.022 | nll_loss 1.715 | ppl 3.28 | wps 27547.2 | ups 1.86 | wpb 14810.4 | bsz 511.8 | num_updates 14688 | lr 2.08741e-05 | gnorm 0.996 | train_wall 1285 | wall 7890
2020-12-21 21:49:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:53 | INFO | fairseq.trainer | begin training epoch 7
2020-12-21 21:49:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:49:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 21:49:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 21:50:05 | INFO | train_inner | epoch 007:     12 / 2448 symm_kl=0.43, self_kl=0, self_cv=9.425, loss=3.999, nll_loss=1.7, ppl=3.25, wps=18627.2, ups=1.27, wpb=14705.6, bsz=516.6, num_updates=14700, lr=2.08656e-05, gnorm=1.002, train_wall=52, wall=7905
2020-12-21 21:50:59 | INFO | train_inner | epoch 007:    112 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.443, loss=4.012, nll_loss=1.709, ppl=3.27, wps=27864.3, ups=1.87, wpb=14864.4, bsz=496.9, num_updates=14800, lr=2.0795e-05, gnorm=0.983, train_wall=53, wall=7958
2020-12-21 21:51:52 | INFO | train_inner | epoch 007:    212 / 2448 symm_kl=0.428, self_kl=0, self_cv=9.453, loss=3.983, nll_loss=1.684, ppl=3.21, wps=27802.3, ups=1.88, wpb=14821.7, bsz=515, num_updates=14900, lr=2.07251e-05, gnorm=0.98, train_wall=53, wall=8012
2020-12-21 21:52:44 | INFO | train_inner | epoch 007:    312 / 2448 symm_kl=0.431, self_kl=0, self_cv=9.43, loss=4, nll_loss=1.7, ppl=3.25, wps=28440.1, ups=1.91, wpb=14919.3, bsz=529.4, num_updates=15000, lr=2.06559e-05, gnorm=0.987, train_wall=52, wall=8064
2020-12-21 21:53:37 | INFO | train_inner | epoch 007:    412 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.462, loss=4.008, nll_loss=1.704, ppl=3.26, wps=28013.1, ups=1.9, wpb=14779.9, bsz=503.6, num_updates=15100, lr=2.05874e-05, gnorm=0.999, train_wall=53, wall=8117
2020-12-21 21:54:30 | INFO | train_inner | epoch 007:    512 / 2448 symm_kl=0.431, self_kl=0, self_cv=9.419, loss=4.012, nll_loss=1.712, ppl=3.28, wps=28261.6, ups=1.9, wpb=14874.8, bsz=550.6, num_updates=15200, lr=2.05196e-05, gnorm=0.991, train_wall=52, wall=8169
2020-12-21 21:55:22 | INFO | train_inner | epoch 007:    612 / 2448 symm_kl=0.43, self_kl=0, self_cv=9.469, loss=4.003, nll_loss=1.704, ppl=3.26, wps=28153.5, ups=1.91, wpb=14775.7, bsz=507.3, num_updates=15300, lr=2.04524e-05, gnorm=0.988, train_wall=52, wall=8222
2020-12-21 21:56:15 | INFO | train_inner | epoch 007:    712 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.464, loss=4.022, nll_loss=1.719, ppl=3.29, wps=28135.2, ups=1.9, wpb=14770.5, bsz=489.8, num_updates=15400, lr=2.03859e-05, gnorm=0.996, train_wall=52, wall=8274
2020-12-21 21:57:07 | INFO | train_inner | epoch 007:    812 / 2448 symm_kl=0.43, self_kl=0, self_cv=9.461, loss=3.995, nll_loss=1.696, ppl=3.24, wps=28088.3, ups=1.9, wpb=14811, bsz=524.5, num_updates=15500, lr=2.032e-05, gnorm=0.992, train_wall=53, wall=8327
2020-12-21 21:58:01 | INFO | train_inner | epoch 007:    912 / 2448 symm_kl=0.432, self_kl=0, self_cv=9.464, loss=4.017, nll_loss=1.717, ppl=3.29, wps=28005.4, ups=1.88, wpb=14872.4, bsz=500.2, num_updates=15600, lr=2.02548e-05, gnorm=0.99, train_wall=53, wall=8380
2020-12-21 21:58:53 | INFO | train_inner | epoch 007:   1012 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.43, loss=4.031, nll_loss=1.729, ppl=3.32, wps=28146.7, ups=1.9, wpb=14784.1, bsz=517.1, num_updates=15700, lr=2.01902e-05, gnorm=0.995, train_wall=52, wall=8433
2020-12-21 21:59:46 | INFO | train_inner | epoch 007:   1112 / 2448 symm_kl=0.43, self_kl=0, self_cv=9.426, loss=4.006, nll_loss=1.709, ppl=3.27, wps=27889.1, ups=1.87, wpb=14883.9, bsz=517.7, num_updates=15800, lr=2.01262e-05, gnorm=0.984, train_wall=53, wall=8486
2020-12-21 22:00:40 | INFO | train_inner | epoch 007:   1212 / 2448 symm_kl=0.431, self_kl=0, self_cv=9.434, loss=4.02, nll_loss=1.721, ppl=3.3, wps=28030.8, ups=1.88, wpb=14890.6, bsz=510.5, num_updates=15900, lr=2.00628e-05, gnorm=0.986, train_wall=53, wall=8539
2020-12-21 22:01:32 | INFO | train_inner | epoch 007:   1312 / 2448 symm_kl=0.437, self_kl=0, self_cv=9.461, loss=4.035, nll_loss=1.73, ppl=3.32, wps=27965.8, ups=1.9, wpb=14743.6, bsz=488.1, num_updates=16000, lr=2e-05, gnorm=1.007, train_wall=53, wall=8592
2020-12-21 22:02:25 | INFO | train_inner | epoch 007:   1412 / 2448 symm_kl=0.429, self_kl=0, self_cv=9.446, loss=4.005, nll_loss=1.708, ppl=3.27, wps=28294.3, ups=1.9, wpb=14857, bsz=507.8, num_updates=16100, lr=1.99378e-05, gnorm=0.984, train_wall=52, wall=8644
2020-12-21 22:03:17 | INFO | train_inner | epoch 007:   1512 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.45, loss=4.029, nll_loss=1.729, ppl=3.32, wps=28175.4, ups=1.91, wpb=14747.3, bsz=529.6, num_updates=16200, lr=1.98762e-05, gnorm=1.004, train_wall=52, wall=8697
2020-12-21 22:04:10 | INFO | train_inner | epoch 007:   1612 / 2448 symm_kl=0.428, self_kl=0, self_cv=9.489, loss=3.999, nll_loss=1.703, ppl=3.26, wps=28056.1, ups=1.9, wpb=14769.3, bsz=504.3, num_updates=16300, lr=1.98151e-05, gnorm=0.989, train_wall=52, wall=8749
2020-12-21 22:05:02 | INFO | train_inner | epoch 007:   1712 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.46, loss=4.021, nll_loss=1.72, ppl=3.3, wps=28198.9, ups=1.91, wpb=14767.6, bsz=497.8, num_updates=16400, lr=1.97546e-05, gnorm=0.996, train_wall=52, wall=8802
2020-12-21 22:05:55 | INFO | train_inner | epoch 007:   1812 / 2448 symm_kl=0.428, self_kl=0, self_cv=9.46, loss=3.997, nll_loss=1.702, ppl=3.25, wps=28093.6, ups=1.9, wpb=14786.8, bsz=504.9, num_updates=16500, lr=1.96946e-05, gnorm=0.991, train_wall=52, wall=8854
2020-12-21 22:06:48 | INFO | train_inner | epoch 007:   1912 / 2448 symm_kl=0.428, self_kl=0, self_cv=9.452, loss=4, nll_loss=1.704, ppl=3.26, wps=28223.1, ups=1.9, wpb=14879.9, bsz=526.6, num_updates=16600, lr=1.96352e-05, gnorm=0.989, train_wall=53, wall=8907
2020-12-21 22:07:40 | INFO | train_inner | epoch 007:   2012 / 2448 symm_kl=0.43, self_kl=0, self_cv=9.43, loss=4.025, nll_loss=1.73, ppl=3.32, wps=28157.7, ups=1.91, wpb=14778.3, bsz=497.4, num_updates=16700, lr=1.95764e-05, gnorm=0.997, train_wall=52, wall=8960
2020-12-21 22:08:33 | INFO | train_inner | epoch 007:   2112 / 2448 symm_kl=0.428, self_kl=0, self_cv=9.437, loss=4.009, nll_loss=1.714, ppl=3.28, wps=28272.5, ups=1.9, wpb=14857.6, bsz=520.1, num_updates=16800, lr=1.9518e-05, gnorm=0.988, train_wall=52, wall=9012
2020-12-21 22:09:26 | INFO | train_inner | epoch 007:   2212 / 2448 symm_kl=0.427, self_kl=0, self_cv=9.417, loss=4.008, nll_loss=1.715, ppl=3.28, wps=28009, ups=1.89, wpb=14837.6, bsz=544.8, num_updates=16900, lr=1.94602e-05, gnorm=0.989, train_wall=53, wall=9065
2020-12-21 22:10:19 | INFO | train_inner | epoch 007:   2312 / 2448 symm_kl=0.427, self_kl=0, self_cv=9.428, loss=4.013, nll_loss=1.721, ppl=3.3, wps=27793.7, ups=1.88, wpb=14809.9, bsz=505.4, num_updates=17000, lr=1.94029e-05, gnorm=0.988, train_wall=53, wall=9118
2020-12-21 22:11:11 | INFO | train_inner | epoch 007:   2412 / 2448 symm_kl=0.433, self_kl=0, self_cv=9.471, loss=4.022, nll_loss=1.721, ppl=3.3, wps=28080.2, ups=1.91, wpb=14722.7, bsz=505.4, num_updates=17100, lr=1.9346e-05, gnorm=1.003, train_wall=52, wall=9171
2020-12-21 22:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 22:11:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 22:11:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 22:11:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 22:11:43 | INFO | valid | epoch 007 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.94 | nll_loss 7.903 | ppl 239.32 | bleu 16.4 | wps 6047.6 | wpb 7930.2 | bsz 208 | num_updates 17136 | best_bleu 16.45
2020-12-21 22:11:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 22:11:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 7 @ 17136 updates, score 16.4) (writing took 4.802002443000674 seconds)
2020-12-21 22:11:48 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-12-21 22:11:48 | INFO | train | epoch 007 | symm_kl 0.431 | self_kl 0 | self_cv 9.448 | loss 4.011 | nll_loss 1.712 | ppl 3.28 | wps 27513.7 | ups 1.86 | wpb 14810.4 | bsz 511.8 | num_updates 17136 | lr 1.93257e-05 | gnorm 0.992 | train_wall 1287 | wall 9208
2020-12-21 22:11:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:51 | INFO | fairseq.trainer | begin training epoch 8
2020-12-21 22:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:11:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:11:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:12:30 | INFO | train_inner | epoch 008:     64 / 2448 symm_kl=0.431, self_kl=0, self_cv=9.454, loss=4.015, nll_loss=1.716, ppl=3.29, wps=18612.4, ups=1.27, wpb=14668.8, bsz=470.1, num_updates=17200, lr=1.92897e-05, gnorm=1.005, train_wall=52, wall=9250
2020-12-21 22:13:22 | INFO | train_inner | epoch 008:    164 / 2448 symm_kl=0.431, self_kl=0, self_cv=9.451, loss=4.009, nll_loss=1.709, ppl=3.27, wps=28187.9, ups=1.91, wpb=14756.1, bsz=504.7, num_updates=17300, lr=1.92339e-05, gnorm=1.001, train_wall=52, wall=9302
2020-12-21 22:14:15 | INFO | train_inner | epoch 008:    264 / 2448 symm_kl=0.426, self_kl=0, self_cv=9.465, loss=3.996, nll_loss=1.703, ppl=3.26, wps=28077.6, ups=1.9, wpb=14802.5, bsz=514.3, num_updates=17400, lr=1.91785e-05, gnorm=0.985, train_wall=53, wall=9355
2020-12-21 22:15:08 | INFO | train_inner | epoch 008:    364 / 2448 symm_kl=0.432, self_kl=0, self_cv=9.447, loss=4.021, nll_loss=1.722, ppl=3.3, wps=28123.5, ups=1.91, wpb=14748.7, bsz=497, num_updates=17500, lr=1.91237e-05, gnorm=0.999, train_wall=52, wall=9407
2020-12-21 22:16:00 | INFO | train_inner | epoch 008:    464 / 2448 symm_kl=0.434, self_kl=0, self_cv=9.458, loss=4.023, nll_loss=1.721, ppl=3.3, wps=27989.1, ups=1.9, wpb=14745.6, bsz=502.3, num_updates=17600, lr=1.90693e-05, gnorm=1.005, train_wall=53, wall=9460
2020-12-21 22:16:53 | INFO | train_inner | epoch 008:    564 / 2448 symm_kl=0.423, self_kl=0, self_cv=9.464, loss=3.982, nll_loss=1.692, ppl=3.23, wps=28258.9, ups=1.91, wpb=14832, bsz=515.1, num_updates=17700, lr=1.90153e-05, gnorm=0.983, train_wall=52, wall=9512
2020-12-21 22:17:45 | INFO | train_inner | epoch 008:    664 / 2448 symm_kl=0.429, self_kl=0, self_cv=9.451, loss=4.013, nll_loss=1.718, ppl=3.29, wps=28201.3, ups=1.91, wpb=14780, bsz=520.1, num_updates=17800, lr=1.89618e-05, gnorm=0.995, train_wall=52, wall=9565
2020-12-21 22:18:38 | INFO | train_inner | epoch 008:    764 / 2448 symm_kl=0.426, self_kl=0, self_cv=9.446, loss=3.998, nll_loss=1.705, ppl=3.26, wps=28281.6, ups=1.9, wpb=14857.6, bsz=497.4, num_updates=17900, lr=1.89088e-05, gnorm=0.987, train_wall=52, wall=9617
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 130 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
nohup: ignoring input
save_dir=./examples/_transformer_base/bash/../checkpoints/kl
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=4000
max_epoch=100
r3f_lambda=1
extr='--noised-no-grad --cv --cv-lambda 0'
2020-12-21 22:19:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:11185
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:11185
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:11185
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:11185
2020-12-21 22:19:26 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-21 22:19:27 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-21 22:19:27 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-21 22:19:30 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=True, cv_lambda=0.0, data='./examples/_transformer_base/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:11185', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/_transformer_base/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3200, max_tokens_valid=3200, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/_transformer_base/bash/../checkpoints/kl', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-21 22:19:30 | INFO | fairseq.tasks.translation | [ch] dictionary: 41952 types
2020-12-21 22:19:30 | INFO | fairseq.tasks.translation | [en] dictionary: 31264 types
2020-12-21 22:19:30 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.ch
2020-12-21 22:19:30 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/_transformer_base/bash/../data-bin/valid.ch-en.en
2020-12-21 22:19:30 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin valid ch-en 1664 examples
2020-12-21 22:19:32 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(41952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31264, bias=False)
  )
)
2020-12-21 22:19:32 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-21 22:19:32 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2020-12-21 22:19:32 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2020-12-21 22:19:32 | INFO | fairseq_cli.train | num. model params: 97632256 (num. trained: 97632256)
2020-12-21 22:19:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-21 22:19:32 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 22:19:32 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 22:19:32 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 22:19:32 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-21 22:19:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-21 22:19:32 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2020-12-21 22:19:32 | INFO | fairseq_cli.train | max tokens per GPU = 3200 and max sentences per GPU = None
2020-12-21 22:19:33 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-21 22:19:34 | INFO | fairseq.trainer | loaded checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 8 @ 17136 updates)
2020-12-21 22:19:34 | INFO | fairseq.trainer | loading train data for epoch 8
2020-12-21 22:19:34 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.ch
2020-12-21 22:19:34 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ./examples/_transformer_base/bash/../data-bin/train.ch-en.en
2020-12-21 22:19:34 | INFO | fairseq.tasks.translation | ./examples/_transformer_base/bash/../data-bin train ch-en 1252977 examples
2020-12-21 22:19:40 | INFO | fairseq.trainer | begin training epoch 8
2020-12-21 22:19:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:19:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:19:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:20:20 | INFO | train_inner | epoch 008:     64 / 3059 symm_kl=0.432, self_kl=0, self_cv=9.457, loss=4.015, nll_loss=1.715, ppl=3.28, wps=16328.4, ups=1.28, wpb=12762.9, bsz=408.6, num_updates=17200, lr=1.92897e-05, gnorm=1.081, train_wall=52, wall=0
2020-12-21 22:21:11 | INFO | train_inner | epoch 008:    164 / 3059 symm_kl=0.433, self_kl=0, self_cv=9.475, loss=4.021, nll_loss=1.721, ppl=3.3, wps=22994.5, ups=1.95, wpb=11789.5, bsz=388.5, num_updates=17300, lr=1.92339e-05, gnorm=1.127, train_wall=51, wall=0
2020-12-21 22:22:03 | INFO | train_inner | epoch 008:    264 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.451, loss=3.978, nll_loss=1.687, ppl=3.22, wps=22847, ups=1.92, wpb=11873.9, bsz=426.8, num_updates=17400, lr=1.91785e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 22:22:55 | INFO | train_inner | epoch 008:    364 / 3059 symm_kl=0.43, self_kl=0, self_cv=9.431, loss=4.018, nll_loss=1.722, ppl=3.3, wps=22852.7, ups=1.92, wpb=11871.8, bsz=410.7, num_updates=17500, lr=1.91237e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 22:23:47 | INFO | train_inner | epoch 008:    464 / 3059 symm_kl=0.434, self_kl=0, self_cv=9.478, loss=4.036, nll_loss=1.736, ppl=3.33, wps=22667.1, ups=1.94, wpb=11670.4, bsz=381.7, num_updates=17600, lr=1.90693e-05, gnorm=1.134, train_wall=51, wall=0
2020-12-21 22:24:39 | INFO | train_inner | epoch 008:    564 / 3059 symm_kl=0.433, self_kl=0, self_cv=9.453, loss=4.014, nll_loss=1.713, ppl=3.28, wps=22777.5, ups=1.92, wpb=11855.3, bsz=399.3, num_updates=17700, lr=1.90153e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-21 22:25:30 | INFO | train_inner | epoch 008:    664 / 3059 symm_kl=0.427, self_kl=0, self_cv=9.442, loss=3.999, nll_loss=1.707, ppl=3.26, wps=22952.1, ups=1.94, wpb=11841.2, bsz=416.8, num_updates=17800, lr=1.89618e-05, gnorm=1.111, train_wall=51, wall=0
2020-12-21 22:26:22 | INFO | train_inner | epoch 008:    764 / 3059 symm_kl=0.428, self_kl=0, self_cv=9.438, loss=4.01, nll_loss=1.716, ppl=3.29, wps=22854.5, ups=1.93, wpb=11839.2, bsz=423.4, num_updates=17900, lr=1.89088e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-21 22:27:14 | INFO | train_inner | epoch 008:    864 / 3059 symm_kl=0.429, self_kl=0, self_cv=9.45, loss=4.003, nll_loss=1.707, ppl=3.26, wps=22856.3, ups=1.93, wpb=11845.1, bsz=401, num_updates=18000, lr=1.88562e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-21 22:28:06 | INFO | train_inner | epoch 008:    964 / 3059 symm_kl=0.424, self_kl=0, self_cv=9.434, loss=3.998, nll_loss=1.709, ppl=3.27, wps=23019.9, ups=1.93, wpb=11925.6, bsz=403.9, num_updates=18100, lr=1.8804e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 22:28:58 | INFO | train_inner | epoch 008:   1064 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.429, loss=3.996, nll_loss=1.703, ppl=3.26, wps=22846.9, ups=1.92, wpb=11891.4, bsz=443.1, num_updates=18200, lr=1.87523e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 22:29:50 | INFO | train_inner | epoch 008:   1164 / 3059 symm_kl=0.428, self_kl=0, self_cv=9.457, loss=4.008, nll_loss=1.714, ppl=3.28, wps=22739.5, ups=1.92, wpb=11870.8, bsz=416.5, num_updates=18300, lr=1.8701e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 22:30:42 | INFO | train_inner | epoch 008:   1264 / 3059 symm_kl=0.434, self_kl=0, self_cv=9.468, loss=4.038, nll_loss=1.739, ppl=3.34, wps=22658.1, ups=1.93, wpb=11763.1, bsz=383.3, num_updates=18400, lr=1.86501e-05, gnorm=1.126, train_wall=52, wall=0
2020-12-21 22:31:34 | INFO | train_inner | epoch 008:   1364 / 3059 symm_kl=0.427, self_kl=0, self_cv=9.412, loss=4.012, nll_loss=1.721, ppl=3.3, wps=22909.1, ups=1.93, wpb=11859.4, bsz=403.8, num_updates=18500, lr=1.85996e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-21 22:32:26 | INFO | train_inner | epoch 008:   1464 / 3059 symm_kl=0.429, self_kl=0, self_cv=9.435, loss=4.024, nll_loss=1.731, ppl=3.32, wps=22690.4, ups=1.92, wpb=11801.4, bsz=400.6, num_updates=18600, lr=1.85496e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-21 22:33:18 | INFO | train_inner | epoch 008:   1564 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.447, loss=3.997, nll_loss=1.71, ppl=3.27, wps=22790.8, ups=1.92, wpb=11871.1, bsz=400.7, num_updates=18700, lr=1.84999e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-21 22:34:10 | INFO | train_inner | epoch 008:   1664 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.416, loss=4, nll_loss=1.71, ppl=3.27, wps=22715.5, ups=1.91, wpb=11883.4, bsz=422.8, num_updates=18800, lr=1.84506e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 22:35:02 | INFO | train_inner | epoch 008:   1764 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.431, loss=4.008, nll_loss=1.72, ppl=3.29, wps=22898.1, ups=1.93, wpb=11868.6, bsz=417, num_updates=18900, lr=1.84017e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 22:35:54 | INFO | train_inner | epoch 008:   1864 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.424, loss=4.01, nll_loss=1.721, ppl=3.3, wps=22816.2, ups=1.92, wpb=11875.7, bsz=429.4, num_updates=19000, lr=1.83533e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 22:36:46 | INFO | train_inner | epoch 008:   1964 / 3059 symm_kl=0.424, self_kl=0, self_cv=9.459, loss=4.011, nll_loss=1.724, ppl=3.3, wps=22889.5, ups=1.93, wpb=11866.1, bsz=418.2, num_updates=19100, lr=1.83052e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-21 22:37:38 | INFO | train_inner | epoch 008:   2064 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.425, loss=3.993, nll_loss=1.71, ppl=3.27, wps=22899, ups=1.93, wpb=11887.2, bsz=412.4, num_updates=19200, lr=1.82574e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-21 22:38:30 | INFO | train_inner | epoch 008:   2164 / 3059 symm_kl=0.427, self_kl=0, self_cv=9.409, loss=4.023, nll_loss=1.734, ppl=3.33, wps=22875, ups=1.93, wpb=11863, bsz=396.6, num_updates=19300, lr=1.82101e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-21 22:39:22 | INFO | train_inner | epoch 008:   2264 / 3059 symm_kl=0.429, self_kl=0, self_cv=9.448, loss=4.014, nll_loss=1.721, ppl=3.3, wps=22760.4, ups=1.92, wpb=11828, bsz=394.4, num_updates=19400, lr=1.81631e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-21 22:40:14 | INFO | train_inner | epoch 008:   2364 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.393, loss=3.985, nll_loss=1.702, ppl=3.25, wps=22732.7, ups=1.92, wpb=11848.6, bsz=427.9, num_updates=19500, lr=1.81164e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-21 22:41:06 | INFO | train_inner | epoch 008:   2464 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.412, loss=4.021, nll_loss=1.735, ppl=3.33, wps=22741.7, ups=1.92, wpb=11829.1, bsz=420.1, num_updates=19600, lr=1.80702e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-21 22:41:57 | INFO | train_inner | epoch 008:   2564 / 3059 symm_kl=0.424, self_kl=0, self_cv=9.461, loss=4.008, nll_loss=1.721, ppl=3.3, wps=22848.4, ups=1.93, wpb=11836.2, bsz=405.7, num_updates=19700, lr=1.80242e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-21 22:42:49 | INFO | train_inner | epoch 008:   2664 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.388, loss=4, nll_loss=1.72, ppl=3.29, wps=22826.7, ups=1.93, wpb=11849.2, bsz=400.4, num_updates=19800, lr=1.79787e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 22:43:41 | INFO | train_inner | epoch 008:   2764 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.382, loss=4.03, nll_loss=1.744, ppl=3.35, wps=22954.1, ups=1.92, wpb=11942.3, bsz=414.2, num_updates=19900, lr=1.79334e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-21 22:44:33 | INFO | train_inner | epoch 008:   2864 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.45, loss=4.003, nll_loss=1.72, ppl=3.29, wps=22853.9, ups=1.93, wpb=11847.9, bsz=397.9, num_updates=20000, lr=1.78885e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 22:45:25 | INFO | train_inner | epoch 008:   2964 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.39, loss=3.979, nll_loss=1.701, ppl=3.25, wps=22891.2, ups=1.93, wpb=11857, bsz=451.5, num_updates=20100, lr=1.7844e-05, gnorm=1.096, train_wall=52, wall=0
2020-12-21 22:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 22:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 22:46:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 22:46:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 22:46:31 | INFO | valid | epoch 008 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.924 | nll_loss 7.892 | ppl 237.52 | bleu 16.33 | wps 4817.9 | wpb 6344.2 | bsz 166.4 | num_updates 20195 | best_bleu 16.45
2020-12-21 22:46:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 22:46:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 8 @ 20195 updates, score 16.33) (writing took 4.788130700588226 seconds)
2020-12-21 22:46:35 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-12-21 22:46:35 | INFO | train | epoch 008 | symm_kl 0.429 | self_kl 0 | self_cv 9.441 | loss 4.01 | nll_loss 1.715 | ppl 3.28 | wps 24712.3 | ups 1.88 | wpb 13167.2 | bsz 455 | num_updates 20195 | lr 1.7802e-05 | gnorm 1.057 | train_wall 2869 | wall 0
2020-12-21 22:46:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:39 | INFO | fairseq.trainer | begin training epoch 9
2020-12-21 22:46:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 22:46:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 22:46:48 | INFO | train_inner | epoch 009:      5 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.39, loss=4.018, nll_loss=1.73, ppl=3.32, wps=14399.3, ups=1.21, wpb=11926.3, bsz=408, num_updates=20200, lr=1.77998e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 22:47:39 | INFO | train_inner | epoch 009:    105 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.418, loss=4.012, nll_loss=1.723, ppl=3.3, wps=23013.4, ups=1.95, wpb=11826.2, bsz=425.8, num_updates=20300, lr=1.77559e-05, gnorm=1.111, train_wall=51, wall=0
2020-12-21 22:48:31 | INFO | train_inner | epoch 009:    205 / 3059 symm_kl=0.424, self_kl=0, self_cv=9.424, loss=4.001, nll_loss=1.715, ppl=3.28, wps=22849.4, ups=1.93, wpb=11817.8, bsz=429.5, num_updates=20400, lr=1.77123e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 22:49:23 | INFO | train_inner | epoch 009:    305 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.415, loss=4.002, nll_loss=1.717, ppl=3.29, wps=22872.6, ups=1.94, wpb=11819.8, bsz=418.2, num_updates=20500, lr=1.7669e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 22:50:15 | INFO | train_inner | epoch 009:    405 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.444, loss=4.005, nll_loss=1.717, ppl=3.29, wps=22665.7, ups=1.92, wpb=11801.4, bsz=395.7, num_updates=20600, lr=1.76261e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-21 22:51:06 | INFO | train_inner | epoch 009:    505 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.44, loss=4.01, nll_loss=1.721, ppl=3.3, wps=22748.3, ups=1.93, wpb=11762.2, bsz=380.7, num_updates=20700, lr=1.75835e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-21 22:51:58 | INFO | train_inner | epoch 009:    605 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.435, loss=4.003, nll_loss=1.719, ppl=3.29, wps=22871, ups=1.93, wpb=11878.6, bsz=395.1, num_updates=20800, lr=1.75412e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-21 22:52:50 | INFO | train_inner | epoch 009:    705 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.474, loss=4.005, nll_loss=1.716, ppl=3.29, wps=22919.8, ups=1.93, wpb=11846.8, bsz=419.2, num_updates=20900, lr=1.74991e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-21 22:53:42 | INFO | train_inner | epoch 009:    805 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.399, loss=3.98, nll_loss=1.699, ppl=3.25, wps=22796.5, ups=1.92, wpb=11859, bsz=435.2, num_updates=21000, lr=1.74574e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 22:54:34 | INFO | train_inner | epoch 009:    905 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.444, loss=3.995, nll_loss=1.71, ppl=3.27, wps=23105.6, ups=1.93, wpb=11953.4, bsz=402.5, num_updates=21100, lr=1.7416e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 22:55:26 | INFO | train_inner | epoch 009:   1005 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.444, loss=3.993, nll_loss=1.709, ppl=3.27, wps=22819.3, ups=1.92, wpb=11896.1, bsz=415.5, num_updates=21200, lr=1.73749e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-21 22:56:18 | INFO | train_inner | epoch 009:   1105 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.425, loss=4.019, nll_loss=1.734, ppl=3.33, wps=22788.3, ups=1.92, wpb=11889.5, bsz=407.4, num_updates=21300, lr=1.73341e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-21 22:57:10 | INFO | train_inner | epoch 009:   1205 / 3059 symm_kl=0.426, self_kl=0, self_cv=9.448, loss=4.024, nll_loss=1.737, ppl=3.33, wps=22468.4, ups=1.92, wpb=11716.6, bsz=401.7, num_updates=21400, lr=1.72935e-05, gnorm=1.13, train_wall=52, wall=0
2020-12-21 22:58:02 | INFO | train_inner | epoch 009:   1305 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.454, loss=3.988, nll_loss=1.707, ppl=3.27, wps=22838.9, ups=1.92, wpb=11900.9, bsz=398.1, num_updates=21500, lr=1.72532e-05, gnorm=1.094, train_wall=52, wall=0
2020-12-21 22:58:54 | INFO | train_inner | epoch 009:   1405 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.387, loss=4.019, nll_loss=1.734, ppl=3.33, wps=22863.4, ups=1.93, wpb=11853.6, bsz=426.3, num_updates=21600, lr=1.72133e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 22:59:46 | INFO | train_inner | epoch 009:   1505 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.439, loss=4, nll_loss=1.716, ppl=3.29, wps=22797.6, ups=1.92, wpb=11859.1, bsz=393.4, num_updates=21700, lr=1.71736e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-21 23:00:38 | INFO | train_inner | epoch 009:   1605 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.392, loss=4, nll_loss=1.72, ppl=3.29, wps=22857.3, ups=1.93, wpb=11827.5, bsz=417.6, num_updates=21800, lr=1.71341e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-21 23:01:30 | INFO | train_inner | epoch 009:   1705 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.369, loss=3.988, nll_loss=1.713, ppl=3.28, wps=22901.8, ups=1.93, wpb=11884.6, bsz=423.8, num_updates=21900, lr=1.7095e-05, gnorm=1.092, train_wall=52, wall=0
2020-12-21 23:02:22 | INFO | train_inner | epoch 009:   1805 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.408, loss=4.016, nll_loss=1.734, ppl=3.33, wps=22952.6, ups=1.93, wpb=11894.6, bsz=398.2, num_updates=22000, lr=1.70561e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 23:03:14 | INFO | train_inner | epoch 009:   1905 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.4, loss=4.005, nll_loss=1.723, ppl=3.3, wps=22826.2, ups=1.92, wpb=11865.7, bsz=411.5, num_updates=22100, lr=1.70174e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-21 23:04:06 | INFO | train_inner | epoch 009:   2005 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.441, loss=4.007, nll_loss=1.725, ppl=3.31, wps=22784.6, ups=1.93, wpb=11823.9, bsz=402.3, num_updates=22200, lr=1.69791e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 23:04:58 | INFO | train_inner | epoch 009:   2105 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.433, loss=4.013, nll_loss=1.731, ppl=3.32, wps=22712.4, ups=1.91, wpb=11879.9, bsz=397.8, num_updates=22300, lr=1.69409e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-21 23:05:50 | INFO | train_inner | epoch 009:   2205 / 3059 symm_kl=0.424, self_kl=0, self_cv=9.411, loss=4.023, nll_loss=1.74, ppl=3.34, wps=22809.9, ups=1.93, wpb=11843.7, bsz=400.4, num_updates=22400, lr=1.69031e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:06:42 | INFO | train_inner | epoch 009:   2305 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.404, loss=3.982, nll_loss=1.705, ppl=3.26, wps=22923.1, ups=1.92, wpb=11937.6, bsz=438.4, num_updates=22500, lr=1.68655e-05, gnorm=1.091, train_wall=52, wall=0
2020-12-21 23:07:34 | INFO | train_inner | epoch 009:   2405 / 3059 symm_kl=0.427, self_kl=0, self_cv=9.422, loss=4.044, nll_loss=1.759, ppl=3.38, wps=22545.9, ups=1.94, wpb=11642.2, bsz=381.7, num_updates=22600, lr=1.68281e-05, gnorm=1.122, train_wall=51, wall=0
2020-12-21 23:08:25 | INFO | train_inner | epoch 009:   2505 / 3059 symm_kl=0.425, self_kl=0, self_cv=9.383, loss=4.033, nll_loss=1.75, ppl=3.36, wps=22861.3, ups=1.93, wpb=11840.4, bsz=406.3, num_updates=22700, lr=1.6791e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:09:17 | INFO | train_inner | epoch 009:   2605 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.375, loss=3.971, nll_loss=1.7, ppl=3.25, wps=23014.3, ups=1.92, wpb=11975.4, bsz=448.7, num_updates=22800, lr=1.67542e-05, gnorm=1.084, train_wall=52, wall=0
2020-12-21 23:10:09 | INFO | train_inner | epoch 009:   2705 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.429, loss=4, nll_loss=1.723, ppl=3.3, wps=22861.1, ups=1.93, wpb=11843.4, bsz=418.4, num_updates=22900, lr=1.67175e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-21 23:11:01 | INFO | train_inner | epoch 009:   2805 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.384, loss=4.006, nll_loss=1.728, ppl=3.31, wps=23012.1, ups=1.93, wpb=11904.5, bsz=399.1, num_updates=23000, lr=1.66812e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 23:11:53 | INFO | train_inner | epoch 009:   2905 / 3059 symm_kl=0.422, self_kl=0, self_cv=9.429, loss=4.016, nll_loss=1.736, ppl=3.33, wps=22817.5, ups=1.94, wpb=11772.1, bsz=381.6, num_updates=23100, lr=1.6645e-05, gnorm=1.114, train_wall=51, wall=0
2020-12-21 23:12:45 | INFO | train_inner | epoch 009:   3005 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.409, loss=3.978, nll_loss=1.702, ppl=3.25, wps=22905.1, ups=1.92, wpb=11942.5, bsz=407.4, num_updates=23200, lr=1.66091e-05, gnorm=1.095, train_wall=52, wall=0
2020-12-21 23:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 23:13:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 23:13:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 23:13:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 23:13:30 | INFO | valid | epoch 009 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.934 | nll_loss 7.902 | ppl 239.2 | bleu 16.37 | wps 4478.4 | wpb 6344.2 | bsz 166.4 | num_updates 23254 | best_bleu 16.45
2020-12-21 23:13:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 23:13:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 9 @ 23254 updates, score 16.37) (writing took 4.791731948032975 seconds)
2020-12-21 23:13:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-12-21 23:13:34 | INFO | train | epoch 009 | symm_kl 0.422 | self_kl 0 | self_cv 9.419 | loss 4.004 | nll_loss 1.722 | ppl 3.3 | wps 22393.9 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 23254 | lr 1.65898e-05 | gnorm 1.107 | train_wall 1582 | wall 0
2020-12-21 23:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:38 | INFO | fairseq.trainer | begin training epoch 10
2020-12-21 23:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:13:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:13:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:14:08 | INFO | train_inner | epoch 010:     46 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.377, loss=4.01, nll_loss=1.733, ppl=3.33, wps=14296.6, ups=1.2, wpb=11870.8, bsz=424.6, num_updates=23300, lr=1.65734e-05, gnorm=1.101, train_wall=51, wall=0
2020-12-21 23:14:59 | INFO | train_inner | epoch 010:    146 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.402, loss=3.965, nll_loss=1.693, ppl=3.23, wps=23183.1, ups=1.95, wpb=11919, bsz=432.7, num_updates=23400, lr=1.6538e-05, gnorm=1.089, train_wall=51, wall=0
2020-12-21 23:15:51 | INFO | train_inner | epoch 010:    246 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.432, loss=4.002, nll_loss=1.721, ppl=3.3, wps=22674.9, ups=1.92, wpb=11821.1, bsz=398, num_updates=23500, lr=1.65027e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:16:43 | INFO | train_inner | epoch 010:    346 / 3059 symm_kl=0.423, self_kl=0, self_cv=9.415, loss=4.014, nll_loss=1.732, ppl=3.32, wps=22726.5, ups=1.92, wpb=11835.7, bsz=415.4, num_updates=23600, lr=1.64677e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:17:36 | INFO | train_inner | epoch 010:    446 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.426, loss=3.991, nll_loss=1.715, ppl=3.28, wps=22616.4, ups=1.92, wpb=11810.1, bsz=428.8, num_updates=23700, lr=1.6433e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 23:18:28 | INFO | train_inner | epoch 010:    546 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.429, loss=3.995, nll_loss=1.714, ppl=3.28, wps=22572.4, ups=1.91, wpb=11801.9, bsz=389.4, num_updates=23800, lr=1.63984e-05, gnorm=1.126, train_wall=52, wall=0
2020-12-21 23:19:20 | INFO | train_inner | epoch 010:    646 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.443, loss=3.968, nll_loss=1.692, ppl=3.23, wps=22790.5, ups=1.92, wpb=11870.5, bsz=427.9, num_updates=23900, lr=1.63641e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-21 23:20:12 | INFO | train_inner | epoch 010:    746 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.466, loss=3.977, nll_loss=1.697, ppl=3.24, wps=23012.7, ups=1.93, wpb=11901.6, bsz=391.2, num_updates=24000, lr=1.63299e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-21 23:21:03 | INFO | train_inner | epoch 010:    846 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.435, loss=4.011, nll_loss=1.731, ppl=3.32, wps=22819.2, ups=1.93, wpb=11793.7, bsz=399.9, num_updates=24100, lr=1.6296e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:21:55 | INFO | train_inner | epoch 010:    946 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.432, loss=3.985, nll_loss=1.712, ppl=3.28, wps=22879.2, ups=1.93, wpb=11872.7, bsz=415.5, num_updates=24200, lr=1.62623e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-21 23:22:47 | INFO | train_inner | epoch 010:   1046 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.405, loss=3.985, nll_loss=1.712, ppl=3.28, wps=22977.7, ups=1.93, wpb=11908.3, bsz=422.6, num_updates=24300, lr=1.62288e-05, gnorm=1.089, train_wall=52, wall=0
2020-12-21 23:23:39 | INFO | train_inner | epoch 010:   1146 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.407, loss=4.002, nll_loss=1.723, ppl=3.3, wps=22860.7, ups=1.93, wpb=11853.3, bsz=405.4, num_updates=24400, lr=1.61955e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-21 23:24:31 | INFO | train_inner | epoch 010:   1246 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.417, loss=4.007, nll_loss=1.726, ppl=3.31, wps=22884, ups=1.92, wpb=11902.5, bsz=390.5, num_updates=24500, lr=1.61624e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-21 23:25:23 | INFO | train_inner | epoch 010:   1346 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.412, loss=3.99, nll_loss=1.72, ppl=3.29, wps=22866.2, ups=1.92, wpb=11903.9, bsz=421, num_updates=24600, lr=1.61296e-05, gnorm=1.092, train_wall=52, wall=0
2020-12-21 23:26:15 | INFO | train_inner | epoch 010:   1446 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.404, loss=3.997, nll_loss=1.72, ppl=3.29, wps=22910.7, ups=1.93, wpb=11881.5, bsz=432.6, num_updates=24700, lr=1.60969e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 23:27:07 | INFO | train_inner | epoch 010:   1546 / 3059 symm_kl=0.421, self_kl=0, self_cv=9.43, loss=4.013, nll_loss=1.733, ppl=3.32, wps=22829.3, ups=1.93, wpb=11819.9, bsz=384.6, num_updates=24800, lr=1.60644e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:27:59 | INFO | train_inner | epoch 010:   1646 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.409, loss=4.011, nll_loss=1.735, ppl=3.33, wps=22860.9, ups=1.93, wpb=11874.8, bsz=406, num_updates=24900, lr=1.60321e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-21 23:28:51 | INFO | train_inner | epoch 010:   1746 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.45, loss=4.009, nll_loss=1.732, ppl=3.32, wps=22725.7, ups=1.92, wpb=11833.5, bsz=414, num_updates=25000, lr=1.6e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:29:43 | INFO | train_inner | epoch 010:   1846 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.423, loss=3.992, nll_loss=1.716, ppl=3.29, wps=22887.2, ups=1.92, wpb=11909.6, bsz=394.1, num_updates=25100, lr=1.59681e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-21 23:30:34 | INFO | train_inner | epoch 010:   1946 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.418, loss=3.983, nll_loss=1.713, ppl=3.28, wps=22737.8, ups=1.93, wpb=11792.9, bsz=420, num_updates=25200, lr=1.59364e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-21 23:31:26 | INFO | train_inner | epoch 010:   2046 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.405, loss=4.012, nll_loss=1.735, ppl=3.33, wps=22848.1, ups=1.93, wpb=11840.2, bsz=422.2, num_updates=25300, lr=1.59049e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 23:32:18 | INFO | train_inner | epoch 010:   2146 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.386, loss=4.004, nll_loss=1.727, ppl=3.31, wps=22642.1, ups=1.92, wpb=11812.2, bsz=407.4, num_updates=25400, lr=1.58735e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 23:33:10 | INFO | train_inner | epoch 010:   2246 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.391, loss=4.024, nll_loss=1.749, ppl=3.36, wps=22804.5, ups=1.92, wpb=11847.4, bsz=386.8, num_updates=25500, lr=1.58424e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 23:34:02 | INFO | train_inner | epoch 010:   2346 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.411, loss=4.012, nll_loss=1.735, ppl=3.33, wps=22837.6, ups=1.93, wpb=11863.4, bsz=390.4, num_updates=25600, lr=1.58114e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-21 23:34:54 | INFO | train_inner | epoch 010:   2446 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.42, loss=4.015, nll_loss=1.74, ppl=3.34, wps=22775.4, ups=1.93, wpb=11815.9, bsz=387.3, num_updates=25700, lr=1.57806e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-21 23:35:46 | INFO | train_inner | epoch 010:   2546 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.435, loss=4.008, nll_loss=1.735, ppl=3.33, wps=22695.9, ups=1.92, wpb=11793.6, bsz=407.4, num_updates=25800, lr=1.575e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:36:38 | INFO | train_inner | epoch 010:   2646 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.384, loss=4.004, nll_loss=1.731, ppl=3.32, wps=22875.7, ups=1.93, wpb=11876, bsz=422.2, num_updates=25900, lr=1.57195e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-21 23:37:30 | INFO | train_inner | epoch 010:   2746 / 3059 symm_kl=0.419, self_kl=0, self_cv=9.379, loss=4.012, nll_loss=1.736, ppl=3.33, wps=22904.2, ups=1.93, wpb=11846, bsz=389.6, num_updates=26000, lr=1.56893e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:38:22 | INFO | train_inner | epoch 010:   2846 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.384, loss=4.01, nll_loss=1.732, ppl=3.32, wps=22832.1, ups=1.92, wpb=11870.3, bsz=429, num_updates=26100, lr=1.56592e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:39:14 | INFO | train_inner | epoch 010:   2946 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.376, loss=3.998, nll_loss=1.728, ppl=3.31, wps=22696.9, ups=1.91, wpb=11864.5, bsz=438, num_updates=26200, lr=1.56293e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 23:40:06 | INFO | train_inner | epoch 010:   3046 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.399, loss=3.986, nll_loss=1.714, ppl=3.28, wps=22660.1, ups=1.92, wpb=11811.2, bsz=418.8, num_updates=26300, lr=1.55996e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-21 23:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-21 23:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-21 23:40:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-21 23:40:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-21 23:40:29 | INFO | valid | epoch 010 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.922 | nll_loss 7.889 | ppl 236.99 | bleu 16.42 | wps 4900.5 | wpb 6344.2 | bsz 166.4 | num_updates 26313 | best_bleu 16.45
2020-12-21 23:40:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-21 23:40:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 10 @ 26313 updates, score 16.42) (writing took 4.817181112244725 seconds)
2020-12-21 23:40:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-12-21 23:40:34 | INFO | train | epoch 010 | symm_kl 0.418 | self_kl 0 | self_cv 9.414 | loss 4 | nll_loss 1.724 | ppl 3.3 | wps 22391.7 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 26313 | lr 1.55957e-05 | gnorm 1.106 | train_wall 1583 | wall 0
2020-12-21 23:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:37 | INFO | fairseq.trainer | begin training epoch 11
2020-12-21 23:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:40:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-21 23:40:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-21 23:41:28 | INFO | train_inner | epoch 011:     87 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.426, loss=3.99, nll_loss=1.714, ppl=3.28, wps=14482.6, ups=1.22, wpb=11885.5, bsz=387.8, num_updates=26400, lr=1.557e-05, gnorm=1.101, train_wall=51, wall=0
2020-12-21 23:42:20 | INFO | train_inner | epoch 011:    187 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.383, loss=3.988, nll_loss=1.719, ppl=3.29, wps=22976.6, ups=1.92, wpb=11940.6, bsz=423.8, num_updates=26500, lr=1.55406e-05, gnorm=1.091, train_wall=52, wall=0
2020-12-21 23:43:12 | INFO | train_inner | epoch 011:    287 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.415, loss=4.001, nll_loss=1.724, ppl=3.3, wps=22791.5, ups=1.92, wpb=11875.3, bsz=400.7, num_updates=26600, lr=1.55113e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-21 23:44:04 | INFO | train_inner | epoch 011:    387 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.425, loss=3.998, nll_loss=1.723, ppl=3.3, wps=22714.3, ups=1.92, wpb=11814.3, bsz=405.9, num_updates=26700, lr=1.54823e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-21 23:44:56 | INFO | train_inner | epoch 011:    487 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.383, loss=3.97, nll_loss=1.701, ppl=3.25, wps=22986.9, ups=1.93, wpb=11904.9, bsz=421, num_updates=26800, lr=1.54533e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-21 23:45:48 | INFO | train_inner | epoch 011:    587 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.432, loss=4.001, nll_loss=1.725, ppl=3.31, wps=22626.6, ups=1.92, wpb=11787.6, bsz=384.2, num_updates=26900, lr=1.54246e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-21 23:46:40 | INFO | train_inner | epoch 011:    687 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.434, loss=3.969, nll_loss=1.699, ppl=3.25, wps=22748.4, ups=1.92, wpb=11839.6, bsz=413.3, num_updates=27000, lr=1.5396e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-21 23:47:32 | INFO | train_inner | epoch 011:    787 / 3059 symm_kl=0.418, self_kl=0, self_cv=9.421, loss=4.015, nll_loss=1.741, ppl=3.34, wps=22604.4, ups=1.92, wpb=11763.9, bsz=409.8, num_updates=27100, lr=1.53676e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-21 23:48:24 | INFO | train_inner | epoch 011:    887 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.433, loss=3.996, nll_loss=1.72, ppl=3.29, wps=22809, ups=1.93, wpb=11846.1, bsz=390.2, num_updates=27200, lr=1.53393e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-21 23:49:16 | INFO | train_inner | epoch 011:    987 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.415, loss=3.995, nll_loss=1.723, ppl=3.3, wps=22726.2, ups=1.93, wpb=11772.2, bsz=406, num_updates=27300, lr=1.53112e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-21 23:50:08 | INFO | train_inner | epoch 011:   1087 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.412, loss=3.996, nll_loss=1.722, ppl=3.3, wps=22781, ups=1.93, wpb=11829.1, bsz=400.5, num_updates=27400, lr=1.52832e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-21 23:51:00 | INFO | train_inner | epoch 011:   1187 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.4, loss=3.995, nll_loss=1.722, ppl=3.3, wps=22811.1, ups=1.92, wpb=11911.3, bsz=402.2, num_updates=27500, lr=1.52554e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-21 23:51:52 | INFO | train_inner | epoch 011:   1287 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.385, loss=4.002, nll_loss=1.729, ppl=3.32, wps=22623.1, ups=1.92, wpb=11778.4, bsz=402.6, num_updates=27600, lr=1.52277e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-21 23:52:44 | INFO | train_inner | epoch 011:   1387 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.433, loss=3.999, nll_loss=1.725, ppl=3.31, wps=22695, ups=1.92, wpb=11830.4, bsz=416, num_updates=27700, lr=1.52002e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-21 23:53:37 | INFO | train_inner | epoch 011:   1487 / 3059 symm_kl=0.416, self_kl=0, self_cv=9.403, loss=4.002, nll_loss=1.729, ppl=3.32, wps=22542.5, ups=1.91, wpb=11799.7, bsz=414.5, num_updates=27800, lr=1.51729e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-21 23:54:29 | INFO | train_inner | epoch 011:   1587 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.427, loss=3.981, nll_loss=1.71, ppl=3.27, wps=22965.4, ups=1.93, wpb=11916.8, bsz=385.8, num_updates=27900, lr=1.51456e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-21 23:55:21 | INFO | train_inner | epoch 011:   1687 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.405, loss=3.971, nll_loss=1.704, ppl=3.26, wps=22840.9, ups=1.92, wpb=11900.2, bsz=423.8, num_updates=28000, lr=1.51186e-05, gnorm=1.093, train_wall=52, wall=0
2020-12-21 23:56:13 | INFO | train_inner | epoch 011:   1787 / 3059 symm_kl=0.42, self_kl=0, self_cv=9.392, loss=4.03, nll_loss=1.754, ppl=3.37, wps=22755.2, ups=1.92, wpb=11837.3, bsz=398.1, num_updates=28100, lr=1.50917e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-21 23:57:05 | INFO | train_inner | epoch 011:   1887 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.422, loss=3.993, nll_loss=1.724, ppl=3.3, wps=22950.1, ups=1.92, wpb=11962.3, bsz=415.6, num_updates=28200, lr=1.50649e-05, gnorm=1.09, train_wall=52, wall=0
2020-12-21 23:57:57 | INFO | train_inner | epoch 011:   1987 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.4, loss=3.998, nll_loss=1.728, ppl=3.31, wps=22845.5, ups=1.91, wpb=11934.6, bsz=405.2, num_updates=28300, lr=1.50382e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-21 23:58:49 | INFO | train_inner | epoch 011:   2087 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.425, loss=4.013, nll_loss=1.741, ppl=3.34, wps=22571.4, ups=1.92, wpb=11764.2, bsz=411.8, num_updates=28400, lr=1.50117e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-21 23:59:41 | INFO | train_inner | epoch 011:   2187 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.408, loss=3.984, nll_loss=1.716, ppl=3.28, wps=22779.8, ups=1.92, wpb=11845, bsz=419.8, num_updates=28500, lr=1.49854e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 00:00:33 | INFO | train_inner | epoch 011:   2287 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.418, loss=4.001, nll_loss=1.732, ppl=3.32, wps=22735.6, ups=1.92, wpb=11855.7, bsz=403, num_updates=28600, lr=1.49592e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 00:01:25 | INFO | train_inner | epoch 011:   2387 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.368, loss=3.995, nll_loss=1.728, ppl=3.31, wps=22822.2, ups=1.92, wpb=11866.7, bsz=431.8, num_updates=28700, lr=1.49331e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 00:02:17 | INFO | train_inner | epoch 011:   2487 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.409, loss=3.979, nll_loss=1.714, ppl=3.28, wps=22818.8, ups=1.93, wpb=11821.7, bsz=427.3, num_updates=28800, lr=1.49071e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 00:03:09 | INFO | train_inner | epoch 011:   2587 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.403, loss=3.981, nll_loss=1.715, ppl=3.28, wps=22909.8, ups=1.93, wpb=11876.3, bsz=416.9, num_updates=28900, lr=1.48813e-05, gnorm=1.096, train_wall=52, wall=0
2020-12-22 00:04:01 | INFO | train_inner | epoch 011:   2687 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.402, loss=4.009, nll_loss=1.743, ppl=3.35, wps=22866.2, ups=1.92, wpb=11928.8, bsz=408.2, num_updates=29000, lr=1.48556e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 00:04:53 | INFO | train_inner | epoch 011:   2787 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.411, loss=4.006, nll_loss=1.736, ppl=3.33, wps=22719.3, ups=1.92, wpb=11815.5, bsz=420.6, num_updates=29100, lr=1.48301e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 00:05:45 | INFO | train_inner | epoch 011:   2887 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.412, loss=3.999, nll_loss=1.729, ppl=3.32, wps=22710.4, ups=1.92, wpb=11814.6, bsz=408.3, num_updates=29200, lr=1.48047e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-22 00:06:37 | INFO | train_inner | epoch 011:   2987 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.4, loss=3.976, nll_loss=1.713, ppl=3.28, wps=22958.8, ups=1.93, wpb=11889.7, bsz=418.3, num_updates=29300, lr=1.47794e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 00:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 00:07:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 00:07:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 00:07:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 00:07:30 | INFO | valid | epoch 011 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.91 | nll_loss 7.877 | ppl 235.13 | bleu 16.34 | wps 4894.6 | wpb 6344.2 | bsz 166.4 | num_updates 29372 | best_bleu 16.45
2020-12-22 00:07:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 00:07:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 11 @ 29372 updates, score 16.34) (writing took 4.775627702474594 seconds)
2020-12-22 00:07:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-12-22 00:07:35 | INFO | train | epoch 011 | symm_kl 0.415 | self_kl 0 | self_cv 9.409 | loss 3.995 | nll_loss 1.724 | ppl 3.3 | wps 22362.1 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 29372 | lr 1.47613e-05 | gnorm 1.107 | train_wall 1586 | wall 0
2020-12-22 00:07:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:38 | INFO | fairseq.trainer | begin training epoch 12
2020-12-22 00:07:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:07:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:07:59 | INFO | train_inner | epoch 012:     28 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.404, loss=4.022, nll_loss=1.751, ppl=3.37, wps=14360.5, ups=1.22, wpb=11764.6, bsz=410.2, num_updates=29400, lr=1.47542e-05, gnorm=1.125, train_wall=51, wall=0
2020-12-22 00:08:50 | INFO | train_inner | epoch 012:    128 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.433, loss=3.994, nll_loss=1.724, ppl=3.3, wps=22949, ups=1.95, wpb=11797.2, bsz=409.1, num_updates=29500, lr=1.47292e-05, gnorm=1.115, train_wall=51, wall=0
2020-12-22 00:09:43 | INFO | train_inner | epoch 012:    228 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.408, loss=3.981, nll_loss=1.715, ppl=3.28, wps=22729.1, ups=1.92, wpb=11842.5, bsz=425.9, num_updates=29600, lr=1.47043e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-22 00:10:35 | INFO | train_inner | epoch 012:    328 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.38, loss=3.997, nll_loss=1.728, ppl=3.31, wps=22839.5, ups=1.92, wpb=11916.5, bsz=423.9, num_updates=29700, lr=1.46795e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 00:11:27 | INFO | train_inner | epoch 012:    428 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.407, loss=3.971, nll_loss=1.703, ppl=3.26, wps=22811.6, ups=1.91, wpb=11932, bsz=397.7, num_updates=29800, lr=1.46549e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-22 00:12:19 | INFO | train_inner | epoch 012:    528 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.394, loss=3.974, nll_loss=1.709, ppl=3.27, wps=22759.2, ups=1.91, wpb=11895.2, bsz=409, num_updates=29900, lr=1.46303e-05, gnorm=1.093, train_wall=52, wall=0
2020-12-22 00:13:11 | INFO | train_inner | epoch 012:    628 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.435, loss=3.98, nll_loss=1.715, ppl=3.28, wps=22907.1, ups=1.93, wpb=11894.3, bsz=420.1, num_updates=30000, lr=1.46059e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-22 00:14:04 | INFO | train_inner | epoch 012:    728 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.409, loss=3.969, nll_loss=1.706, ppl=3.26, wps=22649.6, ups=1.91, wpb=11874.9, bsz=428, num_updates=30100, lr=1.45817e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 00:14:56 | INFO | train_inner | epoch 012:    828 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.436, loss=3.979, nll_loss=1.71, ppl=3.27, wps=22809.1, ups=1.91, wpb=11917.2, bsz=419.9, num_updates=30200, lr=1.45575e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 00:15:48 | INFO | train_inner | epoch 012:    928 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.414, loss=3.998, nll_loss=1.729, ppl=3.31, wps=22723.6, ups=1.92, wpb=11854.9, bsz=396, num_updates=30300, lr=1.45334e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 00:16:40 | INFO | train_inner | epoch 012:   1028 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.387, loss=3.995, nll_loss=1.731, ppl=3.32, wps=22667.7, ups=1.92, wpb=11814.9, bsz=436.2, num_updates=30400, lr=1.45095e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 00:17:32 | INFO | train_inner | epoch 012:   1128 / 3059 symm_kl=0.417, self_kl=0, self_cv=9.406, loss=4.014, nll_loss=1.742, ppl=3.34, wps=22821.2, ups=1.93, wpb=11823.2, bsz=368.8, num_updates=30500, lr=1.44857e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 00:18:24 | INFO | train_inner | epoch 012:   1228 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.397, loss=3.977, nll_loss=1.714, ppl=3.28, wps=22957.2, ups=1.92, wpb=11931.7, bsz=425.5, num_updates=30600, lr=1.4462e-05, gnorm=1.09, train_wall=52, wall=0
2020-12-22 00:19:16 | INFO | train_inner | epoch 012:   1328 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.429, loss=3.963, nll_loss=1.7, ppl=3.25, wps=22598.9, ups=1.92, wpb=11781.1, bsz=444.1, num_updates=30700, lr=1.44385e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 00:20:08 | INFO | train_inner | epoch 012:   1428 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.411, loss=4, nll_loss=1.732, ppl=3.32, wps=22740.3, ups=1.93, wpb=11798.2, bsz=415, num_updates=30800, lr=1.4415e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 00:21:00 | INFO | train_inner | epoch 012:   1528 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.384, loss=3.989, nll_loss=1.724, ppl=3.3, wps=22851.1, ups=1.93, wpb=11851.8, bsz=410.7, num_updates=30900, lr=1.43917e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 00:21:52 | INFO | train_inner | epoch 012:   1628 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.416, loss=3.98, nll_loss=1.713, ppl=3.28, wps=22917.6, ups=1.93, wpb=11883.9, bsz=403.1, num_updates=31000, lr=1.43684e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 00:22:44 | INFO | train_inner | epoch 012:   1728 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.373, loss=4.014, nll_loss=1.746, ppl=3.35, wps=22796.2, ups=1.92, wpb=11866.1, bsz=400.2, num_updates=31100, lr=1.43453e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 00:23:36 | INFO | train_inner | epoch 012:   1828 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.393, loss=3.995, nll_loss=1.728, ppl=3.31, wps=22713.8, ups=1.92, wpb=11825.3, bsz=412.6, num_updates=31200, lr=1.43223e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 00:24:28 | INFO | train_inner | epoch 012:   1928 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.419, loss=3.988, nll_loss=1.72, ppl=3.3, wps=22828.9, ups=1.93, wpb=11846, bsz=391.4, num_updates=31300, lr=1.42994e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 00:25:20 | INFO | train_inner | epoch 012:   2028 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.416, loss=3.989, nll_loss=1.728, ppl=3.31, wps=22715.8, ups=1.91, wpb=11908.8, bsz=411.8, num_updates=31400, lr=1.42766e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:26:12 | INFO | train_inner | epoch 012:   2128 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.375, loss=3.988, nll_loss=1.726, ppl=3.31, wps=22739.8, ups=1.92, wpb=11860.6, bsz=422.2, num_updates=31500, lr=1.42539e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:27:05 | INFO | train_inner | epoch 012:   2228 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.434, loss=3.986, nll_loss=1.721, ppl=3.3, wps=22654.6, ups=1.91, wpb=11842.7, bsz=395.7, num_updates=31600, lr=1.42314e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 00:27:57 | INFO | train_inner | epoch 012:   2328 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.4, loss=3.997, nll_loss=1.729, ppl=3.31, wps=22893.8, ups=1.92, wpb=11911.2, bsz=394.4, num_updates=31700, lr=1.42089e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 00:28:49 | INFO | train_inner | epoch 012:   2428 / 3059 symm_kl=0.413, self_kl=0, self_cv=9.388, loss=3.998, nll_loss=1.732, ppl=3.32, wps=22785.9, ups=1.92, wpb=11840.4, bsz=395, num_updates=31800, lr=1.41865e-05, gnorm=1.123, train_wall=52, wall=0
2020-12-22 00:29:41 | INFO | train_inner | epoch 012:   2528 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.389, loss=3.944, nll_loss=1.688, ppl=3.22, wps=22704.8, ups=1.91, wpb=11878.3, bsz=441, num_updates=31900, lr=1.41643e-05, gnorm=1.091, train_wall=52, wall=0
2020-12-22 00:30:33 | INFO | train_inner | epoch 012:   2628 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.383, loss=4.014, nll_loss=1.747, ppl=3.36, wps=22831, ups=1.93, wpb=11808.5, bsz=396.8, num_updates=32000, lr=1.41421e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 00:31:25 | INFO | train_inner | epoch 012:   2728 / 3059 symm_kl=0.415, self_kl=0, self_cv=9.405, loss=4.01, nll_loss=1.741, ppl=3.34, wps=22785.4, ups=1.92, wpb=11848.3, bsz=376.6, num_updates=32100, lr=1.41201e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 00:32:17 | INFO | train_inner | epoch 012:   2828 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.392, loss=4.004, nll_loss=1.736, ppl=3.33, wps=22651.6, ups=1.92, wpb=11770.9, bsz=429.8, num_updates=32200, lr=1.40981e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 00:33:08 | INFO | train_inner | epoch 012:   2928 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.431, loss=4.008, nll_loss=1.742, ppl=3.34, wps=22665.4, ups=1.93, wpb=11758.2, bsz=390.3, num_updates=32300, lr=1.40763e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-22 00:34:01 | INFO | train_inner | epoch 012:   3028 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.416, loss=4.007, nll_loss=1.74, ppl=3.34, wps=22597.6, ups=1.91, wpb=11829.4, bsz=402.6, num_updates=32400, lr=1.40546e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 00:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 00:34:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 00:34:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 00:34:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 00:34:34 | INFO | valid | epoch 012 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.913 | nll_loss 7.881 | ppl 235.76 | bleu 16.37 | wps 4446.5 | wpb 6344.2 | bsz 166.4 | num_updates 32431 | best_bleu 16.45
2020-12-22 00:34:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 00:34:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 12 @ 32431 updates, score 16.37) (writing took 4.779367228969932 seconds)
2020-12-22 00:34:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-12-22 00:34:39 | INFO | train | epoch 012 | symm_kl 0.412 | self_kl 0 | self_cv 9.405 | loss 3.991 | nll_loss 1.724 | ppl 3.3 | wps 22324.8 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 32431 | lr 1.40478e-05 | gnorm 1.106 | train_wall 1587 | wall 0
2020-12-22 00:34:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:42 | INFO | fairseq.trainer | begin training epoch 13
2020-12-22 00:34:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:34:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 00:34:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 00:35:24 | INFO | train_inner | epoch 013:     69 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.369, loss=3.966, nll_loss=1.705, ppl=3.26, wps=14372.1, ups=1.2, wpb=11997.5, bsz=445.2, num_updates=32500, lr=1.40329e-05, gnorm=1.09, train_wall=52, wall=0
2020-12-22 00:36:16 | INFO | train_inner | epoch 013:    169 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.429, loss=3.977, nll_loss=1.714, ppl=3.28, wps=23051.9, ups=1.94, wpb=11862.5, bsz=388.2, num_updates=32600, lr=1.40114e-05, gnorm=1.105, train_wall=51, wall=0
2020-12-22 00:37:08 | INFO | train_inner | epoch 013:    269 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.399, loss=3.977, nll_loss=1.714, ppl=3.28, wps=22741.5, ups=1.92, wpb=11821.1, bsz=427, num_updates=32700, lr=1.39899e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 00:38:00 | INFO | train_inner | epoch 013:    369 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.387, loss=3.988, nll_loss=1.72, ppl=3.3, wps=22708.2, ups=1.92, wpb=11802.2, bsz=400.2, num_updates=32800, lr=1.39686e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 00:38:52 | INFO | train_inner | epoch 013:    469 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.409, loss=3.963, nll_loss=1.704, ppl=3.26, wps=22707.5, ups=1.93, wpb=11779.2, bsz=432.2, num_updates=32900, lr=1.39474e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 00:39:43 | INFO | train_inner | epoch 013:    569 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.431, loss=3.978, nll_loss=1.714, ppl=3.28, wps=22914.9, ups=1.93, wpb=11879.8, bsz=407.8, num_updates=33000, lr=1.39262e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 00:40:35 | INFO | train_inner | epoch 013:    669 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.463, loss=4.003, nll_loss=1.734, ppl=3.33, wps=22622.6, ups=1.92, wpb=11781.8, bsz=389.5, num_updates=33100, lr=1.39052e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 00:41:28 | INFO | train_inner | epoch 013:    769 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.424, loss=3.99, nll_loss=1.726, ppl=3.31, wps=22972.1, ups=1.92, wpb=11958.1, bsz=412.2, num_updates=33200, lr=1.38842e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 00:42:20 | INFO | train_inner | epoch 013:    869 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.38, loss=3.959, nll_loss=1.702, ppl=3.25, wps=22995, ups=1.92, wpb=11967.6, bsz=438.4, num_updates=33300, lr=1.38633e-05, gnorm=1.086, train_wall=52, wall=0
2020-12-22 00:43:12 | INFO | train_inner | epoch 013:    969 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.39, loss=3.999, nll_loss=1.734, ppl=3.33, wps=22636.4, ups=1.93, wpb=11758.8, bsz=409.3, num_updates=33400, lr=1.38426e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 00:44:04 | INFO | train_inner | epoch 013:   1069 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.42, loss=4.006, nll_loss=1.742, ppl=3.34, wps=22448.8, ups=1.92, wpb=11708.7, bsz=407.1, num_updates=33500, lr=1.38219e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 00:44:56 | INFO | train_inner | epoch 013:   1169 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.395, loss=3.987, nll_loss=1.724, ppl=3.3, wps=22928.9, ups=1.92, wpb=11931.1, bsz=427.2, num_updates=33600, lr=1.38013e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 00:45:48 | INFO | train_inner | epoch 013:   1269 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.412, loss=3.983, nll_loss=1.72, ppl=3.29, wps=22832.9, ups=1.93, wpb=11839.2, bsz=409, num_updates=33700, lr=1.37808e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:46:39 | INFO | train_inner | epoch 013:   1369 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.407, loss=4.008, nll_loss=1.741, ppl=3.34, wps=22657.8, ups=1.93, wpb=11753.4, bsz=394.4, num_updates=33800, lr=1.37604e-05, gnorm=1.123, train_wall=52, wall=0
2020-12-22 00:47:31 | INFO | train_inner | epoch 013:   1469 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.415, loss=3.986, nll_loss=1.723, ppl=3.3, wps=22979.7, ups=1.93, wpb=11908.1, bsz=383.9, num_updates=33900, lr=1.37401e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:48:24 | INFO | train_inner | epoch 013:   1569 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.429, loss=3.994, nll_loss=1.728, ppl=3.31, wps=22643.3, ups=1.91, wpb=11873.5, bsz=401.2, num_updates=34000, lr=1.37199e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 00:49:16 | INFO | train_inner | epoch 013:   1669 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.389, loss=3.975, nll_loss=1.713, ppl=3.28, wps=22782.9, ups=1.92, wpb=11855.8, bsz=411, num_updates=34100, lr=1.36998e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 00:50:08 | INFO | train_inner | epoch 013:   1769 / 3059 symm_kl=0.414, self_kl=0, self_cv=9.406, loss=4.006, nll_loss=1.739, ppl=3.34, wps=22769.1, ups=1.92, wpb=11840.7, bsz=401.9, num_updates=34200, lr=1.36797e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-22 00:51:00 | INFO | train_inner | epoch 013:   1869 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.401, loss=3.985, nll_loss=1.722, ppl=3.3, wps=22733.2, ups=1.92, wpb=11816.7, bsz=416.6, num_updates=34300, lr=1.36598e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 00:51:52 | INFO | train_inner | epoch 013:   1969 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.394, loss=4, nll_loss=1.739, ppl=3.34, wps=22915.7, ups=1.93, wpb=11900.6, bsz=403.6, num_updates=34400, lr=1.36399e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 00:52:43 | INFO | train_inner | epoch 013:   2069 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.441, loss=3.978, nll_loss=1.713, ppl=3.28, wps=22785.2, ups=1.93, wpb=11813.4, bsz=374.8, num_updates=34500, lr=1.36201e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 00:53:36 | INFO | train_inner | epoch 013:   2169 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.362, loss=3.993, nll_loss=1.731, ppl=3.32, wps=22714.5, ups=1.92, wpb=11839.6, bsz=419.8, num_updates=34600, lr=1.36004e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-22 00:54:28 | INFO | train_inner | epoch 013:   2269 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.408, loss=3.957, nll_loss=1.7, ppl=3.25, wps=22756.9, ups=1.91, wpb=11925.6, bsz=435.8, num_updates=34700, lr=1.35808e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-22 00:55:20 | INFO | train_inner | epoch 013:   2369 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.374, loss=4.009, nll_loss=1.746, ppl=3.36, wps=22873.6, ups=1.92, wpb=11887.8, bsz=401.6, num_updates=34800, lr=1.35613e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 00:56:12 | INFO | train_inner | epoch 013:   2469 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.423, loss=3.983, nll_loss=1.724, ppl=3.3, wps=22690.4, ups=1.91, wpb=11891.8, bsz=391.8, num_updates=34900, lr=1.35418e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:57:05 | INFO | train_inner | epoch 013:   2569 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.392, loss=3.991, nll_loss=1.73, ppl=3.32, wps=22761.9, ups=1.91, wpb=11888.2, bsz=395.6, num_updates=35000, lr=1.35225e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 00:57:57 | INFO | train_inner | epoch 013:   2669 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.408, loss=4.013, nll_loss=1.753, ppl=3.37, wps=22636.5, ups=1.92, wpb=11768.6, bsz=407.4, num_updates=35100, lr=1.35032e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 00:58:48 | INFO | train_inner | epoch 013:   2769 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.436, loss=3.98, nll_loss=1.723, ppl=3.3, wps=22928.3, ups=1.93, wpb=11862.7, bsz=420.1, num_updates=35200, lr=1.3484e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 00:59:40 | INFO | train_inner | epoch 013:   2869 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.38, loss=4.001, nll_loss=1.739, ppl=3.34, wps=22747.5, ups=1.92, wpb=11821, bsz=406.4, num_updates=35300, lr=1.34649e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 01:00:32 | INFO | train_inner | epoch 013:   2969 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.392, loss=3.989, nll_loss=1.73, ppl=3.32, wps=22787.1, ups=1.92, wpb=11841.2, bsz=414.7, num_updates=35400, lr=1.34459e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 01:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 01:01:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 01:01:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 01:01:35 | INFO | valid | epoch 013 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.9 | nll_loss 7.866 | ppl 233.3 | bleu 16.45 | wps 4939.3 | wpb 6344.2 | bsz 166.4 | num_updates 35490 | best_bleu 16.45
2020-12-22 01:01:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 01:01:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 13 @ 35490 updates, score 16.45) (writing took 7.814308036118746 seconds)
2020-12-22 01:01:43 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-12-22 01:01:43 | INFO | train | epoch 013 | symm_kl 0.409 | self_kl 0 | self_cv 9.405 | loss 3.987 | nll_loss 1.724 | ppl 3.3 | wps 22329.2 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 35490 | lr 1.34288e-05 | gnorm 1.108 | train_wall 1585 | wall 0
2020-12-22 01:01:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:46 | INFO | fairseq.trainer | begin training epoch 14
2020-12-22 01:01:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:01:57 | INFO | train_inner | epoch 014:     10 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.373, loss=3.972, nll_loss=1.717, ppl=3.29, wps=13893.2, ups=1.17, wpb=11835.1, bsz=430.2, num_updates=35500, lr=1.34269e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-22 01:02:49 | INFO | train_inner | epoch 014:    110 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.419, loss=3.985, nll_loss=1.722, ppl=3.3, wps=22954.7, ups=1.94, wpb=11804.8, bsz=411, num_updates=35600, lr=1.3408e-05, gnorm=1.129, train_wall=51, wall=0
2020-12-22 01:03:41 | INFO | train_inner | epoch 014:    210 / 3059 symm_kl=0.412, self_kl=0, self_cv=9.407, loss=3.999, nll_loss=1.734, ppl=3.33, wps=22655.1, ups=1.92, wpb=11774.1, bsz=395.7, num_updates=35700, lr=1.33892e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 01:04:33 | INFO | train_inner | epoch 014:    310 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.385, loss=3.988, nll_loss=1.726, ppl=3.31, wps=22714.3, ups=1.92, wpb=11812.6, bsz=393.5, num_updates=35800, lr=1.33705e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 01:05:25 | INFO | train_inner | epoch 014:    410 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.428, loss=3.95, nll_loss=1.692, ppl=3.23, wps=22938.6, ups=1.93, wpb=11912.7, bsz=407.1, num_updates=35900, lr=1.33519e-05, gnorm=1.094, train_wall=52, wall=0
2020-12-22 01:06:17 | INFO | train_inner | epoch 014:    510 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.432, loss=3.972, nll_loss=1.713, ppl=3.28, wps=22929.9, ups=1.92, wpb=11913.6, bsz=399.1, num_updates=36000, lr=1.33333e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:07:09 | INFO | train_inner | epoch 014:    610 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.456, loss=3.974, nll_loss=1.712, ppl=3.28, wps=22724.5, ups=1.92, wpb=11857, bsz=415.4, num_updates=36100, lr=1.33149e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 01:08:01 | INFO | train_inner | epoch 014:    710 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.403, loss=3.966, nll_loss=1.709, ppl=3.27, wps=22798.1, ups=1.92, wpb=11865, bsz=455.6, num_updates=36200, lr=1.32964e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 01:08:53 | INFO | train_inner | epoch 014:    810 / 3059 symm_kl=0.411, self_kl=0, self_cv=9.41, loss=4.002, nll_loss=1.738, ppl=3.34, wps=22934.6, ups=1.92, wpb=11949.4, bsz=406.6, num_updates=36300, lr=1.32781e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 01:09:45 | INFO | train_inner | epoch 014:    910 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.442, loss=3.982, nll_loss=1.723, ppl=3.3, wps=22862.9, ups=1.92, wpb=11906.6, bsz=399.4, num_updates=36400, lr=1.32599e-05, gnorm=1.096, train_wall=52, wall=0
2020-12-22 01:10:37 | INFO | train_inner | epoch 014:   1010 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.421, loss=3.967, nll_loss=1.705, ppl=3.26, wps=22772.3, ups=1.92, wpb=11882.2, bsz=391.2, num_updates=36500, lr=1.32417e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 01:11:29 | INFO | train_inner | epoch 014:   1110 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.378, loss=3.976, nll_loss=1.72, ppl=3.29, wps=22987.9, ups=1.93, wpb=11930.6, bsz=412.6, num_updates=36600, lr=1.32236e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-22 01:12:21 | INFO | train_inner | epoch 014:   1210 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.406, loss=3.986, nll_loss=1.725, ppl=3.31, wps=22745.3, ups=1.93, wpb=11805.9, bsz=387, num_updates=36700, lr=1.32056e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 01:13:13 | INFO | train_inner | epoch 014:   1310 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.36, loss=3.987, nll_loss=1.731, ppl=3.32, wps=22808.9, ups=1.93, wpb=11820.8, bsz=411, num_updates=36800, lr=1.31876e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:14:05 | INFO | train_inner | epoch 014:   1410 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.387, loss=3.967, nll_loss=1.712, ppl=3.28, wps=22773.8, ups=1.92, wpb=11849.2, bsz=437.8, num_updates=36900, lr=1.31697e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:14:57 | INFO | train_inner | epoch 014:   1510 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.392, loss=3.997, nll_loss=1.737, ppl=3.33, wps=22766.2, ups=1.94, wpb=11754.4, bsz=408.9, num_updates=37000, lr=1.31519e-05, gnorm=1.122, train_wall=51, wall=0
2020-12-22 01:15:48 | INFO | train_inner | epoch 014:   1610 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.42, loss=3.99, nll_loss=1.728, ppl=3.31, wps=22815.3, ups=1.93, wpb=11796.6, bsz=408.2, num_updates=37100, lr=1.31342e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 01:16:40 | INFO | train_inner | epoch 014:   1710 / 3059 symm_kl=0.41, self_kl=0, self_cv=9.374, loss=4.002, nll_loss=1.74, ppl=3.34, wps=22815.4, ups=1.92, wpb=11865.6, bsz=404.5, num_updates=37200, lr=1.31165e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:17:32 | INFO | train_inner | epoch 014:   1810 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.37, loss=3.997, nll_loss=1.742, ppl=3.35, wps=22805.2, ups=1.94, wpb=11782.4, bsz=435.1, num_updates=37300, lr=1.30989e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 01:18:24 | INFO | train_inner | epoch 014:   1910 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.387, loss=3.972, nll_loss=1.718, ppl=3.29, wps=22925.3, ups=1.93, wpb=11889.6, bsz=407.4, num_updates=37400, lr=1.30814e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 01:19:16 | INFO | train_inner | epoch 014:   2010 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.407, loss=3.989, nll_loss=1.73, ppl=3.32, wps=22727.3, ups=1.92, wpb=11808.1, bsz=404.6, num_updates=37500, lr=1.30639e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 01:20:08 | INFO | train_inner | epoch 014:   2110 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.41, loss=3.989, nll_loss=1.73, ppl=3.32, wps=22701.5, ups=1.92, wpb=11802.7, bsz=407.3, num_updates=37600, lr=1.30466e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 01:21:00 | INFO | train_inner | epoch 014:   2210 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.37, loss=3.989, nll_loss=1.732, ppl=3.32, wps=22830.3, ups=1.91, wpb=11942.9, bsz=421.1, num_updates=37700, lr=1.30292e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 01:21:52 | INFO | train_inner | epoch 014:   2310 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.374, loss=3.986, nll_loss=1.729, ppl=3.31, wps=22792.9, ups=1.92, wpb=11896.5, bsz=413.1, num_updates=37800, lr=1.3012e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:22:44 | INFO | train_inner | epoch 014:   2410 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.408, loss=3.987, nll_loss=1.728, ppl=3.31, wps=22751.8, ups=1.92, wpb=11824.4, bsz=409.7, num_updates=37900, lr=1.29948e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 01:23:36 | INFO | train_inner | epoch 014:   2510 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.368, loss=3.994, nll_loss=1.735, ppl=3.33, wps=22965.8, ups=1.93, wpb=11876.2, bsz=396.6, num_updates=38000, lr=1.29777e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 01:24:28 | INFO | train_inner | epoch 014:   2610 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.426, loss=3.987, nll_loss=1.728, ppl=3.31, wps=22918.5, ups=1.92, wpb=11916.8, bsz=376.8, num_updates=38100, lr=1.29607e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 01:25:20 | INFO | train_inner | epoch 014:   2710 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.388, loss=3.972, nll_loss=1.715, ppl=3.28, wps=22896.8, ups=1.93, wpb=11879.4, bsz=406.4, num_updates=38200, lr=1.29437e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:26:11 | INFO | train_inner | epoch 014:   2810 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.402, loss=3.973, nll_loss=1.719, ppl=3.29, wps=22962.6, ups=1.94, wpb=11843.7, bsz=430.4, num_updates=38300, lr=1.29268e-05, gnorm=1.105, train_wall=51, wall=0
2020-12-22 01:27:04 | INFO | train_inner | epoch 014:   2910 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.401, loss=3.987, nll_loss=1.731, ppl=3.32, wps=22706.4, ups=1.92, wpb=11837.9, bsz=422.1, num_updates=38400, lr=1.29099e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 01:27:56 | INFO | train_inner | epoch 014:   3010 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.405, loss=3.989, nll_loss=1.73, ppl=3.32, wps=22569.6, ups=1.91, wpb=11811.5, bsz=416.9, num_updates=38500, lr=1.28932e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 01:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 01:28:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 01:28:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 01:28:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 01:28:38 | INFO | valid | epoch 014 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.901 | nll_loss 7.868 | ppl 233.6 | bleu 16.48 | wps 4546.3 | wpb 6344.2 | bsz 166.4 | num_updates 38549 | best_bleu 16.48
2020-12-22 01:28:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 01:28:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 14 @ 38549 updates, score 16.48) (writing took 7.9765145517885685 seconds)
2020-12-22 01:28:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-12-22 01:28:46 | INFO | train | epoch 014 | symm_kl 0.407 | self_kl 0 | self_cv 9.401 | loss 3.983 | nll_loss 1.725 | ppl 3.31 | wps 22330.3 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 38549 | lr 1.2885e-05 | gnorm 1.108 | train_wall 1584 | wall 0
2020-12-22 01:28:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:28:50 | INFO | fairseq.trainer | begin training epoch 15
2020-12-22 01:28:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:28:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:29:22 | INFO | train_inner | epoch 015:     51 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.408, loss=3.977, nll_loss=1.719, ppl=3.29, wps=13792.2, ups=1.16, wpb=11862.4, bsz=392, num_updates=38600, lr=1.28765e-05, gnorm=1.106, train_wall=51, wall=0
2020-12-22 01:30:14 | INFO | train_inner | epoch 015:    151 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.399, loss=3.971, nll_loss=1.716, ppl=3.28, wps=22837.6, ups=1.93, wpb=11858, bsz=437.4, num_updates=38700, lr=1.28598e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 01:31:06 | INFO | train_inner | epoch 015:    251 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.411, loss=3.974, nll_loss=1.717, ppl=3.29, wps=22755, ups=1.92, wpb=11837, bsz=414.5, num_updates=38800, lr=1.28432e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 01:31:58 | INFO | train_inner | epoch 015:    351 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.401, loss=3.978, nll_loss=1.719, ppl=3.29, wps=22916.1, ups=1.93, wpb=11902.5, bsz=395.4, num_updates=38900, lr=1.28267e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:32:50 | INFO | train_inner | epoch 015:    451 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.423, loss=3.986, nll_loss=1.726, ppl=3.31, wps=22645.3, ups=1.91, wpb=11848.3, bsz=402.8, num_updates=39000, lr=1.28103e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 01:33:42 | INFO | train_inner | epoch 015:    551 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.387, loss=3.982, nll_loss=1.723, ppl=3.3, wps=22937.9, ups=1.92, wpb=11973, bsz=404.3, num_updates=39100, lr=1.27939e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 01:34:34 | INFO | train_inner | epoch 015:    651 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.375, loss=3.985, nll_loss=1.731, ppl=3.32, wps=22831.4, ups=1.92, wpb=11862.7, bsz=416.4, num_updates=39200, lr=1.27775e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:35:26 | INFO | train_inner | epoch 015:    751 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.383, loss=3.992, nll_loss=1.731, ppl=3.32, wps=22651.1, ups=1.94, wpb=11704.4, bsz=388.4, num_updates=39300, lr=1.27613e-05, gnorm=1.125, train_wall=52, wall=0
2020-12-22 01:36:18 | INFO | train_inner | epoch 015:    851 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.408, loss=3.977, nll_loss=1.721, ppl=3.3, wps=22667.1, ups=1.92, wpb=11832.7, bsz=418.7, num_updates=39400, lr=1.27451e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 01:37:10 | INFO | train_inner | epoch 015:    951 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.396, loss=3.974, nll_loss=1.717, ppl=3.29, wps=22732.2, ups=1.93, wpb=11803.4, bsz=419.6, num_updates=39500, lr=1.27289e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 01:38:02 | INFO | train_inner | epoch 015:   1051 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.404, loss=3.974, nll_loss=1.718, ppl=3.29, wps=22876.1, ups=1.92, wpb=11884.4, bsz=405.5, num_updates=39600, lr=1.27128e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 01:38:54 | INFO | train_inner | epoch 015:   1151 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.423, loss=3.955, nll_loss=1.698, ppl=3.24, wps=23006.8, ups=1.93, wpb=11945.2, bsz=392.4, num_updates=39700, lr=1.26968e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 01:39:46 | INFO | train_inner | epoch 015:   1251 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.364, loss=3.98, nll_loss=1.728, ppl=3.31, wps=22678, ups=1.92, wpb=11841.6, bsz=423, num_updates=39800, lr=1.26809e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 01:40:38 | INFO | train_inner | epoch 015:   1351 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.414, loss=3.972, nll_loss=1.719, ppl=3.29, wps=22796.1, ups=1.93, wpb=11826, bsz=409.8, num_updates=39900, lr=1.2665e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 01:41:30 | INFO | train_inner | epoch 015:   1451 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.415, loss=3.974, nll_loss=1.719, ppl=3.29, wps=22811.2, ups=1.92, wpb=11854, bsz=421.6, num_updates=40000, lr=1.26491e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 01:42:22 | INFO | train_inner | epoch 015:   1551 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.396, loss=3.967, nll_loss=1.716, ppl=3.28, wps=22847.3, ups=1.92, wpb=11870.8, bsz=400.8, num_updates=40100, lr=1.26333e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-22 01:43:14 | INFO | train_inner | epoch 015:   1651 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.375, loss=3.976, nll_loss=1.722, ppl=3.3, wps=22992.1, ups=1.93, wpb=11908.5, bsz=419.8, num_updates=40200, lr=1.26176e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:44:06 | INFO | train_inner | epoch 015:   1751 / 3059 symm_kl=0.409, self_kl=0, self_cv=9.425, loss=3.998, nll_loss=1.739, ppl=3.34, wps=22603.6, ups=1.93, wpb=11698.9, bsz=397, num_updates=40300, lr=1.26019e-05, gnorm=1.132, train_wall=52, wall=0
2020-12-22 01:44:58 | INFO | train_inner | epoch 015:   1851 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.392, loss=3.996, nll_loss=1.737, ppl=3.33, wps=22847, ups=1.92, wpb=11887.6, bsz=378.4, num_updates=40400, lr=1.25863e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 01:45:49 | INFO | train_inner | epoch 015:   1951 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.371, loss=3.988, nll_loss=1.736, ppl=3.33, wps=22861.8, ups=1.93, wpb=11849.7, bsz=398.3, num_updates=40500, lr=1.25708e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 01:46:41 | INFO | train_inner | epoch 015:   2051 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.414, loss=3.973, nll_loss=1.72, ppl=3.29, wps=22885, ups=1.93, wpb=11876.5, bsz=402.4, num_updates=40600, lr=1.25553e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 01:47:33 | INFO | train_inner | epoch 015:   2151 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.399, loss=3.978, nll_loss=1.723, ppl=3.3, wps=22957.2, ups=1.93, wpb=11879.6, bsz=413.7, num_updates=40700, lr=1.25399e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 01:48:25 | INFO | train_inner | epoch 015:   2251 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.393, loss=3.993, nll_loss=1.742, ppl=3.35, wps=22810.7, ups=1.93, wpb=11812.1, bsz=415.1, num_updates=40800, lr=1.25245e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:49:17 | INFO | train_inner | epoch 015:   2351 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.393, loss=3.938, nll_loss=1.692, ppl=3.23, wps=23038.2, ups=1.92, wpb=11989.8, bsz=455.1, num_updates=40900, lr=1.25092e-05, gnorm=1.083, train_wall=52, wall=0
2020-12-22 01:50:09 | INFO | train_inner | epoch 015:   2451 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.407, loss=4.009, nll_loss=1.753, ppl=3.37, wps=22649.4, ups=1.93, wpb=11736.3, bsz=414.3, num_updates=41000, lr=1.24939e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-22 01:51:01 | INFO | train_inner | epoch 015:   2551 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.403, loss=3.991, nll_loss=1.737, ppl=3.33, wps=22610.4, ups=1.92, wpb=11759.9, bsz=399.9, num_updates=41100, lr=1.24787e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 01:51:53 | INFO | train_inner | epoch 015:   2651 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.368, loss=3.996, nll_loss=1.74, ppl=3.34, wps=22690.7, ups=1.92, wpb=11847.7, bsz=409.4, num_updates=41200, lr=1.24635e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 01:52:45 | INFO | train_inner | epoch 015:   2751 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.408, loss=4, nll_loss=1.743, ppl=3.35, wps=22753.8, ups=1.92, wpb=11827.9, bsz=407.5, num_updates=41300, lr=1.24484e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 01:53:37 | INFO | train_inner | epoch 015:   2851 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.422, loss=3.979, nll_loss=1.727, ppl=3.31, wps=22852.9, ups=1.92, wpb=11896.6, bsz=406.6, num_updates=41400, lr=1.24334e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 01:54:29 | INFO | train_inner | epoch 015:   2951 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.407, loss=3.98, nll_loss=1.725, ppl=3.31, wps=22731.8, ups=1.93, wpb=11798.5, bsz=395.8, num_updates=41500, lr=1.24184e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 01:55:21 | INFO | train_inner | epoch 015:   3051 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.414, loss=3.961, nll_loss=1.71, ppl=3.27, wps=22904.6, ups=1.92, wpb=11902.5, bsz=425.7, num_updates=41600, lr=1.24035e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 01:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 01:55:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 01:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 01:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 01:55:42 | INFO | valid | epoch 015 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.892 | nll_loss 7.856 | ppl 231.66 | bleu 16.44 | wps 4380.8 | wpb 6344.2 | bsz 166.4 | num_updates 41608 | best_bleu 16.48
2020-12-22 01:55:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 01:55:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 15 @ 41608 updates, score 16.44) (writing took 4.738496620208025 seconds)
2020-12-22 01:55:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-12-22 01:55:47 | INFO | train | epoch 015 | symm_kl 0.405 | self_kl 0 | self_cv 9.4 | loss 3.98 | nll_loss 1.724 | ppl 3.3 | wps 22370 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 41608 | lr 1.24023e-05 | gnorm 1.11 | train_wall 1584 | wall 0
2020-12-22 01:55:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:51 | INFO | fairseq.trainer | begin training epoch 16
2020-12-22 01:55:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 01:55:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 01:56:44 | INFO | train_inner | epoch 016:     92 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.391, loss=3.991, nll_loss=1.736, ppl=3.33, wps=14183.8, ups=1.2, wpb=11825.7, bsz=417.1, num_updates=41700, lr=1.23886e-05, gnorm=1.111, train_wall=51, wall=0
2020-12-22 01:57:37 | INFO | train_inner | epoch 016:    192 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.384, loss=3.943, nll_loss=1.694, ppl=3.24, wps=22769.1, ups=1.91, wpb=11912.7, bsz=439.8, num_updates=41800, lr=1.23738e-05, gnorm=1.094, train_wall=52, wall=0
2020-12-22 01:58:28 | INFO | train_inner | epoch 016:    292 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.397, loss=3.978, nll_loss=1.725, ppl=3.31, wps=22778.3, ups=1.93, wpb=11825.8, bsz=406.5, num_updates=41900, lr=1.2359e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 01:59:20 | INFO | train_inner | epoch 016:    392 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.421, loss=3.968, nll_loss=1.716, ppl=3.29, wps=22783.8, ups=1.92, wpb=11853, bsz=419.5, num_updates=42000, lr=1.23443e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 02:00:12 | INFO | train_inner | epoch 016:    492 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.38, loss=3.984, nll_loss=1.729, ppl=3.32, wps=22900.3, ups=1.93, wpb=11869.4, bsz=402.7, num_updates=42100, lr=1.23296e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 02:01:04 | INFO | train_inner | epoch 016:    592 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.412, loss=3.967, nll_loss=1.712, ppl=3.28, wps=22867.7, ups=1.93, wpb=11866.5, bsz=415.6, num_updates=42200, lr=1.2315e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 02:01:56 | INFO | train_inner | epoch 016:    692 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.396, loss=3.948, nll_loss=1.699, ppl=3.25, wps=22982.6, ups=1.93, wpb=11925.3, bsz=427.4, num_updates=42300, lr=1.23004e-05, gnorm=1.098, train_wall=52, wall=0
2020-12-22 02:02:48 | INFO | train_inner | epoch 016:    792 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.401, loss=3.988, nll_loss=1.732, ppl=3.32, wps=22750.3, ups=1.92, wpb=11874, bsz=385.6, num_updates=42400, lr=1.22859e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 02:03:40 | INFO | train_inner | epoch 016:    892 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.389, loss=3.976, nll_loss=1.72, ppl=3.29, wps=22912, ups=1.92, wpb=11916.5, bsz=404.6, num_updates=42500, lr=1.22714e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 02:04:32 | INFO | train_inner | epoch 016:    992 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.403, loss=3.982, nll_loss=1.727, ppl=3.31, wps=22848.4, ups=1.92, wpb=11875.4, bsz=415.1, num_updates=42600, lr=1.2257e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 02:05:24 | INFO | train_inner | epoch 016:   1092 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.406, loss=3.992, nll_loss=1.736, ppl=3.33, wps=22820.1, ups=1.93, wpb=11853.1, bsz=397.3, num_updates=42700, lr=1.22427e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 02:06:16 | INFO | train_inner | epoch 016:   1192 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.425, loss=3.99, nll_loss=1.733, ppl=3.33, wps=22768, ups=1.92, wpb=11846.3, bsz=392.2, num_updates=42800, lr=1.22284e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 02:07:08 | INFO | train_inner | epoch 016:   1292 / 3059 symm_kl=0.407, self_kl=0, self_cv=9.379, loss=4.006, nll_loss=1.752, ppl=3.37, wps=22645.9, ups=1.93, wpb=11762.6, bsz=415.5, num_updates=42900, lr=1.22141e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-22 02:08:00 | INFO | train_inner | epoch 016:   1392 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.438, loss=3.978, nll_loss=1.725, ppl=3.31, wps=22761.7, ups=1.93, wpb=11821.6, bsz=406.5, num_updates=43000, lr=1.21999e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 02:08:52 | INFO | train_inner | epoch 016:   1492 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.407, loss=3.974, nll_loss=1.72, ppl=3.29, wps=23020.3, ups=1.93, wpb=11934.2, bsz=393.6, num_updates=43100, lr=1.21857e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 02:09:44 | INFO | train_inner | epoch 016:   1592 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.393, loss=3.978, nll_loss=1.728, ppl=3.31, wps=22923.6, ups=1.93, wpb=11870, bsz=404.8, num_updates=43200, lr=1.21716e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 02:10:36 | INFO | train_inner | epoch 016:   1692 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.397, loss=3.967, nll_loss=1.719, ppl=3.29, wps=22722.3, ups=1.92, wpb=11805.4, bsz=424.5, num_updates=43300, lr=1.21575e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 02:11:28 | INFO | train_inner | epoch 016:   1792 / 3059 symm_kl=0.406, self_kl=0, self_cv=9.405, loss=3.99, nll_loss=1.734, ppl=3.33, wps=22752.2, ups=1.93, wpb=11816.4, bsz=398.4, num_updates=43400, lr=1.21435e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 02:12:19 | INFO | train_inner | epoch 016:   1892 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.379, loss=3.989, nll_loss=1.739, ppl=3.34, wps=22827, ups=1.93, wpb=11816, bsz=419, num_updates=43500, lr=1.21296e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 02:13:12 | INFO | train_inner | epoch 016:   1992 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.423, loss=3.943, nll_loss=1.696, ppl=3.24, wps=22737.4, ups=1.92, wpb=11846.9, bsz=402.9, num_updates=43600, lr=1.21157e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 02:14:03 | INFO | train_inner | epoch 016:   2092 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.403, loss=3.973, nll_loss=1.722, ppl=3.3, wps=22948.7, ups=1.93, wpb=11914.3, bsz=418.2, num_updates=43700, lr=1.21018e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 02:14:56 | INFO | train_inner | epoch 016:   2192 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.377, loss=3.995, nll_loss=1.743, ppl=3.35, wps=22710.9, ups=1.92, wpb=11827.2, bsz=382.1, num_updates=43800, lr=1.2088e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 02:15:47 | INFO | train_inner | epoch 016:   2292 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.38, loss=3.967, nll_loss=1.715, ppl=3.28, wps=23039.4, ups=1.93, wpb=11954.5, bsz=415.8, num_updates=43900, lr=1.20742e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:16:39 | INFO | train_inner | epoch 016:   2392 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.39, loss=3.969, nll_loss=1.72, ppl=3.29, wps=22791.1, ups=1.93, wpb=11830.8, bsz=400.6, num_updates=44000, lr=1.20605e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 02:17:31 | INFO | train_inner | epoch 016:   2492 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.414, loss=3.953, nll_loss=1.705, ppl=3.26, wps=22823.8, ups=1.92, wpb=11868.4, bsz=408.5, num_updates=44100, lr=1.20468e-05, gnorm=1.095, train_wall=52, wall=0
2020-12-22 02:18:23 | INFO | train_inner | epoch 016:   2592 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.409, loss=3.977, nll_loss=1.727, ppl=3.31, wps=22893.1, ups=1.93, wpb=11849.3, bsz=400.8, num_updates=44200, lr=1.20331e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 02:19:15 | INFO | train_inner | epoch 016:   2692 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.42, loss=3.97, nll_loss=1.721, ppl=3.3, wps=22630.5, ups=1.93, wpb=11755.8, bsz=414.7, num_updates=44300, lr=1.20195e-05, gnorm=1.132, train_wall=52, wall=0
2020-12-22 02:20:07 | INFO | train_inner | epoch 016:   2792 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.358, loss=3.998, nll_loss=1.748, ppl=3.36, wps=22709.5, ups=1.93, wpb=11774.4, bsz=441.6, num_updates=44400, lr=1.2006e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 02:20:59 | INFO | train_inner | epoch 016:   2892 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.346, loss=3.967, nll_loss=1.72, ppl=3.29, wps=22870.2, ups=1.93, wpb=11862, bsz=425.4, num_updates=44500, lr=1.19925e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 02:21:51 | INFO | train_inner | epoch 016:   2992 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.397, loss=3.98, nll_loss=1.731, ppl=3.32, wps=22761.3, ups=1.93, wpb=11814.9, bsz=403.4, num_updates=44600, lr=1.19791e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 02:22:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 02:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 02:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 02:22:41 | INFO | valid | epoch 016 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.885 | nll_loss 7.851 | ppl 230.81 | bleu 16.37 | wps 4895.6 | wpb 6344.2 | bsz 166.4 | num_updates 44667 | best_bleu 16.48
2020-12-22 02:22:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 02:22:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 16 @ 44667 updates, score 16.37) (writing took 5.185231767594814 seconds)
2020-12-22 02:22:46 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-12-22 02:22:46 | INFO | train | epoch 016 | symm_kl 0.402 | self_kl 0 | self_cv 9.397 | loss 3.976 | nll_loss 1.724 | ppl 3.3 | wps 22389.7 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 44667 | lr 1.19701e-05 | gnorm 1.109 | train_wall 1583 | wall 0
2020-12-22 02:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:50 | INFO | fairseq.trainer | begin training epoch 17
2020-12-22 02:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:22:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:23:13 | INFO | train_inner | epoch 017:     33 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.391, loss=3.972, nll_loss=1.723, ppl=3.3, wps=14389.3, ups=1.21, wpb=11862.6, bsz=412.9, num_updates=44700, lr=1.19656e-05, gnorm=1.111, train_wall=51, wall=0
2020-12-22 02:24:05 | INFO | train_inner | epoch 017:    133 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.391, loss=3.965, nll_loss=1.715, ppl=3.28, wps=22911.9, ups=1.94, wpb=11824.8, bsz=413.6, num_updates=44800, lr=1.19523e-05, gnorm=1.105, train_wall=51, wall=0
2020-12-22 02:24:56 | INFO | train_inner | epoch 017:    233 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.431, loss=3.947, nll_loss=1.697, ppl=3.24, wps=23028.1, ups=1.93, wpb=11902.6, bsz=384, num_updates=44900, lr=1.1939e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 02:25:48 | INFO | train_inner | epoch 017:    333 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.425, loss=3.973, nll_loss=1.72, ppl=3.3, wps=22632.9, ups=1.93, wpb=11712.8, bsz=418.9, num_updates=45000, lr=1.19257e-05, gnorm=1.126, train_wall=52, wall=0
2020-12-22 02:26:40 | INFO | train_inner | epoch 017:    433 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.381, loss=3.944, nll_loss=1.697, ppl=3.24, wps=22955.2, ups=1.93, wpb=11912.4, bsz=428.2, num_updates=45100, lr=1.19125e-05, gnorm=1.092, train_wall=52, wall=0
2020-12-22 02:27:32 | INFO | train_inner | epoch 017:    533 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.419, loss=3.968, nll_loss=1.718, ppl=3.29, wps=22988.3, ups=1.94, wpb=11836.4, bsz=423, num_updates=45200, lr=1.18993e-05, gnorm=1.111, train_wall=51, wall=0
2020-12-22 02:28:23 | INFO | train_inner | epoch 017:    633 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.399, loss=3.954, nll_loss=1.705, ppl=3.26, wps=22984.1, ups=1.92, wpb=11939.8, bsz=413.2, num_updates=45300, lr=1.18861e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-22 02:29:15 | INFO | train_inner | epoch 017:    733 / 3059 symm_kl=0.405, self_kl=0, self_cv=9.389, loss=3.993, nll_loss=1.74, ppl=3.34, wps=22924.4, ups=1.93, wpb=11862.1, bsz=395.9, num_updates=45400, lr=1.1873e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 02:30:07 | INFO | train_inner | epoch 017:    833 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.378, loss=3.988, nll_loss=1.735, ppl=3.33, wps=22741, ups=1.93, wpb=11796.1, bsz=407.4, num_updates=45500, lr=1.186e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 02:30:59 | INFO | train_inner | epoch 017:    933 / 3059 symm_kl=0.408, self_kl=0, self_cv=9.451, loss=3.999, nll_loss=1.742, ppl=3.34, wps=22629.9, ups=1.93, wpb=11714.5, bsz=393.7, num_updates=45600, lr=1.1847e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-22 02:31:51 | INFO | train_inner | epoch 017:   1033 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.368, loss=3.949, nll_loss=1.702, ppl=3.25, wps=22931.7, ups=1.93, wpb=11911.4, bsz=428, num_updates=45700, lr=1.1834e-05, gnorm=1.096, train_wall=52, wall=0
2020-12-22 02:32:43 | INFO | train_inner | epoch 017:   1133 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.431, loss=3.984, nll_loss=1.73, ppl=3.32, wps=22653.5, ups=1.93, wpb=11739.1, bsz=390.7, num_updates=45800, lr=1.18211e-05, gnorm=1.127, train_wall=52, wall=0
2020-12-22 02:33:34 | INFO | train_inner | epoch 017:   1233 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.383, loss=3.967, nll_loss=1.72, ppl=3.29, wps=23026.8, ups=1.94, wpb=11896.1, bsz=410.4, num_updates=45900, lr=1.18082e-05, gnorm=1.1, train_wall=51, wall=0
2020-12-22 02:34:26 | INFO | train_inner | epoch 017:   1333 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.405, loss=3.968, nll_loss=1.722, ppl=3.3, wps=22707.6, ups=1.93, wpb=11787.6, bsz=399.6, num_updates=46000, lr=1.17954e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:35:18 | INFO | train_inner | epoch 017:   1433 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.399, loss=3.966, nll_loss=1.716, ppl=3.28, wps=22876.4, ups=1.92, wpb=11889.5, bsz=404, num_updates=46100, lr=1.17826e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 02:36:10 | INFO | train_inner | epoch 017:   1533 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.406, loss=3.946, nll_loss=1.7, ppl=3.25, wps=22836.1, ups=1.92, wpb=11921.7, bsz=427.4, num_updates=46200, lr=1.17698e-05, gnorm=1.097, train_wall=52, wall=0
2020-12-22 02:37:02 | INFO | train_inner | epoch 017:   1633 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.418, loss=3.978, nll_loss=1.73, ppl=3.32, wps=22802.2, ups=1.93, wpb=11837.8, bsz=409.3, num_updates=46300, lr=1.17571e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:37:54 | INFO | train_inner | epoch 017:   1733 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.399, loss=3.979, nll_loss=1.73, ppl=3.32, wps=22662.1, ups=1.92, wpb=11818.8, bsz=392.3, num_updates=46400, lr=1.17444e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 02:38:46 | INFO | train_inner | epoch 017:   1833 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.369, loss=3.97, nll_loss=1.721, ppl=3.3, wps=22912.3, ups=1.93, wpb=11869.8, bsz=397.8, num_updates=46500, lr=1.17318e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 02:39:38 | INFO | train_inner | epoch 017:   1933 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.421, loss=3.935, nll_loss=1.689, ppl=3.22, wps=22971.5, ups=1.93, wpb=11892.7, bsz=415.8, num_updates=46600, lr=1.17192e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 02:40:30 | INFO | train_inner | epoch 017:   2033 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.405, loss=3.999, nll_loss=1.749, ppl=3.36, wps=22704.8, ups=1.93, wpb=11779.6, bsz=402.9, num_updates=46700, lr=1.17066e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 02:41:22 | INFO | train_inner | epoch 017:   2133 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.381, loss=3.97, nll_loss=1.723, ppl=3.3, wps=22886.9, ups=1.92, wpb=11915.7, bsz=415.2, num_updates=46800, lr=1.16941e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 02:42:14 | INFO | train_inner | epoch 017:   2233 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.4, loss=3.972, nll_loss=1.724, ppl=3.3, wps=22993.9, ups=1.93, wpb=11927.9, bsz=403.7, num_updates=46900, lr=1.16816e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 02:43:06 | INFO | train_inner | epoch 017:   2333 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.406, loss=3.988, nll_loss=1.736, ppl=3.33, wps=22886.7, ups=1.93, wpb=11853.9, bsz=396.8, num_updates=47000, lr=1.16692e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 02:43:57 | INFO | train_inner | epoch 017:   2433 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.364, loss=3.98, nll_loss=1.731, ppl=3.32, wps=22871.3, ups=1.93, wpb=11834.9, bsz=429, num_updates=47100, lr=1.16568e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 02:44:49 | INFO | train_inner | epoch 017:   2533 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.369, loss=3.987, nll_loss=1.739, ppl=3.34, wps=22711.8, ups=1.92, wpb=11810.2, bsz=422.5, num_updates=47200, lr=1.16445e-05, gnorm=1.124, train_wall=52, wall=0
2020-12-22 02:45:41 | INFO | train_inner | epoch 017:   2633 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.377, loss=3.983, nll_loss=1.736, ppl=3.33, wps=22873.5, ups=1.93, wpb=11860.6, bsz=432.5, num_updates=47300, lr=1.16321e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:46:33 | INFO | train_inner | epoch 017:   2733 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.425, loss=3.992, nll_loss=1.743, ppl=3.35, wps=22898.6, ups=1.93, wpb=11872, bsz=395.4, num_updates=47400, lr=1.16199e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 02:47:25 | INFO | train_inner | epoch 017:   2833 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.366, loss=3.994, nll_loss=1.744, ppl=3.35, wps=22945.8, ups=1.93, wpb=11896.2, bsz=421.3, num_updates=47500, lr=1.16076e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 02:48:17 | INFO | train_inner | epoch 017:   2933 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.413, loss=3.998, nll_loss=1.746, ppl=3.35, wps=22750.3, ups=1.92, wpb=11831.5, bsz=394.2, num_updates=47600, lr=1.15954e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 02:49:09 | INFO | train_inner | epoch 017:   3033 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.399, loss=3.978, nll_loss=1.728, ppl=3.31, wps=22888.1, ups=1.92, wpb=11897.7, bsz=409.8, num_updates=47700, lr=1.15833e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 02:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 02:49:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 02:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 02:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 02:49:38 | INFO | valid | epoch 017 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.894 | nll_loss 7.861 | ppl 232.45 | bleu 16.67 | wps 4980.6 | wpb 6344.2 | bsz 166.4 | num_updates 47726 | best_bleu 16.67
2020-12-22 02:49:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 02:49:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 17 @ 47726 updates, score 16.67) (writing took 8.526219500228763 seconds)
2020-12-22 02:49:46 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-12-22 02:49:46 | INFO | train | epoch 017 | symm_kl 0.401 | self_kl 0 | self_cv 9.398 | loss 3.973 | nll_loss 1.724 | ppl 3.3 | wps 22378.9 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 47726 | lr 1.15801e-05 | gnorm 1.109 | train_wall 1581 | wall 0
2020-12-22 02:49:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:49:50 | INFO | fairseq.trainer | begin training epoch 18
2020-12-22 02:49:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 02:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 02:50:34 | INFO | train_inner | epoch 018:     74 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.383, loss=3.987, nll_loss=1.737, ppl=3.33, wps=13848.2, ups=1.18, wpb=11760, bsz=409.9, num_updates=47800, lr=1.15711e-05, gnorm=1.122, train_wall=51, wall=0
2020-12-22 02:51:26 | INFO | train_inner | epoch 018:    174 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.409, loss=3.935, nll_loss=1.691, ppl=3.23, wps=22935.1, ups=1.93, wpb=11903.8, bsz=420.8, num_updates=47900, lr=1.15591e-05, gnorm=1.091, train_wall=52, wall=0
2020-12-22 02:52:18 | INFO | train_inner | epoch 018:    274 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.406, loss=3.965, nll_loss=1.72, ppl=3.3, wps=22667.3, ups=1.92, wpb=11785.6, bsz=427.4, num_updates=48000, lr=1.1547e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 02:53:09 | INFO | train_inner | epoch 018:    374 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.412, loss=3.974, nll_loss=1.727, ppl=3.31, wps=22937.5, ups=1.93, wpb=11866.9, bsz=420.6, num_updates=48100, lr=1.1535e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 02:54:01 | INFO | train_inner | epoch 018:    474 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.397, loss=3.946, nll_loss=1.701, ppl=3.25, wps=22984.8, ups=1.93, wpb=11883, bsz=410.7, num_updates=48200, lr=1.1523e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 02:54:53 | INFO | train_inner | epoch 018:    574 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.396, loss=3.956, nll_loss=1.708, ppl=3.27, wps=22838.4, ups=1.92, wpb=11891.8, bsz=427.8, num_updates=48300, lr=1.15111e-05, gnorm=1.125, train_wall=52, wall=0
2020-12-22 02:55:45 | INFO | train_inner | epoch 018:    674 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.389, loss=3.963, nll_loss=1.714, ppl=3.28, wps=23004.4, ups=1.93, wpb=11926.4, bsz=416.3, num_updates=48400, lr=1.14992e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 02:56:37 | INFO | train_inner | epoch 018:    774 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.392, loss=3.97, nll_loss=1.724, ppl=3.3, wps=22900.8, ups=1.93, wpb=11884.1, bsz=398.5, num_updates=48500, lr=1.14873e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 02:57:29 | INFO | train_inner | epoch 018:    874 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.406, loss=3.99, nll_loss=1.738, ppl=3.34, wps=22819, ups=1.92, wpb=11880, bsz=384.4, num_updates=48600, lr=1.14755e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-22 02:58:21 | INFO | train_inner | epoch 018:    974 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.396, loss=3.97, nll_loss=1.72, ppl=3.29, wps=22903.1, ups=1.92, wpb=11922.4, bsz=406.1, num_updates=48700, lr=1.14637e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 02:59:13 | INFO | train_inner | epoch 018:   1074 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.415, loss=3.972, nll_loss=1.723, ppl=3.3, wps=22732.2, ups=1.92, wpb=11856.8, bsz=390.2, num_updates=48800, lr=1.1452e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 03:00:05 | INFO | train_inner | epoch 018:   1174 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.377, loss=3.965, nll_loss=1.723, ppl=3.3, wps=22828, ups=1.92, wpb=11871, bsz=435.8, num_updates=48900, lr=1.14403e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 03:00:57 | INFO | train_inner | epoch 018:   1274 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.381, loss=3.996, nll_loss=1.746, ppl=3.35, wps=22735.3, ups=1.94, wpb=11732.6, bsz=412.6, num_updates=49000, lr=1.14286e-05, gnorm=1.123, train_wall=51, wall=0
2020-12-22 03:01:49 | INFO | train_inner | epoch 018:   1374 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.418, loss=3.971, nll_loss=1.722, ppl=3.3, wps=22918.5, ups=1.94, wpb=11835.3, bsz=380.6, num_updates=49100, lr=1.14169e-05, gnorm=1.114, train_wall=51, wall=0
2020-12-22 03:02:41 | INFO | train_inner | epoch 018:   1474 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.392, loss=3.947, nll_loss=1.704, ppl=3.26, wps=22861.2, ups=1.92, wpb=11908.8, bsz=418.6, num_updates=49200, lr=1.14053e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 03:03:32 | INFO | train_inner | epoch 018:   1574 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.394, loss=3.987, nll_loss=1.741, ppl=3.34, wps=22875.1, ups=1.93, wpb=11825.1, bsz=416.5, num_updates=49300, lr=1.13937e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 03:04:24 | INFO | train_inner | epoch 018:   1674 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.402, loss=3.957, nll_loss=1.71, ppl=3.27, wps=22860, ups=1.93, wpb=11860.9, bsz=399.6, num_updates=49400, lr=1.13822e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 03:05:16 | INFO | train_inner | epoch 018:   1774 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.389, loss=3.936, nll_loss=1.696, ppl=3.24, wps=22964.6, ups=1.92, wpb=11933, bsz=419, num_updates=49500, lr=1.13707e-05, gnorm=1.095, train_wall=52, wall=0
2020-12-22 03:06:08 | INFO | train_inner | epoch 018:   1874 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.434, loss=3.979, nll_loss=1.732, ppl=3.32, wps=22621, ups=1.93, wpb=11748.5, bsz=410.7, num_updates=49600, lr=1.13592e-05, gnorm=1.123, train_wall=52, wall=0
2020-12-22 03:07:00 | INFO | train_inner | epoch 018:   1974 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.374, loss=3.949, nll_loss=1.707, ppl=3.26, wps=23045.7, ups=1.94, wpb=11900.6, bsz=425.4, num_updates=49700, lr=1.13478e-05, gnorm=1.099, train_wall=51, wall=0
2020-12-22 03:07:52 | INFO | train_inner | epoch 018:   2074 / 3059 symm_kl=0.404, self_kl=0, self_cv=9.394, loss=4, nll_loss=1.749, ppl=3.36, wps=22666.7, ups=1.92, wpb=11796.2, bsz=403, num_updates=49800, lr=1.13364e-05, gnorm=1.123, train_wall=52, wall=0
2020-12-22 03:08:44 | INFO | train_inner | epoch 018:   2174 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.392, loss=3.967, nll_loss=1.72, ppl=3.29, wps=22874.6, ups=1.93, wpb=11846.2, bsz=415.6, num_updates=49900, lr=1.1325e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 03:09:35 | INFO | train_inner | epoch 018:   2274 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.379, loss=3.991, nll_loss=1.744, ppl=3.35, wps=22808.4, ups=1.93, wpb=11795.5, bsz=413.5, num_updates=50000, lr=1.13137e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 03:10:27 | INFO | train_inner | epoch 018:   2374 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.412, loss=3.974, nll_loss=1.729, ppl=3.32, wps=22753.8, ups=1.92, wpb=11826, bsz=415.1, num_updates=50100, lr=1.13024e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 03:11:19 | INFO | train_inner | epoch 018:   2474 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.393, loss=3.99, nll_loss=1.742, ppl=3.34, wps=22729.3, ups=1.93, wpb=11786.4, bsz=413.4, num_updates=50200, lr=1.12911e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 03:12:11 | INFO | train_inner | epoch 018:   2574 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.397, loss=3.947, nll_loss=1.704, ppl=3.26, wps=22724, ups=1.92, wpb=11819.5, bsz=398.4, num_updates=50300, lr=1.12799e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 03:13:03 | INFO | train_inner | epoch 018:   2674 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.38, loss=4.001, nll_loss=1.753, ppl=3.37, wps=22826.9, ups=1.93, wpb=11838.1, bsz=376.6, num_updates=50400, lr=1.12687e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 03:13:55 | INFO | train_inner | epoch 018:   2774 / 3059 symm_kl=0.403, self_kl=0, self_cv=9.402, loss=3.987, nll_loss=1.736, ppl=3.33, wps=22814.4, ups=1.91, wpb=11915.9, bsz=401.7, num_updates=50500, lr=1.12576e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 03:14:47 | INFO | train_inner | epoch 018:   2874 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.391, loss=3.98, nll_loss=1.731, ppl=3.32, wps=22845.2, ups=1.93, wpb=11855.8, bsz=400.6, num_updates=50600, lr=1.12464e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-22 03:15:39 | INFO | train_inner | epoch 018:   2974 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.399, loss=3.975, nll_loss=1.73, ppl=3.32, wps=22816.9, ups=1.92, wpb=11887.6, bsz=420.3, num_updates=50700, lr=1.12353e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 03:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 03:16:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 03:16:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 03:16:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 03:16:41 | INFO | valid | epoch 018 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.875 | nll_loss 7.839 | ppl 228.97 | bleu 16.64 | wps 4338.4 | wpb 6344.2 | bsz 166.4 | num_updates 50785 | best_bleu 16.67
2020-12-22 03:16:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 03:16:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 18 @ 50785 updates, score 16.64) (writing took 5.138491164892912 seconds)
2020-12-22 03:16:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-12-22 03:16:46 | INFO | train | epoch 018 | symm_kl 0.399 | self_kl 0 | self_cv 9.397 | loss 3.971 | nll_loss 1.724 | ppl 3.3 | wps 22387 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 50785 | lr 1.12259e-05 | gnorm 1.111 | train_wall 1582 | wall 0
2020-12-22 03:16:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:49 | INFO | fairseq.trainer | begin training epoch 19
2020-12-22 03:16:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:17:04 | INFO | train_inner | epoch 019:     15 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.404, loss=3.971, nll_loss=1.726, ppl=3.31, wps=14079.6, ups=1.19, wpb=11871.8, bsz=407.9, num_updates=50800, lr=1.12243e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 03:17:55 | INFO | train_inner | epoch 019:    115 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.448, loss=3.953, nll_loss=1.709, ppl=3.27, wps=23045.1, ups=1.95, wpb=11813.8, bsz=405.1, num_updates=50900, lr=1.12132e-05, gnorm=1.12, train_wall=51, wall=0
2020-12-22 03:18:47 | INFO | train_inner | epoch 019:    215 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.394, loss=3.966, nll_loss=1.721, ppl=3.3, wps=22795.7, ups=1.92, wpb=11884, bsz=412.9, num_updates=51000, lr=1.12022e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 03:19:39 | INFO | train_inner | epoch 019:    315 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.385, loss=3.968, nll_loss=1.723, ppl=3.3, wps=22771.6, ups=1.93, wpb=11790.8, bsz=422.6, num_updates=51100, lr=1.11913e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 03:20:31 | INFO | train_inner | epoch 019:    415 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.419, loss=3.96, nll_loss=1.715, ppl=3.28, wps=22786, ups=1.92, wpb=11891.1, bsz=419.5, num_updates=51200, lr=1.11803e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 03:21:23 | INFO | train_inner | epoch 019:    515 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.397, loss=3.953, nll_loss=1.709, ppl=3.27, wps=23080.8, ups=1.93, wpb=11974.2, bsz=411, num_updates=51300, lr=1.11694e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 03:22:15 | INFO | train_inner | epoch 019:    615 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.368, loss=3.951, nll_loss=1.709, ppl=3.27, wps=22823.8, ups=1.93, wpb=11852.2, bsz=405.5, num_updates=51400, lr=1.11586e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 03:23:06 | INFO | train_inner | epoch 019:    715 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.39, loss=3.96, nll_loss=1.717, ppl=3.29, wps=22912.8, ups=1.93, wpb=11847, bsz=415.4, num_updates=51500, lr=1.11477e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 03:23:59 | INFO | train_inner | epoch 019:    815 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.393, loss=3.959, nll_loss=1.715, ppl=3.28, wps=22942.5, ups=1.92, wpb=11959.6, bsz=417.8, num_updates=51600, lr=1.11369e-05, gnorm=1.095, train_wall=52, wall=0
2020-12-22 03:24:50 | INFO | train_inner | epoch 019:    915 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.409, loss=3.971, nll_loss=1.723, ppl=3.3, wps=22798.4, ups=1.93, wpb=11803.4, bsz=405.4, num_updates=51700, lr=1.11261e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 03:25:42 | INFO | train_inner | epoch 019:   1015 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.381, loss=3.973, nll_loss=1.727, ppl=3.31, wps=22845.4, ups=1.93, wpb=11836.7, bsz=404.6, num_updates=51800, lr=1.11154e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 03:26:34 | INFO | train_inner | epoch 019:   1115 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.411, loss=3.962, nll_loss=1.715, ppl=3.28, wps=22740.7, ups=1.92, wpb=11813.7, bsz=404.7, num_updates=51900, lr=1.11047e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 03:27:26 | INFO | train_inner | epoch 019:   1215 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.392, loss=3.953, nll_loss=1.713, ppl=3.28, wps=22936.2, ups=1.93, wpb=11911.7, bsz=415.4, num_updates=52000, lr=1.1094e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 03:28:18 | INFO | train_inner | epoch 019:   1315 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.384, loss=3.983, nll_loss=1.736, ppl=3.33, wps=22673.3, ups=1.92, wpb=11836.9, bsz=426, num_updates=52100, lr=1.10834e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 03:29:10 | INFO | train_inner | epoch 019:   1415 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.376, loss=3.985, nll_loss=1.739, ppl=3.34, wps=22898.2, ups=1.93, wpb=11860, bsz=411, num_updates=52200, lr=1.10727e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 03:30:02 | INFO | train_inner | epoch 019:   1515 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.408, loss=3.972, nll_loss=1.73, ppl=3.32, wps=22655.8, ups=1.92, wpb=11814, bsz=422.1, num_updates=52300, lr=1.10621e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 03:30:54 | INFO | train_inner | epoch 019:   1615 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.398, loss=3.976, nll_loss=1.731, ppl=3.32, wps=22902.3, ups=1.93, wpb=11855.9, bsz=403.8, num_updates=52400, lr=1.10516e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 03:31:46 | INFO | train_inner | epoch 019:   1715 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.398, loss=3.966, nll_loss=1.721, ppl=3.3, wps=22725.7, ups=1.93, wpb=11782.3, bsz=413, num_updates=52500, lr=1.1041e-05, gnorm=1.131, train_wall=52, wall=0
2020-12-22 03:32:38 | INFO | train_inner | epoch 019:   1815 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.388, loss=3.967, nll_loss=1.722, ppl=3.3, wps=22796.5, ups=1.93, wpb=11839.4, bsz=428.4, num_updates=52600, lr=1.10305e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 03:33:30 | INFO | train_inner | epoch 019:   1915 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.421, loss=3.985, nll_loss=1.737, ppl=3.33, wps=22792.9, ups=1.93, wpb=11840.3, bsz=386.5, num_updates=52700, lr=1.10201e-05, gnorm=1.131, train_wall=52, wall=0
2020-12-22 03:34:21 | INFO | train_inner | epoch 019:   2015 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.378, loss=3.952, nll_loss=1.711, ppl=3.27, wps=22928.4, ups=1.93, wpb=11852, bsz=394.9, num_updates=52800, lr=1.10096e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 03:35:13 | INFO | train_inner | epoch 019:   2115 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.385, loss=3.966, nll_loss=1.723, ppl=3.3, wps=22737.7, ups=1.93, wpb=11804.7, bsz=421.4, num_updates=52900, lr=1.09992e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 03:36:05 | INFO | train_inner | epoch 019:   2215 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.405, loss=3.967, nll_loss=1.722, ppl=3.3, wps=22874.1, ups=1.93, wpb=11846.3, bsz=401.1, num_updates=53000, lr=1.09888e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 03:36:57 | INFO | train_inner | epoch 019:   2315 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.412, loss=3.971, nll_loss=1.727, ppl=3.31, wps=22768.1, ups=1.93, wpb=11809.8, bsz=413.5, num_updates=53100, lr=1.09785e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 03:37:49 | INFO | train_inner | epoch 019:   2415 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.394, loss=3.976, nll_loss=1.732, ppl=3.32, wps=22765.4, ups=1.94, wpb=11764.8, bsz=411, num_updates=53200, lr=1.09682e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 03:38:40 | INFO | train_inner | epoch 019:   2515 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.415, loss=3.974, nll_loss=1.729, ppl=3.32, wps=22813.7, ups=1.93, wpb=11821.9, bsz=381.2, num_updates=53300, lr=1.09579e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 03:39:32 | INFO | train_inner | epoch 019:   2615 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.362, loss=3.981, nll_loss=1.738, ppl=3.33, wps=22899.4, ups=1.92, wpb=11911.8, bsz=428.5, num_updates=53400, lr=1.09476e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 03:40:24 | INFO | train_inner | epoch 019:   2715 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.409, loss=3.964, nll_loss=1.72, ppl=3.29, wps=22875.9, ups=1.92, wpb=11896.1, bsz=397.3, num_updates=53500, lr=1.09374e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 03:41:16 | INFO | train_inner | epoch 019:   2815 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.387, loss=3.969, nll_loss=1.726, ppl=3.31, wps=22885, ups=1.93, wpb=11837.1, bsz=407.4, num_updates=53600, lr=1.09272e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 03:42:08 | INFO | train_inner | epoch 019:   2915 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.359, loss=3.976, nll_loss=1.734, ppl=3.33, wps=23014.3, ups=1.93, wpb=11951.3, bsz=412.8, num_updates=53700, lr=1.0917e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 03:43:00 | INFO | train_inner | epoch 019:   3015 / 3059 symm_kl=0.401, self_kl=0, self_cv=9.396, loss=3.988, nll_loss=1.741, ppl=3.34, wps=22825.7, ups=1.92, wpb=11866.1, bsz=396.7, num_updates=53800, lr=1.09068e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 03:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 03:43:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 03:43:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 03:43:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 03:43:38 | INFO | valid | epoch 019 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.893 | nll_loss 7.858 | ppl 232.07 | bleu 16.54 | wps 4985.1 | wpb 6344.2 | bsz 166.4 | num_updates 53844 | best_bleu 16.67
2020-12-22 03:43:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 03:43:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 19 @ 53844 updates, score 16.54) (writing took 5.289794301614165 seconds)
2020-12-22 03:43:44 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-12-22 03:43:44 | INFO | train | epoch 019 | symm_kl 0.398 | self_kl 0 | self_cv 9.396 | loss 3.969 | nll_loss 1.724 | ppl 3.3 | wps 22409.4 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 53844 | lr 1.09024e-05 | gnorm 1.112 | train_wall 1582 | wall 0
2020-12-22 03:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:47 | INFO | fairseq.trainer | begin training epoch 20
2020-12-22 03:43:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:43:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 03:43:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 03:44:22 | INFO | train_inner | epoch 020:     56 / 3059 symm_kl=0.402, self_kl=0, self_cv=9.398, loss=4.001, nll_loss=1.754, ppl=3.37, wps=14365.7, ups=1.22, wpb=11797.9, bsz=408.6, num_updates=53900, lr=1.08967e-05, gnorm=1.118, train_wall=51, wall=0
2020-12-22 03:45:14 | INFO | train_inner | epoch 020:    156 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.388, loss=3.967, nll_loss=1.724, ppl=3.3, wps=22849.3, ups=1.93, wpb=11824.8, bsz=399.8, num_updates=54000, lr=1.08866e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 03:46:06 | INFO | train_inner | epoch 020:    256 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.394, loss=3.954, nll_loss=1.713, ppl=3.28, wps=22722.6, ups=1.92, wpb=11833.8, bsz=413.4, num_updates=54100, lr=1.08766e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 03:46:58 | INFO | train_inner | epoch 020:    356 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.378, loss=3.958, nll_loss=1.714, ppl=3.28, wps=22923.4, ups=1.93, wpb=11886.2, bsz=410.9, num_updates=54200, lr=1.08665e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 03:47:50 | INFO | train_inner | epoch 020:    456 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.412, loss=3.955, nll_loss=1.715, ppl=3.28, wps=23047.4, ups=1.93, wpb=11919.8, bsz=408.7, num_updates=54300, lr=1.08565e-05, gnorm=1.099, train_wall=52, wall=0
2020-12-22 03:48:41 | INFO | train_inner | epoch 020:    556 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.37, loss=3.944, nll_loss=1.706, ppl=3.26, wps=22897.5, ups=1.93, wpb=11880.4, bsz=432.6, num_updates=54400, lr=1.08465e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 03:49:34 | INFO | train_inner | epoch 020:    656 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.408, loss=3.976, nll_loss=1.733, ppl=3.32, wps=22802.7, ups=1.92, wpb=11863.4, bsz=412.6, num_updates=54500, lr=1.08366e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 03:50:26 | INFO | train_inner | epoch 020:    756 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.415, loss=3.935, nll_loss=1.696, ppl=3.24, wps=22782.1, ups=1.92, wpb=11845.9, bsz=433.5, num_updates=54600, lr=1.08266e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 03:51:17 | INFO | train_inner | epoch 020:    856 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.427, loss=3.973, nll_loss=1.727, ppl=3.31, wps=22755, ups=1.93, wpb=11808.7, bsz=381.6, num_updates=54700, lr=1.08167e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 03:52:09 | INFO | train_inner | epoch 020:    956 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.413, loss=3.962, nll_loss=1.72, ppl=3.3, wps=22748.5, ups=1.93, wpb=11773.5, bsz=417.8, num_updates=54800, lr=1.08069e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 03:53:01 | INFO | train_inner | epoch 020:   1056 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.402, loss=3.978, nll_loss=1.734, ppl=3.33, wps=22752.8, ups=1.93, wpb=11758.9, bsz=405.2, num_updates=54900, lr=1.0797e-05, gnorm=1.118, train_wall=52, wall=0
2020-12-22 03:53:53 | INFO | train_inner | epoch 020:   1156 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.391, loss=3.993, nll_loss=1.748, ppl=3.36, wps=22783.5, ups=1.93, wpb=11788.6, bsz=396.8, num_updates=55000, lr=1.07872e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 03:54:45 | INFO | train_inner | epoch 020:   1256 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.397, loss=3.961, nll_loss=1.717, ppl=3.29, wps=22785.3, ups=1.92, wpb=11863, bsz=420.6, num_updates=55100, lr=1.07774e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 03:55:37 | INFO | train_inner | epoch 020:   1356 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.413, loss=3.968, nll_loss=1.722, ppl=3.3, wps=22824.9, ups=1.92, wpb=11874.6, bsz=385.6, num_updates=55200, lr=1.07676e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 03:56:29 | INFO | train_inner | epoch 020:   1456 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.373, loss=3.969, nll_loss=1.726, ppl=3.31, wps=22984.2, ups=1.92, wpb=11946.8, bsz=419, num_updates=55300, lr=1.07579e-05, gnorm=1.103, train_wall=52, wall=0
2020-12-22 03:57:20 | INFO | train_inner | epoch 020:   1556 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.399, loss=3.956, nll_loss=1.715, ppl=3.28, wps=23054.4, ups=1.94, wpb=11875.7, bsz=409, num_updates=55400, lr=1.07482e-05, gnorm=1.107, train_wall=51, wall=0
2020-12-22 03:58:12 | INFO | train_inner | epoch 020:   1656 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.395, loss=3.981, nll_loss=1.738, ppl=3.34, wps=22884.1, ups=1.93, wpb=11886.1, bsz=401, num_updates=55500, lr=1.07385e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 03:59:04 | INFO | train_inner | epoch 020:   1756 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.373, loss=3.972, nll_loss=1.73, ppl=3.32, wps=22796.5, ups=1.92, wpb=11849.7, bsz=415.8, num_updates=55600, lr=1.07288e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 03:59:56 | INFO | train_inner | epoch 020:   1856 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.416, loss=3.979, nll_loss=1.735, ppl=3.33, wps=22841.6, ups=1.93, wpb=11855.4, bsz=390.9, num_updates=55700, lr=1.07192e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 04:00:48 | INFO | train_inner | epoch 020:   1956 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.405, loss=3.965, nll_loss=1.724, ppl=3.3, wps=22737.4, ups=1.93, wpb=11796.6, bsz=429.2, num_updates=55800, lr=1.07096e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:01:40 | INFO | train_inner | epoch 020:   2056 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.411, loss=3.959, nll_loss=1.716, ppl=3.28, wps=22813.6, ups=1.91, wpb=11925.3, bsz=401.7, num_updates=55900, lr=1.07e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 04:02:32 | INFO | train_inner | epoch 020:   2156 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.385, loss=3.957, nll_loss=1.717, ppl=3.29, wps=22959.3, ups=1.93, wpb=11890.5, bsz=443.8, num_updates=56000, lr=1.06904e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 04:03:24 | INFO | train_inner | epoch 020:   2256 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.384, loss=3.97, nll_loss=1.731, ppl=3.32, wps=22968.2, ups=1.93, wpb=11893.3, bsz=427.4, num_updates=56100, lr=1.06809e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 04:04:15 | INFO | train_inner | epoch 020:   2356 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.39, loss=3.969, nll_loss=1.728, ppl=3.31, wps=22953.5, ups=1.93, wpb=11865.6, bsz=397.6, num_updates=56200, lr=1.06714e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 04:05:07 | INFO | train_inner | epoch 020:   2456 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.408, loss=3.976, nll_loss=1.731, ppl=3.32, wps=22733.3, ups=1.92, wpb=11819.2, bsz=374.7, num_updates=56300, lr=1.06619e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:05:59 | INFO | train_inner | epoch 020:   2556 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.385, loss=3.954, nll_loss=1.712, ppl=3.28, wps=22865.9, ups=1.93, wpb=11850.6, bsz=401.5, num_updates=56400, lr=1.06525e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 04:06:51 | INFO | train_inner | epoch 020:   2656 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.39, loss=3.945, nll_loss=1.705, ppl=3.26, wps=22864.6, ups=1.93, wpb=11876.6, bsz=396.1, num_updates=56500, lr=1.0643e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 04:07:43 | INFO | train_inner | epoch 020:   2756 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.399, loss=3.95, nll_loss=1.711, ppl=3.27, wps=22752.7, ups=1.92, wpb=11834.6, bsz=429, num_updates=56600, lr=1.06336e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 04:08:35 | INFO | train_inner | epoch 020:   2856 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.395, loss=3.985, nll_loss=1.74, ppl=3.34, wps=22642.1, ups=1.91, wpb=11829.2, bsz=384.4, num_updates=56700, lr=1.06243e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-22 04:09:27 | INFO | train_inner | epoch 020:   2956 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.377, loss=3.955, nll_loss=1.715, ppl=3.28, wps=22772.4, ups=1.92, wpb=11855, bsz=407.3, num_updates=56800, lr=1.06149e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 04:10:19 | INFO | train_inner | epoch 020:   3056 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.353, loss=3.986, nll_loss=1.747, ppl=3.36, wps=22906.7, ups=1.93, wpb=11856.9, bsz=435, num_updates=56900, lr=1.06056e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 04:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 04:10:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 04:10:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 04:10:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 04:10:36 | INFO | valid | epoch 020 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.877 | nll_loss 7.843 | ppl 229.62 | bleu 16.38 | wps 4939.9 | wpb 6344.2 | bsz 166.4 | num_updates 56903 | best_bleu 16.67
2020-12-22 04:10:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 04:10:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 20 @ 56903 updates, score 16.38) (writing took 5.171633560210466 seconds)
2020-12-22 04:10:42 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-12-22 04:10:42 | INFO | train | epoch 020 | symm_kl 0.396 | self_kl 0 | self_cv 9.395 | loss 3.966 | nll_loss 1.724 | ppl 3.3 | wps 22408.9 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 56903 | lr 1.06053e-05 | gnorm 1.112 | train_wall 1582 | wall 0
2020-12-22 04:10:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:45 | INFO | fairseq.trainer | begin training epoch 21
2020-12-22 04:10:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:10:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:10:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:11:41 | INFO | train_inner | epoch 021:     97 / 3059 symm_kl=0.399, self_kl=0, self_cv=9.432, loss=3.973, nll_loss=1.727, ppl=3.31, wps=14294.7, ups=1.22, wpb=11739.9, bsz=421.5, num_updates=57000, lr=1.05963e-05, gnorm=1.13, train_wall=51, wall=0
2020-12-22 04:12:33 | INFO | train_inner | epoch 021:    197 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.421, loss=3.974, nll_loss=1.734, ppl=3.33, wps=22913.9, ups=1.94, wpb=11827.4, bsz=399.6, num_updates=57100, lr=1.0587e-05, gnorm=1.116, train_wall=51, wall=0
2020-12-22 04:13:25 | INFO | train_inner | epoch 021:    297 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.382, loss=3.958, nll_loss=1.715, ppl=3.28, wps=22921.1, ups=1.93, wpb=11894.8, bsz=426.1, num_updates=57200, lr=1.05777e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 04:14:17 | INFO | train_inner | epoch 021:    397 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.426, loss=3.977, nll_loss=1.733, ppl=3.32, wps=22801.9, ups=1.92, wpb=11861.2, bsz=403.3, num_updates=57300, lr=1.05685e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:15:09 | INFO | train_inner | epoch 021:    497 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.403, loss=3.969, nll_loss=1.725, ppl=3.31, wps=22897.6, ups=1.93, wpb=11843.8, bsz=403.7, num_updates=57400, lr=1.05593e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 04:16:00 | INFO | train_inner | epoch 021:    597 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.366, loss=3.977, nll_loss=1.738, ppl=3.33, wps=22810.2, ups=1.93, wpb=11788.6, bsz=436.5, num_updates=57500, lr=1.05501e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:16:52 | INFO | train_inner | epoch 021:    697 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.393, loss=3.965, nll_loss=1.722, ppl=3.3, wps=22933.2, ups=1.93, wpb=11866.4, bsz=411.6, num_updates=57600, lr=1.05409e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 04:17:44 | INFO | train_inner | epoch 021:    797 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.387, loss=3.955, nll_loss=1.716, ppl=3.28, wps=22770.6, ups=1.93, wpb=11800.6, bsz=415, num_updates=57700, lr=1.05318e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 04:18:35 | INFO | train_inner | epoch 021:    897 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.417, loss=3.94, nll_loss=1.7, ppl=3.25, wps=22866.1, ups=1.94, wpb=11795.6, bsz=392.1, num_updates=57800, lr=1.05227e-05, gnorm=1.115, train_wall=51, wall=0
2020-12-22 04:19:28 | INFO | train_inner | epoch 021:    997 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.394, loss=3.939, nll_loss=1.703, ppl=3.26, wps=23007, ups=1.92, wpb=11970, bsz=427.5, num_updates=57900, lr=1.05136e-05, gnorm=1.092, train_wall=52, wall=0
2020-12-22 04:20:19 | INFO | train_inner | epoch 021:   1097 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.389, loss=3.957, nll_loss=1.716, ppl=3.28, wps=22952.7, ups=1.93, wpb=11894.1, bsz=404.8, num_updates=58000, lr=1.05045e-05, gnorm=1.104, train_wall=52, wall=0
2020-12-22 04:21:11 | INFO | train_inner | epoch 021:   1197 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.404, loss=3.958, nll_loss=1.717, ppl=3.29, wps=22926, ups=1.93, wpb=11873.1, bsz=403.6, num_updates=58100, lr=1.04955e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 04:22:03 | INFO | train_inner | epoch 021:   1297 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.402, loss=3.958, nll_loss=1.715, ppl=3.28, wps=23003.5, ups=1.93, wpb=11898.4, bsz=412.2, num_updates=58200, lr=1.04865e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 04:22:55 | INFO | train_inner | epoch 021:   1397 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.399, loss=3.971, nll_loss=1.73, ppl=3.32, wps=23031.6, ups=1.94, wpb=11899.5, bsz=408.5, num_updates=58300, lr=1.04775e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 04:23:46 | INFO | train_inner | epoch 021:   1497 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.353, loss=3.956, nll_loss=1.718, ppl=3.29, wps=22812.8, ups=1.93, wpb=11821.3, bsz=418.6, num_updates=58400, lr=1.04685e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 04:24:39 | INFO | train_inner | epoch 021:   1597 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.388, loss=3.955, nll_loss=1.716, ppl=3.29, wps=22842.7, ups=1.92, wpb=11925.3, bsz=409, num_updates=58500, lr=1.04595e-05, gnorm=1.124, train_wall=52, wall=0
2020-12-22 04:25:30 | INFO | train_inner | epoch 021:   1697 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.377, loss=3.939, nll_loss=1.701, ppl=3.25, wps=22887.8, ups=1.93, wpb=11870.2, bsz=411.6, num_updates=58600, lr=1.04506e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 04:26:22 | INFO | train_inner | epoch 021:   1797 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.367, loss=3.967, nll_loss=1.726, ppl=3.31, wps=22931.3, ups=1.94, wpb=11842.9, bsz=398.3, num_updates=58700, lr=1.04417e-05, gnorm=1.112, train_wall=51, wall=0
2020-12-22 04:27:14 | INFO | train_inner | epoch 021:   1897 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.408, loss=3.968, nll_loss=1.727, ppl=3.31, wps=22828.4, ups=1.93, wpb=11851.3, bsz=387.8, num_updates=58800, lr=1.04328e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:28:06 | INFO | train_inner | epoch 021:   1997 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.388, loss=3.968, nll_loss=1.73, ppl=3.32, wps=22812.4, ups=1.93, wpb=11804.1, bsz=421, num_updates=58900, lr=1.0424e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 04:28:58 | INFO | train_inner | epoch 021:   2097 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.401, loss=3.97, nll_loss=1.729, ppl=3.32, wps=22881.3, ups=1.93, wpb=11883.6, bsz=398.8, num_updates=59000, lr=1.04151e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 04:29:49 | INFO | train_inner | epoch 021:   2197 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.38, loss=3.959, nll_loss=1.72, ppl=3.29, wps=22724.6, ups=1.93, wpb=11778.9, bsz=411.4, num_updates=59100, lr=1.04063e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 04:30:41 | INFO | train_inner | epoch 021:   2297 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.402, loss=3.979, nll_loss=1.735, ppl=3.33, wps=22895.9, ups=1.93, wpb=11846.1, bsz=391.9, num_updates=59200, lr=1.03975e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:31:33 | INFO | train_inner | epoch 021:   2397 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.396, loss=3.975, nll_loss=1.732, ppl=3.32, wps=22695, ups=1.92, wpb=11809.3, bsz=411.8, num_updates=59300, lr=1.03887e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:32:25 | INFO | train_inner | epoch 021:   2497 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.363, loss=3.965, nll_loss=1.728, ppl=3.31, wps=23024.4, ups=1.93, wpb=11908.2, bsz=407.6, num_updates=59400, lr=1.038e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 04:33:17 | INFO | train_inner | epoch 021:   2597 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.425, loss=3.987, nll_loss=1.746, ppl=3.36, wps=22710.5, ups=1.93, wpb=11788.1, bsz=419.7, num_updates=59500, lr=1.03713e-05, gnorm=1.127, train_wall=52, wall=0
2020-12-22 04:34:09 | INFO | train_inner | epoch 021:   2697 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.386, loss=3.952, nll_loss=1.715, ppl=3.28, wps=22866.3, ups=1.92, wpb=11895.1, bsz=429.2, num_updates=59600, lr=1.03626e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 04:35:01 | INFO | train_inner | epoch 021:   2797 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.413, loss=3.984, nll_loss=1.743, ppl=3.35, wps=22892.1, ups=1.93, wpb=11878.2, bsz=391.9, num_updates=59700, lr=1.03539e-05, gnorm=1.124, train_wall=52, wall=0
2020-12-22 04:35:53 | INFO | train_inner | epoch 021:   2897 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.432, loss=3.936, nll_loss=1.701, ppl=3.25, wps=22689.8, ups=1.91, wpb=11855.7, bsz=414.1, num_updates=59800, lr=1.03452e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 04:36:45 | INFO | train_inner | epoch 021:   2997 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.385, loss=3.985, nll_loss=1.744, ppl=3.35, wps=22832.8, ups=1.93, wpb=11828.4, bsz=399.7, num_updates=59900, lr=1.03366e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 04:37:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 04:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 04:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 04:37:33 | INFO | valid | epoch 021 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.882 | nll_loss 7.848 | ppl 230.35 | bleu 16.46 | wps 5034.4 | wpb 6344.2 | bsz 166.4 | num_updates 59962 | best_bleu 16.67
2020-12-22 04:37:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 04:37:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 21 @ 59962 updates, score 16.46) (writing took 5.1370773278176785 seconds)
2020-12-22 04:37:38 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-12-22 04:37:38 | INFO | train | epoch 021 | symm_kl 0.395 | self_kl 0 | self_cv 9.395 | loss 3.964 | nll_loss 1.723 | ppl 3.3 | wps 22433.1 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 59962 | lr 1.03312e-05 | gnorm 1.114 | train_wall 1581 | wall 0
2020-12-22 04:37:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:41 | INFO | fairseq.trainer | begin training epoch 22
2020-12-22 04:37:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:37:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 04:37:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 04:38:07 | INFO | train_inner | epoch 022:     38 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.385, loss=3.96, nll_loss=1.721, ppl=3.3, wps=14464.5, ups=1.21, wpb=11914.9, bsz=400.9, num_updates=60000, lr=1.0328e-05, gnorm=1.101, train_wall=52, wall=0
2020-12-22 04:38:59 | INFO | train_inner | epoch 022:    138 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.398, loss=3.951, nll_loss=1.71, ppl=3.27, wps=23067.1, ups=1.94, wpb=11867.4, bsz=417.1, num_updates=60100, lr=1.03194e-05, gnorm=1.113, train_wall=51, wall=0
2020-12-22 04:39:51 | INFO | train_inner | epoch 022:    238 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.399, loss=3.974, nll_loss=1.73, ppl=3.32, wps=22762.4, ups=1.93, wpb=11812.9, bsz=409.2, num_updates=60200, lr=1.03108e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 04:40:42 | INFO | train_inner | epoch 022:    338 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.392, loss=3.951, nll_loss=1.716, ppl=3.29, wps=22991, ups=1.93, wpb=11909, bsz=438.8, num_updates=60300, lr=1.03022e-05, gnorm=1.107, train_wall=52, wall=0
2020-12-22 04:41:34 | INFO | train_inner | epoch 022:    438 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.408, loss=3.939, nll_loss=1.7, ppl=3.25, wps=22772.3, ups=1.93, wpb=11812.1, bsz=437.2, num_updates=60400, lr=1.02937e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 04:42:26 | INFO | train_inner | epoch 022:    538 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.395, loss=3.966, nll_loss=1.725, ppl=3.31, wps=22916.4, ups=1.93, wpb=11851.4, bsz=400.3, num_updates=60500, lr=1.02852e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 04:43:18 | INFO | train_inner | epoch 022:    638 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.418, loss=3.928, nll_loss=1.694, ppl=3.23, wps=22858.4, ups=1.92, wpb=11874.6, bsz=421.5, num_updates=60600, lr=1.02767e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 04:44:10 | INFO | train_inner | epoch 022:    738 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.406, loss=3.957, nll_loss=1.717, ppl=3.29, wps=22937.9, ups=1.93, wpb=11873, bsz=403.4, num_updates=60700, lr=1.02682e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 04:45:02 | INFO | train_inner | epoch 022:    838 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.383, loss=3.971, nll_loss=1.73, ppl=3.32, wps=22637.3, ups=1.92, wpb=11802.3, bsz=428.2, num_updates=60800, lr=1.02598e-05, gnorm=1.119, train_wall=52, wall=0
2020-12-22 04:45:54 | INFO | train_inner | epoch 022:    938 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.391, loss=3.948, nll_loss=1.711, ppl=3.27, wps=22968.3, ups=1.92, wpb=11958.1, bsz=406.2, num_updates=60900, lr=1.02514e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 04:46:46 | INFO | train_inner | epoch 022:   1038 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.377, loss=3.976, nll_loss=1.735, ppl=3.33, wps=22543.9, ups=1.92, wpb=11748.8, bsz=391.2, num_updates=61000, lr=1.0243e-05, gnorm=1.122, train_wall=52, wall=0
2020-12-22 04:47:38 | INFO | train_inner | epoch 022:   1138 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.395, loss=3.96, nll_loss=1.719, ppl=3.29, wps=22688.3, ups=1.92, wpb=11809.3, bsz=418.3, num_updates=61100, lr=1.02346e-05, gnorm=1.117, train_wall=52, wall=0
2020-12-22 04:48:30 | INFO | train_inner | epoch 022:   1238 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.407, loss=3.964, nll_loss=1.723, ppl=3.3, wps=22679.9, ups=1.92, wpb=11825.8, bsz=397.3, num_updates=61200, lr=1.02262e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-22 04:49:22 | INFO | train_inner | epoch 022:   1338 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.422, loss=3.966, nll_loss=1.728, ppl=3.31, wps=22770, ups=1.93, wpb=11807.2, bsz=392.7, num_updates=61300, lr=1.02179e-05, gnorm=1.128, train_wall=52, wall=0
2020-12-22 04:50:14 | INFO | train_inner | epoch 022:   1438 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.378, loss=3.977, nll_loss=1.738, ppl=3.34, wps=22937.2, ups=1.92, wpb=11926, bsz=420.7, num_updates=61400, lr=1.02095e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 04:51:06 | INFO | train_inner | epoch 022:   1538 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.405, loss=3.969, nll_loss=1.726, ppl=3.31, wps=22880.6, ups=1.93, wpb=11838.8, bsz=397.8, num_updates=61500, lr=1.02012e-05, gnorm=1.112, train_wall=52, wall=0
2020-12-22 04:51:58 | INFO | train_inner | epoch 022:   1638 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.387, loss=3.957, nll_loss=1.72, ppl=3.29, wps=22763.1, ups=1.93, wpb=11818.1, bsz=423.7, num_updates=61600, lr=1.01929e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 04:52:49 | INFO | train_inner | epoch 022:   1738 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.411, loss=3.954, nll_loss=1.716, ppl=3.28, wps=22836.4, ups=1.93, wpb=11814.3, bsz=391.8, num_updates=61700, lr=1.01847e-05, gnorm=1.126, train_wall=52, wall=0
2020-12-22 04:53:42 | INFO | train_inner | epoch 022:   1838 / 3059 symm_kl=0.398, self_kl=0, self_cv=9.364, loss=3.993, nll_loss=1.752, ppl=3.37, wps=22526, ups=1.91, wpb=11766, bsz=387.6, num_updates=61800, lr=1.01764e-05, gnorm=1.121, train_wall=52, wall=0
2020-12-22 04:54:33 | INFO | train_inner | epoch 022:   1938 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.417, loss=3.939, nll_loss=1.705, ppl=3.26, wps=22958.7, ups=1.93, wpb=11886.8, bsz=410, num_updates=61900, lr=1.01682e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 04:55:25 | INFO | train_inner | epoch 022:   2038 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.369, loss=3.949, nll_loss=1.716, ppl=3.29, wps=22800, ups=1.92, wpb=11874.8, bsz=419.2, num_updates=62000, lr=1.016e-05, gnorm=1.108, train_wall=52, wall=0
2020-12-22 04:56:18 | INFO | train_inner | epoch 022:   2138 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.379, loss=3.981, nll_loss=1.744, ppl=3.35, wps=22781, ups=1.91, wpb=11904.2, bsz=405.5, num_updates=62100, lr=1.01518e-05, gnorm=1.11, train_wall=52, wall=0
2020-12-22 04:57:10 | INFO | train_inner | epoch 022:   2238 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.359, loss=3.967, nll_loss=1.731, ppl=3.32, wps=22914.5, ups=1.93, wpb=11869.7, bsz=417.5, num_updates=62200, lr=1.01437e-05, gnorm=1.109, train_wall=52, wall=0
2020-12-22 04:58:02 | INFO | train_inner | epoch 022:   2338 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.402, loss=3.96, nll_loss=1.723, ppl=3.3, wps=22851.6, ups=1.92, wpb=11875.5, bsz=386.1, num_updates=62300, lr=1.01355e-05, gnorm=1.106, train_wall=52, wall=0
2020-12-22 04:58:54 | INFO | train_inner | epoch 022:   2438 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.396, loss=3.982, nll_loss=1.743, ppl=3.35, wps=22525.9, ups=1.91, wpb=11802.7, bsz=425.9, num_updates=62400, lr=1.01274e-05, gnorm=1.12, train_wall=52, wall=0
2020-12-22 04:59:46 | INFO | train_inner | epoch 022:   2538 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.375, loss=3.967, nll_loss=1.73, ppl=3.32, wps=22907.2, ups=1.93, wpb=11880, bsz=415.8, num_updates=62500, lr=1.01193e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 05:00:38 | INFO | train_inner | epoch 022:   2638 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.387, loss=3.937, nll_loss=1.704, ppl=3.26, wps=22824.5, ups=1.92, wpb=11909.5, bsz=422.6, num_updates=62600, lr=1.01112e-05, gnorm=1.1, train_wall=52, wall=0
2020-12-22 05:01:30 | INFO | train_inner | epoch 022:   2738 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.425, loss=3.961, nll_loss=1.723, ppl=3.3, wps=22918.2, ups=1.93, wpb=11875.1, bsz=397.2, num_updates=62700, lr=1.01031e-05, gnorm=1.127, train_wall=52, wall=0
2020-12-22 05:02:22 | INFO | train_inner | epoch 022:   2838 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.38, loss=3.976, nll_loss=1.74, ppl=3.34, wps=22807.1, ups=1.93, wpb=11820.8, bsz=396.6, num_updates=62800, lr=1.00951e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 05:03:14 | INFO | train_inner | epoch 022:   2938 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.392, loss=3.966, nll_loss=1.726, ppl=3.31, wps=22725.1, ups=1.91, wpb=11891.3, bsz=425, num_updates=62900, lr=1.00871e-05, gnorm=1.115, train_wall=52, wall=0
2020-12-22 05:04:06 | INFO | train_inner | epoch 022:   3038 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.39, loss=3.96, nll_loss=1.722, ppl=3.3, wps=22891.5, ups=1.93, wpb=11857.7, bsz=394.7, num_updates=63000, lr=1.00791e-05, gnorm=1.116, train_wall=52, wall=0
2020-12-22 05:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 05:04:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 05:04:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 05:04:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 05:04:32 | INFO | valid | epoch 022 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.872 | nll_loss 7.838 | ppl 228.84 | bleu 16.73 | wps 5017 | wpb 6344.2 | bsz 166.4 | num_updates 63021 | best_bleu 16.73
2020-12-22 05:04:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 05:04:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_best.pt (epoch 22 @ 63021 updates, score 16.73) (writing took 8.480433551594615 seconds)
2020-12-22 05:04:41 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-12-22 05:04:41 | INFO | train | epoch 022 | symm_kl 0.393 | self_kl 0 | self_cv 9.394 | loss 3.962 | nll_loss 1.723 | ppl 3.3 | wps 22343 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 63021 | lr 1.00774e-05 | gnorm 1.115 | train_wall 1584 | wall 0
2020-12-22 05:04:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:04:44 | INFO | fairseq.trainer | begin training epoch 23
2020-12-22 05:04:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:04:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:05:31 | INFO | train_inner | epoch 023:     79 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.361, loss=3.963, nll_loss=1.726, ppl=3.31, wps=13844.1, ups=1.17, wpb=11836.8, bsz=421.2, num_updates=63100, lr=1.00711e-05, gnorm=1.109, train_wall=51, wall=0
2020-12-22 05:06:23 | INFO | train_inner | epoch 023:    179 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.394, loss=3.955, nll_loss=1.715, ppl=3.28, wps=22869.2, ups=1.93, wpb=11877.3, bsz=393.1, num_updates=63200, lr=1.00631e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 05:07:15 | INFO | train_inner | epoch 023:    279 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.386, loss=3.947, nll_loss=1.71, ppl=3.27, wps=22890.7, ups=1.92, wpb=11913.8, bsz=419.6, num_updates=63300, lr=1.00551e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 05:08:07 | INFO | train_inner | epoch 023:    379 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.397, loss=3.957, nll_loss=1.718, ppl=3.29, wps=22911.1, ups=1.93, wpb=11898.4, bsz=403.9, num_updates=63400, lr=1.00472e-05, gnorm=1.114, train_wall=52, wall=0
2020-12-22 05:08:59 | INFO | train_inner | epoch 023:    479 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.381, loss=3.964, nll_loss=1.721, ppl=3.3, wps=22794.7, ups=1.93, wpb=11840.1, bsz=409.5, num_updates=63500, lr=1.00393e-05, gnorm=1.123, train_wall=52, wall=0
2020-12-22 05:09:51 | INFO | train_inner | epoch 023:    579 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.418, loss=3.939, nll_loss=1.703, ppl=3.26, wps=22970.1, ups=1.93, wpb=11912.6, bsz=413.9, num_updates=63600, lr=1.00314e-05, gnorm=1.105, train_wall=52, wall=0
2020-12-22 05:10:43 | INFO | train_inner | epoch 023:    679 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.387, loss=3.932, nll_loss=1.695, ppl=3.24, wps=22868.4, ups=1.92, wpb=11920, bsz=416.2, num_updates=63700, lr=1.00235e-05, gnorm=1.102, train_wall=52, wall=0
2020-12-22 05:11:35 | INFO | train_inner | epoch 023:    779 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.411, loss=3.964, nll_loss=1.726, ppl=3.31, wps=22765, ups=1.93, wpb=11810, bsz=409.5, num_updates=63800, lr=1.00157e-05, gnorm=1.113, train_wall=52, wall=0
2020-12-22 05:12:27 | INFO | train_inner | epoch 023:    879 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.394, loss=3.963, nll_loss=1.726, ppl=3.31, wps=22879.1, ups=1.93, wpb=11878.2, bsz=398.1, num_updates=63900, lr=1.00078e-05, gnorm=1.111, train_wall=52, wall=0
2020-12-22 05:13:18 | INFO | train_inner | epoch 023:    979 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.368, loss=3.966, nll_loss=1.732, ppl=3.32, wps=22938.5, ups=1.94, wpb=11832, bsz=418.2, num_updates=64000, lr=1e-05, gnorm=1.119, train_wall=51, wall=0
2020-12-22 05:14:10 | INFO | train_inner | epoch 023:   1079 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.393, loss=3.962, nll_loss=1.724, ppl=3.3, wps=22807.3, ups=1.92, wpb=11854.2, bsz=392, num_updates=64100, lr=9.9922e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 05:15:02 | INFO | train_inner | epoch 023:   1179 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.377, loss=3.942, nll_loss=1.709, ppl=3.27, wps=23097, ups=1.93, wpb=11940.8, bsz=419.7, num_updates=64200, lr=9.98441e-06, gnorm=1.103, train_wall=52, wall=0
2020-12-22 05:15:54 | INFO | train_inner | epoch 023:   1279 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.386, loss=3.924, nll_loss=1.692, ppl=3.23, wps=23079.6, ups=1.92, wpb=11999.9, bsz=419.1, num_updates=64300, lr=9.97664e-06, gnorm=1.094, train_wall=52, wall=0
2020-12-22 05:16:46 | INFO | train_inner | epoch 023:   1379 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.381, loss=3.967, nll_loss=1.73, ppl=3.32, wps=22720.1, ups=1.93, wpb=11774, bsz=412.5, num_updates=64400, lr=9.9689e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 05:17:38 | INFO | train_inner | epoch 023:   1479 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.435, loss=3.979, nll_loss=1.739, ppl=3.34, wps=22592.3, ups=1.92, wpb=11747.6, bsz=396.7, num_updates=64500, lr=9.96116e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 05:18:30 | INFO | train_inner | epoch 023:   1579 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.403, loss=3.964, nll_loss=1.725, ppl=3.31, wps=22646.5, ups=1.92, wpb=11774.1, bsz=403.8, num_updates=64600, lr=9.95345e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 05:19:22 | INFO | train_inner | epoch 023:   1679 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.399, loss=3.956, nll_loss=1.72, ppl=3.3, wps=22833.8, ups=1.94, wpb=11794.8, bsz=417.9, num_updates=64700, lr=9.94576e-06, gnorm=1.117, train_wall=51, wall=0
2020-12-22 05:20:14 | INFO | train_inner | epoch 023:   1779 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.363, loss=3.945, nll_loss=1.712, ppl=3.28, wps=22765.9, ups=1.92, wpb=11828.3, bsz=447.3, num_updates=64800, lr=9.93808e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 05:21:05 | INFO | train_inner | epoch 023:   1879 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.366, loss=3.984, nll_loss=1.746, ppl=3.36, wps=22924, ups=1.94, wpb=11806.2, bsz=418.3, num_updates=64900, lr=9.93042e-06, gnorm=1.122, train_wall=51, wall=0
2020-12-22 05:21:57 | INFO | train_inner | epoch 023:   1979 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.381, loss=3.975, nll_loss=1.735, ppl=3.33, wps=22761.1, ups=1.93, wpb=11811.5, bsz=386.6, num_updates=65000, lr=9.92278e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 05:22:49 | INFO | train_inner | epoch 023:   2079 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.401, loss=3.984, nll_loss=1.746, ppl=3.35, wps=22716.8, ups=1.93, wpb=11777.7, bsz=416.2, num_updates=65100, lr=9.91515e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 05:23:40 | INFO | train_inner | epoch 023:   2179 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.401, loss=3.96, nll_loss=1.725, ppl=3.31, wps=23023.9, ups=1.94, wpb=11867.1, bsz=389.4, num_updates=65200, lr=9.90755e-06, gnorm=1.118, train_wall=51, wall=0
2020-12-22 05:24:32 | INFO | train_inner | epoch 023:   2279 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.375, loss=3.975, nll_loss=1.739, ppl=3.34, wps=22866.2, ups=1.94, wpb=11813, bsz=409, num_updates=65300, lr=9.89996e-06, gnorm=1.117, train_wall=51, wall=0
2020-12-22 05:25:24 | INFO | train_inner | epoch 023:   2379 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.406, loss=3.957, nll_loss=1.722, ppl=3.3, wps=22951.5, ups=1.93, wpb=11903.6, bsz=391.8, num_updates=65400, lr=9.89239e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 05:26:16 | INFO | train_inner | epoch 023:   2479 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.419, loss=3.957, nll_loss=1.719, ppl=3.29, wps=22773.4, ups=1.91, wpb=11897.7, bsz=415.6, num_updates=65500, lr=9.88483e-06, gnorm=1.108, train_wall=52, wall=0
2020-12-22 05:27:08 | INFO | train_inner | epoch 023:   2579 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.366, loss=3.949, nll_loss=1.717, ppl=3.29, wps=22839.9, ups=1.92, wpb=11918.8, bsz=436.2, num_updates=65600, lr=9.8773e-06, gnorm=1.104, train_wall=52, wall=0
2020-12-22 05:28:01 | INFO | train_inner | epoch 023:   2679 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.404, loss=3.967, nll_loss=1.732, ppl=3.32, wps=22679.4, ups=1.91, wpb=11843.5, bsz=396.9, num_updates=65700, lr=9.86978e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 05:28:52 | INFO | train_inner | epoch 023:   2779 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.384, loss=3.965, nll_loss=1.733, ppl=3.32, wps=22741.7, ups=1.93, wpb=11808.1, bsz=423.9, num_updates=65800, lr=9.86227e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 05:29:44 | INFO | train_inner | epoch 023:   2879 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.414, loss=3.971, nll_loss=1.734, ppl=3.33, wps=22920.5, ups=1.93, wpb=11849.6, bsz=391.1, num_updates=65900, lr=9.85479e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 05:30:36 | INFO | train_inner | epoch 023:   2979 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.392, loss=3.958, nll_loss=1.725, ppl=3.3, wps=22826.3, ups=1.93, wpb=11853.3, bsz=421, num_updates=66000, lr=9.84732e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 05:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 05:31:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 05:31:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 05:31:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 05:31:33 | INFO | valid | epoch 023 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.863 | nll_loss 7.827 | ppl 227.1 | bleu 16.59 | wps 4996 | wpb 6344.2 | bsz 166.4 | num_updates 66080 | best_bleu 16.73
2020-12-22 05:31:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 05:31:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 23 @ 66080 updates, score 16.59) (writing took 5.119787253439426 seconds)
2020-12-22 05:31:38 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-12-22 05:31:38 | INFO | train | epoch 023 | symm_kl 0.392 | self_kl 0 | self_cv 9.392 | loss 3.96 | nll_loss 1.723 | ppl 3.3 | wps 22411.7 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 66080 | lr 9.84136e-06 | gnorm 1.115 | train_wall 1582 | wall 0
2020-12-22 05:31:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:42 | INFO | fairseq.trainer | begin training epoch 24
2020-12-22 05:31:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:31:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:31:58 | INFO | train_inner | epoch 024:     20 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.412, loss=3.965, nll_loss=1.728, ppl=3.31, wps=14359.6, ups=1.22, wpb=11800.3, bsz=396.4, num_updates=66100, lr=9.83987e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 05:32:50 | INFO | train_inner | epoch 024:    120 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.36, loss=3.965, nll_loss=1.73, ppl=3.32, wps=23104.3, ups=1.94, wpb=11879, bsz=420.9, num_updates=66200, lr=9.83243e-06, gnorm=1.114, train_wall=51, wall=0
2020-12-22 05:33:42 | INFO | train_inner | epoch 024:    220 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.448, loss=3.977, nll_loss=1.737, ppl=3.33, wps=22600.2, ups=1.92, wpb=11780.5, bsz=422.9, num_updates=66300, lr=9.82502e-06, gnorm=1.143, train_wall=52, wall=0
2020-12-22 05:34:34 | INFO | train_inner | epoch 024:    320 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.391, loss=3.936, nll_loss=1.703, ppl=3.26, wps=22855.5, ups=1.93, wpb=11846.2, bsz=415.6, num_updates=66400, lr=9.81761e-06, gnorm=1.108, train_wall=52, wall=0
2020-12-22 05:35:26 | INFO | train_inner | epoch 024:    420 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.41, loss=3.951, nll_loss=1.714, ppl=3.28, wps=22785.7, ups=1.92, wpb=11870.4, bsz=445.4, num_updates=66500, lr=9.81023e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 05:36:17 | INFO | train_inner | epoch 024:    520 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.43, loss=3.956, nll_loss=1.72, ppl=3.3, wps=22915, ups=1.93, wpb=11861.3, bsz=414.3, num_updates=66600, lr=9.80286e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 05:37:09 | INFO | train_inner | epoch 024:    620 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.41, loss=3.951, nll_loss=1.714, ppl=3.28, wps=22976.8, ups=1.94, wpb=11825, bsz=411.6, num_updates=66700, lr=9.79551e-06, gnorm=1.116, train_wall=51, wall=0
2020-12-22 05:38:01 | INFO | train_inner | epoch 024:    720 / 3059 symm_kl=0.396, self_kl=0, self_cv=9.402, loss=3.979, nll_loss=1.739, ppl=3.34, wps=22776.3, ups=1.93, wpb=11803, bsz=386.5, num_updates=66800, lr=9.78818e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 05:38:53 | INFO | train_inner | epoch 024:    820 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.364, loss=3.948, nll_loss=1.713, ppl=3.28, wps=22899.6, ups=1.93, wpb=11889.2, bsz=427.6, num_updates=66900, lr=9.78086e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 05:39:45 | INFO | train_inner | epoch 024:    920 / 3059 symm_kl=0.4, self_kl=0, self_cv=9.377, loss=4, nll_loss=1.756, ppl=3.38, wps=22603.9, ups=1.93, wpb=11717.4, bsz=389.3, num_updates=67000, lr=9.77356e-06, gnorm=1.145, train_wall=52, wall=0
2020-12-22 05:40:36 | INFO | train_inner | epoch 024:   1020 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.385, loss=3.959, nll_loss=1.723, ppl=3.3, wps=22847.8, ups=1.93, wpb=11841.4, bsz=423.1, num_updates=67100, lr=9.76627e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 05:41:28 | INFO | train_inner | epoch 024:   1120 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.399, loss=3.952, nll_loss=1.717, ppl=3.29, wps=22912.1, ups=1.92, wpb=11919.1, bsz=428.8, num_updates=67200, lr=9.759e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 05:42:20 | INFO | train_inner | epoch 024:   1220 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.41, loss=3.963, nll_loss=1.729, ppl=3.31, wps=22736, ups=1.93, wpb=11764.7, bsz=392.5, num_updates=67300, lr=9.75175e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 05:43:12 | INFO | train_inner | epoch 024:   1320 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.408, loss=3.942, nll_loss=1.709, ppl=3.27, wps=22666.1, ups=1.92, wpb=11832.2, bsz=414.9, num_updates=67400, lr=9.74451e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 05:44:04 | INFO | train_inner | epoch 024:   1420 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.39, loss=3.953, nll_loss=1.719, ppl=3.29, wps=22760.4, ups=1.92, wpb=11829.9, bsz=403.1, num_updates=67500, lr=9.73729e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 05:44:56 | INFO | train_inner | epoch 024:   1520 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.388, loss=3.992, nll_loss=1.756, ppl=3.38, wps=23050.8, ups=1.93, wpb=11927.8, bsz=408.2, num_updates=67600, lr=9.73009e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 05:45:48 | INFO | train_inner | epoch 024:   1620 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.377, loss=3.94, nll_loss=1.706, ppl=3.26, wps=22840, ups=1.92, wpb=11877.4, bsz=415.1, num_updates=67700, lr=9.7229e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 05:46:40 | INFO | train_inner | epoch 024:   1720 / 3059 symm_kl=0.397, self_kl=0, self_cv=9.402, loss=3.978, nll_loss=1.737, ppl=3.33, wps=22662.2, ups=1.93, wpb=11738.6, bsz=392.4, num_updates=67800, lr=9.71572e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 05:47:32 | INFO | train_inner | epoch 024:   1820 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.426, loss=3.968, nll_loss=1.732, ppl=3.32, wps=22803, ups=1.93, wpb=11820.8, bsz=399.9, num_updates=67900, lr=9.70857e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 05:48:24 | INFO | train_inner | epoch 024:   1920 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.396, loss=3.943, nll_loss=1.708, ppl=3.27, wps=22934.2, ups=1.92, wpb=11914.9, bsz=376.4, num_updates=68000, lr=9.70143e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 05:49:15 | INFO | train_inner | epoch 024:   2020 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.413, loss=3.951, nll_loss=1.715, ppl=3.28, wps=22996.8, ups=1.93, wpb=11913.1, bsz=392.6, num_updates=68100, lr=9.6943e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 05:50:07 | INFO | train_inner | epoch 024:   2120 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.36, loss=3.943, nll_loss=1.714, ppl=3.28, wps=22909.2, ups=1.94, wpb=11837.8, bsz=413.6, num_updates=68200, lr=9.68719e-06, gnorm=1.1, train_wall=52, wall=0
2020-12-22 05:50:59 | INFO | train_inner | epoch 024:   2220 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.37, loss=3.958, nll_loss=1.727, ppl=3.31, wps=22893, ups=1.92, wpb=11913.8, bsz=420.1, num_updates=68300, lr=9.6801e-06, gnorm=1.102, train_wall=52, wall=0
2020-12-22 05:51:51 | INFO | train_inner | epoch 024:   2320 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.365, loss=3.954, nll_loss=1.723, ppl=3.3, wps=22991.9, ups=1.93, wpb=11933.4, bsz=402.6, num_updates=68400, lr=9.67302e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 05:52:43 | INFO | train_inner | epoch 024:   2420 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.384, loss=3.959, nll_loss=1.723, ppl=3.3, wps=22959.9, ups=1.94, wpb=11837, bsz=414.4, num_updates=68500, lr=9.66595e-06, gnorm=1.116, train_wall=51, wall=0
2020-12-22 05:53:34 | INFO | train_inner | epoch 024:   2520 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.375, loss=3.935, nll_loss=1.705, ppl=3.26, wps=23003.8, ups=1.93, wpb=11931.3, bsz=418.2, num_updates=68600, lr=9.65891e-06, gnorm=1.106, train_wall=52, wall=0
2020-12-22 05:54:26 | INFO | train_inner | epoch 024:   2620 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.389, loss=3.931, nll_loss=1.701, ppl=3.25, wps=22868.9, ups=1.93, wpb=11866.4, bsz=409.7, num_updates=68700, lr=9.65187e-06, gnorm=1.106, train_wall=52, wall=0
2020-12-22 05:55:18 | INFO | train_inner | epoch 024:   2720 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.359, loss=3.956, nll_loss=1.724, ppl=3.3, wps=23004.7, ups=1.93, wpb=11907.4, bsz=386.6, num_updates=68800, lr=9.64486e-06, gnorm=1.106, train_wall=52, wall=0
2020-12-22 05:56:10 | INFO | train_inner | epoch 024:   2820 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.373, loss=3.972, nll_loss=1.736, ppl=3.33, wps=22796.7, ups=1.93, wpb=11840.8, bsz=408.3, num_updates=68900, lr=9.63785e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 05:57:02 | INFO | train_inner | epoch 024:   2920 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.407, loss=3.973, nll_loss=1.739, ppl=3.34, wps=22689.5, ups=1.92, wpb=11802.9, bsz=404.3, num_updates=69000, lr=9.63087e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 05:57:54 | INFO | train_inner | epoch 024:   3020 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.371, loss=3.968, nll_loss=1.735, ppl=3.33, wps=22720.7, ups=1.92, wpb=11856.4, bsz=412.2, num_updates=69100, lr=9.6239e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 05:58:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 05:58:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 05:58:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 05:58:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 05:58:32 | INFO | valid | epoch 024 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.878 | nll_loss 7.844 | ppl 229.79 | bleu 16.63 | wps 4432.8 | wpb 6344.2 | bsz 166.4 | num_updates 69139 | best_bleu 16.73
2020-12-22 05:58:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 05:58:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 24 @ 69139 updates, score 16.63) (writing took 4.658897466957569 seconds)
2020-12-22 05:58:36 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-12-22 05:58:36 | INFO | train | epoch 024 | symm_kl 0.391 | self_kl 0 | self_cv 9.391 | loss 3.958 | nll_loss 1.723 | ppl 3.3 | wps 22408.8 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 69139 | lr 9.62118e-06 | gnorm 1.116 | train_wall 1582 | wall 0
2020-12-22 05:58:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:40 | INFO | fairseq.trainer | begin training epoch 25
2020-12-22 05:58:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:58:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 05:58:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 05:59:17 | INFO | train_inner | epoch 025:     61 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.388, loss=3.929, nll_loss=1.7, ppl=3.25, wps=14341, ups=1.21, wpb=11878.3, bsz=424.9, num_updates=69200, lr=9.61694e-06, gnorm=1.11, train_wall=51, wall=0
2020-12-22 06:00:09 | INFO | train_inner | epoch 025:    161 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.411, loss=3.928, nll_loss=1.695, ppl=3.24, wps=22884.6, ups=1.93, wpb=11838, bsz=391, num_updates=69300, lr=9.61e-06, gnorm=1.108, train_wall=52, wall=0
2020-12-22 06:01:01 | INFO | train_inner | epoch 025:    261 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.416, loss=3.968, nll_loss=1.731, ppl=3.32, wps=22830, ups=1.92, wpb=11865.7, bsz=405.2, num_updates=69400, lr=9.60307e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 06:01:53 | INFO | train_inner | epoch 025:    361 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.379, loss=3.955, nll_loss=1.719, ppl=3.29, wps=22971.7, ups=1.92, wpb=11935.5, bsz=400.7, num_updates=69500, lr=9.59616e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 06:02:45 | INFO | train_inner | epoch 025:    461 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.365, loss=3.957, nll_loss=1.722, ppl=3.3, wps=22813.4, ups=1.93, wpb=11840.7, bsz=406.1, num_updates=69600, lr=9.58927e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 06:03:37 | INFO | train_inner | epoch 025:    561 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.367, loss=3.93, nll_loss=1.703, ppl=3.26, wps=22903.6, ups=1.91, wpb=11965.3, bsz=428.2, num_updates=69700, lr=9.58238e-06, gnorm=1.1, train_wall=52, wall=0
2020-12-22 06:04:29 | INFO | train_inner | epoch 025:    661 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.422, loss=3.972, nll_loss=1.735, ppl=3.33, wps=22747.5, ups=1.92, wpb=11845.6, bsz=383.8, num_updates=69800, lr=9.57552e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 06:05:21 | INFO | train_inner | epoch 025:    761 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.403, loss=3.951, nll_loss=1.718, ppl=3.29, wps=22778.4, ups=1.92, wpb=11868.9, bsz=401.2, num_updates=69900, lr=9.56867e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 06:06:13 | INFO | train_inner | epoch 025:    861 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.403, loss=3.931, nll_loss=1.7, ppl=3.25, wps=22939, ups=1.93, wpb=11907.6, bsz=414.2, num_updates=70000, lr=9.56183e-06, gnorm=1.101, train_wall=52, wall=0
2020-12-22 06:07:05 | INFO | train_inner | epoch 025:    961 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.38, loss=3.965, nll_loss=1.733, ppl=3.32, wps=22919.6, ups=1.94, wpb=11822.4, bsz=413.4, num_updates=70100, lr=9.55501e-06, gnorm=1.12, train_wall=51, wall=0
2020-12-22 06:07:57 | INFO | train_inner | epoch 025:   1061 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.369, loss=3.955, nll_loss=1.717, ppl=3.29, wps=22846.9, ups=1.92, wpb=11895.2, bsz=407.4, num_updates=70200, lr=9.5482e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 06:08:48 | INFO | train_inner | epoch 025:   1161 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.385, loss=3.938, nll_loss=1.704, ppl=3.26, wps=23012, ups=1.93, wpb=11919.7, bsz=422.3, num_updates=70300, lr=9.5414e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 06:09:40 | INFO | train_inner | epoch 025:   1261 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.394, loss=3.965, nll_loss=1.732, ppl=3.32, wps=22781.3, ups=1.92, wpb=11840.8, bsz=413.6, num_updates=70400, lr=9.53463e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 06:10:32 | INFO | train_inner | epoch 025:   1361 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.372, loss=3.951, nll_loss=1.719, ppl=3.29, wps=22891.3, ups=1.93, wpb=11879.7, bsz=416.5, num_updates=70500, lr=9.52786e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 06:11:25 | INFO | train_inner | epoch 025:   1461 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.382, loss=3.955, nll_loss=1.722, ppl=3.3, wps=22689.9, ups=1.92, wpb=11841.1, bsz=407.5, num_updates=70600, lr=9.52111e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 06:12:16 | INFO | train_inner | epoch 025:   1561 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.387, loss=3.965, nll_loss=1.73, ppl=3.32, wps=22748, ups=1.93, wpb=11803.8, bsz=390.7, num_updates=70700, lr=9.51438e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 06:13:08 | INFO | train_inner | epoch 025:   1661 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.375, loss=3.931, nll_loss=1.704, ppl=3.26, wps=22822.2, ups=1.93, wpb=11842.7, bsz=449.8, num_updates=70800, lr=9.50765e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 06:14:00 | INFO | train_inner | epoch 025:   1761 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.394, loss=3.952, nll_loss=1.717, ppl=3.29, wps=22801.8, ups=1.92, wpb=11860.3, bsz=418.5, num_updates=70900, lr=9.50095e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:14:52 | INFO | train_inner | epoch 025:   1861 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.379, loss=3.958, nll_loss=1.725, ppl=3.31, wps=22844.5, ups=1.92, wpb=11913.7, bsz=391, num_updates=71000, lr=9.49425e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:15:45 | INFO | train_inner | epoch 025:   1961 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.387, loss=3.953, nll_loss=1.72, ppl=3.29, wps=22857.2, ups=1.92, wpb=11915.2, bsz=420.6, num_updates=71100, lr=9.48757e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 06:16:37 | INFO | train_inner | epoch 025:   2061 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.364, loss=3.96, nll_loss=1.727, ppl=3.31, wps=22877, ups=1.92, wpb=11923.2, bsz=437.8, num_updates=71200, lr=9.48091e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 06:17:29 | INFO | train_inner | epoch 025:   2161 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.412, loss=3.972, nll_loss=1.737, ppl=3.33, wps=22569.5, ups=1.92, wpb=11744.6, bsz=401.5, num_updates=71300, lr=9.47426e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 06:18:21 | INFO | train_inner | epoch 025:   2261 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.443, loss=3.964, nll_loss=1.731, ppl=3.32, wps=22744.4, ups=1.92, wpb=11834.3, bsz=399.1, num_updates=71400, lr=9.46762e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 06:19:13 | INFO | train_inner | epoch 025:   2361 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.415, loss=3.949, nll_loss=1.714, ppl=3.28, wps=22720.8, ups=1.92, wpb=11811.8, bsz=394.4, num_updates=71500, lr=9.461e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 06:20:05 | INFO | train_inner | epoch 025:   2461 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.385, loss=3.982, nll_loss=1.749, ppl=3.36, wps=22682.4, ups=1.92, wpb=11795.5, bsz=402.6, num_updates=71600, lr=9.45439e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 06:20:57 | INFO | train_inner | epoch 025:   2561 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.366, loss=3.955, nll_loss=1.725, ppl=3.3, wps=22765.5, ups=1.93, wpb=11806.8, bsz=412.5, num_updates=71700, lr=9.44779e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 06:21:49 | INFO | train_inner | epoch 025:   2661 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.38, loss=3.965, nll_loss=1.731, ppl=3.32, wps=22742.1, ups=1.92, wpb=11821.7, bsz=403.8, num_updates=71800, lr=9.44121e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 06:22:41 | INFO | train_inner | epoch 025:   2761 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.414, loss=3.967, nll_loss=1.736, ppl=3.33, wps=22768, ups=1.92, wpb=11855.9, bsz=412.9, num_updates=71900, lr=9.43464e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 06:23:32 | INFO | train_inner | epoch 025:   2861 / 3059 symm_kl=0.395, self_kl=0, self_cv=9.411, loss=3.992, nll_loss=1.755, ppl=3.38, wps=22742, ups=1.93, wpb=11761, bsz=394, num_updates=72000, lr=9.42809e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 06:24:24 | INFO | train_inner | epoch 025:   2961 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.364, loss=3.969, nll_loss=1.736, ppl=3.33, wps=22631.5, ups=1.93, wpb=11747.9, bsz=404.5, num_updates=72100, lr=9.42155e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 06:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 06:25:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 06:25:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 06:25:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 06:25:31 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.882 | nll_loss 7.849 | ppl 230.59 | bleu 16.58 | wps 4969.8 | wpb 6344.2 | bsz 166.4 | num_updates 72198 | best_bleu 16.73
2020-12-22 06:25:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 06:25:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 25 @ 72198 updates, score 16.58) (writing took 5.076864609494805 seconds)
2020-12-22 06:25:36 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-12-22 06:25:36 | INFO | train | epoch 025 | symm_kl 0.39 | self_kl 0 | self_cv 9.39 | loss 3.956 | nll_loss 1.723 | ppl 3.3 | wps 22383.3 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 72198 | lr 9.41515e-06 | gnorm 1.117 | train_wall 1584 | wall 0
2020-12-22 06:25:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:39 | INFO | fairseq.trainer | begin training epoch 26
2020-12-22 06:25:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:25:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:25:47 | INFO | train_inner | epoch 026:      2 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.398, loss=3.939, nll_loss=1.712, ppl=3.28, wps=14379.8, ups=1.21, wpb=11839.3, bsz=440.4, num_updates=72200, lr=9.41502e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 06:26:38 | INFO | train_inner | epoch 026:    102 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.369, loss=3.96, nll_loss=1.73, ppl=3.32, wps=23063.4, ups=1.94, wpb=11868.1, bsz=419, num_updates=72300, lr=9.40851e-06, gnorm=1.121, train_wall=51, wall=0
2020-12-22 06:27:30 | INFO | train_inner | epoch 026:    202 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.407, loss=3.958, nll_loss=1.723, ppl=3.3, wps=22937, ups=1.94, wpb=11846.5, bsz=400.5, num_updates=72400, lr=9.40201e-06, gnorm=1.119, train_wall=51, wall=0
2020-12-22 06:28:22 | INFO | train_inner | epoch 026:    302 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.402, loss=3.956, nll_loss=1.723, ppl=3.3, wps=22753.9, ups=1.93, wpb=11798, bsz=416.3, num_updates=72500, lr=9.39552e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 06:29:14 | INFO | train_inner | epoch 026:    402 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.383, loss=3.928, nll_loss=1.701, ppl=3.25, wps=22796.9, ups=1.92, wpb=11844.6, bsz=417.4, num_updates=72600, lr=9.38905e-06, gnorm=1.108, train_wall=52, wall=0
2020-12-22 06:30:05 | INFO | train_inner | epoch 026:    502 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.422, loss=3.944, nll_loss=1.71, ppl=3.27, wps=22871.5, ups=1.93, wpb=11836.9, bsz=404.1, num_updates=72700, lr=9.38259e-06, gnorm=1.132, train_wall=52, wall=0
2020-12-22 06:30:57 | INFO | train_inner | epoch 026:    602 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.389, loss=3.951, nll_loss=1.717, ppl=3.29, wps=22929.5, ups=1.92, wpb=11922.4, bsz=419.8, num_updates=72800, lr=9.37614e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 06:31:49 | INFO | train_inner | epoch 026:    702 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.399, loss=3.95, nll_loss=1.716, ppl=3.29, wps=22830.2, ups=1.93, wpb=11846.7, bsz=414.6, num_updates=72900, lr=9.36971e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 06:32:41 | INFO | train_inner | epoch 026:    802 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.365, loss=3.979, nll_loss=1.746, ppl=3.35, wps=22715.4, ups=1.92, wpb=11810.5, bsz=422.7, num_updates=73000, lr=9.36329e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 06:33:33 | INFO | train_inner | epoch 026:    902 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.383, loss=3.94, nll_loss=1.71, ppl=3.27, wps=23023.4, ups=1.93, wpb=11932.6, bsz=424.9, num_updates=73100, lr=9.35689e-06, gnorm=1.104, train_wall=52, wall=0
2020-12-22 06:34:25 | INFO | train_inner | epoch 026:   1002 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.416, loss=3.951, nll_loss=1.722, ppl=3.3, wps=22806.7, ups=1.93, wpb=11796.5, bsz=402.7, num_updates=73200, lr=9.35049e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 06:35:17 | INFO | train_inner | epoch 026:   1102 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.396, loss=3.938, nll_loss=1.709, ppl=3.27, wps=22964.4, ups=1.93, wpb=11922.6, bsz=418.1, num_updates=73300, lr=9.34411e-06, gnorm=1.105, train_wall=52, wall=0
2020-12-22 06:36:09 | INFO | train_inner | epoch 026:   1202 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.377, loss=3.966, nll_loss=1.734, ppl=3.33, wps=22830.9, ups=1.92, wpb=11864.4, bsz=408.3, num_updates=73400, lr=9.33774e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:37:01 | INFO | train_inner | epoch 026:   1302 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.387, loss=3.944, nll_loss=1.715, ppl=3.28, wps=22846.6, ups=1.92, wpb=11880.9, bsz=420.3, num_updates=73500, lr=9.33139e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 06:37:53 | INFO | train_inner | epoch 026:   1402 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.421, loss=3.949, nll_loss=1.718, ppl=3.29, wps=22699.5, ups=1.92, wpb=11802.8, bsz=405.4, num_updates=73600, lr=9.32505e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 06:38:45 | INFO | train_inner | epoch 026:   1502 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.402, loss=3.941, nll_loss=1.712, ppl=3.28, wps=22913.5, ups=1.93, wpb=11902.3, bsz=401.4, num_updates=73700, lr=9.31872e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 06:39:37 | INFO | train_inner | epoch 026:   1602 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.399, loss=3.956, nll_loss=1.723, ppl=3.3, wps=22849.2, ups=1.93, wpb=11864.4, bsz=387.9, num_updates=73800, lr=9.3124e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 06:40:29 | INFO | train_inner | epoch 026:   1702 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.406, loss=3.96, nll_loss=1.729, ppl=3.32, wps=22652.1, ups=1.92, wpb=11815.4, bsz=419.1, num_updates=73900, lr=9.3061e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 06:41:21 | INFO | train_inner | epoch 026:   1802 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.381, loss=3.932, nll_loss=1.703, ppl=3.26, wps=22896.3, ups=1.91, wpb=11957.7, bsz=418.8, num_updates=74000, lr=9.29981e-06, gnorm=1.101, train_wall=52, wall=0
2020-12-22 06:42:13 | INFO | train_inner | epoch 026:   1902 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.405, loss=3.962, nll_loss=1.728, ppl=3.31, wps=22836.4, ups=1.93, wpb=11861.6, bsz=388.5, num_updates=74100, lr=9.29353e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 06:43:05 | INFO | train_inner | epoch 026:   2002 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.365, loss=3.924, nll_loss=1.697, ppl=3.24, wps=22935.2, ups=1.93, wpb=11909.4, bsz=422, num_updates=74200, lr=9.28727e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 06:43:57 | INFO | train_inner | epoch 026:   2102 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.39, loss=3.956, nll_loss=1.722, ppl=3.3, wps=22918.1, ups=1.93, wpb=11891, bsz=392, num_updates=74300, lr=9.28102e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 06:44:49 | INFO | train_inner | epoch 026:   2202 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.381, loss=3.944, nll_loss=1.712, ppl=3.28, wps=22730.7, ups=1.92, wpb=11841.6, bsz=416.2, num_updates=74400, lr=9.27478e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:45:41 | INFO | train_inner | epoch 026:   2302 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.381, loss=3.961, nll_loss=1.728, ppl=3.31, wps=22821.9, ups=1.93, wpb=11842.5, bsz=410.9, num_updates=74500, lr=9.26855e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 06:46:33 | INFO | train_inner | epoch 026:   2402 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.398, loss=3.976, nll_loss=1.74, ppl=3.34, wps=22806.7, ups=1.92, wpb=11861.1, bsz=407.6, num_updates=74600, lr=9.26234e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 06:47:24 | INFO | train_inner | epoch 026:   2502 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.365, loss=3.985, nll_loss=1.752, ppl=3.37, wps=22823.7, ups=1.93, wpb=11827.5, bsz=383.6, num_updates=74700, lr=9.25614e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 06:48:16 | INFO | train_inner | epoch 026:   2602 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.384, loss=3.981, nll_loss=1.746, ppl=3.35, wps=22686, ups=1.93, wpb=11774.1, bsz=388.2, num_updates=74800, lr=9.24995e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 06:49:08 | INFO | train_inner | epoch 026:   2702 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.387, loss=3.983, nll_loss=1.749, ppl=3.36, wps=22781.3, ups=1.93, wpb=11814.6, bsz=401, num_updates=74900, lr=9.24377e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 06:50:00 | INFO | train_inner | epoch 026:   2802 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.379, loss=3.946, nll_loss=1.716, ppl=3.29, wps=22625.9, ups=1.92, wpb=11805.3, bsz=408.6, num_updates=75000, lr=9.2376e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:50:53 | INFO | train_inner | epoch 026:   2902 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.345, loss=3.95, nll_loss=1.726, ppl=3.31, wps=22668.2, ups=1.92, wpb=11833.3, bsz=436.1, num_updates=75100, lr=9.23145e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 06:51:45 | INFO | train_inner | epoch 026:   3002 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.401, loss=3.974, nll_loss=1.741, ppl=3.34, wps=22620.8, ups=1.92, wpb=11785.6, bsz=417.2, num_updates=75200, lr=9.22531e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 06:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 06:52:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 06:52:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 06:52:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 06:52:31 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.876 | nll_loss 7.844 | ppl 229.82 | bleu 16.53 | wps 4560.2 | wpb 6344.2 | bsz 166.4 | num_updates 75257 | best_bleu 16.73
2020-12-22 06:52:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 06:52:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 26 @ 75257 updates, score 16.53) (writing took 4.763225490227342 seconds)
2020-12-22 06:52:36 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-12-22 06:52:36 | INFO | train | epoch 026 | symm_kl 0.389 | self_kl 0 | self_cv 9.39 | loss 3.954 | nll_loss 1.723 | ppl 3.3 | wps 22382.7 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 75257 | lr 9.22182e-06 | gnorm 1.117 | train_wall 1584 | wall 0
2020-12-22 06:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:39 | INFO | fairseq.trainer | begin training epoch 27
2020-12-22 06:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:52:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 06:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 06:53:08 | INFO | train_inner | epoch 027:     43 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.392, loss=3.936, nll_loss=1.705, ppl=3.26, wps=14304.3, ups=1.21, wpb=11863.2, bsz=421.4, num_updates=75300, lr=9.21918e-06, gnorm=1.117, train_wall=51, wall=0
2020-12-22 06:53:59 | INFO | train_inner | epoch 027:    143 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.392, loss=3.945, nll_loss=1.715, ppl=3.28, wps=22985.2, ups=1.93, wpb=11918.3, bsz=395, num_updates=75400, lr=9.21307e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 06:54:51 | INFO | train_inner | epoch 027:    243 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.429, loss=3.953, nll_loss=1.721, ppl=3.3, wps=22758.1, ups=1.93, wpb=11807.6, bsz=394.8, num_updates=75500, lr=9.20697e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 06:55:43 | INFO | train_inner | epoch 027:    343 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.404, loss=3.957, nll_loss=1.726, ppl=3.31, wps=22908, ups=1.93, wpb=11843.1, bsz=408.3, num_updates=75600, lr=9.20087e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 06:56:35 | INFO | train_inner | epoch 027:    443 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.384, loss=3.964, nll_loss=1.732, ppl=3.32, wps=22766.8, ups=1.92, wpb=11876.9, bsz=411, num_updates=75700, lr=9.19479e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 06:57:27 | INFO | train_inner | epoch 027:    543 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.387, loss=3.959, nll_loss=1.729, ppl=3.31, wps=22688.2, ups=1.92, wpb=11833.7, bsz=418.7, num_updates=75800, lr=9.18873e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 06:58:20 | INFO | train_inner | epoch 027:    643 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.426, loss=3.938, nll_loss=1.709, ppl=3.27, wps=22736, ups=1.92, wpb=11853.2, bsz=413.1, num_updates=75900, lr=9.18267e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 06:59:12 | INFO | train_inner | epoch 027:    743 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.42, loss=3.961, nll_loss=1.726, ppl=3.31, wps=22640.9, ups=1.92, wpb=11820.1, bsz=388.2, num_updates=76000, lr=9.17663e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 07:00:04 | INFO | train_inner | epoch 027:    843 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.391, loss=3.993, nll_loss=1.758, ppl=3.38, wps=22512, ups=1.92, wpb=11710.8, bsz=404.4, num_updates=76100, lr=9.1706e-06, gnorm=1.138, train_wall=52, wall=0
2020-12-22 07:00:56 | INFO | train_inner | epoch 027:    943 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.371, loss=3.976, nll_loss=1.74, ppl=3.34, wps=22634.9, ups=1.92, wpb=11781.9, bsz=414.3, num_updates=76200, lr=9.16458e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 07:01:48 | INFO | train_inner | epoch 027:   1043 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.363, loss=3.934, nll_loss=1.707, ppl=3.26, wps=22931.7, ups=1.92, wpb=11949.1, bsz=457.4, num_updates=76300, lr=9.15857e-06, gnorm=1.104, train_wall=52, wall=0
2020-12-22 07:02:40 | INFO | train_inner | epoch 027:   1143 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.401, loss=3.953, nll_loss=1.725, ppl=3.31, wps=22763.8, ups=1.92, wpb=11832.5, bsz=409.8, num_updates=76400, lr=9.15258e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 07:03:32 | INFO | train_inner | epoch 027:   1243 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.363, loss=3.94, nll_loss=1.708, ppl=3.27, wps=22948, ups=1.93, wpb=11884.9, bsz=424.8, num_updates=76500, lr=9.14659e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 07:04:24 | INFO | train_inner | epoch 027:   1343 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.479, loss=3.96, nll_loss=1.726, ppl=3.31, wps=22623.9, ups=1.93, wpb=11742.9, bsz=383, num_updates=76600, lr=9.14062e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 07:05:15 | INFO | train_inner | epoch 027:   1443 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.343, loss=3.969, nll_loss=1.741, ppl=3.34, wps=23027.4, ups=1.93, wpb=11900.9, bsz=421.4, num_updates=76700, lr=9.13466e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 07:06:07 | INFO | train_inner | epoch 027:   1543 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.375, loss=3.965, nll_loss=1.733, ppl=3.33, wps=22921.6, ups=1.93, wpb=11875.2, bsz=401.8, num_updates=76800, lr=9.12871e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 07:06:59 | INFO | train_inner | epoch 027:   1643 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.393, loss=3.951, nll_loss=1.72, ppl=3.3, wps=22994.8, ups=1.94, wpb=11843, bsz=388.1, num_updates=76900, lr=9.12277e-06, gnorm=1.115, train_wall=51, wall=0
2020-12-22 07:07:51 | INFO | train_inner | epoch 027:   1743 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.388, loss=3.928, nll_loss=1.7, ppl=3.25, wps=23075.5, ups=1.92, wpb=12004.2, bsz=418.3, num_updates=77000, lr=9.11685e-06, gnorm=1.099, train_wall=52, wall=0
2020-12-22 07:08:42 | INFO | train_inner | epoch 027:   1843 / 3059 symm_kl=0.394, self_kl=0, self_cv=9.416, loss=3.998, nll_loss=1.763, ppl=3.39, wps=22673.6, ups=1.94, wpb=11697, bsz=373.3, num_updates=77100, lr=9.11093e-06, gnorm=1.146, train_wall=51, wall=0
2020-12-22 07:09:34 | INFO | train_inner | epoch 027:   1943 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.383, loss=3.963, nll_loss=1.732, ppl=3.32, wps=22820.6, ups=1.93, wpb=11830.9, bsz=412.9, num_updates=77200, lr=9.10503e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 07:10:26 | INFO | train_inner | epoch 027:   2043 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.415, loss=3.927, nll_loss=1.702, ppl=3.25, wps=22891.5, ups=1.92, wpb=11895.3, bsz=420.6, num_updates=77300, lr=9.09914e-06, gnorm=1.103, train_wall=52, wall=0
2020-12-22 07:11:18 | INFO | train_inner | epoch 027:   2143 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.41, loss=3.958, nll_loss=1.728, ppl=3.31, wps=22707.6, ups=1.92, wpb=11839.1, bsz=402.3, num_updates=77400, lr=9.09326e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 07:12:10 | INFO | train_inner | epoch 027:   2243 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.375, loss=3.927, nll_loss=1.699, ppl=3.25, wps=22816, ups=1.92, wpb=11861.6, bsz=405.1, num_updates=77500, lr=9.08739e-06, gnorm=1.108, train_wall=52, wall=0
2020-12-22 07:13:02 | INFO | train_inner | epoch 027:   2343 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.368, loss=3.931, nll_loss=1.703, ppl=3.26, wps=22948.8, ups=1.93, wpb=11919.6, bsz=410.5, num_updates=77600, lr=9.08153e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 07:13:54 | INFO | train_inner | epoch 027:   2443 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.37, loss=3.955, nll_loss=1.724, ppl=3.3, wps=22736.2, ups=1.92, wpb=11832.1, bsz=408.6, num_updates=77700, lr=9.07569e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 07:14:46 | INFO | train_inner | epoch 027:   2543 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.401, loss=3.958, nll_loss=1.728, ppl=3.31, wps=22926.6, ups=1.93, wpb=11861.5, bsz=382.5, num_updates=77800, lr=9.06985e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 07:15:38 | INFO | train_inner | epoch 027:   2643 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.404, loss=3.951, nll_loss=1.722, ppl=3.3, wps=22935.8, ups=1.93, wpb=11891.6, bsz=402.2, num_updates=77900, lr=9.06403e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 07:16:30 | INFO | train_inner | epoch 027:   2743 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.393, loss=3.943, nll_loss=1.714, ppl=3.28, wps=22757.5, ups=1.92, wpb=11837.9, bsz=417.3, num_updates=78000, lr=9.05822e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 07:17:22 | INFO | train_inner | epoch 027:   2843 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.371, loss=3.934, nll_loss=1.712, ppl=3.28, wps=22876.7, ups=1.92, wpb=11900, bsz=430, num_updates=78100, lr=9.05242e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 07:18:14 | INFO | train_inner | epoch 027:   2943 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.365, loss=3.953, nll_loss=1.725, ppl=3.31, wps=22698.9, ups=1.92, wpb=11835, bsz=429.6, num_updates=78200, lr=9.04663e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 07:19:06 | INFO | train_inner | epoch 027:   3043 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.375, loss=3.951, nll_loss=1.724, ppl=3.3, wps=22906.3, ups=1.92, wpb=11911.4, bsz=409.8, num_updates=78300, lr=9.04085e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 07:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 07:19:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 07:19:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 07:19:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 07:19:30 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.882 | nll_loss 7.85 | ppl 230.67 | bleu 16.4 | wps 4957.5 | wpb 6344.2 | bsz 166.4 | num_updates 78316 | best_bleu 16.73
2020-12-22 07:19:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 07:19:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 27 @ 78316 updates, score 16.4) (writing took 5.134812152013183 seconds)
2020-12-22 07:19:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-12-22 07:19:35 | INFO | train | epoch 027 | symm_kl 0.388 | self_kl 0 | self_cv 9.391 | loss 3.953 | nll_loss 1.723 | ppl 3.3 | wps 22392.3 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 78316 | lr 9.03992e-06 | gnorm 1.118 | train_wall 1584 | wall 0
2020-12-22 07:19:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:38 | INFO | fairseq.trainer | begin training epoch 28
2020-12-22 07:19:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:19:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:19:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:20:28 | INFO | train_inner | epoch 028:     84 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.364, loss=3.937, nll_loss=1.707, ppl=3.27, wps=14538.3, ups=1.22, wpb=11893.6, bsz=416.6, num_updates=78400, lr=9.03508e-06, gnorm=1.114, train_wall=51, wall=0
2020-12-22 07:21:20 | INFO | train_inner | epoch 028:    184 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.396, loss=3.931, nll_loss=1.705, ppl=3.26, wps=22847.7, ups=1.93, wpb=11863.2, bsz=409.2, num_updates=78500, lr=9.02932e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 07:22:12 | INFO | train_inner | epoch 028:    284 / 3059 symm_kl=0.391, self_kl=0, self_cv=9.407, loss=3.956, nll_loss=1.722, ppl=3.3, wps=22799.8, ups=1.93, wpb=11841.9, bsz=393.5, num_updates=78600, lr=9.02358e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 07:23:03 | INFO | train_inner | epoch 028:    384 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.371, loss=3.949, nll_loss=1.725, ppl=3.31, wps=22882.1, ups=1.93, wpb=11862.1, bsz=429.9, num_updates=78700, lr=9.01784e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 07:23:55 | INFO | train_inner | epoch 028:    484 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.412, loss=3.946, nll_loss=1.716, ppl=3.29, wps=22770.9, ups=1.93, wpb=11814.4, bsz=410.8, num_updates=78800, lr=9.01212e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 07:24:47 | INFO | train_inner | epoch 028:    584 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.405, loss=3.955, nll_loss=1.724, ppl=3.3, wps=22699.2, ups=1.93, wpb=11769.3, bsz=414.2, num_updates=78900, lr=9.00641e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 07:25:39 | INFO | train_inner | epoch 028:    684 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.393, loss=3.954, nll_loss=1.723, ppl=3.3, wps=22845.5, ups=1.92, wpb=11870.7, bsz=414.8, num_updates=79000, lr=9.0007e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 07:26:31 | INFO | train_inner | epoch 028:    784 / 3059 symm_kl=0.392, self_kl=0, self_cv=9.393, loss=3.982, nll_loss=1.748, ppl=3.36, wps=22752.1, ups=1.93, wpb=11767.6, bsz=400.8, num_updates=79100, lr=8.99501e-06, gnorm=1.138, train_wall=52, wall=0
2020-12-22 07:27:23 | INFO | train_inner | epoch 028:    884 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.392, loss=3.964, nll_loss=1.732, ppl=3.32, wps=22841.1, ups=1.91, wpb=11934.1, bsz=403.1, num_updates=79200, lr=8.98933e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 07:28:15 | INFO | train_inner | epoch 028:    984 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.378, loss=3.967, nll_loss=1.737, ppl=3.33, wps=22918.6, ups=1.94, wpb=11826.8, bsz=391.2, num_updates=79300, lr=8.98366e-06, gnorm=1.119, train_wall=51, wall=0
2020-12-22 07:29:07 | INFO | train_inner | epoch 028:   1084 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.434, loss=3.955, nll_loss=1.725, ppl=3.31, wps=22538.7, ups=1.92, wpb=11768.7, bsz=401.7, num_updates=79400, lr=8.978e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 07:29:59 | INFO | train_inner | epoch 028:   1184 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.383, loss=3.941, nll_loss=1.712, ppl=3.28, wps=22999, ups=1.93, wpb=11898.8, bsz=398.2, num_updates=79500, lr=8.97235e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 07:30:50 | INFO | train_inner | epoch 028:   1284 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.368, loss=3.949, nll_loss=1.719, ppl=3.29, wps=22899.8, ups=1.93, wpb=11867.2, bsz=413.8, num_updates=79600, lr=8.96672e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 07:31:43 | INFO | train_inner | epoch 028:   1384 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.372, loss=3.942, nll_loss=1.715, ppl=3.28, wps=22808.5, ups=1.92, wpb=11879.8, bsz=437, num_updates=79700, lr=8.96109e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 07:32:34 | INFO | train_inner | epoch 028:   1484 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.387, loss=3.964, nll_loss=1.736, ppl=3.33, wps=22727.1, ups=1.92, wpb=11810.1, bsz=426.1, num_updates=79800, lr=8.95547e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 07:33:26 | INFO | train_inner | epoch 028:   1584 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.371, loss=3.968, nll_loss=1.739, ppl=3.34, wps=22765, ups=1.93, wpb=11819.9, bsz=406.6, num_updates=79900, lr=8.94987e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 07:34:18 | INFO | train_inner | epoch 028:   1684 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.417, loss=3.952, nll_loss=1.725, ppl=3.31, wps=22807.2, ups=1.93, wpb=11847.8, bsz=410.5, num_updates=80000, lr=8.94427e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 07:35:10 | INFO | train_inner | epoch 028:   1784 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.4, loss=3.941, nll_loss=1.714, ppl=3.28, wps=22878.7, ups=1.92, wpb=11907.1, bsz=415.4, num_updates=80100, lr=8.93869e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 07:36:02 | INFO | train_inner | epoch 028:   1884 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.409, loss=3.953, nll_loss=1.723, ppl=3.3, wps=22845.5, ups=1.93, wpb=11863.6, bsz=394, num_updates=80200, lr=8.93311e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 07:36:54 | INFO | train_inner | epoch 028:   1984 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.379, loss=3.948, nll_loss=1.719, ppl=3.29, wps=22794, ups=1.93, wpb=11814.2, bsz=401.8, num_updates=80300, lr=8.92755e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 07:37:46 | INFO | train_inner | epoch 028:   2084 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.417, loss=3.944, nll_loss=1.718, ppl=3.29, wps=22632.8, ups=1.92, wpb=11773.3, bsz=421.4, num_updates=80400, lr=8.92199e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 07:38:38 | INFO | train_inner | epoch 028:   2184 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.392, loss=3.962, nll_loss=1.733, ppl=3.33, wps=22779.8, ups=1.93, wpb=11799.2, bsz=400.3, num_updates=80500, lr=8.91645e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 07:39:30 | INFO | train_inner | epoch 028:   2284 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.395, loss=3.933, nll_loss=1.707, ppl=3.26, wps=22905.8, ups=1.93, wpb=11841.6, bsz=412.7, num_updates=80600, lr=8.91092e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 07:40:22 | INFO | train_inner | epoch 028:   2384 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.369, loss=3.932, nll_loss=1.706, ppl=3.26, wps=22947.3, ups=1.92, wpb=11925.4, bsz=425.9, num_updates=80700, lr=8.9054e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 07:41:14 | INFO | train_inner | epoch 028:   2484 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.371, loss=3.955, nll_loss=1.727, ppl=3.31, wps=22916.3, ups=1.93, wpb=11902.9, bsz=398.4, num_updates=80800, lr=8.89988e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 07:42:05 | INFO | train_inner | epoch 028:   2584 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.385, loss=3.962, nll_loss=1.735, ppl=3.33, wps=22933.1, ups=1.93, wpb=11890.8, bsz=420.2, num_updates=80900, lr=8.89438e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 07:42:58 | INFO | train_inner | epoch 028:   2684 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.378, loss=3.946, nll_loss=1.719, ppl=3.29, wps=22832.3, ups=1.92, wpb=11909.8, bsz=394.2, num_updates=81000, lr=8.88889e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 07:43:50 | INFO | train_inner | epoch 028:   2784 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.408, loss=3.949, nll_loss=1.717, ppl=3.29, wps=22776.2, ups=1.92, wpb=11876, bsz=392.2, num_updates=81100, lr=8.88341e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 07:44:42 | INFO | train_inner | epoch 028:   2884 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.366, loss=3.937, nll_loss=1.711, ppl=3.27, wps=22975.7, ups=1.93, wpb=11912.9, bsz=413.1, num_updates=81200, lr=8.87794e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 07:45:34 | INFO | train_inner | epoch 028:   2984 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.384, loss=3.961, nll_loss=1.73, ppl=3.32, wps=22582, ups=1.92, wpb=11789.4, bsz=411, num_updates=81300, lr=8.87247e-06, gnorm=1.141, train_wall=52, wall=0
2020-12-22 07:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 07:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 07:46:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 07:46:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 07:46:30 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.874 | nll_loss 7.84 | ppl 229.14 | bleu 16.46 | wps 4492.5 | wpb 6344.2 | bsz 166.4 | num_updates 81375 | best_bleu 16.73
2020-12-22 07:46:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 07:46:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 28 @ 81375 updates, score 16.46) (writing took 4.736385585740209 seconds)
2020-12-22 07:46:34 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-12-22 07:46:34 | INFO | train | epoch 028 | symm_kl 0.387 | self_kl 0 | self_cv 9.39 | loss 3.951 | nll_loss 1.723 | ppl 3.3 | wps 22387.6 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 81375 | lr 8.86838e-06 | gnorm 1.12 | train_wall 1583 | wall 0
2020-12-22 07:46:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:38 | INFO | fairseq.trainer | begin training epoch 29
2020-12-22 07:46:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 07:46:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 07:46:57 | INFO | train_inner | epoch 029:     25 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.36, loss=3.95, nll_loss=1.724, ppl=3.3, wps=14231.9, ups=1.2, wpb=11849.8, bsz=442.6, num_updates=81400, lr=8.86702e-06, gnorm=1.119, train_wall=51, wall=0
2020-12-22 07:47:49 | INFO | train_inner | epoch 029:    125 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.421, loss=3.929, nll_loss=1.701, ppl=3.25, wps=22993.9, ups=1.94, wpb=11871.7, bsz=402.2, num_updates=81500, lr=8.86158e-06, gnorm=1.118, train_wall=51, wall=0
2020-12-22 07:48:41 | INFO | train_inner | epoch 029:    225 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.402, loss=3.948, nll_loss=1.721, ppl=3.3, wps=22678.8, ups=1.93, wpb=11769.9, bsz=407.7, num_updates=81600, lr=8.85615e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 07:49:32 | INFO | train_inner | epoch 029:    325 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.373, loss=3.94, nll_loss=1.713, ppl=3.28, wps=23030.2, ups=1.93, wpb=11920, bsz=409.2, num_updates=81700, lr=8.85073e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 07:50:24 | INFO | train_inner | epoch 029:    425 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.358, loss=3.959, nll_loss=1.731, ppl=3.32, wps=22837.4, ups=1.93, wpb=11855.1, bsz=437.5, num_updates=81800, lr=8.84532e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 07:51:16 | INFO | train_inner | epoch 029:    525 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.368, loss=3.948, nll_loss=1.724, ppl=3.3, wps=22741.9, ups=1.92, wpb=11868.5, bsz=445.5, num_updates=81900, lr=8.83991e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 07:52:09 | INFO | train_inner | epoch 029:    625 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.42, loss=3.947, nll_loss=1.716, ppl=3.28, wps=22787.3, ups=1.92, wpb=11883.8, bsz=399.9, num_updates=82000, lr=8.83452e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 07:53:00 | INFO | train_inner | epoch 029:    725 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.409, loss=3.955, nll_loss=1.723, ppl=3.3, wps=22854.9, ups=1.93, wpb=11854.3, bsz=379.2, num_updates=82100, lr=8.82914e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 07:53:52 | INFO | train_inner | epoch 029:    825 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.357, loss=3.966, nll_loss=1.738, ppl=3.34, wps=22768.9, ups=1.93, wpb=11821, bsz=411.5, num_updates=82200, lr=8.82377e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 07:54:45 | INFO | train_inner | epoch 029:    925 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.386, loss=3.942, nll_loss=1.716, ppl=3.29, wps=22739.1, ups=1.91, wpb=11889.6, bsz=422.9, num_updates=82300, lr=8.81841e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 07:55:37 | INFO | train_inner | epoch 029:   1025 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.351, loss=3.959, nll_loss=1.731, ppl=3.32, wps=22676.9, ups=1.92, wpb=11833.1, bsz=403.8, num_updates=82400, lr=8.81305e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 07:56:29 | INFO | train_inner | epoch 029:   1125 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.391, loss=3.948, nll_loss=1.719, ppl=3.29, wps=22891.5, ups=1.93, wpb=11836.9, bsz=415.5, num_updates=82500, lr=8.80771e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 07:57:20 | INFO | train_inner | epoch 029:   1225 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.398, loss=3.968, nll_loss=1.738, ppl=3.34, wps=22733.7, ups=1.94, wpb=11715.3, bsz=403.5, num_updates=82600, lr=8.80238e-06, gnorm=1.128, train_wall=51, wall=0
2020-12-22 07:58:12 | INFO | train_inner | epoch 029:   1325 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.404, loss=3.989, nll_loss=1.761, ppl=3.39, wps=22909.3, ups=1.94, wpb=11800.7, bsz=393.3, num_updates=82700, lr=8.79705e-06, gnorm=1.126, train_wall=51, wall=0
2020-12-22 07:59:04 | INFO | train_inner | epoch 029:   1425 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.388, loss=3.949, nll_loss=1.725, ppl=3.31, wps=22891.6, ups=1.93, wpb=11881.2, bsz=422.7, num_updates=82800, lr=8.79174e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 07:59:55 | INFO | train_inner | epoch 029:   1525 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.398, loss=3.955, nll_loss=1.728, ppl=3.31, wps=22820.6, ups=1.93, wpb=11807.4, bsz=415.5, num_updates=82900, lr=8.78644e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 08:00:47 | INFO | train_inner | epoch 029:   1625 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.384, loss=3.942, nll_loss=1.715, ppl=3.28, wps=22913.6, ups=1.93, wpb=11865.8, bsz=415.8, num_updates=83000, lr=8.78114e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:01:39 | INFO | train_inner | epoch 029:   1725 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.362, loss=3.96, nll_loss=1.729, ppl=3.31, wps=22890.2, ups=1.93, wpb=11872.2, bsz=389.8, num_updates=83100, lr=8.77586e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 08:02:31 | INFO | train_inner | epoch 029:   1825 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.398, loss=3.923, nll_loss=1.698, ppl=3.25, wps=22769.8, ups=1.92, wpb=11865, bsz=388.6, num_updates=83200, lr=8.77058e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 08:03:23 | INFO | train_inner | epoch 029:   1925 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.375, loss=3.945, nll_loss=1.718, ppl=3.29, wps=22840.9, ups=1.93, wpb=11829, bsz=406.6, num_updates=83300, lr=8.76531e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 08:04:15 | INFO | train_inner | epoch 029:   2025 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.387, loss=3.94, nll_loss=1.713, ppl=3.28, wps=22924.2, ups=1.93, wpb=11905.6, bsz=417.4, num_updates=83400, lr=8.76006e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 08:05:07 | INFO | train_inner | epoch 029:   2125 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.421, loss=3.947, nll_loss=1.718, ppl=3.29, wps=22968.6, ups=1.93, wpb=11916.7, bsz=411.4, num_updates=83500, lr=8.75481e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:05:59 | INFO | train_inner | epoch 029:   2225 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.37, loss=3.936, nll_loss=1.712, ppl=3.28, wps=22831.7, ups=1.92, wpb=11889.4, bsz=421.3, num_updates=83600, lr=8.74957e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 08:06:51 | INFO | train_inner | epoch 029:   2325 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.395, loss=3.968, nll_loss=1.737, ppl=3.33, wps=22862.3, ups=1.93, wpb=11848, bsz=379.4, num_updates=83700, lr=8.74434e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 08:07:42 | INFO | train_inner | epoch 029:   2425 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.388, loss=3.968, nll_loss=1.741, ppl=3.34, wps=22927.6, ups=1.94, wpb=11833.6, bsz=394.6, num_updates=83800, lr=8.73913e-06, gnorm=1.124, train_wall=51, wall=0
2020-12-22 08:08:34 | INFO | train_inner | epoch 029:   2525 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.411, loss=3.94, nll_loss=1.716, ppl=3.28, wps=22989.2, ups=1.93, wpb=11896.1, bsz=400.8, num_updates=83900, lr=8.73392e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 08:09:26 | INFO | train_inner | epoch 029:   2625 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.369, loss=3.977, nll_loss=1.752, ppl=3.37, wps=22681.2, ups=1.93, wpb=11757.1, bsz=410.2, num_updates=84000, lr=8.72872e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 08:10:18 | INFO | train_inner | epoch 029:   2725 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.391, loss=3.922, nll_loss=1.698, ppl=3.25, wps=22872.5, ups=1.92, wpb=11897.5, bsz=444.1, num_updates=84100, lr=8.72352e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 08:11:10 | INFO | train_inner | epoch 029:   2825 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.393, loss=3.953, nll_loss=1.725, ppl=3.3, wps=22848, ups=1.93, wpb=11845.9, bsz=383.2, num_updates=84200, lr=8.71834e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 08:12:01 | INFO | train_inner | epoch 029:   2925 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.364, loss=3.944, nll_loss=1.719, ppl=3.29, wps=23114.8, ups=1.94, wpb=11902.1, bsz=416, num_updates=84300, lr=8.71317e-06, gnorm=1.114, train_wall=51, wall=0
2020-12-22 08:12:53 | INFO | train_inner | epoch 029:   3025 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.436, loss=3.93, nll_loss=1.704, ppl=3.26, wps=23040.6, ups=1.94, wpb=11885.5, bsz=415.8, num_updates=84400, lr=8.70801e-06, gnorm=1.119, train_wall=51, wall=0
2020-12-22 08:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 08:13:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 08:13:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 08:13:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 08:13:27 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.87 | nll_loss 7.835 | ppl 228.34 | bleu 16.56 | wps 4363.2 | wpb 6344.2 | bsz 166.4 | num_updates 84434 | best_bleu 16.73
2020-12-22 08:13:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 08:13:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 29 @ 84434 updates, score 16.56) (writing took 4.66933879442513 seconds)
2020-12-22 08:13:32 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-12-22 08:13:32 | INFO | train | epoch 029 | symm_kl 0.386 | self_kl 0 | self_cv 9.389 | loss 3.95 | nll_loss 1.722 | ppl 3.3 | wps 22412.3 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 84434 | lr 8.70625e-06 | gnorm 1.12 | train_wall 1581 | wall 0
2020-12-22 08:13:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:36 | INFO | fairseq.trainer | begin training epoch 30
2020-12-22 08:13:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:13:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:13:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:14:16 | INFO | train_inner | epoch 030:     66 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.395, loss=3.94, nll_loss=1.713, ppl=3.28, wps=14206, ups=1.2, wpb=11792.6, bsz=437.4, num_updates=84500, lr=8.70285e-06, gnorm=1.122, train_wall=51, wall=0
2020-12-22 08:15:08 | INFO | train_inner | epoch 030:    166 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.406, loss=3.947, nll_loss=1.722, ppl=3.3, wps=22782.9, ups=1.92, wpb=11843.6, bsz=429.2, num_updates=84600, lr=8.69771e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 08:15:59 | INFO | train_inner | epoch 030:    266 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.371, loss=3.927, nll_loss=1.7, ppl=3.25, wps=23075.5, ups=1.94, wpb=11922.4, bsz=413.1, num_updates=84700, lr=8.69257e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 08:16:51 | INFO | train_inner | epoch 030:    366 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.411, loss=3.96, nll_loss=1.733, ppl=3.32, wps=22825.7, ups=1.93, wpb=11811.7, bsz=403, num_updates=84800, lr=8.68744e-06, gnorm=1.136, train_wall=52, wall=0
2020-12-22 08:17:43 | INFO | train_inner | epoch 030:    466 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.349, loss=3.942, nll_loss=1.719, ppl=3.29, wps=22992, ups=1.94, wpb=11877, bsz=444.9, num_updates=84900, lr=8.68233e-06, gnorm=1.109, train_wall=52, wall=0
2020-12-22 08:18:35 | INFO | train_inner | epoch 030:    566 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.408, loss=3.956, nll_loss=1.727, ppl=3.31, wps=22865.3, ups=1.93, wpb=11876.7, bsz=397.4, num_updates=85000, lr=8.67722e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 08:19:27 | INFO | train_inner | epoch 030:    666 / 3059 symm_kl=0.393, self_kl=0, self_cv=9.394, loss=3.965, nll_loss=1.73, ppl=3.32, wps=22772.9, ups=1.93, wpb=11805.1, bsz=371.8, num_updates=85100, lr=8.67212e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 08:20:18 | INFO | train_inner | epoch 030:    766 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.406, loss=3.961, nll_loss=1.733, ppl=3.32, wps=22907.8, ups=1.94, wpb=11805.6, bsz=401.8, num_updates=85200, lr=8.66703e-06, gnorm=1.128, train_wall=51, wall=0
2020-12-22 08:21:10 | INFO | train_inner | epoch 030:    866 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.377, loss=3.946, nll_loss=1.722, ppl=3.3, wps=22932, ups=1.93, wpb=11901.4, bsz=424.5, num_updates=85300, lr=8.66195e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 08:22:02 | INFO | train_inner | epoch 030:    966 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.39, loss=3.949, nll_loss=1.725, ppl=3.3, wps=22909.9, ups=1.92, wpb=11917.6, bsz=417.4, num_updates=85400, lr=8.65687e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 08:22:54 | INFO | train_inner | epoch 030:   1066 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.391, loss=3.949, nll_loss=1.72, ppl=3.29, wps=22835.2, ups=1.94, wpb=11789.8, bsz=405.7, num_updates=85500, lr=8.65181e-06, gnorm=1.127, train_wall=51, wall=0
2020-12-22 08:23:46 | INFO | train_inner | epoch 030:   1166 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.38, loss=3.925, nll_loss=1.702, ppl=3.25, wps=22925.2, ups=1.92, wpb=11943.1, bsz=442.5, num_updates=85600, lr=8.64675e-06, gnorm=1.1, train_wall=52, wall=0
2020-12-22 08:24:37 | INFO | train_inner | epoch 030:   1266 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.389, loss=3.962, nll_loss=1.733, ppl=3.32, wps=22896.5, ups=1.94, wpb=11804.4, bsz=392.1, num_updates=85700, lr=8.64171e-06, gnorm=1.127, train_wall=51, wall=0
2020-12-22 08:25:29 | INFO | train_inner | epoch 030:   1366 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.379, loss=3.956, nll_loss=1.726, ppl=3.31, wps=23138.6, ups=1.94, wpb=11934.3, bsz=381, num_updates=85800, lr=8.63667e-06, gnorm=1.119, train_wall=51, wall=0
2020-12-22 08:26:21 | INFO | train_inner | epoch 030:   1466 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.403, loss=3.934, nll_loss=1.711, ppl=3.27, wps=22772.7, ups=1.93, wpb=11822.2, bsz=440.6, num_updates=85900, lr=8.63164e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 08:27:13 | INFO | train_inner | epoch 030:   1566 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.412, loss=3.944, nll_loss=1.72, ppl=3.29, wps=22834, ups=1.93, wpb=11835.6, bsz=429, num_updates=86000, lr=8.62662e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 08:28:04 | INFO | train_inner | epoch 030:   1666 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.397, loss=3.953, nll_loss=1.726, ppl=3.31, wps=22979.5, ups=1.93, wpb=11876.6, bsz=389.8, num_updates=86100, lr=8.62161e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:28:56 | INFO | train_inner | epoch 030:   1766 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.399, loss=3.95, nll_loss=1.723, ppl=3.3, wps=23073.2, ups=1.93, wpb=11932.8, bsz=401.5, num_updates=86200, lr=8.61661e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 08:29:48 | INFO | train_inner | epoch 030:   1866 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.385, loss=3.947, nll_loss=1.72, ppl=3.29, wps=22879.7, ups=1.92, wpb=11886.7, bsz=397, num_updates=86300, lr=8.61161e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 08:30:40 | INFO | train_inner | epoch 030:   1966 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.395, loss=3.945, nll_loss=1.721, ppl=3.3, wps=22669.1, ups=1.93, wpb=11752.1, bsz=423.4, num_updates=86400, lr=8.60663e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 08:31:32 | INFO | train_inner | epoch 030:   2066 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.383, loss=3.953, nll_loss=1.725, ppl=3.31, wps=22725.6, ups=1.92, wpb=11856.9, bsz=402, num_updates=86500, lr=8.60165e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:32:24 | INFO | train_inner | epoch 030:   2166 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.41, loss=3.961, nll_loss=1.733, ppl=3.32, wps=22746.1, ups=1.93, wpb=11780.2, bsz=394.2, num_updates=86600, lr=8.59669e-06, gnorm=1.135, train_wall=52, wall=0
2020-12-22 08:33:16 | INFO | train_inner | epoch 030:   2266 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.423, loss=3.963, nll_loss=1.732, ppl=3.32, wps=22672, ups=1.93, wpb=11743.7, bsz=386.8, num_updates=86700, lr=8.59173e-06, gnorm=1.137, train_wall=52, wall=0
2020-12-22 08:34:07 | INFO | train_inner | epoch 030:   2366 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.39, loss=3.939, nll_loss=1.716, ppl=3.29, wps=22873.2, ups=1.93, wpb=11850, bsz=414.7, num_updates=86800, lr=8.58678e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 08:34:59 | INFO | train_inner | epoch 030:   2466 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.377, loss=3.935, nll_loss=1.713, ppl=3.28, wps=23024.2, ups=1.94, wpb=11892.6, bsz=423.4, num_updates=86900, lr=8.58183e-06, gnorm=1.113, train_wall=51, wall=0
2020-12-22 08:35:51 | INFO | train_inner | epoch 030:   2566 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.371, loss=3.965, nll_loss=1.738, ppl=3.34, wps=22816.2, ups=1.93, wpb=11822, bsz=385.8, num_updates=87000, lr=8.5769e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 08:36:43 | INFO | train_inner | epoch 030:   2666 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.408, loss=3.94, nll_loss=1.713, ppl=3.28, wps=22898.2, ups=1.93, wpb=11845.3, bsz=383.8, num_updates=87100, lr=8.57198e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 08:37:34 | INFO | train_inner | epoch 030:   2766 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.348, loss=3.954, nll_loss=1.731, ppl=3.32, wps=22969.6, ups=1.93, wpb=11906.5, bsz=425.1, num_updates=87200, lr=8.56706e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 08:38:26 | INFO | train_inner | epoch 030:   2866 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.372, loss=3.937, nll_loss=1.717, ppl=3.29, wps=22849.7, ups=1.93, wpb=11832.1, bsz=425.8, num_updates=87300, lr=8.56215e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 08:39:18 | INFO | train_inner | epoch 030:   2966 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.371, loss=3.945, nll_loss=1.722, ppl=3.3, wps=22910.8, ups=1.93, wpb=11844.4, bsz=423.1, num_updates=87400, lr=8.55725e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 08:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 08:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 08:40:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 08:40:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 08:40:21 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.872 | nll_loss 7.837 | ppl 228.7 | bleu 16.4 | wps 5028.7 | wpb 6344.2 | bsz 166.4 | num_updates 87493 | best_bleu 16.73
2020-12-22 08:40:21 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 08:40:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 30 @ 87493 updates, score 16.4) (writing took 4.725459950044751 seconds)
2020-12-22 08:40:26 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-12-22 08:40:26 | INFO | train | epoch 030 | symm_kl 0.385 | self_kl 0 | self_cv 9.389 | loss 3.948 | nll_loss 1.722 | ppl 3.3 | wps 22461.5 | ups 1.9 | wpb 11852.2 | bsz 409.6 | num_updates 87493 | lr 8.5527e-06 | gnorm 1.12 | train_wall 1579 | wall 0
2020-12-22 08:40:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:30 | INFO | fairseq.trainer | begin training epoch 31
2020-12-22 08:40:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 08:40:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 08:40:40 | INFO | train_inner | epoch 031:      7 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.391, loss=3.946, nll_loss=1.721, ppl=3.3, wps=14467.8, ups=1.22, wpb=11849.1, bsz=401.9, num_updates=87500, lr=8.55236e-06, gnorm=1.114, train_wall=51, wall=0
2020-12-22 08:41:31 | INFO | train_inner | epoch 031:    107 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.375, loss=3.957, nll_loss=1.727, ppl=3.31, wps=23107.6, ups=1.96, wpb=11807.7, bsz=376.2, num_updates=87600, lr=8.54748e-06, gnorm=1.127, train_wall=51, wall=0
2020-12-22 08:42:23 | INFO | train_inner | epoch 031:    207 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.387, loss=3.928, nll_loss=1.706, ppl=3.26, wps=22965.8, ups=1.92, wpb=11935.7, bsz=405.8, num_updates=87700, lr=8.5426e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 08:43:15 | INFO | train_inner | epoch 031:    307 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.401, loss=3.946, nll_loss=1.721, ppl=3.3, wps=22703.6, ups=1.94, wpb=11732.4, bsz=411.6, num_updates=87800, lr=8.53774e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 08:44:07 | INFO | train_inner | epoch 031:    407 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.416, loss=3.932, nll_loss=1.709, ppl=3.27, wps=22769.8, ups=1.91, wpb=11894.1, bsz=420.3, num_updates=87900, lr=8.53288e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 08:44:59 | INFO | train_inner | epoch 031:    507 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.377, loss=3.954, nll_loss=1.729, ppl=3.31, wps=22846.1, ups=1.93, wpb=11821, bsz=408.4, num_updates=88000, lr=8.52803e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 08:45:50 | INFO | train_inner | epoch 031:    607 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.419, loss=3.935, nll_loss=1.711, ppl=3.27, wps=22807.9, ups=1.92, wpb=11854.9, bsz=411.1, num_updates=88100, lr=8.52319e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 08:46:42 | INFO | train_inner | epoch 031:    707 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.391, loss=3.956, nll_loss=1.726, ppl=3.31, wps=23034.2, ups=1.93, wpb=11911.6, bsz=389.8, num_updates=88200, lr=8.51835e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:47:34 | INFO | train_inner | epoch 031:    807 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.407, loss=3.971, nll_loss=1.743, ppl=3.35, wps=22753.1, ups=1.93, wpb=11818.2, bsz=365.3, num_updates=88300, lr=8.51353e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 08:48:26 | INFO | train_inner | epoch 031:    907 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.41, loss=3.933, nll_loss=1.709, ppl=3.27, wps=22692.7, ups=1.92, wpb=11828.2, bsz=415.8, num_updates=88400, lr=8.50871e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 08:49:18 | INFO | train_inner | epoch 031:   1007 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.407, loss=3.944, nll_loss=1.717, ppl=3.29, wps=22670.5, ups=1.92, wpb=11779.2, bsz=419.8, num_updates=88500, lr=8.5039e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 08:50:10 | INFO | train_inner | epoch 031:   1107 / 3059 symm_kl=0.39, self_kl=0, self_cv=9.419, loss=3.967, nll_loss=1.736, ppl=3.33, wps=22863.9, ups=1.93, wpb=11837.4, bsz=386.3, num_updates=88600, lr=8.4991e-06, gnorm=1.136, train_wall=52, wall=0
2020-12-22 08:51:02 | INFO | train_inner | epoch 031:   1207 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.376, loss=3.958, nll_loss=1.731, ppl=3.32, wps=22872.5, ups=1.93, wpb=11864.4, bsz=382.4, num_updates=88700, lr=8.49431e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 08:51:54 | INFO | train_inner | epoch 031:   1307 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.38, loss=3.932, nll_loss=1.708, ppl=3.27, wps=22858, ups=1.93, wpb=11843.7, bsz=441, num_updates=88800, lr=8.48953e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 08:52:45 | INFO | train_inner | epoch 031:   1407 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.402, loss=3.952, nll_loss=1.727, ppl=3.31, wps=23045.2, ups=1.94, wpb=11879.1, bsz=414.7, num_updates=88900, lr=8.48475e-06, gnorm=1.115, train_wall=51, wall=0
2020-12-22 08:53:37 | INFO | train_inner | epoch 031:   1507 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.371, loss=3.945, nll_loss=1.721, ppl=3.3, wps=22891.8, ups=1.93, wpb=11857.6, bsz=405.7, num_updates=89000, lr=8.47998e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 08:54:29 | INFO | train_inner | epoch 031:   1607 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.378, loss=3.949, nll_loss=1.722, ppl=3.3, wps=22946.8, ups=1.93, wpb=11861.9, bsz=395.9, num_updates=89100, lr=8.47522e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 08:55:20 | INFO | train_inner | epoch 031:   1707 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.423, loss=3.945, nll_loss=1.719, ppl=3.29, wps=22858.5, ups=1.94, wpb=11773.6, bsz=399.1, num_updates=89200, lr=8.47047e-06, gnorm=1.133, train_wall=51, wall=0
2020-12-22 08:56:12 | INFO | train_inner | epoch 031:   1807 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.376, loss=3.92, nll_loss=1.698, ppl=3.25, wps=22827.6, ups=1.93, wpb=11841, bsz=421.9, num_updates=89300, lr=8.46573e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 08:57:04 | INFO | train_inner | epoch 031:   1907 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.378, loss=3.938, nll_loss=1.713, ppl=3.28, wps=22962.5, ups=1.93, wpb=11880.3, bsz=400.2, num_updates=89400, lr=8.46099e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 08:57:55 | INFO | train_inner | epoch 031:   2007 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.378, loss=3.963, nll_loss=1.74, ppl=3.34, wps=22866, ups=1.94, wpb=11812.1, bsz=400.1, num_updates=89500, lr=8.45626e-06, gnorm=1.128, train_wall=51, wall=0
2020-12-22 08:58:47 | INFO | train_inner | epoch 031:   2107 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.385, loss=3.953, nll_loss=1.729, ppl=3.32, wps=23039, ups=1.94, wpb=11889.6, bsz=410.9, num_updates=89600, lr=8.45154e-06, gnorm=1.115, train_wall=51, wall=0
2020-12-22 08:59:39 | INFO | train_inner | epoch 031:   2207 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.378, loss=3.938, nll_loss=1.717, ppl=3.29, wps=22837, ups=1.93, wpb=11817.9, bsz=446.2, num_updates=89700, lr=8.44683e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:00:31 | INFO | train_inner | epoch 031:   2307 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.376, loss=3.978, nll_loss=1.749, ppl=3.36, wps=22903.8, ups=1.93, wpb=11891.4, bsz=394.2, num_updates=89800, lr=8.44213e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 09:01:22 | INFO | train_inner | epoch 031:   2407 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.37, loss=3.952, nll_loss=1.728, ppl=3.31, wps=22956.6, ups=1.94, wpb=11843.6, bsz=426.4, num_updates=89900, lr=8.43743e-06, gnorm=1.123, train_wall=51, wall=0
2020-12-22 09:02:14 | INFO | train_inner | epoch 031:   2507 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.353, loss=3.934, nll_loss=1.712, ppl=3.28, wps=22938.4, ups=1.92, wpb=11931.6, bsz=425.6, num_updates=90000, lr=8.43274e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 09:03:06 | INFO | train_inner | epoch 031:   2607 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.368, loss=3.921, nll_loss=1.698, ppl=3.25, wps=23010.4, ups=1.93, wpb=11947.2, bsz=401, num_updates=90100, lr=8.42806e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 09:03:58 | INFO | train_inner | epoch 031:   2707 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.373, loss=3.952, nll_loss=1.734, ppl=3.33, wps=22909.3, ups=1.93, wpb=11874.9, bsz=437.9, num_updates=90200, lr=8.42339e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 09:04:50 | INFO | train_inner | epoch 031:   2807 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.371, loss=3.974, nll_loss=1.749, ppl=3.36, wps=22790.9, ups=1.93, wpb=11825.8, bsz=439.7, num_updates=90300, lr=8.41872e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 09:05:42 | INFO | train_inner | epoch 031:   2907 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.388, loss=3.938, nll_loss=1.716, ppl=3.29, wps=22788.5, ups=1.92, wpb=11851.5, bsz=436.6, num_updates=90400, lr=8.41406e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 09:06:34 | INFO | train_inner | epoch 031:   3007 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.392, loss=3.939, nll_loss=1.716, ppl=3.29, wps=22750.6, ups=1.92, wpb=11831.6, bsz=401.4, num_updates=90500, lr=8.40941e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 09:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 09:07:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 09:07:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 09:07:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 09:07:17 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.863 | nll_loss 7.83 | ppl 227.48 | bleu 16.71 | wps 4968.7 | wpb 6344.2 | bsz 166.4 | num_updates 90552 | best_bleu 16.73
2020-12-22 09:07:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 09:07:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 31 @ 90552 updates, score 16.71) (writing took 4.715973164886236 seconds)
2020-12-22 09:07:21 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-12-22 09:07:21 | INFO | train | epoch 031 | symm_kl 0.384 | self_kl 0 | self_cv 9.387 | loss 3.947 | nll_loss 1.722 | ppl 3.3 | wps 22447 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 90552 | lr 8.407e-06 | gnorm 1.122 | train_wall 1580 | wall 0
2020-12-22 09:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:25 | INFO | fairseq.trainer | begin training epoch 32
2020-12-22 09:07:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:07:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:07:56 | INFO | train_inner | epoch 032:     48 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.365, loss=3.944, nll_loss=1.721, ppl=3.3, wps=14563.3, ups=1.22, wpb=11894.8, bsz=399, num_updates=90600, lr=8.40477e-06, gnorm=1.115, train_wall=51, wall=0
2020-12-22 09:08:47 | INFO | train_inner | epoch 032:    148 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.344, loss=3.945, nll_loss=1.723, ppl=3.3, wps=22992.2, ups=1.93, wpb=11888.4, bsz=411.8, num_updates=90700, lr=8.40014e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 09:09:39 | INFO | train_inner | epoch 032:    248 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.429, loss=3.919, nll_loss=1.694, ppl=3.23, wps=22888.2, ups=1.93, wpb=11844.6, bsz=412.2, num_updates=90800, lr=8.39551e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 09:10:31 | INFO | train_inner | epoch 032:    348 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.406, loss=3.916, nll_loss=1.697, ppl=3.24, wps=22898.2, ups=1.93, wpb=11879.5, bsz=420.5, num_updates=90900, lr=8.39089e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 09:11:23 | INFO | train_inner | epoch 032:    448 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.409, loss=3.952, nll_loss=1.727, ppl=3.31, wps=22765.3, ups=1.93, wpb=11773.8, bsz=406.8, num_updates=91000, lr=8.38628e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 09:12:15 | INFO | train_inner | epoch 032:    548 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.359, loss=3.954, nll_loss=1.729, ppl=3.31, wps=22861.4, ups=1.93, wpb=11833.8, bsz=433.8, num_updates=91100, lr=8.38167e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 09:13:06 | INFO | train_inner | epoch 032:    648 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.397, loss=3.931, nll_loss=1.71, ppl=3.27, wps=22896, ups=1.93, wpb=11872.6, bsz=433.4, num_updates=91200, lr=8.37708e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 09:13:58 | INFO | train_inner | epoch 032:    748 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.385, loss=3.956, nll_loss=1.732, ppl=3.32, wps=22911.4, ups=1.93, wpb=11870.3, bsz=407.9, num_updates=91300, lr=8.37249e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 09:14:51 | INFO | train_inner | epoch 032:    848 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.396, loss=3.95, nll_loss=1.727, ppl=3.31, wps=22506.9, ups=1.9, wpb=11841.7, bsz=411.2, num_updates=91400, lr=8.36791e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 09:15:43 | INFO | train_inner | epoch 032:    948 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.415, loss=3.96, nll_loss=1.732, ppl=3.32, wps=22275.4, ups=1.9, wpb=11729.3, bsz=410.1, num_updates=91500, lr=8.36333e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 09:16:36 | INFO | train_inner | epoch 032:   1048 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.395, loss=3.931, nll_loss=1.707, ppl=3.26, wps=22629.2, ups=1.9, wpb=11888.5, bsz=407.8, num_updates=91600, lr=8.35877e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 09:17:28 | INFO | train_inner | epoch 032:   1148 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.373, loss=3.943, nll_loss=1.719, ppl=3.29, wps=22843.8, ups=1.93, wpb=11851.8, bsz=422.2, num_updates=91700, lr=8.35421e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 09:18:20 | INFO | train_inner | epoch 032:   1248 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.391, loss=3.954, nll_loss=1.727, ppl=3.31, wps=22899.3, ups=1.93, wpb=11870, bsz=408.6, num_updates=91800, lr=8.34966e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 09:19:11 | INFO | train_inner | epoch 032:   1348 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.421, loss=3.93, nll_loss=1.706, ppl=3.26, wps=22968.8, ups=1.93, wpb=11875.7, bsz=399, num_updates=91900, lr=8.34511e-06, gnorm=1.117, train_wall=52, wall=0
2020-12-22 09:20:03 | INFO | train_inner | epoch 032:   1448 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.375, loss=3.937, nll_loss=1.712, ppl=3.28, wps=22939.2, ups=1.92, wpb=11927.6, bsz=407.7, num_updates=92000, lr=8.34058e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 09:20:56 | INFO | train_inner | epoch 032:   1548 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.378, loss=3.956, nll_loss=1.732, ppl=3.32, wps=22428.9, ups=1.91, wpb=11753.4, bsz=423.9, num_updates=92100, lr=8.33605e-06, gnorm=1.151, train_wall=52, wall=0
2020-12-22 09:21:49 | INFO | train_inner | epoch 032:   1648 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.396, loss=3.942, nll_loss=1.72, ppl=3.29, wps=22572, ups=1.89, wpb=11937.6, bsz=391.1, num_updates=92200, lr=8.33153e-06, gnorm=1.117, train_wall=53, wall=0
2020-12-22 09:22:41 | INFO | train_inner | epoch 032:   1748 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.391, loss=3.958, nll_loss=1.731, ppl=3.32, wps=22558.5, ups=1.9, wpb=11849.6, bsz=394.6, num_updates=92300, lr=8.32701e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 09:23:33 | INFO | train_inner | epoch 032:   1848 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.393, loss=3.938, nll_loss=1.716, ppl=3.29, wps=22908.5, ups=1.92, wpb=11914.1, bsz=395.8, num_updates=92400, lr=8.3225e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 09:24:25 | INFO | train_inner | epoch 032:   1948 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.376, loss=3.956, nll_loss=1.73, ppl=3.32, wps=22841, ups=1.93, wpb=11820.3, bsz=412.4, num_updates=92500, lr=8.318e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 09:25:17 | INFO | train_inner | epoch 032:   2048 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.368, loss=3.929, nll_loss=1.706, ppl=3.26, wps=22934.6, ups=1.92, wpb=11921.7, bsz=423, num_updates=92600, lr=8.31351e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 09:26:09 | INFO | train_inner | epoch 032:   2148 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.41, loss=3.953, nll_loss=1.729, ppl=3.32, wps=22823.5, ups=1.94, wpb=11784.1, bsz=401.2, num_updates=92700, lr=8.30903e-06, gnorm=1.13, train_wall=51, wall=0
2020-12-22 09:27:00 | INFO | train_inner | epoch 032:   2248 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.414, loss=3.958, nll_loss=1.73, ppl=3.32, wps=22875.1, ups=1.94, wpb=11762.4, bsz=386.3, num_updates=92800, lr=8.30455e-06, gnorm=1.138, train_wall=51, wall=0
2020-12-22 09:27:52 | INFO | train_inner | epoch 032:   2348 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.381, loss=3.971, nll_loss=1.746, ppl=3.35, wps=22959.6, ups=1.93, wpb=11903.2, bsz=382.9, num_updates=92900, lr=8.30008e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 09:28:44 | INFO | train_inner | epoch 032:   2448 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.39, loss=3.958, nll_loss=1.737, ppl=3.33, wps=22924.3, ups=1.93, wpb=11875.5, bsz=435.8, num_updates=93000, lr=8.29561e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 09:29:36 | INFO | train_inner | epoch 032:   2548 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.376, loss=3.942, nll_loss=1.719, ppl=3.29, wps=22899.2, ups=1.92, wpb=11915.6, bsz=398.6, num_updates=93100, lr=8.29116e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 09:30:28 | INFO | train_inner | epoch 032:   2648 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.374, loss=3.928, nll_loss=1.71, ppl=3.27, wps=22771.6, ups=1.92, wpb=11855.6, bsz=428.3, num_updates=93200, lr=8.28671e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 09:31:20 | INFO | train_inner | epoch 032:   2748 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.392, loss=3.982, nll_loss=1.754, ppl=3.37, wps=22490, ups=1.92, wpb=11710.7, bsz=377.7, num_updates=93300, lr=8.28227e-06, gnorm=1.137, train_wall=52, wall=0
2020-12-22 09:32:12 | INFO | train_inner | epoch 032:   2848 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.42, loss=3.933, nll_loss=1.711, ppl=3.27, wps=22966.6, ups=1.93, wpb=11913.6, bsz=392.4, num_updates=93400, lr=8.27783e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:33:04 | INFO | train_inner | epoch 032:   2948 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.371, loss=3.964, nll_loss=1.74, ppl=3.34, wps=22957.7, ups=1.93, wpb=11903.1, bsz=411.8, num_updates=93500, lr=8.2734e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:33:56 | INFO | train_inner | epoch 032:   3048 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.335, loss=3.934, nll_loss=1.716, ppl=3.28, wps=22627.2, ups=1.92, wpb=11791.5, bsz=440.7, num_updates=93600, lr=8.26898e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 09:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 09:34:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 09:34:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 09:34:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 09:34:19 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.876 | nll_loss 7.842 | ppl 229.37 | bleu 16.38 | wps 4355.8 | wpb 6344.2 | bsz 166.4 | num_updates 93611 | best_bleu 16.73
2020-12-22 09:34:19 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 09:34:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 32 @ 93611 updates, score 16.38) (writing took 4.3120421804487705 seconds)
2020-12-22 09:34:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-12-22 09:34:23 | INFO | train | epoch 032 | symm_kl 0.384 | self_kl 0 | self_cv 9.388 | loss 3.946 | nll_loss 1.722 | ppl 3.3 | wps 22358.6 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 93611 | lr 8.2685e-06 | gnorm 1.123 | train_wall 1585 | wall 0
2020-12-22 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:27 | INFO | fairseq.trainer | begin training epoch 33
2020-12-22 09:34:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:34:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 09:34:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 09:35:18 | INFO | train_inner | epoch 033:     89 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.389, loss=3.946, nll_loss=1.722, ppl=3.3, wps=14292.2, ups=1.21, wpb=11829.5, bsz=416.8, num_updates=93700, lr=8.26457e-06, gnorm=1.127, train_wall=51, wall=0
2020-12-22 09:36:10 | INFO | train_inner | epoch 033:    189 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.39, loss=3.918, nll_loss=1.697, ppl=3.24, wps=22887.8, ups=1.92, wpb=11890.9, bsz=416.6, num_updates=93800, lr=8.26016e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 09:37:02 | INFO | train_inner | epoch 033:    289 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.396, loss=3.923, nll_loss=1.702, ppl=3.25, wps=22843.2, ups=1.92, wpb=11878.1, bsz=391.4, num_updates=93900, lr=8.25576e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 09:37:54 | INFO | train_inner | epoch 033:    389 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.392, loss=3.942, nll_loss=1.716, ppl=3.28, wps=23030.2, ups=1.93, wpb=11923.9, bsz=379.8, num_updates=94000, lr=8.25137e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 09:38:46 | INFO | train_inner | epoch 033:    489 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.375, loss=3.936, nll_loss=1.714, ppl=3.28, wps=22797.8, ups=1.92, wpb=11847.1, bsz=427, num_updates=94100, lr=8.24698e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 09:39:38 | INFO | train_inner | epoch 033:    589 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.336, loss=3.942, nll_loss=1.722, ppl=3.3, wps=22951.4, ups=1.93, wpb=11874.5, bsz=463, num_updates=94200, lr=8.24261e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 09:40:30 | INFO | train_inner | epoch 033:    689 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.366, loss=3.961, nll_loss=1.736, ppl=3.33, wps=22552.9, ups=1.93, wpb=11711.8, bsz=432.8, num_updates=94300, lr=8.23823e-06, gnorm=1.154, train_wall=52, wall=0
2020-12-22 09:41:22 | INFO | train_inner | epoch 033:    789 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.407, loss=3.975, nll_loss=1.748, ppl=3.36, wps=22794.5, ups=1.93, wpb=11810.9, bsz=391.9, num_updates=94400, lr=8.23387e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 09:42:14 | INFO | train_inner | epoch 033:    889 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.422, loss=3.935, nll_loss=1.712, ppl=3.28, wps=22767.1, ups=1.93, wpb=11813.5, bsz=406.4, num_updates=94500, lr=8.22951e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:43:05 | INFO | train_inner | epoch 033:    989 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.366, loss=3.939, nll_loss=1.719, ppl=3.29, wps=22972.4, ups=1.93, wpb=11932.6, bsz=411.8, num_updates=94600, lr=8.22516e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 09:43:57 | INFO | train_inner | epoch 033:   1089 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.374, loss=3.95, nll_loss=1.727, ppl=3.31, wps=22910.2, ups=1.93, wpb=11853.4, bsz=426.2, num_updates=94700, lr=8.22082e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 09:44:49 | INFO | train_inner | epoch 033:   1189 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.44, loss=3.955, nll_loss=1.731, ppl=3.32, wps=22663.8, ups=1.93, wpb=11741.6, bsz=397.6, num_updates=94800, lr=8.21648e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 09:45:41 | INFO | train_inner | epoch 033:   1289 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.374, loss=3.929, nll_loss=1.71, ppl=3.27, wps=22869.2, ups=1.93, wpb=11835.1, bsz=410.2, num_updates=94900, lr=8.21215e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 09:46:32 | INFO | train_inner | epoch 033:   1389 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.431, loss=3.954, nll_loss=1.732, ppl=3.32, wps=22669.5, ups=1.93, wpb=11723.3, bsz=408, num_updates=95000, lr=8.20783e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 09:47:24 | INFO | train_inner | epoch 033:   1489 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.396, loss=3.938, nll_loss=1.715, ppl=3.28, wps=22826.8, ups=1.93, wpb=11850.8, bsz=383.7, num_updates=95100, lr=8.20351e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 09:48:16 | INFO | train_inner | epoch 033:   1589 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.412, loss=3.941, nll_loss=1.717, ppl=3.29, wps=22880.7, ups=1.93, wpb=11855.2, bsz=407.4, num_updates=95200, lr=8.1992e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 09:49:08 | INFO | train_inner | epoch 033:   1689 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.396, loss=3.928, nll_loss=1.707, ppl=3.26, wps=23012.1, ups=1.93, wpb=11926.7, bsz=415.9, num_updates=95300, lr=8.1949e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 09:50:00 | INFO | train_inner | epoch 033:   1789 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.367, loss=3.949, nll_loss=1.728, ppl=3.31, wps=22802.6, ups=1.93, wpb=11805, bsz=431.8, num_updates=95400, lr=8.1906e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 09:50:52 | INFO | train_inner | epoch 033:   1889 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.38, loss=3.928, nll_loss=1.707, ppl=3.27, wps=22946.7, ups=1.92, wpb=11923.6, bsz=408, num_updates=95500, lr=8.18631e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 09:51:44 | INFO | train_inner | epoch 033:   1989 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.366, loss=3.94, nll_loss=1.723, ppl=3.3, wps=22960.4, ups=1.93, wpb=11914.7, bsz=395.6, num_updates=95600, lr=8.18203e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 09:52:37 | INFO | train_inner | epoch 033:   2089 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.373, loss=3.944, nll_loss=1.721, ppl=3.3, wps=22245.5, ups=1.89, wpb=11777.1, bsz=411.4, num_updates=95700, lr=8.17775e-06, gnorm=1.135, train_wall=53, wall=0
2020-12-22 09:53:29 | INFO | train_inner | epoch 033:   2189 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.377, loss=3.926, nll_loss=1.707, ppl=3.26, wps=23027.2, ups=1.92, wpb=12015.1, bsz=411.8, num_updates=95800, lr=8.17348e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 09:54:20 | INFO | train_inner | epoch 033:   2289 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.414, loss=3.958, nll_loss=1.735, ppl=3.33, wps=22887.9, ups=1.94, wpb=11784.2, bsz=412.7, num_updates=95900, lr=8.16922e-06, gnorm=1.136, train_wall=51, wall=0
2020-12-22 09:55:12 | INFO | train_inner | epoch 033:   2389 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.356, loss=3.951, nll_loss=1.728, ppl=3.31, wps=22817.2, ups=1.94, wpb=11790.7, bsz=404.7, num_updates=96000, lr=8.16497e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:56:04 | INFO | train_inner | epoch 033:   2489 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.357, loss=3.968, nll_loss=1.744, ppl=3.35, wps=22980.8, ups=1.93, wpb=11927.6, bsz=404.6, num_updates=96100, lr=8.16072e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:56:56 | INFO | train_inner | epoch 033:   2589 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.386, loss=3.964, nll_loss=1.738, ppl=3.34, wps=22861.7, ups=1.92, wpb=11882.7, bsz=383.4, num_updates=96200, lr=8.15647e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 09:57:48 | INFO | train_inner | epoch 033:   2689 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.381, loss=3.944, nll_loss=1.722, ppl=3.3, wps=22789.7, ups=1.92, wpb=11873.1, bsz=414.6, num_updates=96300, lr=8.15224e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 09:58:40 | INFO | train_inner | epoch 033:   2789 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.395, loss=3.946, nll_loss=1.724, ppl=3.3, wps=22787.5, ups=1.93, wpb=11819.4, bsz=419.8, num_updates=96400, lr=8.14801e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 09:59:32 | INFO | train_inner | epoch 033:   2889 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.403, loss=3.946, nll_loss=1.722, ppl=3.3, wps=22893.6, ups=1.93, wpb=11865, bsz=396.3, num_updates=96500, lr=8.14379e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 10:00:24 | INFO | train_inner | epoch 033:   2989 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.397, loss=3.954, nll_loss=1.73, ppl=3.32, wps=22873.7, ups=1.92, wpb=11895.4, bsz=407.4, num_updates=96600, lr=8.13957e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 10:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 10:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 10:01:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 10:01:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 10:01:16 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.869 | nll_loss 7.834 | ppl 228.24 | bleu 16.51 | wps 5013.4 | wpb 6344.2 | bsz 166.4 | num_updates 96670 | best_bleu 16.73
2020-12-22 10:01:16 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 10:01:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 33 @ 96670 updates, score 16.51) (writing took 4.657998075708747 seconds)
2020-12-22 10:01:20 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-12-22 10:01:20 | INFO | train | epoch 033 | symm_kl 0.383 | self_kl 0 | self_cv 9.387 | loss 3.945 | nll_loss 1.722 | ppl 3.3 | wps 22418.9 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 96670 | lr 8.13662e-06 | gnorm 1.124 | train_wall 1582 | wall 0
2020-12-22 10:01:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:24 | INFO | fairseq.trainer | begin training epoch 34
2020-12-22 10:01:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:01:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:01:45 | INFO | train_inner | epoch 034:     30 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.384, loss=3.952, nll_loss=1.73, ppl=3.32, wps=14481.1, ups=1.22, wpb=11832.1, bsz=412, num_updates=96700, lr=8.13536e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 10:02:37 | INFO | train_inner | epoch 034:    130 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.37, loss=3.914, nll_loss=1.694, ppl=3.24, wps=23154.6, ups=1.94, wpb=11928.2, bsz=403.4, num_updates=96800, lr=8.13116e-06, gnorm=1.117, train_wall=51, wall=0
2020-12-22 10:03:29 | INFO | train_inner | epoch 034:    230 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.362, loss=3.927, nll_loss=1.707, ppl=3.27, wps=22797.9, ups=1.93, wpb=11817.8, bsz=429.3, num_updates=96900, lr=8.12696e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 10:04:20 | INFO | train_inner | epoch 034:    330 / 3059 symm_kl=0.389, self_kl=0, self_cv=9.38, loss=3.971, nll_loss=1.743, ppl=3.35, wps=22953.8, ups=1.94, wpb=11828.8, bsz=394.1, num_updates=97000, lr=8.12277e-06, gnorm=1.133, train_wall=51, wall=0
2020-12-22 10:05:12 | INFO | train_inner | epoch 034:    430 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.366, loss=3.926, nll_loss=1.706, ppl=3.26, wps=22952.4, ups=1.93, wpb=11906.7, bsz=423.4, num_updates=97100, lr=8.11859e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 10:06:04 | INFO | train_inner | epoch 034:    530 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.407, loss=3.952, nll_loss=1.726, ppl=3.31, wps=22801.4, ups=1.92, wpb=11847.5, bsz=392.3, num_updates=97200, lr=8.11441e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 10:06:56 | INFO | train_inner | epoch 034:    630 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.399, loss=3.909, nll_loss=1.692, ppl=3.23, wps=22832.7, ups=1.92, wpb=11880.7, bsz=433.8, num_updates=97300, lr=8.11024e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 10:07:49 | INFO | train_inner | epoch 034:    730 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.403, loss=3.941, nll_loss=1.716, ppl=3.29, wps=22545.7, ups=1.89, wpb=11900.6, bsz=400.8, num_updates=97400, lr=8.10607e-06, gnorm=1.131, train_wall=53, wall=0
2020-12-22 10:08:42 | INFO | train_inner | epoch 034:    830 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.443, loss=3.931, nll_loss=1.71, ppl=3.27, wps=22291.3, ups=1.89, wpb=11821.2, bsz=438.8, num_updates=97500, lr=8.10191e-06, gnorm=1.125, train_wall=53, wall=0
2020-12-22 10:09:35 | INFO | train_inner | epoch 034:    930 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.39, loss=3.937, nll_loss=1.715, ppl=3.28, wps=22558.8, ups=1.9, wpb=11886, bsz=424.4, num_updates=97600, lr=8.09776e-06, gnorm=1.116, train_wall=53, wall=0
2020-12-22 10:10:27 | INFO | train_inner | epoch 034:   1030 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.401, loss=3.958, nll_loss=1.731, ppl=3.32, wps=22899.2, ups=1.93, wpb=11884.2, bsz=374.6, num_updates=97700, lr=8.09362e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 10:11:18 | INFO | train_inner | epoch 034:   1130 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.386, loss=3.963, nll_loss=1.737, ppl=3.33, wps=22740.9, ups=1.93, wpb=11813.4, bsz=404.2, num_updates=97800, lr=8.08948e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 10:12:11 | INFO | train_inner | epoch 034:   1230 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.386, loss=3.933, nll_loss=1.709, ppl=3.27, wps=22798.4, ups=1.92, wpb=11871.4, bsz=408, num_updates=97900, lr=8.08535e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 10:13:02 | INFO | train_inner | epoch 034:   1330 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.386, loss=3.955, nll_loss=1.735, ppl=3.33, wps=22768.2, ups=1.94, wpb=11747.1, bsz=426.4, num_updates=98000, lr=8.08122e-06, gnorm=1.128, train_wall=51, wall=0
2020-12-22 10:13:54 | INFO | train_inner | epoch 034:   1430 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.445, loss=3.965, nll_loss=1.736, ppl=3.33, wps=22760.1, ups=1.93, wpb=11808.3, bsz=377.6, num_updates=98100, lr=8.0771e-06, gnorm=1.136, train_wall=52, wall=0
2020-12-22 10:14:46 | INFO | train_inner | epoch 034:   1530 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.395, loss=3.932, nll_loss=1.714, ppl=3.28, wps=22868.4, ups=1.92, wpb=11896.8, bsz=401, num_updates=98200, lr=8.07299e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 10:15:38 | INFO | train_inner | epoch 034:   1630 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.419, loss=3.932, nll_loss=1.71, ppl=3.27, wps=22922.2, ups=1.94, wpb=11834.7, bsz=405.9, num_updates=98300, lr=8.06888e-06, gnorm=1.122, train_wall=51, wall=0
2020-12-22 10:16:29 | INFO | train_inner | epoch 034:   1730 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.418, loss=3.948, nll_loss=1.724, ppl=3.3, wps=22914.5, ups=1.94, wpb=11828.9, bsz=388.1, num_updates=98400, lr=8.06478e-06, gnorm=1.126, train_wall=51, wall=0
2020-12-22 10:17:21 | INFO | train_inner | epoch 034:   1830 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.381, loss=3.957, nll_loss=1.733, ppl=3.32, wps=22676.9, ups=1.93, wpb=11749.8, bsz=408.3, num_updates=98500, lr=8.06068e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 10:18:13 | INFO | train_inner | epoch 034:   1930 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.375, loss=3.945, nll_loss=1.724, ppl=3.3, wps=22791.7, ups=1.92, wpb=11860.3, bsz=412, num_updates=98600, lr=8.05659e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 10:19:05 | INFO | train_inner | epoch 034:   2030 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.368, loss=3.927, nll_loss=1.713, ppl=3.28, wps=22967.1, ups=1.92, wpb=11931.6, bsz=419.4, num_updates=98700, lr=8.05251e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 10:19:57 | INFO | train_inner | epoch 034:   2130 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.388, loss=3.947, nll_loss=1.728, ppl=3.31, wps=22696, ups=1.92, wpb=11851.6, bsz=428.2, num_updates=98800, lr=8.04844e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 10:20:50 | INFO | train_inner | epoch 034:   2230 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.358, loss=3.94, nll_loss=1.721, ppl=3.3, wps=22523.3, ups=1.9, wpb=11849.1, bsz=412, num_updates=98900, lr=8.04437e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 10:21:43 | INFO | train_inner | epoch 034:   2330 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.372, loss=3.942, nll_loss=1.719, ppl=3.29, wps=22558.9, ups=1.9, wpb=11881.4, bsz=395.7, num_updates=99000, lr=8.0403e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 10:22:35 | INFO | train_inner | epoch 034:   2430 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.382, loss=3.961, nll_loss=1.739, ppl=3.34, wps=22546.7, ups=1.92, wpb=11771.3, bsz=406.8, num_updates=99100, lr=8.03624e-06, gnorm=1.136, train_wall=52, wall=0
2020-12-22 10:23:27 | INFO | train_inner | epoch 034:   2530 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.402, loss=3.951, nll_loss=1.729, ppl=3.32, wps=22735.3, ups=1.93, wpb=11805.7, bsz=389.4, num_updates=99200, lr=8.03219e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 10:24:19 | INFO | train_inner | epoch 034:   2630 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.352, loss=3.943, nll_loss=1.721, ppl=3.3, wps=22928.1, ups=1.92, wpb=11949, bsz=410.3, num_updates=99300, lr=8.02815e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 10:25:11 | INFO | train_inner | epoch 034:   2730 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.403, loss=3.94, nll_loss=1.722, ppl=3.3, wps=22664.2, ups=1.91, wpb=11873.8, bsz=442.2, num_updates=99400, lr=8.02411e-06, gnorm=1.115, train_wall=52, wall=0
2020-12-22 10:26:03 | INFO | train_inner | epoch 034:   2830 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.391, loss=3.951, nll_loss=1.733, ppl=3.32, wps=22558.2, ups=1.92, wpb=11761.3, bsz=410.4, num_updates=99500, lr=8.02008e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 10:26:55 | INFO | train_inner | epoch 034:   2930 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.381, loss=3.943, nll_loss=1.724, ppl=3.3, wps=22848.2, ups=1.93, wpb=11832.9, bsz=401, num_updates=99600, lr=8.01605e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 10:27:48 | INFO | train_inner | epoch 034:   3030 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.353, loss=3.937, nll_loss=1.718, ppl=3.29, wps=22681.3, ups=1.9, wpb=11966.2, bsz=439.9, num_updates=99700, lr=8.01203e-06, gnorm=1.113, train_wall=53, wall=0
2020-12-22 10:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 10:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 10:28:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 10:28:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 10:28:18 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.867 | nll_loss 7.833 | ppl 228.01 | bleu 16.66 | wps 5000.5 | wpb 6344.2 | bsz 166.4 | num_updates 99729 | best_bleu 16.73
2020-12-22 10:28:18 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 10:28:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 34 @ 99729 updates, score 16.66) (writing took 4.766152624040842 seconds)
2020-12-22 10:28:23 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-12-22 10:28:23 | INFO | train | epoch 034 | symm_kl 0.382 | self_kl 0 | self_cv 9.389 | loss 3.943 | nll_loss 1.721 | ppl 3.3 | wps 22337.9 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 99729 | lr 8.01086e-06 | gnorm 1.123 | train_wall 1588 | wall 0
2020-12-22 10:28:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:27 | INFO | fairseq.trainer | begin training epoch 35
2020-12-22 10:28:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:28:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:28:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:29:10 | INFO | train_inner | epoch 035:     71 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.361, loss=3.944, nll_loss=1.724, ppl=3.3, wps=14561.7, ups=1.22, wpb=11921, bsz=414.7, num_updates=99800, lr=8.00801e-06, gnorm=1.129, train_wall=51, wall=0
2020-12-22 10:30:02 | INFO | train_inner | epoch 035:    171 / 3059 symm_kl=0.388, self_kl=0, self_cv=9.386, loss=3.969, nll_loss=1.742, ppl=3.34, wps=22619, ups=1.93, wpb=11728.4, bsz=383.3, num_updates=99900, lr=8.004e-06, gnorm=1.137, train_wall=52, wall=0
2020-12-22 10:30:54 | INFO | train_inner | epoch 035:    271 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.408, loss=3.918, nll_loss=1.697, ppl=3.24, wps=22842.6, ups=1.92, wpb=11867.1, bsz=429, num_updates=100000, lr=8e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 10:31:45 | INFO | train_inner | epoch 035:    371 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.411, loss=3.938, nll_loss=1.718, ppl=3.29, wps=22872.1, ups=1.93, wpb=11872.5, bsz=409.6, num_updates=100100, lr=7.996e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 10:32:38 | INFO | train_inner | epoch 035:    471 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.421, loss=3.927, nll_loss=1.709, ppl=3.27, wps=22704.8, ups=1.92, wpb=11838.6, bsz=426, num_updates=100200, lr=7.99201e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 10:33:30 | INFO | train_inner | epoch 035:    571 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.373, loss=3.959, nll_loss=1.735, ppl=3.33, wps=22757.3, ups=1.92, wpb=11860.5, bsz=411, num_updates=100300, lr=7.98803e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 10:34:23 | INFO | train_inner | epoch 035:    671 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.442, loss=3.934, nll_loss=1.711, ppl=3.27, wps=22228.9, ups=1.87, wpb=11856.1, bsz=375.3, num_updates=100400, lr=7.98405e-06, gnorm=1.126, train_wall=53, wall=0
2020-12-22 10:35:17 | INFO | train_inner | epoch 035:    771 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.399, loss=3.943, nll_loss=1.717, ppl=3.29, wps=22165.7, ups=1.87, wpb=11849.4, bsz=387.4, num_updates=100500, lr=7.98007e-06, gnorm=1.13, train_wall=53, wall=0
2020-12-22 10:36:10 | INFO | train_inner | epoch 035:    871 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.395, loss=3.958, nll_loss=1.732, ppl=3.32, wps=22046.6, ups=1.88, wpb=11740.1, bsz=412.2, num_updates=100600, lr=7.97611e-06, gnorm=1.142, train_wall=53, wall=0
2020-12-22 10:37:03 | INFO | train_inner | epoch 035:    971 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.388, loss=3.94, nll_loss=1.719, ppl=3.29, wps=22418.1, ups=1.88, wpb=11893.1, bsz=400.2, num_updates=100700, lr=7.97215e-06, gnorm=1.123, train_wall=53, wall=0
2020-12-22 10:37:55 | INFO | train_inner | epoch 035:   1071 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.402, loss=3.958, nll_loss=1.734, ppl=3.33, wps=22723.2, ups=1.93, wpb=11778.7, bsz=390.6, num_updates=100800, lr=7.96819e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 10:38:47 | INFO | train_inner | epoch 035:   1171 / 3059 symm_kl=0.387, self_kl=0, self_cv=9.391, loss=3.978, nll_loss=1.754, ppl=3.37, wps=22504, ups=1.91, wpb=11759.8, bsz=403.5, num_updates=100900, lr=7.96424e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 10:39:39 | INFO | train_inner | epoch 035:   1271 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.379, loss=3.954, nll_loss=1.73, ppl=3.32, wps=22513.2, ups=1.92, wpb=11736.5, bsz=403.7, num_updates=101000, lr=7.9603e-06, gnorm=1.141, train_wall=52, wall=0
2020-12-22 10:40:31 | INFO | train_inner | epoch 035:   1371 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.369, loss=3.94, nll_loss=1.721, ppl=3.3, wps=22765.8, ups=1.92, wpb=11870.1, bsz=428.2, num_updates=101100, lr=7.95636e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 10:41:23 | INFO | train_inner | epoch 035:   1471 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.39, loss=3.922, nll_loss=1.702, ppl=3.25, wps=22732.9, ups=1.92, wpb=11862.2, bsz=405.6, num_updates=101200, lr=7.95243e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 10:42:17 | INFO | train_inner | epoch 035:   1571 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.382, loss=3.941, nll_loss=1.72, ppl=3.29, wps=22085.1, ups=1.87, wpb=11785.7, bsz=383.2, num_updates=101300, lr=7.9485e-06, gnorm=1.126, train_wall=53, wall=0
2020-12-22 10:43:10 | INFO | train_inner | epoch 035:   1671 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.403, loss=3.924, nll_loss=1.705, ppl=3.26, wps=22141.2, ups=1.87, wpb=11826.5, bsz=424.4, num_updates=101400, lr=7.94458e-06, gnorm=1.122, train_wall=53, wall=0
2020-12-22 10:44:02 | INFO | train_inner | epoch 035:   1771 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.367, loss=3.936, nll_loss=1.714, ppl=3.28, wps=22800.6, ups=1.92, wpb=11854.3, bsz=402.7, num_updates=101500, lr=7.94067e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 10:44:54 | INFO | train_inner | epoch 035:   1871 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.373, loss=3.93, nll_loss=1.713, ppl=3.28, wps=22938.5, ups=1.92, wpb=11939.9, bsz=415.9, num_updates=101600, lr=7.93676e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 10:45:46 | INFO | train_inner | epoch 035:   1971 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.394, loss=3.958, nll_loss=1.738, ppl=3.34, wps=22705.5, ups=1.92, wpb=11827, bsz=402.7, num_updates=101700, lr=7.93285e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 10:46:38 | INFO | train_inner | epoch 035:   2071 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.393, loss=3.931, nll_loss=1.713, ppl=3.28, wps=22840.2, ups=1.92, wpb=11867.2, bsz=415.1, num_updates=101800, lr=7.92896e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 10:47:30 | INFO | train_inner | epoch 035:   2171 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.37, loss=3.94, nll_loss=1.721, ppl=3.3, wps=22964, ups=1.92, wpb=11931.8, bsz=415.8, num_updates=101900, lr=7.92507e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 10:48:23 | INFO | train_inner | epoch 035:   2271 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.383, loss=3.912, nll_loss=1.697, ppl=3.24, wps=22923.8, ups=1.91, wpb=12015.8, bsz=439.2, num_updates=102000, lr=7.92118e-06, gnorm=1.111, train_wall=52, wall=0
2020-12-22 10:49:16 | INFO | train_inner | epoch 035:   2371 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.38, loss=3.936, nll_loss=1.719, ppl=3.29, wps=22461.7, ups=1.89, wpb=11884.1, bsz=410, num_updates=102100, lr=7.9173e-06, gnorm=1.117, train_wall=53, wall=0
2020-12-22 10:50:09 | INFO | train_inner | epoch 035:   2471 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.357, loss=3.929, nll_loss=1.713, ppl=3.28, wps=22423.3, ups=1.88, wpb=11901.5, bsz=422.7, num_updates=102200, lr=7.91343e-06, gnorm=1.117, train_wall=53, wall=0
2020-12-22 10:51:01 | INFO | train_inner | epoch 035:   2571 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.406, loss=3.935, nll_loss=1.718, ppl=3.29, wps=22838, ups=1.92, wpb=11892.8, bsz=405, num_updates=102300, lr=7.90956e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 10:51:52 | INFO | train_inner | epoch 035:   2671 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.362, loss=3.969, nll_loss=1.748, ppl=3.36, wps=22784.4, ups=1.93, wpb=11795.5, bsz=429.3, num_updates=102400, lr=7.90569e-06, gnorm=1.149, train_wall=52, wall=0
2020-12-22 10:52:44 | INFO | train_inner | epoch 035:   2771 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.362, loss=3.954, nll_loss=1.733, ppl=3.32, wps=22873.9, ups=1.92, wpb=11887.8, bsz=389.5, num_updates=102500, lr=7.90184e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 10:53:37 | INFO | train_inner | epoch 035:   2871 / 3059 symm_kl=0.386, self_kl=0, self_cv=9.357, loss=3.973, nll_loss=1.75, ppl=3.36, wps=22671.9, ups=1.92, wpb=11820.5, bsz=400.9, num_updates=102600, lr=7.89799e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 10:54:29 | INFO | train_inner | epoch 035:   2971 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.375, loss=3.921, nll_loss=1.704, ppl=3.26, wps=22820.8, ups=1.91, wpb=11927.2, bsz=416.9, num_updates=102700, lr=7.89414e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 10:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 10:55:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 10:55:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 10:55:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 10:55:34 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.875 | nll_loss 7.842 | ppl 229.47 | bleu 16.58 | wps 4513.7 | wpb 6344.2 | bsz 166.4 | num_updates 102788 | best_bleu 16.73
2020-12-22 10:55:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 10:55:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 35 @ 102788 updates, score 16.58) (writing took 4.877472665160894 seconds)
2020-12-22 10:55:39 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-12-22 10:55:39 | INFO | train | epoch 035 | symm_kl 0.382 | self_kl 0 | self_cv 9.385 | loss 3.942 | nll_loss 1.721 | ppl 3.3 | wps 22169.1 | ups 1.87 | wpb 11852.2 | bsz 409.6 | num_updates 102788 | lr 7.89076e-06 | gnorm 1.125 | train_wall 1597 | wall 0
2020-12-22 10:55:43 | INFO | fairseq.trainer | begin training epoch 36
2020-12-22 10:55:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 10:55:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 10:55:56 | INFO | train_inner | epoch 036:     12 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.352, loss=3.949, nll_loss=1.73, ppl=3.32, wps=13534, ups=1.15, wpb=11814.4, bsz=430.1, num_updates=102800, lr=7.8903e-06, gnorm=1.127, train_wall=53, wall=0
2020-12-22 10:56:48 | INFO | train_inner | epoch 036:    112 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.385, loss=3.944, nll_loss=1.724, ppl=3.3, wps=22980.8, ups=1.94, wpb=11818.7, bsz=406.7, num_updates=102900, lr=7.88646e-06, gnorm=1.127, train_wall=51, wall=0
2020-12-22 10:57:40 | INFO | train_inner | epoch 036:    212 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.382, loss=3.95, nll_loss=1.728, ppl=3.31, wps=22743.7, ups=1.92, wpb=11828.8, bsz=396.6, num_updates=103000, lr=7.88263e-06, gnorm=1.142, train_wall=52, wall=0
2020-12-22 10:58:31 | INFO | train_inner | epoch 036:    312 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.406, loss=3.926, nll_loss=1.706, ppl=3.26, wps=22760, ups=1.93, wpb=11787.5, bsz=407.6, num_updates=103100, lr=7.87881e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 10:59:24 | INFO | train_inner | epoch 036:    412 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.399, loss=3.923, nll_loss=1.704, ppl=3.26, wps=22927.3, ups=1.92, wpb=11952.3, bsz=417.8, num_updates=103200, lr=7.87499e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 11:00:16 | INFO | train_inner | epoch 036:    512 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.399, loss=3.95, nll_loss=1.727, ppl=3.31, wps=22765.9, ups=1.92, wpb=11843.2, bsz=407.7, num_updates=103300, lr=7.87118e-06, gnorm=1.139, train_wall=52, wall=0
2020-12-22 11:01:07 | INFO | train_inner | epoch 036:    612 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.416, loss=3.935, nll_loss=1.715, ppl=3.28, wps=22853.5, ups=1.93, wpb=11856.4, bsz=405.2, num_updates=103400, lr=7.86737e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 11:02:00 | INFO | train_inner | epoch 036:    712 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.396, loss=3.941, nll_loss=1.719, ppl=3.29, wps=22409.9, ups=1.9, wpb=11800.5, bsz=406.2, num_updates=103500, lr=7.86357e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 11:02:54 | INFO | train_inner | epoch 036:    812 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.422, loss=3.935, nll_loss=1.715, ppl=3.28, wps=22036.3, ups=1.87, wpb=11799.6, bsz=404.7, num_updates=103600, lr=7.85977e-06, gnorm=1.126, train_wall=53, wall=0
2020-12-22 11:03:47 | INFO | train_inner | epoch 036:    912 / 3059 symm_kl=0.377, self_kl=0, self_cv=9.4, loss=3.915, nll_loss=1.698, ppl=3.24, wps=22433, ups=1.89, wpb=11880, bsz=453.4, num_updates=103700, lr=7.85598e-06, gnorm=1.12, train_wall=53, wall=0
2020-12-22 11:04:40 | INFO | train_inner | epoch 036:   1012 / 3059 symm_kl=0.377, self_kl=0, self_cv=9.4, loss=3.925, nll_loss=1.709, ppl=3.27, wps=22141.7, ups=1.88, wpb=11804.4, bsz=416.2, num_updates=103800, lr=7.8522e-06, gnorm=1.124, train_wall=53, wall=0
2020-12-22 11:05:32 | INFO | train_inner | epoch 036:   1112 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.375, loss=3.946, nll_loss=1.724, ppl=3.3, wps=22768.8, ups=1.91, wpb=11906.4, bsz=409.6, num_updates=103900, lr=7.84842e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 11:06:25 | INFO | train_inner | epoch 036:   1212 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.385, loss=3.957, nll_loss=1.735, ppl=3.33, wps=22586.2, ups=1.91, wpb=11847.9, bsz=399.4, num_updates=104000, lr=7.84465e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 11:07:17 | INFO | train_inner | epoch 036:   1312 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.399, loss=3.933, nll_loss=1.716, ppl=3.29, wps=22780.5, ups=1.92, wpb=11843.4, bsz=420.6, num_updates=104100, lr=7.84088e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 11:08:09 | INFO | train_inner | epoch 036:   1412 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.373, loss=3.936, nll_loss=1.72, ppl=3.29, wps=22720.5, ups=1.92, wpb=11859.4, bsz=427.8, num_updates=104200, lr=7.83711e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 11:09:01 | INFO | train_inner | epoch 036:   1512 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.38, loss=3.941, nll_loss=1.721, ppl=3.3, wps=22809.5, ups=1.92, wpb=11880.7, bsz=416.6, num_updates=104300, lr=7.83336e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 11:09:53 | INFO | train_inner | epoch 036:   1612 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.377, loss=3.943, nll_loss=1.722, ppl=3.3, wps=22712.4, ups=1.92, wpb=11850.3, bsz=409.8, num_updates=104400, lr=7.8296e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 11:10:46 | INFO | train_inner | epoch 036:   1712 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.361, loss=3.95, nll_loss=1.731, ppl=3.32, wps=22466.8, ups=1.89, wpb=11892.1, bsz=446.3, num_updates=104500, lr=7.82586e-06, gnorm=1.127, train_wall=53, wall=0
2020-12-22 11:11:39 | INFO | train_inner | epoch 036:   1812 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.363, loss=3.976, nll_loss=1.753, ppl=3.37, wps=22430, ups=1.9, wpb=11785.9, bsz=406.3, num_updates=104600, lr=7.82211e-06, gnorm=1.144, train_wall=52, wall=0
2020-12-22 11:12:32 | INFO | train_inner | epoch 036:   1912 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.396, loss=3.947, nll_loss=1.728, ppl=3.31, wps=22136.4, ups=1.86, wpb=11872.1, bsz=411, num_updates=104700, lr=7.81838e-06, gnorm=1.125, train_wall=53, wall=0
2020-12-22 11:13:24 | INFO | train_inner | epoch 036:   2012 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.349, loss=3.95, nll_loss=1.731, ppl=3.32, wps=23001.3, ups=1.93, wpb=11898.7, bsz=401.8, num_updates=104800, lr=7.81465e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:14:16 | INFO | train_inner | epoch 036:   2112 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.364, loss=3.941, nll_loss=1.721, ppl=3.3, wps=22857.3, ups=1.93, wpb=11863.7, bsz=410.5, num_updates=104900, lr=7.81092e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 11:15:08 | INFO | train_inner | epoch 036:   2212 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.407, loss=3.936, nll_loss=1.719, ppl=3.29, wps=22814.3, ups=1.93, wpb=11843.5, bsz=418.2, num_updates=105000, lr=7.8072e-06, gnorm=1.116, train_wall=52, wall=0
2020-12-22 11:16:00 | INFO | train_inner | epoch 036:   2312 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.391, loss=3.948, nll_loss=1.727, ppl=3.31, wps=22731.9, ups=1.92, wpb=11850, bsz=414.5, num_updates=105100, lr=7.80349e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:16:52 | INFO | train_inner | epoch 036:   2412 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.404, loss=3.927, nll_loss=1.708, ppl=3.27, wps=22891.9, ups=1.93, wpb=11845.4, bsz=394.6, num_updates=105200, lr=7.79978e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 11:17:44 | INFO | train_inner | epoch 036:   2512 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.411, loss=3.945, nll_loss=1.725, ppl=3.31, wps=22674.8, ups=1.92, wpb=11832.2, bsz=385, num_updates=105300, lr=7.79607e-06, gnorm=1.137, train_wall=52, wall=0
2020-12-22 11:18:36 | INFO | train_inner | epoch 036:   2612 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.355, loss=3.953, nll_loss=1.733, ppl=3.32, wps=22791.2, ups=1.92, wpb=11889, bsz=399.1, num_updates=105400, lr=7.79237e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 11:19:28 | INFO | train_inner | epoch 036:   2712 / 3059 symm_kl=0.375, self_kl=0, self_cv=9.362, loss=3.92, nll_loss=1.706, ppl=3.26, wps=22854.1, ups=1.93, wpb=11841.8, bsz=429, num_updates=105500, lr=7.78868e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 11:20:20 | INFO | train_inner | epoch 036:   2812 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.395, loss=3.959, nll_loss=1.737, ppl=3.33, wps=22768.7, ups=1.92, wpb=11839.7, bsz=374.3, num_updates=105600, lr=7.78499e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 11:21:12 | INFO | train_inner | epoch 036:   2912 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.384, loss=3.932, nll_loss=1.717, ppl=3.29, wps=22928.6, ups=1.93, wpb=11858, bsz=389.1, num_updates=105700, lr=7.78131e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 11:22:03 | INFO | train_inner | epoch 036:   3012 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.391, loss=3.952, nll_loss=1.73, ppl=3.32, wps=22909.6, ups=1.93, wpb=11849.9, bsz=386.5, num_updates=105800, lr=7.77763e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 11:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 11:22:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 11:22:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 11:22:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 11:22:43 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.864 | nll_loss 7.829 | ppl 227.4 | bleu 16.61 | wps 5007.9 | wpb 6344.2 | bsz 166.4 | num_updates 105847 | best_bleu 16.73
2020-12-22 11:22:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 11:22:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 36 @ 105847 updates, score 16.61) (writing took 4.662499396130443 seconds)
2020-12-22 11:22:48 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-12-22 11:22:48 | INFO | train | epoch 036 | symm_kl 0.381 | self_kl 0 | self_cv 9.387 | loss 3.941 | nll_loss 1.721 | ppl 3.3 | wps 22255.9 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 105847 | lr 7.7759e-06 | gnorm 1.125 | train_wall 1592 | wall 0
2020-12-22 11:22:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:51 | INFO | fairseq.trainer | begin training epoch 37
2020-12-22 11:22:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:22:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:22:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:23:25 | INFO | train_inner | epoch 037:     53 / 3059 symm_kl=0.371, self_kl=0, self_cv=9.366, loss=3.896, nll_loss=1.687, ppl=3.22, wps=14641.4, ups=1.23, wpb=11928.9, bsz=458.6, num_updates=105900, lr=7.77395e-06, gnorm=1.103, train_wall=51, wall=0
2020-12-22 11:24:16 | INFO | train_inner | epoch 037:    153 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.369, loss=3.947, nll_loss=1.727, ppl=3.31, wps=22632.8, ups=1.94, wpb=11683.2, bsz=402.3, num_updates=106000, lr=7.77029e-06, gnorm=1.145, train_wall=51, wall=0
2020-12-22 11:25:08 | INFO | train_inner | epoch 037:    253 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.386, loss=3.936, nll_loss=1.714, ppl=3.28, wps=22997.5, ups=1.92, wpb=11948.3, bsz=388.6, num_updates=106100, lr=7.76662e-06, gnorm=1.114, train_wall=52, wall=0
2020-12-22 11:26:00 | INFO | train_inner | epoch 037:    353 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.352, loss=3.942, nll_loss=1.725, ppl=3.3, wps=22819.8, ups=1.92, wpb=11877.2, bsz=432.8, num_updates=106200, lr=7.76297e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 11:26:52 | INFO | train_inner | epoch 037:    453 / 3059 symm_kl=0.385, self_kl=0, self_cv=9.376, loss=3.957, nll_loss=1.733, ppl=3.33, wps=22779, ups=1.93, wpb=11807.6, bsz=380.4, num_updates=106300, lr=7.75931e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 11:27:44 | INFO | train_inner | epoch 037:    553 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.373, loss=3.954, nll_loss=1.734, ppl=3.33, wps=22770.8, ups=1.91, wpb=11896.9, bsz=402.3, num_updates=106400, lr=7.75567e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 11:28:37 | INFO | train_inner | epoch 037:    653 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.394, loss=3.934, nll_loss=1.717, ppl=3.29, wps=22503, ups=1.9, wpb=11821.7, bsz=400.4, num_updates=106500, lr=7.75203e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 11:29:30 | INFO | train_inner | epoch 037:    753 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.388, loss=3.933, nll_loss=1.718, ppl=3.29, wps=22471.8, ups=1.9, wpb=11836.8, bsz=409.7, num_updates=106600, lr=7.74839e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 11:30:22 | INFO | train_inner | epoch 037:    853 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.394, loss=3.951, nll_loss=1.732, ppl=3.32, wps=22373.8, ups=1.89, wpb=11816.4, bsz=403.4, num_updates=106700, lr=7.74476e-06, gnorm=1.143, train_wall=53, wall=0
2020-12-22 11:31:14 | INFO | train_inner | epoch 037:    953 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.377, loss=3.942, nll_loss=1.723, ppl=3.3, wps=22685.1, ups=1.92, wpb=11796.1, bsz=430.6, num_updates=106800, lr=7.74113e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 11:32:06 | INFO | train_inner | epoch 037:   1053 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.366, loss=3.941, nll_loss=1.724, ppl=3.3, wps=22922.1, ups=1.93, wpb=11847.9, bsz=422.2, num_updates=106900, lr=7.73751e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 11:32:58 | INFO | train_inner | epoch 037:   1153 / 3059 symm_kl=0.377, self_kl=0, self_cv=9.396, loss=3.92, nll_loss=1.705, ppl=3.26, wps=22877.8, ups=1.93, wpb=11836.3, bsz=401.3, num_updates=107000, lr=7.73389e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 11:33:50 | INFO | train_inner | epoch 037:   1253 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.387, loss=3.936, nll_loss=1.718, ppl=3.29, wps=22807.8, ups=1.92, wpb=11891.8, bsz=417.2, num_updates=107100, lr=7.73028e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 11:34:42 | INFO | train_inner | epoch 037:   1353 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.378, loss=3.931, nll_loss=1.711, ppl=3.27, wps=22769.5, ups=1.92, wpb=11863.9, bsz=391.8, num_updates=107200, lr=7.72667e-06, gnorm=1.125, train_wall=52, wall=0
2020-12-22 11:35:34 | INFO | train_inner | epoch 037:   1453 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.38, loss=3.939, nll_loss=1.72, ppl=3.29, wps=22779.5, ups=1.92, wpb=11877.2, bsz=400.5, num_updates=107300, lr=7.72307e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 11:36:26 | INFO | train_inner | epoch 037:   1553 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.376, loss=3.971, nll_loss=1.751, ppl=3.36, wps=22843.3, ups=1.93, wpb=11841.6, bsz=402.8, num_updates=107400, lr=7.71948e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:37:19 | INFO | train_inner | epoch 037:   1653 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.393, loss=3.942, nll_loss=1.722, ppl=3.3, wps=22470.8, ups=1.91, wpb=11791.4, bsz=432.8, num_updates=107500, lr=7.71589e-06, gnorm=1.138, train_wall=52, wall=0
2020-12-22 11:38:11 | INFO | train_inner | epoch 037:   1753 / 3059 symm_kl=0.374, self_kl=0, self_cv=9.349, loss=3.916, nll_loss=1.705, ppl=3.26, wps=22819.7, ups=1.92, wpb=11911.6, bsz=445.1, num_updates=107600, lr=7.7123e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 11:39:03 | INFO | train_inner | epoch 037:   1853 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.386, loss=3.936, nll_loss=1.716, ppl=3.29, wps=22683.2, ups=1.92, wpb=11834.2, bsz=404.9, num_updates=107700, lr=7.70872e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:39:55 | INFO | train_inner | epoch 037:   1953 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.407, loss=3.945, nll_loss=1.724, ppl=3.3, wps=22867.8, ups=1.93, wpb=11832.4, bsz=411.8, num_updates=107800, lr=7.70514e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 11:40:47 | INFO | train_inner | epoch 037:   2053 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.408, loss=3.927, nll_loss=1.706, ppl=3.26, wps=22890.5, ups=1.92, wpb=11947.7, bsz=398, num_updates=107900, lr=7.70157e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 11:41:39 | INFO | train_inner | epoch 037:   2153 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.362, loss=3.944, nll_loss=1.729, ppl=3.31, wps=22858.5, ups=1.93, wpb=11827.8, bsz=413.5, num_updates=108000, lr=7.698e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 11:42:30 | INFO | train_inner | epoch 037:   2253 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.386, loss=3.925, nll_loss=1.708, ppl=3.27, wps=23110.1, ups=1.93, wpb=11977.7, bsz=411.3, num_updates=108100, lr=7.69444e-06, gnorm=1.11, train_wall=52, wall=0
2020-12-22 11:43:22 | INFO | train_inner | epoch 037:   2353 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.438, loss=3.964, nll_loss=1.742, ppl=3.35, wps=22726.7, ups=1.94, wpb=11722.4, bsz=388.8, num_updates=108200, lr=7.69089e-06, gnorm=1.143, train_wall=51, wall=0
2020-12-22 11:44:14 | INFO | train_inner | epoch 037:   2453 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.393, loss=3.964, nll_loss=1.744, ppl=3.35, wps=22780.3, ups=1.92, wpb=11875, bsz=422.8, num_updates=108300, lr=7.68733e-06, gnorm=1.138, train_wall=52, wall=0
2020-12-22 11:45:06 | INFO | train_inner | epoch 037:   2553 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.413, loss=3.929, nll_loss=1.716, ppl=3.29, wps=22968.8, ups=1.93, wpb=11902.2, bsz=424.7, num_updates=108400, lr=7.68379e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 11:45:58 | INFO | train_inner | epoch 037:   2653 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.399, loss=3.942, nll_loss=1.723, ppl=3.3, wps=22890.2, ups=1.93, wpb=11834.5, bsz=400.3, num_updates=108500, lr=7.68025e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 11:46:50 | INFO | train_inner | epoch 037:   2753 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.4, loss=3.948, nll_loss=1.726, ppl=3.31, wps=22691.9, ups=1.92, wpb=11798.8, bsz=403.8, num_updates=108600, lr=7.67671e-06, gnorm=1.137, train_wall=52, wall=0
2020-12-22 11:47:41 | INFO | train_inner | epoch 037:   2853 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.38, loss=3.934, nll_loss=1.718, ppl=3.29, wps=22909.1, ups=1.94, wpb=11821.3, bsz=404.2, num_updates=108700, lr=7.67318e-06, gnorm=1.133, train_wall=51, wall=0
2020-12-22 11:48:33 | INFO | train_inner | epoch 037:   2953 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.389, loss=3.925, nll_loss=1.708, ppl=3.27, wps=22853.7, ups=1.92, wpb=11908.3, bsz=412.3, num_updates=108800, lr=7.66965e-06, gnorm=1.112, train_wall=52, wall=0
2020-12-22 11:49:26 | INFO | train_inner | epoch 037:   3053 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.41, loss=3.933, nll_loss=1.717, ppl=3.29, wps=22828.8, ups=1.92, wpb=11915.1, bsz=399.5, num_updates=108900, lr=7.66613e-06, gnorm=1.121, train_wall=52, wall=0
2020-12-22 11:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 11:49:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 11:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 11:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 11:49:46 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.865 | nll_loss 7.832 | ppl 227.85 | bleu 16.61 | wps 4346.8 | wpb 6344.2 | bsz 166.4 | num_updates 108906 | best_bleu 16.73
2020-12-22 11:49:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 11:49:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 37 @ 108906 updates, score 16.61) (writing took 4.908106628805399 seconds)
2020-12-22 11:49:51 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-12-22 11:49:51 | INFO | train | epoch 037 | symm_kl 0.38 | self_kl 0 | self_cv 9.386 | loss 3.94 | nll_loss 1.721 | ppl 3.3 | wps 22336 | ups 1.88 | wpb 11852.2 | bsz 409.6 | num_updates 108906 | lr 7.66592e-06 | gnorm 1.126 | train_wall 1586 | wall 0
2020-12-22 11:49:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:49:54 | INFO | fairseq.trainer | begin training epoch 38
2020-12-22 11:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:49:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 11:50:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 11:50:49 | INFO | train_inner | epoch 038:     94 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.382, loss=3.917, nll_loss=1.703, ppl=3.25, wps=14257.6, ups=1.2, wpb=11893.2, bsz=419.9, num_updates=109000, lr=7.66261e-06, gnorm=1.121, train_wall=51, wall=0
2020-12-22 11:51:41 | INFO | train_inner | epoch 038:    194 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.415, loss=3.947, nll_loss=1.726, ppl=3.31, wps=22862.6, ups=1.93, wpb=11872.1, bsz=387.2, num_updates=109100, lr=7.6591e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:52:33 | INFO | train_inner | epoch 038:    294 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.396, loss=3.937, nll_loss=1.718, ppl=3.29, wps=22684.4, ups=1.93, wpb=11766.4, bsz=407.2, num_updates=109200, lr=7.65559e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 11:53:25 | INFO | train_inner | epoch 038:    394 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.389, loss=3.931, nll_loss=1.714, ppl=3.28, wps=23029.6, ups=1.93, wpb=11915.7, bsz=411.3, num_updates=109300, lr=7.65209e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 11:54:16 | INFO | train_inner | epoch 038:    494 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.362, loss=3.945, nll_loss=1.727, ppl=3.31, wps=22865.1, ups=1.93, wpb=11866.7, bsz=409.4, num_updates=109400, lr=7.64859e-06, gnorm=1.126, train_wall=52, wall=0
2020-12-22 11:55:08 | INFO | train_inner | epoch 038:    594 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.422, loss=3.925, nll_loss=1.709, ppl=3.27, wps=22851.7, ups=1.94, wpb=11809.3, bsz=420.9, num_updates=109500, lr=7.6451e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 11:56:00 | INFO | train_inner | epoch 038:    694 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.383, loss=3.945, nll_loss=1.725, ppl=3.31, wps=22719.4, ups=1.92, wpb=11833.9, bsz=416.2, num_updates=109600, lr=7.64161e-06, gnorm=1.135, train_wall=52, wall=0
2020-12-22 11:56:52 | INFO | train_inner | epoch 038:    794 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.404, loss=3.948, nll_loss=1.729, ppl=3.32, wps=22621.2, ups=1.93, wpb=11742.5, bsz=424.5, num_updates=109700, lr=7.63812e-06, gnorm=1.141, train_wall=52, wall=0
2020-12-22 11:57:44 | INFO | train_inner | epoch 038:    894 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.397, loss=3.958, nll_loss=1.736, ppl=3.33, wps=22835.4, ups=1.93, wpb=11813.6, bsz=384.6, num_updates=109800, lr=7.63464e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 11:58:36 | INFO | train_inner | epoch 038:    994 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.39, loss=3.938, nll_loss=1.722, ppl=3.3, wps=22580.4, ups=1.92, wpb=11780.2, bsz=442.8, num_updates=109900, lr=7.63117e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 11:59:28 | INFO | train_inner | epoch 038:   1094 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.411, loss=3.933, nll_loss=1.712, ppl=3.28, wps=22718.3, ups=1.92, wpb=11859.4, bsz=398.2, num_updates=110000, lr=7.6277e-06, gnorm=1.131, train_wall=52, wall=0
2020-12-22 12:00:20 | INFO | train_inner | epoch 038:   1194 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.388, loss=3.931, nll_loss=1.715, ppl=3.28, wps=22856.9, ups=1.92, wpb=11879.1, bsz=432.3, num_updates=110100, lr=7.62424e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 12:01:12 | INFO | train_inner | epoch 038:   1294 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.371, loss=3.938, nll_loss=1.721, ppl=3.3, wps=22871.1, ups=1.93, wpb=11877, bsz=378.8, num_updates=110200, lr=7.62078e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 12:02:04 | INFO | train_inner | epoch 038:   1394 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.407, loss=3.942, nll_loss=1.725, ppl=3.31, wps=22653.7, ups=1.91, wpb=11829.7, bsz=435.4, num_updates=110300, lr=7.61732e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 12:02:56 | INFO | train_inner | epoch 038:   1494 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.395, loss=3.927, nll_loss=1.711, ppl=3.27, wps=22978.5, ups=1.93, wpb=11888.7, bsz=424.9, num_updates=110400, lr=7.61387e-06, gnorm=1.12, train_wall=52, wall=0
2020-12-22 12:03:48 | INFO | train_inner | epoch 038:   1594 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.395, loss=3.928, nll_loss=1.711, ppl=3.27, wps=22846.1, ups=1.92, wpb=11914.6, bsz=424.2, num_updates=110500, lr=7.61042e-06, gnorm=1.13, train_wall=52, wall=0
2020-12-22 12:04:40 | INFO | train_inner | epoch 038:   1694 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.339, loss=3.965, nll_loss=1.748, ppl=3.36, wps=22843.4, ups=1.93, wpb=11857.9, bsz=413.7, num_updates=110600, lr=7.60698e-06, gnorm=1.127, train_wall=52, wall=0
2020-12-22 12:05:32 | INFO | train_inner | epoch 038:   1794 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.38, loss=3.927, nll_loss=1.714, ppl=3.28, wps=23081, ups=1.92, wpb=12032.8, bsz=435.8, num_updates=110700, lr=7.60355e-06, gnorm=1.107, train_wall=52, wall=0
2020-12-22 12:06:24 | INFO | train_inner | epoch 038:   1894 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.405, loss=3.945, nll_loss=1.727, ppl=3.31, wps=22917.8, ups=1.94, wpb=11842.4, bsz=378.3, num_updates=110800, lr=7.60011e-06, gnorm=1.132, train_wall=52, wall=0
2020-12-22 12:07:16 | INFO | train_inner | epoch 038:   1994 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.376, loss=3.934, nll_loss=1.717, ppl=3.29, wps=22961.5, ups=1.93, wpb=11924.6, bsz=399.2, num_updates=110900, lr=7.59669e-06, gnorm=1.123, train_wall=52, wall=0
2020-12-22 12:08:08 | INFO | train_inner | epoch 038:   2094 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.37, loss=3.944, nll_loss=1.726, ppl=3.31, wps=23063.1, ups=1.94, wpb=11916.1, bsz=403.1, num_updates=111000, lr=7.59326e-06, gnorm=1.124, train_wall=52, wall=0
2020-12-22 12:08:59 | INFO | train_inner | epoch 038:   2194 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.364, loss=3.924, nll_loss=1.71, ppl=3.27, wps=22964.2, ups=1.93, wpb=11879.6, bsz=412.4, num_updates=111100, lr=7.58985e-06, gnorm=1.122, train_wall=52, wall=0
2020-12-22 12:09:51 | INFO | train_inner | epoch 038:   2294 / 3059 symm_kl=0.375, self_kl=0, self_cv=9.353, loss=3.919, nll_loss=1.707, ppl=3.26, wps=22760.5, ups=1.92, wpb=11854.9, bsz=425.9, num_updates=111200, lr=7.58643e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 12:10:43 | INFO | train_inner | epoch 038:   2394 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.378, loss=3.954, nll_loss=1.733, ppl=3.32, wps=22757.8, ups=1.92, wpb=11865.9, bsz=404.1, num_updates=111300, lr=7.58302e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 12:11:36 | INFO | train_inner | epoch 038:   2494 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.37, loss=3.936, nll_loss=1.718, ppl=3.29, wps=22680.9, ups=1.92, wpb=11805.6, bsz=401.7, num_updates=111400, lr=7.57962e-06, gnorm=1.144, train_wall=52, wall=0
2020-12-22 12:12:27 | INFO | train_inner | epoch 038:   2594 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.39, loss=3.94, nll_loss=1.721, ppl=3.3, wps=22978.5, ups=1.93, wpb=11885.1, bsz=402.3, num_updates=111500, lr=7.57622e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 12:13:19 | INFO | train_inner | epoch 038:   2694 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.365, loss=3.947, nll_loss=1.73, ppl=3.32, wps=22621, ups=1.92, wpb=11786.6, bsz=384.5, num_updates=111600, lr=7.57282e-06, gnorm=1.132, train_wall=52, wall=0
2020-12-22 12:14:11 | INFO | train_inner | epoch 038:   2794 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.367, loss=3.939, nll_loss=1.72, ppl=3.3, wps=22785, ups=1.93, wpb=11799.6, bsz=427.2, num_updates=111700, lr=7.56943e-06, gnorm=1.134, train_wall=52, wall=0
2020-12-22 12:15:03 | INFO | train_inner | epoch 038:   2894 / 3059 symm_kl=0.378, self_kl=0, self_cv=9.422, loss=3.927, nll_loss=1.71, ppl=3.27, wps=22686.6, ups=1.92, wpb=11790.1, bsz=403.6, num_updates=111800, lr=7.56605e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 12:15:55 | INFO | train_inner | epoch 038:   2994 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.382, loss=3.95, nll_loss=1.732, ppl=3.32, wps=22763, ups=1.93, wpb=11811.4, bsz=397.2, num_updates=111900, lr=7.56267e-06, gnorm=1.135, train_wall=52, wall=0
2020-12-22 12:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-22 12:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-22 12:16:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-22 12:16:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-22 12:16:46 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 8.874 | nll_loss 7.841 | ppl 229.29 | bleu 16.47 | wps 4471.4 | wpb 6344.2 | bsz 166.4 | num_updates 111965 | best_bleu 16.73
2020-12-22 12:16:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-22 12:16:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/_transformer_base/bash/../checkpoints/kl/checkpoint_last.pt (epoch 38 @ 111965 updates, score 16.47) (writing took 4.979417961090803 seconds)
2020-12-22 12:16:51 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-12-22 12:16:51 | INFO | train | epoch 038 | symm_kl 0.38 | self_kl 0 | self_cv 9.386 | loss 3.939 | nll_loss 1.721 | ppl 3.3 | wps 22381.4 | ups 1.89 | wpb 11852.2 | bsz 409.6 | num_updates 111965 | lr 7.56047e-06 | gnorm 1.128 | train_wall 1583 | wall 0
2020-12-22 12:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:16:55 | INFO | fairseq.trainer | begin training epoch 39
2020-12-22 12:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:16:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-22 12:17:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-22 12:17:19 | INFO | train_inner | epoch 039:     35 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.368, loss=3.959, nll_loss=1.74, ppl=3.34, wps=14124.5, ups=1.19, wpb=11824.2, bsz=397.2, num_updates=112000, lr=7.55929e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 12:18:10 | INFO | train_inner | epoch 039:    135 / 3059 symm_kl=0.38, self_kl=0, self_cv=9.381, loss=3.937, nll_loss=1.719, ppl=3.29, wps=22823.6, ups=1.93, wpb=11808.2, bsz=417.5, num_updates=112100, lr=7.55592e-06, gnorm=1.132, train_wall=52, wall=0
2020-12-22 12:19:02 | INFO | train_inner | epoch 039:    235 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.408, loss=3.93, nll_loss=1.713, ppl=3.28, wps=23050.5, ups=1.94, wpb=11875, bsz=387.7, num_updates=112200, lr=7.55255e-06, gnorm=1.126, train_wall=51, wall=0
2020-12-22 12:19:54 | INFO | train_inner | epoch 039:    335 / 3059 symm_kl=0.376, self_kl=0, self_cv=9.382, loss=3.921, nll_loss=1.707, ppl=3.27, wps=22875.5, ups=1.93, wpb=11870.9, bsz=410.2, num_updates=112300, lr=7.54919e-06, gnorm=1.113, train_wall=52, wall=0
2020-12-22 12:20:46 | INFO | train_inner | epoch 039:    435 / 3059 symm_kl=0.379, self_kl=0, self_cv=9.362, loss=3.931, nll_loss=1.714, ppl=3.28, wps=22856, ups=1.92, wpb=11885.1, bsz=383.3, num_updates=112400, lr=7.54583e-06, gnorm=1.118, train_wall=52, wall=0
2020-12-22 12:21:38 | INFO | train_inner | epoch 039:    535 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.421, loss=3.935, nll_loss=1.715, ppl=3.28, wps=22765.8, ups=1.92, wpb=11836.6, bsz=386.6, num_updates=112500, lr=7.54247e-06, gnorm=1.129, train_wall=52, wall=0
2020-12-22 12:22:30 | INFO | train_inner | epoch 039:    635 / 3059 symm_kl=0.377, self_kl=0, self_cv=9.375, loss=3.925, nll_loss=1.71, ppl=3.27, wps=22964, ups=1.92, wpb=11962.9, bsz=445.4, num_updates=112600, lr=7.53912e-06, gnorm=1.119, train_wall=52, wall=0
2020-12-22 12:23:22 | INFO | train_inner | epoch 039:    735 / 3059 symm_kl=0.384, self_kl=0, self_cv=9.386, loss=3.967, nll_loss=1.746, ppl=3.35, wps=22526.2, ups=1.92, wpb=11718.8, bsz=388, num_updates=112700, lr=7.53578e-06, gnorm=1.138, train_wall=52, wall=0
2020-12-22 12:24:14 | INFO | train_inner | epoch 039:    835 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.404, loss=3.959, nll_loss=1.74, ppl=3.34, wps=22575.5, ups=1.92, wpb=11767.3, bsz=402.2, num_updates=112800, lr=7.53244e-06, gnorm=1.14, train_wall=52, wall=0
2020-12-22 12:25:06 | INFO | train_inner | epoch 039:    935 / 3059 symm_kl=0.381, self_kl=0, self_cv=9.395, loss=3.933, nll_loss=1.713, ppl=3.28, wps=22894.2, ups=1.92, wpb=11905.7, bsz=409.6, num_updates=112900, lr=7.5291e-06, gnorm=1.128, train_wall=52, wall=0
2020-12-22 12:25:58 | INFO | train_inner | epoch 039:   1035 / 3059 symm_kl=0.382, self_kl=0, self_cv=9.391, loss=3.946, nll_loss=1.726, ppl=3.31, wps=22746.8, ups=1.92, wpb=11826, bsz=415.3, num_updates=113000, lr=7.52577e-06, gnorm=1.139, train_wall=52, wall=0
2020-12-22 12:26:50 | INFO | train_inner | epoch 039:   1135 / 3059 symm_kl=0.383, self_kl=0, self_cv=9.362, loss=3.97, nll_loss=1.751, ppl=3.37, wps=22856, ups=1.93, wpb=11817.4, bsz=404, num_updates=113100, lr=7.52244e-06, gnorm=1.133, train_wall=52, wall=0
2020-12-22 12:27:42 | INFO | train_inner | epoch 039:   1235 / 3059 symm_kl=0.375, self_kl=0, self_cv=9.409, loss=3.905, nll_loss=1.69, ppl=3.23, wps=22948.8, ups=1.92, wpb=11922.1, bsz=412.5, num_updates=113200, lr=7.51912e-06, gnorm=1.115, train_wall=52, wall=0
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 296 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
