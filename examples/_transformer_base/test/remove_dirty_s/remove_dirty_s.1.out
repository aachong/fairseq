save_dir=././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1
criterion=cross_entropy_dirty_s
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=3000
max_epoch=200
threshold=3
extr='--warmup-init-lr 1e-07'
2021-03-14 13:09:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:08 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:15224
2021-03-14 13:09:08 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:15224
2021-03-14 13:09:09 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:15224
2021-03-14 13:09:09 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2021-03-14 13:09:09 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2021-03-14 13:09:09 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2021-03-14 13:09:12 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='cross_entropy_dirty_s', cross_self_attention=False, curriculum=0, data='././examples/_transformer_base/bash/../bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:15224', distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='././examples/_transformer_base/bash/../bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, nprocs_per_node=3, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold=3.0, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=3000, weight_decay=0.0, zero_sharding='none')
2021-03-14 13:09:12 | INFO | fairseq.tasks.translation | [ch] dictionary: 41952 types
2021-03-14 13:09:12 | INFO | fairseq.tasks.translation | [en] dictionary: 31264 types
2021-03-14 13:09:12 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/valid.ch-en.ch
2021-03-14 13:09:12 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/valid.ch-en.en
2021-03-14 13:09:12 | INFO | fairseq.tasks.translation | ././examples/_transformer_base/bash/../bash/../data-bin valid ch-en 1664 examples
2021-03-14 13:09:15 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(41952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31264, bias=False)
  )
)
2021-03-14 13:09:15 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-03-14 13:09:15 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2021-03-14 13:09:15 | INFO | fairseq_cli.train | criterion: cross_entropy_dirty_s (CrossEntropyDirtyS)
2021-03-14 13:09:15 | INFO | fairseq_cli.train | num. model params: 97632256 (num. trained: 97632256)
2021-03-14 13:09:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-03-14 13:09:15 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 13:09:15 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 13:09:15 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 13:09:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-03-14 13:09:15 | INFO | fairseq_cli.train | training on 3 devices (GPUs/TPUs)
2021-03-14 13:09:15 | INFO | fairseq_cli.train | max tokens per GPU = 4400 and max sentences per GPU = None
2021-03-14 13:09:15 | INFO | fairseq.checkpoint_utils | loading pretrained model from ././examples/_transformer_base/bash/../bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2021-03-14 13:09:16 | INFO | fairseq.trainer | loaded checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/baseline/checkpoint_last.pt (epoch 80 @ 0 updates)
2021-03-14 13:09:16 | INFO | fairseq.optim.adam | using FusedAdam
2021-03-14 13:09:16 | INFO | fairseq.trainer | loading train data for epoch 1
2021-03-14 13:09:16 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/train.ch-en.ch
2021-03-14 13:09:16 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/train.ch-en.en
2021-03-14 13:09:16 | INFO | fairseq.tasks.translation | ././examples/_transformer_base/bash/../bash/../data-bin train ch-en 1252977 examples
2021-03-14 13:09:23 | INFO | fairseq.trainer | begin training epoch 1
2021-03-14 13:09:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:09:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:09:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:10:23 | INFO | train_inner | epoch 001:    100 / 2938 loss=3.353, nll_loss=1.641, ppl=3.12, wps=24267.5, ups=1.96, wpb=12355.6, bsz=423.8, num_updates=100, lr=1.43e-06, gnorm=0.835, train_wall=51, wall=68
2021-03-14 13:11:15 | INFO | train_inner | epoch 001:    200 / 2938 loss=3.375, nll_loss=1.663, ppl=3.17, wps=23618.5, ups=1.93, wpb=12226.8, bsz=432.1, num_updates=200, lr=2.76e-06, gnorm=0.833, train_wall=52, wall=120
2021-03-14 13:12:07 | INFO | train_inner | epoch 001:    300 / 2938 loss=3.32, nll_loss=1.602, ppl=3.04, wps=23625.1, ups=1.91, wpb=12393.7, bsz=445, num_updates=300, lr=4.09e-06, gnorm=0.813, train_wall=52, wall=172
2021-03-14 13:13:00 | INFO | train_inner | epoch 001:    400 / 2938 loss=3.336, nll_loss=1.619, ppl=3.07, wps=23247.8, ups=1.9, wpb=12225.6, bsz=429.4, num_updates=400, lr=5.42e-06, gnorm=0.834, train_wall=52, wall=225
2021-03-14 13:13:52 | INFO | train_inner | epoch 001:    500 / 2938 loss=3.332, nll_loss=1.615, ppl=3.06, wps=23576.2, ups=1.9, wpb=12393.8, bsz=459.5, num_updates=500, lr=6.75e-06, gnorm=0.809, train_wall=52, wall=278
2021-03-14 13:14:46 | INFO | train_inner | epoch 001:    600 / 2938 loss=3.342, nll_loss=1.625, ppl=3.08, wps=23173.1, ups=1.88, wpb=12343.8, bsz=431.4, num_updates=600, lr=8.08e-06, gnorm=0.818, train_wall=53, wall=331
2021-03-14 13:15:37 | INFO | train_inner | epoch 001:    700 / 2938 loss=3.348, nll_loss=1.633, ppl=3.1, wps=23838.7, ups=1.95, wpb=12228.7, bsz=414.4, num_updates=700, lr=9.41e-06, gnorm=0.825, train_wall=51, wall=382
2021-03-14 13:16:29 | INFO | train_inner | epoch 001:    800 / 2938 loss=3.318, nll_loss=1.599, ppl=3.03, wps=23638.8, ups=1.91, wpb=12363.1, bsz=430.8, num_updates=800, lr=1.074e-05, gnorm=0.812, train_wall=52, wall=435
2021-03-14 13:17:22 | INFO | train_inner | epoch 001:    900 / 2938 loss=3.357, nll_loss=1.643, ppl=3.12, wps=23430, ups=1.91, wpb=12261.2, bsz=432.7, num_updates=900, lr=1.207e-05, gnorm=0.827, train_wall=52, wall=487
2021-03-14 13:18:14 | INFO | train_inner | epoch 001:   1000 / 2938 loss=3.328, nll_loss=1.611, ppl=3.05, wps=23701, ups=1.92, wpb=12361.9, bsz=431.9, num_updates=1000, lr=1.34e-05, gnorm=0.811, train_wall=52, wall=539
2021-03-14 13:19:06 | INFO | train_inner | epoch 001:   1100 / 2938 loss=3.346, nll_loss=1.632, ppl=3.1, wps=23862.9, ups=1.91, wpb=12468.6, bsz=418.2, num_updates=1100, lr=1.473e-05, gnorm=0.812, train_wall=52, wall=591
2021-03-14 13:19:58 | INFO | train_inner | epoch 001:   1200 / 2938 loss=3.346, nll_loss=1.631, ppl=3.1, wps=23415.8, ups=1.91, wpb=12273.1, bsz=424.2, num_updates=1200, lr=1.606e-05, gnorm=0.834, train_wall=52, wall=644
2021-03-14 13:20:51 | INFO | train_inner | epoch 001:   1300 / 2938 loss=3.325, nll_loss=1.608, ppl=3.05, wps=23589.3, ups=1.91, wpb=12365.1, bsz=432, num_updates=1300, lr=1.739e-05, gnorm=0.814, train_wall=52, wall=696
2021-03-14 13:21:42 | INFO | train_inner | epoch 001:   1400 / 2938 loss=3.371, nll_loss=1.66, ppl=3.16, wps=24071, ups=1.96, wpb=12262.6, bsz=401.4, num_updates=1400, lr=1.872e-05, gnorm=0.833, train_wall=51, wall=747
2021-03-14 13:22:35 | INFO | train_inner | epoch 001:   1500 / 2938 loss=3.312, nll_loss=1.593, ppl=3.02, wps=23585.7, ups=1.89, wpb=12465.6, bsz=442.5, num_updates=1500, lr=2.005e-05, gnorm=0.811, train_wall=53, wall=800
2021-03-14 13:23:26 | INFO | train_inner | epoch 001:   1600 / 2938 loss=3.341, nll_loss=1.626, ppl=3.09, wps=23972.4, ups=1.95, wpb=12323.3, bsz=425.9, num_updates=1600, lr=2.138e-05, gnorm=0.824, train_wall=51, wall=851
2021-03-14 13:24:18 | INFO | train_inner | epoch 001:   1700 / 2938 loss=3.368, nll_loss=1.656, ppl=3.15, wps=23385.8, ups=1.91, wpb=12260.2, bsz=442.6, num_updates=1700, lr=2.271e-05, gnorm=0.831, train_wall=52, wall=904
2021-03-14 13:25:11 | INFO | train_inner | epoch 001:   1800 / 2938 loss=3.32, nll_loss=1.603, ppl=3.04, wps=23686.7, ups=1.91, wpb=12383.9, bsz=423.1, num_updates=1800, lr=2.404e-05, gnorm=0.816, train_wall=52, wall=956
2021-03-14 13:26:02 | INFO | train_inner | epoch 001:   1900 / 2938 loss=3.341, nll_loss=1.626, ppl=3.09, wps=23878.9, ups=1.94, wpb=12324.7, bsz=409.4, num_updates=1900, lr=2.537e-05, gnorm=0.826, train_wall=51, wall=1008
2021-03-14 13:26:54 | INFO | train_inner | epoch 001:   2000 / 2938 loss=3.323, nll_loss=1.607, ppl=3.05, wps=23736.2, ups=1.92, wpb=12376.9, bsz=439.6, num_updates=2000, lr=2.67e-05, gnorm=0.817, train_wall=52, wall=1060
2021-03-14 13:27:48 | INFO | train_inner | epoch 001:   2100 / 2938 loss=3.344, nll_loss=1.63, ppl=3.1, wps=22949.1, ups=1.85, wpb=12375.7, bsz=431.3, num_updates=2100, lr=2.803e-05, gnorm=0.83, train_wall=54, wall=1114
2021-03-14 13:28:40 | INFO | train_inner | epoch 001:   2200 / 2938 loss=3.344, nll_loss=1.63, ppl=3.09, wps=23882.3, ups=1.93, wpb=12364.8, bsz=406.7, num_updates=2200, lr=2.936e-05, gnorm=0.822, train_wall=52, wall=1165
2021-03-14 13:29:33 | INFO | train_inner | epoch 001:   2300 / 2938 loss=3.341, nll_loss=1.627, ppl=3.09, wps=23564.5, ups=1.9, wpb=12373.6, bsz=433.6, num_updates=2300, lr=3.069e-05, gnorm=0.824, train_wall=52, wall=1218
2021-03-14 13:30:24 | INFO | train_inner | epoch 001:   2400 / 2938 loss=3.333, nll_loss=1.618, ppl=3.07, wps=24360.6, ups=1.95, wpb=12481.3, bsz=399, num_updates=2400, lr=3.202e-05, gnorm=0.821, train_wall=51, wall=1269
2021-03-14 13:31:16 | INFO | train_inner | epoch 001:   2500 / 2938 loss=3.364, nll_loss=1.653, ppl=3.14, wps=23953.4, ups=1.93, wpb=12398.9, bsz=426.6, num_updates=2500, lr=3.335e-05, gnorm=0.83, train_wall=52, wall=1321
2021-03-14 13:32:07 | INFO | train_inner | epoch 001:   2600 / 2938 loss=3.338, nll_loss=1.624, ppl=3.08, wps=24172.3, ups=1.95, wpb=12389.5, bsz=398.1, num_updates=2600, lr=3.468e-05, gnorm=0.828, train_wall=51, wall=1372
2021-03-14 13:32:59 | INFO | train_inner | epoch 001:   2700 / 2938 loss=3.375, nll_loss=1.665, ppl=3.17, wps=23313.3, ups=1.9, wpb=12257.5, bsz=439.3, num_updates=2700, lr=3.601e-05, gnorm=0.845, train_wall=52, wall=1425
2021-03-14 13:33:51 | INFO | train_inner | epoch 001:   2800 / 2938 loss=3.366, nll_loss=1.656, ppl=3.15, wps=23691.7, ups=1.94, wpb=12242.6, bsz=414.2, num_updates=2800, lr=3.734e-05, gnorm=0.837, train_wall=52, wall=1476
2021-03-14 13:34:43 | INFO | train_inner | epoch 001:   2900 / 2938 loss=3.336, nll_loss=1.622, ppl=3.08, wps=23706.1, ups=1.92, wpb=12360.3, bsz=430, num_updates=2900, lr=3.867e-05, gnorm=0.833, train_wall=52, wall=1529
2021-03-14 13:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 13:35:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:35:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:35:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:35:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.547 | nll_loss 8.504 | ppl 362.94 | bleu 15.69 | wps 4276.6 | wpb 6344.2 | bsz 166.4 | num_updates 2938
2021-03-14 13:35:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 13:35:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_best.pt (epoch 1 @ 2938 updates, score 15.69) (writing took 4.0906522665172815 seconds)
2021-03-14 13:35:25 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-03-14 13:35:25 | INFO | train | epoch 001 | loss 3.343 | nll_loss 1.629 | ppl 3.09 | wps 23345.2 | ups 1.89 | wpb 12340.4 | bsz 426.5 | num_updates 2938 | lr 3.91754e-05 | gnorm 0.825 | train_wall 1527 | wall 1570
2021-03-14 13:35:31 | INFO | fairseq.trainer | begin training epoch 2
2021-03-14 13:35:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:35:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:35:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 13:35:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 13:36:10 | INFO | train_inner | epoch 002:     62 / 2938 loss=3.362, nll_loss=1.65, ppl=3.14, wps=14235.4, ups=1.16, wpb=12286.5, bsz=417.3, num_updates=3000, lr=4e-05, gnorm=0.843, train_wall=51, wall=1615
2021-03-14 13:37:02 | INFO | train_inner | epoch 002:    162 / 2938 loss=3.32, nll_loss=1.603, ppl=3.04, wps=23852, ups=1.92, wpb=12407.8, bsz=437.8, num_updates=3100, lr=3.93496e-05, gnorm=0.834, train_wall=52, wall=1667
2021-03-14 13:37:53 | INFO | train_inner | epoch 002:    262 / 2938 loss=3.336, nll_loss=1.622, ppl=3.08, wps=24003.3, ups=1.93, wpb=12429.1, bsz=421.4, num_updates=3200, lr=3.87298e-05, gnorm=0.827, train_wall=52, wall=1719
2021-03-14 13:38:44 | INFO | train_inner | epoch 002:    362 / 2938 loss=3.348, nll_loss=1.635, ppl=3.11, wps=24165.2, ups=1.96, wpb=12330.2, bsz=393.1, num_updates=3300, lr=3.81385e-05, gnorm=0.835, train_wall=51, wall=1770
2021-03-14 13:39:37 | INFO | train_inner | epoch 002:    462 / 2938 loss=3.339, nll_loss=1.626, ppl=3.09, wps=23401.8, ups=1.9, wpb=12294.1, bsz=438, num_updates=3400, lr=3.75735e-05, gnorm=0.833, train_wall=52, wall=1822
2021-03-14 13:40:28 | INFO | train_inner | epoch 002:    562 / 2938 loss=3.359, nll_loss=1.647, ppl=3.13, wps=24039.7, ups=1.96, wpb=12272.4, bsz=398.6, num_updates=3500, lr=3.70328e-05, gnorm=0.848, train_wall=51, wall=1873
2021-03-14 13:41:21 | INFO | train_inner | epoch 002:    662 / 2938 loss=3.354, nll_loss=1.642, ppl=3.12, wps=23187, ups=1.88, wpb=12307.9, bsz=438.9, num_updates=3600, lr=3.65148e-05, gnorm=0.836, train_wall=53, wall=1926
2021-03-14 13:42:13 | INFO | train_inner | epoch 002:    762 / 2938 loss=3.359, nll_loss=1.648, ppl=3.13, wps=23655.3, ups=1.94, wpb=12219.2, bsz=421.3, num_updates=3700, lr=3.6018e-05, gnorm=0.832, train_wall=51, wall=1978
2021-03-14 13:43:05 | INFO | train_inner | epoch 002:    862 / 2938 loss=3.345, nll_loss=1.632, ppl=3.1, wps=23562.6, ups=1.9, wpb=12400.6, bsz=426.8, num_updates=3800, lr=3.55409e-05, gnorm=0.834, train_wall=52, wall=2031
2021-03-14 13:43:58 | INFO | train_inner | epoch 002:    962 / 2938 loss=3.356, nll_loss=1.644, ppl=3.13, wps=23303, ups=1.89, wpb=12305.2, bsz=439.4, num_updates=3900, lr=3.50823e-05, gnorm=0.838, train_wall=53, wall=2084
2021-03-14 13:44:50 | INFO | train_inner | epoch 002:   1062 / 2938 loss=3.355, nll_loss=1.643, ppl=3.12, wps=23895.6, ups=1.92, wpb=12426.1, bsz=411.2, num_updates=4000, lr=3.4641e-05, gnorm=0.833, train_wall=52, wall=2136
2021-03-14 13:45:44 | INFO | train_inner | epoch 002:   1162 / 2938 loss=3.33, nll_loss=1.615, ppl=3.06, wps=22848.9, ups=1.85, wpb=12334.4, bsz=445, num_updates=4100, lr=3.4216e-05, gnorm=0.83, train_wall=54, wall=2189
2021-03-14 13:46:36 | INFO | train_inner | epoch 002:   1262 / 2938 loss=3.361, nll_loss=1.65, ppl=3.14, wps=23735, ups=1.92, wpb=12359.1, bsz=419.2, num_updates=4200, lr=3.38062e-05, gnorm=0.829, train_wall=52, wall=2242
2021-03-14 13:47:28 | INFO | train_inner | epoch 002:   1362 / 2938 loss=3.378, nll_loss=1.67, ppl=3.18, wps=23334.1, ups=1.92, wpb=12132.1, bsz=423.1, num_updates=4300, lr=3.34108e-05, gnorm=0.847, train_wall=52, wall=2294
2021-03-14 13:48:20 | INFO | train_inner | epoch 002:   1462 / 2938 loss=3.362, nll_loss=1.651, ppl=3.14, wps=23875.9, ups=1.92, wpb=12446, bsz=434.3, num_updates=4400, lr=3.30289e-05, gnorm=0.831, train_wall=52, wall=2346
2021-03-14 13:49:13 | INFO | train_inner | epoch 002:   1562 / 2938 loss=3.338, nll_loss=1.625, ppl=3.09, wps=23480, ups=1.9, wpb=12340.6, bsz=441.8, num_updates=4500, lr=3.26599e-05, gnorm=0.836, train_wall=52, wall=2398
2021-03-14 13:50:05 | INFO | train_inner | epoch 002:   1662 / 2938 loss=3.359, nll_loss=1.649, ppl=3.14, wps=24032.9, ups=1.94, wpb=12410.8, bsz=405, num_updates=4600, lr=3.23029e-05, gnorm=0.826, train_wall=51, wall=2450
2021-03-14 13:50:58 | INFO | train_inner | epoch 002:   1762 / 2938 loss=3.37, nll_loss=1.662, ppl=3.16, wps=23223.3, ups=1.89, wpb=12306.6, bsz=441, num_updates=4700, lr=3.19574e-05, gnorm=0.841, train_wall=53, wall=2503
2021-03-14 13:51:50 | INFO | train_inner | epoch 002:   1862 / 2938 loss=3.336, nll_loss=1.622, ppl=3.08, wps=23664.5, ups=1.91, wpb=12387.4, bsz=423.2, num_updates=4800, lr=3.16228e-05, gnorm=0.825, train_wall=52, wall=2555
2021-03-14 13:52:42 | INFO | train_inner | epoch 002:   1962 / 2938 loss=3.339, nll_loss=1.626, ppl=3.09, wps=23612.5, ups=1.9, wpb=12400.8, bsz=435.8, num_updates=4900, lr=3.12984e-05, gnorm=0.83, train_wall=52, wall=2608
2021-03-14 13:53:36 | INFO | train_inner | epoch 002:   2062 / 2938 loss=3.337, nll_loss=1.624, ppl=3.08, wps=23190.9, ups=1.88, wpb=12338.8, bsz=432.6, num_updates=5000, lr=3.09839e-05, gnorm=0.832, train_wall=53, wall=2661
2021-03-14 13:54:28 | INFO | train_inner | epoch 002:   2162 / 2938 loss=3.373, nll_loss=1.665, ppl=3.17, wps=23287, ups=1.9, wpb=12269.9, bsz=410.3, num_updates=5100, lr=3.06786e-05, gnorm=0.846, train_wall=53, wall=2714
2021-03-14 13:55:21 | INFO | train_inner | epoch 002:   2262 / 2938 loss=3.377, nll_loss=1.669, ppl=3.18, wps=23171.8, ups=1.89, wpb=12258.7, bsz=440.6, num_updates=5200, lr=3.03822e-05, gnorm=0.843, train_wall=53, wall=2767
2021-03-14 13:56:13 | INFO | train_inner | epoch 002:   2362 / 2938 loss=3.342, nll_loss=1.63, ppl=3.1, wps=23778.6, ups=1.92, wpb=12406.4, bsz=433.9, num_updates=5300, lr=3.00942e-05, gnorm=0.833, train_wall=52, wall=2819
2021-03-14 13:57:05 | INFO | train_inner | epoch 002:   2462 / 2938 loss=3.384, nll_loss=1.676, ppl=3.2, wps=23689.2, ups=1.93, wpb=12263.3, bsz=421.4, num_updates=5400, lr=2.98142e-05, gnorm=0.849, train_wall=52, wall=2870
2021-03-14 13:57:58 | INFO | train_inner | epoch 002:   2562 / 2938 loss=3.359, nll_loss=1.649, ppl=3.14, wps=23605.3, ups=1.91, wpb=12378.3, bsz=444.3, num_updates=5500, lr=2.9542e-05, gnorm=0.836, train_wall=52, wall=2923
2021-03-14 13:58:50 | INFO | train_inner | epoch 002:   2662 / 2938 loss=3.357, nll_loss=1.647, ppl=3.13, wps=23526.4, ups=1.9, wpb=12354, bsz=432.5, num_updates=5600, lr=2.9277e-05, gnorm=0.858, train_wall=52, wall=2975
2021-03-14 13:59:43 | INFO | train_inner | epoch 002:   2762 / 2938 loss=3.347, nll_loss=1.635, ppl=3.11, wps=23557.1, ups=1.9, wpb=12392.6, bsz=430.8, num_updates=5700, lr=2.90191e-05, gnorm=0.839, train_wall=52, wall=3028
2021-03-14 14:00:35 | INFO | train_inner | epoch 002:   2862 / 2938 loss=3.349, nll_loss=1.639, ppl=3.11, wps=23578.3, ups=1.92, wpb=12311.5, bsz=423.1, num_updates=5800, lr=2.87678e-05, gnorm=0.831, train_wall=52, wall=3080
2021-03-14 14:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 14:01:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:01:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:01:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:01:31 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.528 | nll_loss 8.486 | ppl 358.45 | bleu 15.59 | wps 4422.6 | wpb 6344.2 | bsz 166.4 | num_updates 5876 | best_bleu 15.69
2021-03-14 14:01:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 14:01:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 2 @ 5876 updates, score 15.59) (writing took 5.26081688515842 seconds)
2021-03-14 14:01:37 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-03-14 14:01:37 | INFO | train | epoch 002 | loss 3.353 | nll_loss 1.641 | ppl 3.12 | wps 23069.8 | ups 1.87 | wpb 12340.4 | bsz 426.5 | num_updates 5876 | lr 2.85812e-05 | gnorm 0.836 | train_wall 1530 | wall 3142
2021-03-14 14:01:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:42 | INFO | fairseq.trainer | begin training epoch 3
2021-03-14 14:01:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:01:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:01:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:01:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:02:02 | INFO | train_inner | epoch 003:     24 / 2938 loss=3.354, nll_loss=1.643, ppl=3.12, wps=14213.5, ups=1.15, wpb=12408.5, bsz=413.9, num_updates=5900, lr=2.8523e-05, gnorm=0.832, train_wall=51, wall=3168
2021-03-14 14:02:55 | INFO | train_inner | epoch 003:    124 / 2938 loss=3.323, nll_loss=1.608, ppl=3.05, wps=23598.1, ups=1.91, wpb=12382.7, bsz=442.6, num_updates=6000, lr=2.82843e-05, gnorm=0.835, train_wall=52, wall=3220
2021-03-14 14:03:47 | INFO | train_inner | epoch 003:    224 / 2938 loss=3.329, nll_loss=1.614, ppl=3.06, wps=23729.1, ups=1.92, wpb=12386.3, bsz=406.9, num_updates=6100, lr=2.80515e-05, gnorm=0.83, train_wall=52, wall=3272
2021-03-14 14:04:39 | INFO | train_inner | epoch 003:    324 / 2938 loss=3.349, nll_loss=1.636, ppl=3.11, wps=23557.8, ups=1.91, wpb=12327, bsz=423.7, num_updates=6200, lr=2.78243e-05, gnorm=0.837, train_wall=52, wall=3325
2021-03-14 14:05:33 | INFO | train_inner | epoch 003:    424 / 2938 loss=3.356, nll_loss=1.645, ppl=3.13, wps=22722.6, ups=1.85, wpb=12286.4, bsz=448.5, num_updates=6300, lr=2.76026e-05, gnorm=0.848, train_wall=54, wall=3379
2021-03-14 14:06:25 | INFO | train_inner | epoch 003:    524 / 2938 loss=3.341, nll_loss=1.628, ppl=3.09, wps=23616.9, ups=1.92, wpb=12284.6, bsz=399, num_updates=6400, lr=2.73861e-05, gnorm=0.829, train_wall=52, wall=3431
2021-03-14 14:07:17 | INFO | train_inner | epoch 003:    624 / 2938 loss=3.331, nll_loss=1.617, ppl=3.07, wps=23820.7, ups=1.93, wpb=12361.3, bsz=412.8, num_updates=6500, lr=2.71746e-05, gnorm=0.829, train_wall=52, wall=3483
2021-03-14 14:08:11 | INFO | train_inner | epoch 003:    724 / 2938 loss=3.338, nll_loss=1.625, ppl=3.08, wps=23041.6, ups=1.88, wpb=12282.2, bsz=442.4, num_updates=6600, lr=2.6968e-05, gnorm=0.847, train_wall=53, wall=3536
2021-03-14 14:09:03 | INFO | train_inner | epoch 003:    824 / 2938 loss=3.329, nll_loss=1.614, ppl=3.06, wps=23713.6, ups=1.92, wpb=12378.4, bsz=424.5, num_updates=6700, lr=2.6766e-05, gnorm=0.831, train_wall=52, wall=3588
2021-03-14 14:09:55 | INFO | train_inner | epoch 003:    924 / 2938 loss=3.34, nll_loss=1.627, ppl=3.09, wps=23715.4, ups=1.92, wpb=12354.7, bsz=425.3, num_updates=6800, lr=2.65684e-05, gnorm=0.835, train_wall=52, wall=3640
2021-03-14 14:10:47 | INFO | train_inner | epoch 003:   1024 / 2938 loss=3.322, nll_loss=1.607, ppl=3.05, wps=23874, ups=1.93, wpb=12354.9, bsz=408, num_updates=6900, lr=2.63752e-05, gnorm=0.83, train_wall=52, wall=3692
2021-03-14 14:11:38 | INFO | train_inner | epoch 003:   1124 / 2938 loss=3.331, nll_loss=1.618, ppl=3.07, wps=23884, ups=1.94, wpb=12339.3, bsz=417, num_updates=7000, lr=2.61861e-05, gnorm=0.838, train_wall=51, wall=3744
2021-03-14 14:12:30 | INFO | train_inner | epoch 003:   1224 / 2938 loss=3.345, nll_loss=1.633, ppl=3.1, wps=23771.8, ups=1.92, wpb=12373, bsz=417.5, num_updates=7100, lr=2.60011e-05, gnorm=0.835, train_wall=52, wall=3796
2021-03-14 14:13:22 | INFO | train_inner | epoch 003:   1324 / 2938 loss=3.354, nll_loss=1.643, ppl=3.12, wps=23577.2, ups=1.92, wpb=12308.2, bsz=412.9, num_updates=7200, lr=2.58199e-05, gnorm=0.837, train_wall=52, wall=3848
2021-03-14 14:14:14 | INFO | train_inner | epoch 003:   1424 / 2938 loss=3.355, nll_loss=1.644, ppl=3.13, wps=23787.8, ups=1.92, wpb=12368.7, bsz=412.2, num_updates=7300, lr=2.56424e-05, gnorm=0.845, train_wall=52, wall=3900
2021-03-14 14:15:07 | INFO | train_inner | epoch 003:   1524 / 2938 loss=3.322, nll_loss=1.607, ppl=3.05, wps=23745.4, ups=1.92, wpb=12375, bsz=421.6, num_updates=7400, lr=2.54686e-05, gnorm=0.83, train_wall=52, wall=3952
2021-03-14 14:15:59 | INFO | train_inner | epoch 003:   1624 / 2938 loss=3.352, nll_loss=1.641, ppl=3.12, wps=23192.7, ups=1.9, wpb=12238.1, bsz=423.5, num_updates=7500, lr=2.52982e-05, gnorm=0.843, train_wall=53, wall=4005
2021-03-14 14:16:52 | INFO | train_inner | epoch 003:   1724 / 2938 loss=3.341, nll_loss=1.628, ppl=3.09, wps=23366.2, ups=1.89, wpb=12346.1, bsz=435.8, num_updates=7600, lr=2.51312e-05, gnorm=0.837, train_wall=53, wall=4058
2021-03-14 14:17:45 | INFO | train_inner | epoch 003:   1824 / 2938 loss=3.349, nll_loss=1.638, ppl=3.11, wps=23420.3, ups=1.91, wpb=12247.1, bsz=426.3, num_updates=7700, lr=2.49675e-05, gnorm=0.84, train_wall=52, wall=4110
2021-03-14 14:18:38 | INFO | train_inner | epoch 003:   1924 / 2938 loss=3.329, nll_loss=1.615, ppl=3.06, wps=23473.1, ups=1.89, wpb=12441.9, bsz=456.8, num_updates=7800, lr=2.48069e-05, gnorm=0.827, train_wall=53, wall=4163
2021-03-14 14:19:31 | INFO | train_inner | epoch 003:   2024 / 2938 loss=3.321, nll_loss=1.607, ppl=3.05, wps=23218, ups=1.87, wpb=12393.5, bsz=457.4, num_updates=7900, lr=2.46494e-05, gnorm=0.832, train_wall=53, wall=4216
2021-03-14 14:20:24 | INFO | train_inner | epoch 003:   2124 / 2938 loss=3.349, nll_loss=1.638, ppl=3.11, wps=23290.1, ups=1.88, wpb=12379.2, bsz=439.8, num_updates=8000, lr=2.44949e-05, gnorm=0.838, train_wall=53, wall=4269
2021-03-14 14:21:16 | INFO | train_inner | epoch 003:   2224 / 2938 loss=3.351, nll_loss=1.641, ppl=3.12, wps=23520.5, ups=1.91, wpb=12336.4, bsz=406.9, num_updates=8100, lr=2.43432e-05, gnorm=0.839, train_wall=52, wall=4322
2021-03-14 14:22:08 | INFO | train_inner | epoch 003:   2324 / 2938 loss=3.333, nll_loss=1.619, ppl=3.07, wps=23940.8, ups=1.93, wpb=12392.9, bsz=398.4, num_updates=8200, lr=2.41943e-05, gnorm=0.83, train_wall=52, wall=4374
2021-03-14 14:23:01 | INFO | train_inner | epoch 003:   2424 / 2938 loss=3.362, nll_loss=1.652, ppl=3.14, wps=23593.4, ups=1.9, wpb=12396.8, bsz=429.5, num_updates=8300, lr=2.40481e-05, gnorm=0.837, train_wall=52, wall=4426
2021-03-14 14:23:54 | INFO | train_inner | epoch 003:   2524 / 2938 loss=3.366, nll_loss=1.658, ppl=3.15, wps=23157.4, ups=1.89, wpb=12266, bsz=436.1, num_updates=8400, lr=2.39046e-05, gnorm=0.869, train_wall=53, wall=4479
2021-03-14 14:24:46 | INFO | train_inner | epoch 003:   2624 / 2938 loss=3.352, nll_loss=1.642, ppl=3.12, wps=23769, ups=1.93, wpb=12333.7, bsz=440.2, num_updates=8500, lr=2.37635e-05, gnorm=0.843, train_wall=52, wall=4531
2021-03-14 14:25:38 | INFO | train_inner | epoch 003:   2724 / 2938 loss=3.343, nll_loss=1.632, ppl=3.1, wps=23611.1, ups=1.91, wpb=12353.8, bsz=425.7, num_updates=8600, lr=2.3625e-05, gnorm=0.837, train_wall=52, wall=4583
2021-03-14 14:26:31 | INFO | train_inner | epoch 003:   2824 / 2938 loss=3.355, nll_loss=1.646, ppl=3.13, wps=22838.2, ups=1.87, wpb=12216.4, bsz=460.4, num_updates=8700, lr=2.34888e-05, gnorm=0.84, train_wall=53, wall=4637
2021-03-14 14:27:24 | INFO | train_inner | epoch 003:   2924 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=23816.8, ups=1.92, wpb=12399.5, bsz=417.7, num_updates=8800, lr=2.3355e-05, gnorm=0.829, train_wall=52, wall=4689
2021-03-14 14:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 14:27:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:27:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:27:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:27:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:27:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:27:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:27:48 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.507 | nll_loss 8.464 | ppl 353 | bleu 15.69 | wps 4338.2 | wpb 6344.2 | bsz 166.4 | num_updates 8814 | best_bleu 15.69
2021-03-14 14:27:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 14:27:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_best.pt (epoch 3 @ 8814 updates, score 15.69) (writing took 8.438941052183509 seconds)
2021-03-14 14:27:57 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-03-14 14:27:57 | INFO | train | epoch 003 | loss 3.341 | nll_loss 1.629 | ppl 3.09 | wps 22944.1 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 8814 | lr 2.33364e-05 | gnorm 0.837 | train_wall 1536 | wall 4722
2021-03-14 14:27:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:27:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:28:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:28:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:28:03 | INFO | fairseq.trainer | begin training epoch 4
2021-03-14 14:28:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:28:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:28:56 | INFO | train_inner | epoch 004:     86 / 2938 loss=3.342, nll_loss=1.63, ppl=3.1, wps=13331.1, ups=1.08, wpb=12317, bsz=445.7, num_updates=8900, lr=2.32234e-05, gnorm=0.834, train_wall=52, wall=4781
2021-03-14 14:29:48 | INFO | train_inner | epoch 004:    186 / 2938 loss=3.33, nll_loss=1.615, ppl=3.06, wps=23496.3, ups=1.92, wpb=12262.1, bsz=413.6, num_updates=9000, lr=2.3094e-05, gnorm=0.845, train_wall=52, wall=4833
2021-03-14 14:30:40 | INFO | train_inner | epoch 004:    286 / 2938 loss=3.299, nll_loss=1.582, ppl=2.99, wps=23650.5, ups=1.91, wpb=12378.6, bsz=423.9, num_updates=9100, lr=2.29668e-05, gnorm=0.833, train_wall=52, wall=4886
2021-03-14 14:31:32 | INFO | train_inner | epoch 004:    386 / 2938 loss=3.335, nll_loss=1.621, ppl=3.08, wps=23808.9, ups=1.93, wpb=12351.8, bsz=419.5, num_updates=9200, lr=2.28416e-05, gnorm=0.842, train_wall=52, wall=4938
2021-03-14 14:32:24 | INFO | train_inner | epoch 004:    486 / 2938 loss=3.33, nll_loss=1.616, ppl=3.07, wps=23684.3, ups=1.92, wpb=12326.5, bsz=411.3, num_updates=9300, lr=2.27185e-05, gnorm=0.835, train_wall=52, wall=4990
2021-03-14 14:33:16 | INFO | train_inner | epoch 004:    586 / 2938 loss=3.339, nll_loss=1.626, ppl=3.09, wps=23709.4, ups=1.93, wpb=12269.2, bsz=399.4, num_updates=9400, lr=2.25973e-05, gnorm=0.845, train_wall=52, wall=5041
2021-03-14 14:34:09 | INFO | train_inner | epoch 004:    686 / 2938 loss=3.337, nll_loss=1.625, ppl=3.08, wps=23227.8, ups=1.89, wpb=12290.9, bsz=422.6, num_updates=9500, lr=2.24781e-05, gnorm=0.839, train_wall=53, wall=5094
2021-03-14 14:35:02 | INFO | train_inner | epoch 004:    786 / 2938 loss=3.327, nll_loss=1.613, ppl=3.06, wps=23481.1, ups=1.9, wpb=12367.9, bsz=430.9, num_updates=9600, lr=2.23607e-05, gnorm=0.84, train_wall=52, wall=5147
2021-03-14 14:35:55 | INFO | train_inner | epoch 004:    886 / 2938 loss=3.305, nll_loss=1.589, ppl=3.01, wps=23060.8, ups=1.87, wpb=12349.3, bsz=445.8, num_updates=9700, lr=2.22451e-05, gnorm=0.833, train_wall=53, wall=5201
2021-03-14 14:36:48 | INFO | train_inner | epoch 004:    986 / 2938 loss=3.314, nll_loss=1.599, ppl=3.03, wps=23479.2, ups=1.9, wpb=12352.4, bsz=423, num_updates=9800, lr=2.21313e-05, gnorm=0.833, train_wall=52, wall=5253
2021-03-14 14:37:40 | INFO | train_inner | epoch 004:   1086 / 2938 loss=3.351, nll_loss=1.64, ppl=3.12, wps=23671.9, ups=1.92, wpb=12327.9, bsz=407, num_updates=9900, lr=2.20193e-05, gnorm=0.838, train_wall=52, wall=5305
2021-03-14 14:38:33 | INFO | train_inner | epoch 004:   1186 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=23095.9, ups=1.88, wpb=12272.9, bsz=435.6, num_updates=10000, lr=2.19089e-05, gnorm=0.835, train_wall=53, wall=5358
2021-03-14 14:39:25 | INFO | train_inner | epoch 004:   1286 / 2938 loss=3.355, nll_loss=1.644, ppl=3.13, wps=23924.7, ups=1.94, wpb=12313.3, bsz=400.7, num_updates=10100, lr=2.18002e-05, gnorm=0.845, train_wall=51, wall=5410
2021-03-14 14:40:18 | INFO | train_inner | epoch 004:   1386 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=23187.8, ups=1.88, wpb=12363.6, bsz=456.6, num_updates=10200, lr=2.1693e-05, gnorm=0.832, train_wall=53, wall=5463
2021-03-14 14:41:12 | INFO | train_inner | epoch 004:   1486 / 2938 loss=3.294, nll_loss=1.576, ppl=2.98, wps=23181.2, ups=1.86, wpb=12473.4, bsz=451.4, num_updates=10300, lr=2.15875e-05, gnorm=0.815, train_wall=54, wall=5517
2021-03-14 14:42:05 | INFO | train_inner | epoch 004:   1586 / 2938 loss=3.334, nll_loss=1.622, ppl=3.08, wps=23335.1, ups=1.89, wpb=12372, bsz=442.6, num_updates=10400, lr=2.14834e-05, gnorm=0.832, train_wall=53, wall=5570
2021-03-14 14:42:57 | INFO | train_inner | epoch 004:   1686 / 2938 loss=3.357, nll_loss=1.648, ppl=3.13, wps=23486.8, ups=1.91, wpb=12281.4, bsz=425.1, num_updates=10500, lr=2.13809e-05, gnorm=0.843, train_wall=52, wall=5622
2021-03-14 14:43:50 | INFO | train_inner | epoch 004:   1786 / 2938 loss=3.33, nll_loss=1.617, ppl=3.07, wps=23088.2, ups=1.87, wpb=12329.6, bsz=464.6, num_updates=10600, lr=2.12798e-05, gnorm=0.837, train_wall=53, wall=5676
2021-03-14 14:44:43 | INFO | train_inner | epoch 004:   1886 / 2938 loss=3.34, nll_loss=1.628, ppl=3.09, wps=23678.5, ups=1.92, wpb=12345.5, bsz=428.5, num_updates=10700, lr=2.11801e-05, gnorm=0.837, train_wall=52, wall=5728
2021-03-14 14:45:37 | INFO | train_inner | epoch 004:   1986 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=22967.3, ups=1.85, wpb=12446.5, bsz=454.7, num_updates=10800, lr=2.10819e-05, gnorm=0.828, train_wall=54, wall=5782
2021-03-14 14:46:30 | INFO | train_inner | epoch 004:   2086 / 2938 loss=3.33, nll_loss=1.617, ppl=3.07, wps=23480.2, ups=1.89, wpb=12420.1, bsz=438.5, num_updates=10900, lr=2.09849e-05, gnorm=0.835, train_wall=53, wall=5835
2021-03-14 14:47:22 | INFO | train_inner | epoch 004:   2186 / 2938 loss=3.344, nll_loss=1.633, ppl=3.1, wps=23510.7, ups=1.91, wpb=12321, bsz=408.4, num_updates=11000, lr=2.08893e-05, gnorm=0.868, train_wall=52, wall=5887
2021-03-14 14:48:14 | INFO | train_inner | epoch 004:   2286 / 2938 loss=3.351, nll_loss=1.641, ppl=3.12, wps=23726.5, ups=1.92, wpb=12338.2, bsz=423.1, num_updates=11100, lr=2.0795e-05, gnorm=0.844, train_wall=52, wall=5939
2021-03-14 14:49:06 | INFO | train_inner | epoch 004:   2386 / 2938 loss=3.34, nll_loss=1.628, ppl=3.09, wps=23518.7, ups=1.91, wpb=12301.5, bsz=423.9, num_updates=11200, lr=2.0702e-05, gnorm=0.845, train_wall=52, wall=5992
2021-03-14 14:49:57 | INFO | train_inner | epoch 004:   2486 / 2938 loss=3.358, nll_loss=1.648, ppl=3.13, wps=24193.5, ups=1.97, wpb=12308.8, bsz=388.8, num_updates=11300, lr=2.06102e-05, gnorm=0.844, train_wall=51, wall=6043
2021-03-14 14:50:50 | INFO | train_inner | epoch 004:   2586 / 2938 loss=3.353, nll_loss=1.644, ppl=3.12, wps=23273.4, ups=1.89, wpb=12299.5, bsz=437.3, num_updates=11400, lr=2.05196e-05, gnorm=0.844, train_wall=53, wall=6095
2021-03-14 14:51:42 | INFO | train_inner | epoch 004:   2686 / 2938 loss=3.332, nll_loss=1.62, ppl=3.07, wps=23886.1, ups=1.92, wpb=12432.5, bsz=424.6, num_updates=11500, lr=2.04302e-05, gnorm=0.834, train_wall=52, wall=6147
2021-03-14 14:52:34 | INFO | train_inner | epoch 004:   2786 / 2938 loss=3.343, nll_loss=1.632, ppl=3.1, wps=23818.5, ups=1.93, wpb=12332.4, bsz=397.7, num_updates=11600, lr=2.03419e-05, gnorm=0.839, train_wall=52, wall=6199
2021-03-14 14:53:27 | INFO | train_inner | epoch 004:   2886 / 2938 loss=3.336, nll_loss=1.624, ppl=3.08, wps=23328.6, ups=1.88, wpb=12379.9, bsz=422.6, num_updates=11700, lr=2.02548e-05, gnorm=0.836, train_wall=53, wall=6252
2021-03-14 14:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 14:53:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:53:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:53:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:53:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:53:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:53:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:54:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.535 | nll_loss 8.495 | ppl 360.7 | bleu 15.58 | wps 4410.3 | wpb 6344.2 | bsz 166.4 | num_updates 11752 | best_bleu 15.69
2021-03-14 14:54:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 14:54:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 4 @ 11752 updates, score 15.58) (writing took 5.32990007661283 seconds)
2021-03-14 14:54:17 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-03-14 14:54:17 | INFO | train | epoch 004 | loss 3.334 | nll_loss 1.622 | ppl 3.08 | wps 22950.5 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 11752 | lr 2.02099e-05 | gnorm 0.838 | train_wall 1538 | wall 6302
2021-03-14 14:54:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:54:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:54:22 | INFO | fairseq.trainer | begin training epoch 5
2021-03-14 14:54:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:54:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:54:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 14:54:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 14:54:56 | INFO | train_inner | epoch 005:     48 / 2938 loss=3.346, nll_loss=1.636, ppl=3.11, wps=13821.6, ups=1.13, wpb=12240.9, bsz=436.2, num_updates=11800, lr=2.01688e-05, gnorm=0.844, train_wall=52, wall=6341
2021-03-14 14:55:47 | INFO | train_inner | epoch 005:    148 / 2938 loss=3.297, nll_loss=1.58, ppl=2.99, wps=23909, ups=1.93, wpb=12402.6, bsz=411, num_updates=11900, lr=2.00839e-05, gnorm=0.827, train_wall=52, wall=6393
2021-03-14 14:56:41 | INFO | train_inner | epoch 005:    248 / 2938 loss=3.312, nll_loss=1.597, ppl=3.02, wps=23088.1, ups=1.87, wpb=12353.4, bsz=453.7, num_updates=12000, lr=2e-05, gnorm=0.837, train_wall=53, wall=6446
2021-03-14 14:57:34 | INFO | train_inner | epoch 005:    348 / 2938 loss=3.31, nll_loss=1.594, ppl=3.02, wps=23351.3, ups=1.9, wpb=12298.7, bsz=443.4, num_updates=12100, lr=1.99172e-05, gnorm=0.837, train_wall=52, wall=6499
2021-03-14 14:58:26 | INFO | train_inner | epoch 005:    448 / 2938 loss=3.326, nll_loss=1.613, ppl=3.06, wps=23286.5, ups=1.9, wpb=12277, bsz=455, num_updates=12200, lr=1.98354e-05, gnorm=0.843, train_wall=53, wall=6552
2021-03-14 14:59:19 | INFO | train_inner | epoch 005:    548 / 2938 loss=3.35, nll_loss=1.639, ppl=3.11, wps=23480.9, ups=1.89, wpb=12408.1, bsz=435.7, num_updates=12300, lr=1.97546e-05, gnorm=0.84, train_wall=53, wall=6604
2021-03-14 15:00:12 | INFO | train_inner | epoch 005:    648 / 2938 loss=3.323, nll_loss=1.608, ppl=3.05, wps=23500.6, ups=1.9, wpb=12355.6, bsz=412.9, num_updates=12400, lr=1.96748e-05, gnorm=0.838, train_wall=52, wall=6657
2021-03-14 15:01:04 | INFO | train_inner | epoch 005:    748 / 2938 loss=3.322, nll_loss=1.607, ppl=3.05, wps=23548.9, ups=1.91, wpb=12322.4, bsz=422.4, num_updates=12500, lr=1.95959e-05, gnorm=0.834, train_wall=52, wall=6709
2021-03-14 15:01:57 | INFO | train_inner | epoch 005:    848 / 2938 loss=3.326, nll_loss=1.613, ppl=3.06, wps=23065.3, ups=1.88, wpb=12258.1, bsz=428.9, num_updates=12600, lr=1.9518e-05, gnorm=0.839, train_wall=53, wall=6763
2021-03-14 15:02:50 | INFO | train_inner | epoch 005:    948 / 2938 loss=3.334, nll_loss=1.621, ppl=3.08, wps=23391.2, ups=1.9, wpb=12340.9, bsz=421.7, num_updates=12700, lr=1.9441e-05, gnorm=0.842, train_wall=53, wall=6815
2021-03-14 15:03:43 | INFO | train_inner | epoch 005:   1048 / 2938 loss=3.317, nll_loss=1.603, ppl=3.04, wps=23230.9, ups=1.88, wpb=12367.1, bsz=445.4, num_updates=12800, lr=1.93649e-05, gnorm=0.833, train_wall=53, wall=6869
2021-03-14 15:04:36 | INFO | train_inner | epoch 005:   1148 / 2938 loss=3.342, nll_loss=1.63, ppl=3.1, wps=23332.4, ups=1.9, wpb=12308.9, bsz=428.6, num_updates=12900, lr=1.92897e-05, gnorm=0.848, train_wall=53, wall=6921
2021-03-14 15:05:29 | INFO | train_inner | epoch 005:   1248 / 2938 loss=3.323, nll_loss=1.608, ppl=3.05, wps=23408.3, ups=1.89, wpb=12359.9, bsz=428.4, num_updates=13000, lr=1.92154e-05, gnorm=0.836, train_wall=53, wall=6974
2021-03-14 15:06:21 | INFO | train_inner | epoch 005:   1348 / 2938 loss=3.327, nll_loss=1.613, ppl=3.06, wps=23762.2, ups=1.92, wpb=12364.1, bsz=418.3, num_updates=13100, lr=1.91419e-05, gnorm=0.841, train_wall=52, wall=7026
2021-03-14 15:07:13 | INFO | train_inner | epoch 005:   1448 / 2938 loss=3.324, nll_loss=1.611, ppl=3.05, wps=23649.8, ups=1.92, wpb=12314.4, bsz=430.6, num_updates=13200, lr=1.90693e-05, gnorm=0.837, train_wall=52, wall=7078
2021-03-14 15:08:05 | INFO | train_inner | epoch 005:   1548 / 2938 loss=3.333, nll_loss=1.62, ppl=3.07, wps=23611.5, ups=1.91, wpb=12374.1, bsz=418.5, num_updates=13300, lr=1.89974e-05, gnorm=0.837, train_wall=52, wall=7131
2021-03-14 15:08:58 | INFO | train_inner | epoch 005:   1648 / 2938 loss=3.33, nll_loss=1.617, ppl=3.07, wps=23194.3, ups=1.89, wpb=12292.5, bsz=442.4, num_updates=13400, lr=1.89264e-05, gnorm=0.839, train_wall=53, wall=7184
2021-03-14 15:09:50 | INFO | train_inner | epoch 005:   1748 / 2938 loss=3.334, nll_loss=1.622, ppl=3.08, wps=23642.7, ups=1.92, wpb=12325.7, bsz=419.2, num_updates=13500, lr=1.88562e-05, gnorm=0.847, train_wall=52, wall=7236
2021-03-14 15:10:43 | INFO | train_inner | epoch 005:   1848 / 2938 loss=3.355, nll_loss=1.646, ppl=3.13, wps=23217.6, ups=1.9, wpb=12206.8, bsz=429.2, num_updates=13600, lr=1.87867e-05, gnorm=0.852, train_wall=52, wall=7288
2021-03-14 15:11:37 | INFO | train_inner | epoch 005:   1948 / 2938 loss=3.3, nll_loss=1.583, ppl=3, wps=23189.1, ups=1.86, wpb=12451.4, bsz=435.2, num_updates=13700, lr=1.8718e-05, gnorm=0.828, train_wall=54, wall=7342
2021-03-14 15:12:29 | INFO | train_inner | epoch 005:   2048 / 2938 loss=3.337, nll_loss=1.625, ppl=3.08, wps=23616.8, ups=1.91, wpb=12339, bsz=408.7, num_updates=13800, lr=1.86501e-05, gnorm=0.839, train_wall=52, wall=7394
2021-03-14 15:13:21 | INFO | train_inner | epoch 005:   2148 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23485.5, ups=1.91, wpb=12319.2, bsz=419, num_updates=13900, lr=1.85829e-05, gnorm=0.836, train_wall=52, wall=7447
2021-03-14 15:14:14 | INFO | train_inner | epoch 005:   2248 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=23751, ups=1.91, wpb=12435.4, bsz=416.1, num_updates=14000, lr=1.85164e-05, gnorm=0.832, train_wall=52, wall=7499
2021-03-14 15:15:07 | INFO | train_inner | epoch 005:   2348 / 2938 loss=3.357, nll_loss=1.647, ppl=3.13, wps=23051, ups=1.88, wpb=12271.5, bsz=424.7, num_updates=14100, lr=1.84506e-05, gnorm=0.85, train_wall=53, wall=7552
2021-03-14 15:15:59 | INFO | train_inner | epoch 005:   2448 / 2938 loss=3.363, nll_loss=1.654, ppl=3.15, wps=23702.1, ups=1.92, wpb=12349.7, bsz=398.8, num_updates=14200, lr=1.83855e-05, gnorm=0.848, train_wall=52, wall=7604
2021-03-14 15:16:52 | INFO | train_inner | epoch 005:   2548 / 2938 loss=3.329, nll_loss=1.617, ppl=3.07, wps=23261.7, ups=1.88, wpb=12364.7, bsz=444, num_updates=14300, lr=1.83211e-05, gnorm=0.837, train_wall=53, wall=7658
2021-03-14 15:17:45 | INFO | train_inner | epoch 005:   2648 / 2938 loss=3.347, nll_loss=1.636, ppl=3.11, wps=23363.5, ups=1.9, wpb=12264.3, bsz=422.6, num_updates=14400, lr=1.82574e-05, gnorm=0.866, train_wall=52, wall=7710
2021-03-14 15:18:37 | INFO | train_inner | epoch 005:   2748 / 2938 loss=3.335, nll_loss=1.623, ppl=3.08, wps=23811, ups=1.92, wpb=12394, bsz=402.2, num_updates=14500, lr=1.81944e-05, gnorm=0.84, train_wall=52, wall=7762
2021-03-14 15:19:29 | INFO | train_inner | epoch 005:   2848 / 2938 loss=3.32, nll_loss=1.606, ppl=3.04, wps=23766.5, ups=1.91, wpb=12470.5, bsz=419, num_updates=14600, lr=1.81319e-05, gnorm=0.833, train_wall=52, wall=7815
2021-03-14 15:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 15:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:34 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.522 | nll_loss 8.481 | ppl 357.32 | bleu 15.66 | wps 4369.4 | wpb 6344.2 | bsz 166.4 | num_updates 14690 | best_bleu 15.69
2021-03-14 15:20:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 15:20:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 5 @ 14690 updates, score 15.66) (writing took 5.346932739019394 seconds)
2021-03-14 15:20:40 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-03-14 15:20:40 | INFO | train | epoch 005 | loss 3.33 | nll_loss 1.617 | ppl 3.07 | wps 22902.7 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 14690 | lr 1.80763e-05 | gnorm 0.84 | train_wall 1541 | wall 7885
2021-03-14 15:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:45 | INFO | fairseq.trainer | begin training epoch 6
2021-03-14 15:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 15:20:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 15:20:58 | INFO | train_inner | epoch 006:     10 / 2938 loss=3.35, nll_loss=1.64, ppl=3.12, wps=13803.7, ups=1.12, wpb=12296.9, bsz=414.2, num_updates=14700, lr=1.80702e-05, gnorm=0.852, train_wall=52, wall=7904
2021-03-14 15:21:49 | INFO | train_inner | epoch 006:    110 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=24239.6, ups=1.96, wpb=12359.4, bsz=398.9, num_updates=14800, lr=1.8009e-05, gnorm=0.837, train_wall=51, wall=7955
2021-03-14 15:22:43 | INFO | train_inner | epoch 006:    210 / 2938 loss=3.308, nll_loss=1.592, ppl=3.01, wps=23148.3, ups=1.86, wpb=12435.6, bsz=441.4, num_updates=14900, lr=1.79485e-05, gnorm=0.827, train_wall=54, wall=8008
2021-03-14 15:23:35 | INFO | train_inner | epoch 006:    310 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=23627.7, ups=1.91, wpb=12389.9, bsz=419.3, num_updates=15000, lr=1.78885e-05, gnorm=0.837, train_wall=52, wall=8061
2021-03-14 15:24:29 | INFO | train_inner | epoch 006:    410 / 2938 loss=3.306, nll_loss=1.589, ppl=3.01, wps=23230.4, ups=1.87, wpb=12392.5, bsz=456.2, num_updates=15100, lr=1.78292e-05, gnorm=0.832, train_wall=53, wall=8114
2021-03-14 15:25:22 | INFO | train_inner | epoch 006:    510 / 2938 loss=3.318, nll_loss=1.603, ppl=3.04, wps=23294.5, ups=1.89, wpb=12307.4, bsz=426.4, num_updates=15200, lr=1.77705e-05, gnorm=0.843, train_wall=53, wall=8167
2021-03-14 15:26:14 | INFO | train_inner | epoch 006:    610 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=23487.9, ups=1.89, wpb=12399.1, bsz=430.6, num_updates=15300, lr=1.77123e-05, gnorm=0.838, train_wall=53, wall=8220
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 66 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
save_dir=././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1
criterion=cross_entropy_dirty_s
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=3000
max_epoch=200
threshold=3
extr='--warmup-init-lr 1e-07 --sensword sentence'
2021-03-14 19:14:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:30 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:12009
2021-03-14 19:14:30 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:12009
2021-03-14 19:14:30 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:12009
2021-03-14 19:14:31 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2021-03-14 19:14:31 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2021-03-14 19:14:31 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2021-03-14 19:14:34 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='cross_entropy_dirty_s', cross_self_attention=False, curriculum=0, data='././examples/_transformer_base/bash/../bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:12009', distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='././examples/_transformer_base/bash/../bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, nprocs_per_node=3, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sensword='sentence', sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold=3.0, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=3000, weight_decay=0.0, zero_sharding='none')
2021-03-14 19:14:34 | INFO | fairseq.tasks.translation | [ch] dictionary: 41952 types
2021-03-14 19:14:34 | INFO | fairseq.tasks.translation | [en] dictionary: 31264 types
2021-03-14 19:14:34 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/valid.ch-en.ch
2021-03-14 19:14:34 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/valid.ch-en.en
2021-03-14 19:14:34 | INFO | fairseq.tasks.translation | ././examples/_transformer_base/bash/../bash/../data-bin valid ch-en 1664 examples
2021-03-14 19:14:36 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(41952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=31264, bias=False)
  )
)
2021-03-14 19:14:36 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-03-14 19:14:36 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2021-03-14 19:14:36 | INFO | fairseq_cli.train | criterion: cross_entropy_dirty_s (CrossEntropyDirtyS)
2021-03-14 19:14:36 | INFO | fairseq_cli.train | num. model params: 97632256 (num. trained: 97632256)
2021-03-14 19:14:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-03-14 19:14:36 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 19:14:36 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 19:14:36 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-03-14 19:14:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-03-14 19:14:36 | INFO | fairseq_cli.train | training on 3 devices (GPUs/TPUs)
2021-03-14 19:14:36 | INFO | fairseq_cli.train | max tokens per GPU = 4400 and max sentences per GPU = None
2021-03-14 19:14:37 | INFO | fairseq.optim.adam | using FusedAdam
2021-03-14 19:14:38 | INFO | fairseq.trainer | loaded checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 6 @ 14690 updates)
2021-03-14 19:14:38 | INFO | fairseq.trainer | loading train data for epoch 6
2021-03-14 19:14:38 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/train.ch-en.ch
2021-03-14 19:14:38 | INFO | fairseq.data.data_utils | loaded 1252977 examples from: ././examples/_transformer_base/bash/../bash/../data-bin/train.ch-en.en
2021-03-14 19:14:38 | INFO | fairseq.tasks.translation | ././examples/_transformer_base/bash/../bash/../data-bin train ch-en 1252977 examples
2021-03-14 19:14:46 | INFO | fairseq.trainer | begin training epoch 6
2021-03-14 19:14:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:14:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:14:59 | INFO | train_inner | epoch 006:     10 / 2938 loss=3.35, nll_loss=1.64, ppl=3.12, wps=14260.7, ups=1.16, wpb=12296.9, bsz=414.2, num_updates=14700, lr=1.80702e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 19:15:50 | INFO | train_inner | epoch 006:    110 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=24600, ups=1.99, wpb=12359.4, bsz=398.9, num_updates=14800, lr=1.8009e-05, gnorm=0.837, train_wall=50, wall=0
2021-03-14 19:16:41 | INFO | train_inner | epoch 006:    210 / 2938 loss=3.308, nll_loss=1.592, ppl=3.01, wps=24199.3, ups=1.95, wpb=12435.6, bsz=441.4, num_updates=14900, lr=1.79485e-05, gnorm=0.827, train_wall=51, wall=0
2021-03-14 19:17:32 | INFO | train_inner | epoch 006:    310 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=24153.4, ups=1.95, wpb=12389.9, bsz=419.3, num_updates=15000, lr=1.78885e-05, gnorm=0.837, train_wall=51, wall=0
2021-03-14 19:18:26 | INFO | train_inner | epoch 006:    410 / 2938 loss=3.306, nll_loss=1.589, ppl=3.01, wps=23237.8, ups=1.88, wpb=12392.5, bsz=456.2, num_updates=15100, lr=1.78292e-05, gnorm=0.832, train_wall=53, wall=0
2021-03-14 19:19:18 | INFO | train_inner | epoch 006:    510 / 2938 loss=3.318, nll_loss=1.603, ppl=3.04, wps=23503.8, ups=1.91, wpb=12307.4, bsz=426.4, num_updates=15200, lr=1.77705e-05, gnorm=0.843, train_wall=52, wall=0
2021-03-14 19:20:10 | INFO | train_inner | epoch 006:    610 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=23598.1, ups=1.9, wpb=12399.1, bsz=430.6, num_updates=15300, lr=1.77123e-05, gnorm=0.837, train_wall=52, wall=0
2021-03-14 19:21:02 | INFO | train_inner | epoch 006:    710 / 2938 loss=3.347, nll_loss=1.636, ppl=3.11, wps=23453.6, ups=1.92, wpb=12193.7, bsz=426.2, num_updates=15400, lr=1.76547e-05, gnorm=0.852, train_wall=52, wall=0
2021-03-14 19:21:57 | INFO | train_inner | epoch 006:    810 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=22773.2, ups=1.85, wpb=12324.3, bsz=454.7, num_updates=15500, lr=1.75977e-05, gnorm=0.834, train_wall=54, wall=0
2021-03-14 19:22:48 | INFO | train_inner | epoch 006:    910 / 2938 loss=3.372, nll_loss=1.663, ppl=3.17, wps=23799.1, ups=1.96, wpb=12160.5, bsz=381.1, num_updates=15600, lr=1.75412e-05, gnorm=0.858, train_wall=51, wall=0
2021-03-14 19:23:40 | INFO | train_inner | epoch 006:   1010 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=23714, ups=1.92, wpb=12365.7, bsz=409.8, num_updates=15700, lr=1.74852e-05, gnorm=0.839, train_wall=52, wall=0
2021-03-14 19:24:32 | INFO | train_inner | epoch 006:   1110 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=23702.4, ups=1.91, wpb=12394.4, bsz=440.9, num_updates=15800, lr=1.74298e-05, gnorm=0.829, train_wall=52, wall=0
2021-03-14 19:25:26 | INFO | train_inner | epoch 006:   1210 / 2938 loss=3.322, nll_loss=1.608, ppl=3.05, wps=23025.4, ups=1.87, wpb=12322.8, bsz=430.8, num_updates=15900, lr=1.73749e-05, gnorm=0.859, train_wall=53, wall=0
2021-03-14 19:26:17 | INFO | train_inner | epoch 006:   1310 / 2938 loss=3.341, nll_loss=1.629, ppl=3.09, wps=23813.1, ups=1.94, wpb=12276, bsz=382, num_updates=16000, lr=1.73205e-05, gnorm=0.849, train_wall=51, wall=0
2021-03-14 19:27:10 | INFO | train_inner | epoch 006:   1410 / 2938 loss=3.322, nll_loss=1.608, ppl=3.05, wps=23230.3, ups=1.88, wpb=12372.5, bsz=434.7, num_updates=16100, lr=1.72666e-05, gnorm=0.837, train_wall=53, wall=0
2021-03-14 19:28:04 | INFO | train_inner | epoch 006:   1510 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=22900.4, ups=1.85, wpb=12382, bsz=452.6, num_updates=16200, lr=1.72133e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 19:28:57 | INFO | train_inner | epoch 006:   1610 / 2938 loss=3.331, nll_loss=1.618, ppl=3.07, wps=23180, ups=1.89, wpb=12274, bsz=416.8, num_updates=16300, lr=1.71604e-05, gnorm=0.842, train_wall=53, wall=0
2021-03-14 19:29:50 | INFO | train_inner | epoch 006:   1710 / 2938 loss=3.33, nll_loss=1.617, ppl=3.07, wps=23477.3, ups=1.91, wpb=12306.1, bsz=433.8, num_updates=16400, lr=1.7108e-05, gnorm=0.85, train_wall=52, wall=0
2021-03-14 19:30:44 | INFO | train_inner | epoch 006:   1810 / 2938 loss=3.333, nll_loss=1.622, ppl=3.08, wps=22882.2, ups=1.86, wpb=12304.1, bsz=431.6, num_updates=16500, lr=1.70561e-05, gnorm=0.842, train_wall=54, wall=0
2021-03-14 19:31:37 | INFO | train_inner | epoch 006:   1910 / 2938 loss=3.347, nll_loss=1.637, ppl=3.11, wps=22915.2, ups=1.86, wpb=12324.4, bsz=437.8, num_updates=16600, lr=1.70046e-05, gnorm=0.846, train_wall=54, wall=0
2021-03-14 19:32:30 | INFO | train_inner | epoch 006:   2010 / 2938 loss=3.341, nll_loss=1.63, ppl=3.1, wps=23432.9, ups=1.9, wpb=12332.4, bsz=427.7, num_updates=16700, lr=1.69536e-05, gnorm=0.849, train_wall=52, wall=0
2021-03-14 19:33:22 | INFO | train_inner | epoch 006:   2110 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=23864.7, ups=1.94, wpb=12301.8, bsz=385.8, num_updates=16800, lr=1.69031e-05, gnorm=0.843, train_wall=51, wall=0
2021-03-14 19:34:16 | INFO | train_inner | epoch 006:   2210 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=22792.4, ups=1.84, wpb=12409.6, bsz=457.3, num_updates=16900, lr=1.6853e-05, gnorm=0.842, train_wall=54, wall=0
2021-03-14 19:35:09 | INFO | train_inner | epoch 006:   2310 / 2938 loss=3.343, nll_loss=1.632, ppl=3.1, wps=23405, ups=1.9, wpb=12340.6, bsz=423.3, num_updates=17000, lr=1.68034e-05, gnorm=0.841, train_wall=53, wall=0
2021-03-14 19:36:02 | INFO | train_inner | epoch 006:   2410 / 2938 loss=3.328, nll_loss=1.615, ppl=3.06, wps=23453.8, ups=1.89, wpb=12385.2, bsz=417.8, num_updates=17100, lr=1.67542e-05, gnorm=0.841, train_wall=53, wall=0
2021-03-14 19:36:54 | INFO | train_inner | epoch 006:   2510 / 2938 loss=3.338, nll_loss=1.627, ppl=3.09, wps=23325, ups=1.91, wpb=12239.4, bsz=432.9, num_updates=17200, lr=1.67054e-05, gnorm=0.857, train_wall=52, wall=0
2021-03-14 19:37:47 | INFO | train_inner | epoch 006:   2610 / 2938 loss=3.335, nll_loss=1.623, ppl=3.08, wps=23478.3, ups=1.9, wpb=12338.5, bsz=432.9, num_updates=17300, lr=1.6657e-05, gnorm=0.852, train_wall=52, wall=0
2021-03-14 19:38:40 | INFO | train_inner | epoch 006:   2710 / 2938 loss=3.304, nll_loss=1.588, ppl=3.01, wps=23401.6, ups=1.89, wpb=12413.9, bsz=446.6, num_updates=17400, lr=1.66091e-05, gnorm=0.824, train_wall=53, wall=0
2021-03-14 19:39:33 | INFO | train_inner | epoch 006:   2810 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=23347.3, ups=1.88, wpb=12391.5, bsz=423.6, num_updates=17500, lr=1.65616e-05, gnorm=0.835, train_wall=53, wall=0
2021-03-14 19:40:26 | INFO | train_inner | epoch 006:   2910 / 2938 loss=3.317, nll_loss=1.603, ppl=3.04, wps=23083.2, ups=1.86, wpb=12392.9, bsz=432, num_updates=17600, lr=1.65145e-05, gnorm=0.837, train_wall=54, wall=0
2021-03-14 19:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 19:40:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:40:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:40:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:40:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:40:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:40:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:40:58 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.523 | nll_loss 8.481 | ppl 357.34 | bleu 15.86 | wps 4388.1 | wpb 6344.2 | bsz 166.4 | num_updates 17628 | best_bleu 15.86
2021-03-14 19:40:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 19:41:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_best.pt (epoch 6 @ 17628 updates, score 15.86) (writing took 8.22492972202599 seconds)
2021-03-14 19:41:07 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-03-14 19:41:07 | INFO | train | epoch 006 | loss 3.328 | nll_loss 1.615 | ppl 3.06 | wps 22901.5 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 17628 | lr 1.65013e-05 | gnorm 0.841 | train_wall 3084 | wall 0
2021-03-14 19:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:41:12 | INFO | fairseq.trainer | begin training epoch 7
2021-03-14 19:41:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 19:41:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 19:41:58 | INFO | train_inner | epoch 007:     72 / 2938 loss=3.286, nll_loss=1.567, ppl=2.96, wps=13450.1, ups=1.09, wpb=12358.6, bsz=427, num_updates=17700, lr=1.64677e-05, gnorm=0.843, train_wall=52, wall=0
2021-03-14 19:42:51 | INFO | train_inner | epoch 007:    172 / 2938 loss=3.307, nll_loss=1.591, ppl=3.01, wps=23132.5, ups=1.88, wpb=12302.3, bsz=437.8, num_updates=17800, lr=1.64214e-05, gnorm=0.841, train_wall=53, wall=0
2021-03-14 19:43:44 | INFO | train_inner | epoch 007:    272 / 2938 loss=3.315, nll_loss=1.6, ppl=3.03, wps=23721.4, ups=1.92, wpb=12367.1, bsz=414.2, num_updates=17900, lr=1.63755e-05, gnorm=0.84, train_wall=52, wall=0
2021-03-14 19:44:36 | INFO | train_inner | epoch 007:    372 / 2938 loss=3.324, nll_loss=1.61, ppl=3.05, wps=23468.3, ups=1.91, wpb=12282.1, bsz=424.9, num_updates=18000, lr=1.63299e-05, gnorm=0.848, train_wall=52, wall=0
2021-03-14 19:45:29 | INFO | train_inner | epoch 007:    472 / 2938 loss=3.31, nll_loss=1.594, ppl=3.02, wps=23571.8, ups=1.9, wpb=12409.6, bsz=435.2, num_updates=18100, lr=1.62848e-05, gnorm=0.841, train_wall=52, wall=0
2021-03-14 19:46:21 | INFO | train_inner | epoch 007:    572 / 2938 loss=3.328, nll_loss=1.615, ppl=3.06, wps=23543.1, ups=1.91, wpb=12304.2, bsz=413, num_updates=18200, lr=1.624e-05, gnorm=0.843, train_wall=52, wall=0
2021-03-14 19:47:14 | INFO | train_inner | epoch 007:    672 / 2938 loss=3.32, nll_loss=1.606, ppl=3.04, wps=23244.2, ups=1.89, wpb=12291.8, bsz=424.6, num_updates=18300, lr=1.61955e-05, gnorm=0.84, train_wall=53, wall=0
2021-03-14 19:48:08 | INFO | train_inner | epoch 007:    772 / 2938 loss=3.323, nll_loss=1.609, ppl=3.05, wps=22680.6, ups=1.84, wpb=12325.4, bsz=455.4, num_updates=18400, lr=1.61515e-05, gnorm=0.841, train_wall=54, wall=0
2021-03-14 19:49:02 | INFO | train_inner | epoch 007:    872 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=22959.4, ups=1.85, wpb=12379.1, bsz=458.8, num_updates=18500, lr=1.61077e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 19:49:55 | INFO | train_inner | epoch 007:    972 / 2938 loss=3.337, nll_loss=1.626, ppl=3.09, wps=23269.7, ups=1.89, wpb=12310.3, bsz=437.8, num_updates=18600, lr=1.60644e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 19:50:48 | INFO | train_inner | epoch 007:   1072 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=23250.8, ups=1.89, wpb=12286.8, bsz=407.6, num_updates=18700, lr=1.60214e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 19:51:40 | INFO | train_inner | epoch 007:   1172 / 2938 loss=3.334, nll_loss=1.621, ppl=3.08, wps=23565.8, ups=1.91, wpb=12349.1, bsz=402.9, num_updates=18800, lr=1.59787e-05, gnorm=0.865, train_wall=52, wall=0
2021-03-14 19:52:35 | INFO | train_inner | epoch 007:   1272 / 2938 loss=3.33, nll_loss=1.618, ppl=3.07, wps=22634.7, ups=1.83, wpb=12337.4, bsz=457.8, num_updates=18900, lr=1.59364e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 19:53:27 | INFO | train_inner | epoch 007:   1372 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=23489.1, ups=1.9, wpb=12385.4, bsz=407, num_updates=19000, lr=1.58944e-05, gnorm=0.835, train_wall=53, wall=0
2021-03-14 19:54:20 | INFO | train_inner | epoch 007:   1472 / 2938 loss=3.329, nll_loss=1.617, ppl=3.07, wps=23321.9, ups=1.89, wpb=12341.9, bsz=411.9, num_updates=19100, lr=1.58527e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 19:55:13 | INFO | train_inner | epoch 007:   1572 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=23653.1, ups=1.91, wpb=12403.5, bsz=418, num_updates=19200, lr=1.58114e-05, gnorm=0.84, train_wall=52, wall=0
2021-03-14 19:56:06 | INFO | train_inner | epoch 007:   1672 / 2938 loss=3.342, nll_loss=1.631, ppl=3.1, wps=23237.9, ups=1.89, wpb=12317.5, bsz=418, num_updates=19300, lr=1.57704e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 19:56:59 | INFO | train_inner | epoch 007:   1772 / 2938 loss=3.322, nll_loss=1.608, ppl=3.05, wps=23354.1, ups=1.88, wpb=12405.1, bsz=427.2, num_updates=19400, lr=1.57297e-05, gnorm=0.84, train_wall=53, wall=0
2021-03-14 19:57:52 | INFO | train_inner | epoch 007:   1872 / 2938 loss=3.333, nll_loss=1.62, ppl=3.07, wps=23174.7, ups=1.88, wpb=12333.2, bsz=412.9, num_updates=19500, lr=1.56893e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 19:58:47 | INFO | train_inner | epoch 007:   1972 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=22475.9, ups=1.83, wpb=12273, bsz=445.2, num_updates=19600, lr=1.56492e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-14 19:59:39 | INFO | train_inner | epoch 007:   2072 / 2938 loss=3.334, nll_loss=1.622, ppl=3.08, wps=23354.4, ups=1.9, wpb=12274.4, bsz=404.6, num_updates=19700, lr=1.56094e-05, gnorm=0.849, train_wall=52, wall=0
2021-03-14 20:00:33 | INFO | train_inner | epoch 007:   2172 / 2938 loss=3.348, nll_loss=1.638, ppl=3.11, wps=23029.6, ups=1.87, wpb=12301.1, bsz=423.5, num_updates=19800, lr=1.557e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 20:01:26 | INFO | train_inner | epoch 007:   2272 / 2938 loss=3.335, nll_loss=1.623, ppl=3.08, wps=23091.8, ups=1.87, wpb=12357.4, bsz=422.2, num_updates=19900, lr=1.55308e-05, gnorm=0.843, train_wall=53, wall=0
2021-03-14 20:02:20 | INFO | train_inner | epoch 007:   2372 / 2938 loss=3.311, nll_loss=1.596, ppl=3.02, wps=23181.9, ups=1.87, wpb=12398.2, bsz=413.4, num_updates=20000, lr=1.54919e-05, gnorm=0.833, train_wall=53, wall=0
2021-03-14 20:03:14 | INFO | train_inner | epoch 007:   2472 / 2938 loss=3.31, nll_loss=1.595, ppl=3.02, wps=22880.4, ups=1.84, wpb=12415.4, bsz=470.7, num_updates=20100, lr=1.54533e-05, gnorm=0.839, train_wall=54, wall=0
2021-03-14 20:04:07 | INFO | train_inner | epoch 007:   2572 / 2938 loss=3.335, nll_loss=1.623, ppl=3.08, wps=23203.4, ups=1.87, wpb=12378.1, bsz=425, num_updates=20200, lr=1.5415e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 20:05:00 | INFO | train_inner | epoch 007:   2672 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=23283.3, ups=1.88, wpb=12354.5, bsz=426.2, num_updates=20300, lr=1.5377e-05, gnorm=0.841, train_wall=53, wall=0
2021-03-14 20:05:53 | INFO | train_inner | epoch 007:   2772 / 2938 loss=3.338, nll_loss=1.626, ppl=3.09, wps=23139.8, ups=1.89, wpb=12275.5, bsz=409, num_updates=20400, lr=1.53393e-05, gnorm=0.854, train_wall=53, wall=0
2021-03-14 20:06:47 | INFO | train_inner | epoch 007:   2872 / 2938 loss=3.306, nll_loss=1.59, ppl=3.01, wps=22922.7, ups=1.86, wpb=12339.6, bsz=424.2, num_updates=20500, lr=1.53018e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 20:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 20:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:07:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:07:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:07:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:07:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:07:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.533 | nll_loss 8.49 | ppl 359.63 | bleu 15.9 | wps 4087.6 | wpb 6344.2 | bsz 166.4 | num_updates 20566 | best_bleu 15.9
2021-03-14 20:07:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 20:07:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_best.pt (epoch 7 @ 20566 updates, score 15.9) (writing took 8.336305739358068 seconds)
2021-03-14 20:07:49 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-03-14 20:07:49 | INFO | train | epoch 007 | loss 3.324 | nll_loss 1.61 | ppl 3.05 | wps 22619.1 | ups 1.83 | wpb 12340.4 | bsz 426.5 | num_updates 20566 | lr 1.52773e-05 | gnorm 0.845 | train_wall 1557 | wall 0
2021-03-14 20:07:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:07:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:07:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:07:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:07:55 | INFO | fairseq.trainer | begin training epoch 8
2021-03-14 20:08:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:08:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:08:21 | INFO | train_inner | epoch 008:     34 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=13209.5, ups=1.07, wpb=12347.3, bsz=406.3, num_updates=20600, lr=1.52647e-05, gnorm=0.839, train_wall=52, wall=0
2021-03-14 20:09:15 | INFO | train_inner | epoch 008:    134 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=22694.8, ups=1.83, wpb=12389, bsz=468.8, num_updates=20700, lr=1.52277e-05, gnorm=0.835, train_wall=54, wall=0
2021-03-14 20:10:09 | INFO | train_inner | epoch 008:    234 / 2938 loss=3.311, nll_loss=1.595, ppl=3.02, wps=23380.8, ups=1.88, wpb=12441.4, bsz=414.6, num_updates=20800, lr=1.51911e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 20:11:03 | INFO | train_inner | epoch 008:    334 / 2938 loss=3.298, nll_loss=1.582, ppl=2.99, wps=22958.6, ups=1.85, wpb=12405.7, bsz=439.5, num_updates=20900, lr=1.51547e-05, gnorm=0.831, train_wall=54, wall=0
2021-03-14 20:11:56 | INFO | train_inner | epoch 008:    434 / 2938 loss=3.324, nll_loss=1.611, ppl=3.05, wps=23165.8, ups=1.88, wpb=12352.7, bsz=405.8, num_updates=21000, lr=1.51186e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 20:12:49 | INFO | train_inner | epoch 008:    534 / 2938 loss=3.307, nll_loss=1.592, ppl=3.01, wps=23021.6, ups=1.87, wpb=12319.3, bsz=441, num_updates=21100, lr=1.50827e-05, gnorm=0.837, train_wall=53, wall=0
2021-03-14 20:13:43 | INFO | train_inner | epoch 008:    634 / 2938 loss=3.303, nll_loss=1.587, ppl=3, wps=23194.8, ups=1.87, wpb=12405.3, bsz=418.1, num_updates=21200, lr=1.50471e-05, gnorm=0.842, train_wall=53, wall=0
2021-03-14 20:14:36 | INFO | train_inner | epoch 008:    734 / 2938 loss=3.315, nll_loss=1.6, ppl=3.03, wps=23380.8, ups=1.9, wpb=12328.6, bsz=403.5, num_updates=21300, lr=1.50117e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 20:15:29 | INFO | train_inner | epoch 008:    834 / 2938 loss=3.324, nll_loss=1.61, ppl=3.05, wps=23030.7, ups=1.87, wpb=12316.1, bsz=425.5, num_updates=21400, lr=1.49766e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 20:16:23 | INFO | train_inner | epoch 008:    934 / 2938 loss=3.329, nll_loss=1.616, ppl=3.07, wps=22941.3, ups=1.87, wpb=12280.8, bsz=448.1, num_updates=21500, lr=1.49417e-05, gnorm=0.853, train_wall=53, wall=0
2021-03-14 20:17:16 | INFO | train_inner | epoch 008:   1034 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=23010.2, ups=1.86, wpb=12386.1, bsz=437.4, num_updates=21600, lr=1.49071e-05, gnorm=0.837, train_wall=54, wall=0
2021-03-14 20:18:10 | INFO | train_inner | epoch 008:   1134 / 2938 loss=3.317, nll_loss=1.603, ppl=3.04, wps=22972.8, ups=1.86, wpb=12354.3, bsz=440.5, num_updates=21700, lr=1.48727e-05, gnorm=0.843, train_wall=54, wall=0
2021-03-14 20:19:03 | INFO | train_inner | epoch 008:   1234 / 2938 loss=3.315, nll_loss=1.6, ppl=3.03, wps=23583.8, ups=1.91, wpb=12365.1, bsz=414.6, num_updates=21800, lr=1.48386e-05, gnorm=0.852, train_wall=52, wall=0
2021-03-14 20:19:57 | INFO | train_inner | epoch 008:   1334 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22774.7, ups=1.84, wpb=12384.5, bsz=447.2, num_updates=21900, lr=1.48047e-05, gnorm=0.84, train_wall=54, wall=0
2021-03-14 20:20:52 | INFO | train_inner | epoch 008:   1434 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=22572.6, ups=1.84, wpb=12298.2, bsz=458.1, num_updates=22000, lr=1.4771e-05, gnorm=0.841, train_wall=54, wall=0
2021-03-14 20:21:44 | INFO | train_inner | epoch 008:   1534 / 2938 loss=3.328, nll_loss=1.615, ppl=3.06, wps=23550.4, ups=1.91, wpb=12333.4, bsz=406.4, num_updates=22100, lr=1.47375e-05, gnorm=0.846, train_wall=52, wall=0
2021-03-14 20:22:37 | INFO | train_inner | epoch 008:   1634 / 2938 loss=3.32, nll_loss=1.606, ppl=3.04, wps=23265.6, ups=1.89, wpb=12332.1, bsz=428.3, num_updates=22200, lr=1.47043e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 20:23:30 | INFO | train_inner | epoch 008:   1734 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=23038.2, ups=1.87, wpb=12306.1, bsz=426, num_updates=22300, lr=1.46713e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 20:24:23 | INFO | train_inner | epoch 008:   1834 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=23339.3, ups=1.91, wpb=12238.2, bsz=402.5, num_updates=22400, lr=1.46385e-05, gnorm=0.854, train_wall=52, wall=0
2021-03-14 20:25:16 | INFO | train_inner | epoch 008:   1934 / 2938 loss=3.344, nll_loss=1.634, ppl=3.1, wps=22977.8, ups=1.87, wpb=12291.4, bsz=438.8, num_updates=22500, lr=1.46059e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 20:26:10 | INFO | train_inner | epoch 008:   2034 / 2938 loss=3.324, nll_loss=1.611, ppl=3.06, wps=23033.8, ups=1.85, wpb=12420.8, bsz=450.7, num_updates=22600, lr=1.45736e-05, gnorm=0.837, train_wall=54, wall=0
2021-03-14 20:27:04 | INFO | train_inner | epoch 008:   2134 / 2938 loss=3.326, nll_loss=1.613, ppl=3.06, wps=22812.3, ups=1.84, wpb=12365, bsz=436.8, num_updates=22700, lr=1.45414e-05, gnorm=0.846, train_wall=54, wall=0
2021-03-14 20:27:57 | INFO | train_inner | epoch 008:   2234 / 2938 loss=3.335, nll_loss=1.624, ppl=3.08, wps=23210.7, ups=1.89, wpb=12250.9, bsz=399.2, num_updates=22800, lr=1.45095e-05, gnorm=0.859, train_wall=53, wall=0
2021-03-14 20:28:51 | INFO | train_inner | epoch 008:   2334 / 2938 loss=3.335, nll_loss=1.623, ppl=3.08, wps=23038, ups=1.87, wpb=12315.3, bsz=419.4, num_updates=22900, lr=1.44778e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 20:29:43 | INFO | train_inner | epoch 008:   2434 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=23460.4, ups=1.9, wpb=12348.6, bsz=397.7, num_updates=23000, lr=1.44463e-05, gnorm=0.865, train_wall=52, wall=0
2021-03-14 20:30:36 | INFO | train_inner | epoch 008:   2534 / 2938 loss=3.328, nll_loss=1.615, ppl=3.06, wps=23346.3, ups=1.88, wpb=12397.2, bsz=406.2, num_updates=23100, lr=1.4415e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 20:31:30 | INFO | train_inner | epoch 008:   2634 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=23032.5, ups=1.87, wpb=12292.4, bsz=416.2, num_updates=23200, lr=1.43839e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 20:32:22 | INFO | train_inner | epoch 008:   2734 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=23659.5, ups=1.91, wpb=12379.2, bsz=397, num_updates=23300, lr=1.4353e-05, gnorm=0.841, train_wall=52, wall=0
2021-03-14 20:33:17 | INFO | train_inner | epoch 008:   2834 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=22156.3, ups=1.8, wpb=12286, bsz=471.8, num_updates=23400, lr=1.43223e-05, gnorm=0.856, train_wall=55, wall=0
2021-03-14 20:34:11 | INFO | train_inner | epoch 008:   2934 / 2938 loss=3.334, nll_loss=1.621, ppl=3.08, wps=22966, ups=1.86, wpb=12322.5, bsz=428.3, num_updates=23500, lr=1.42918e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 20:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 20:34:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:34:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:34:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:34:31 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.512 | nll_loss 8.469 | ppl 354.41 | bleu 15.62 | wps 4329.8 | wpb 6344.2 | bsz 166.4 | num_updates 23504 | best_bleu 15.9
2021-03-14 20:34:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 20:34:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 8 @ 23504 updates, score 15.62) (writing took 5.2871929397806525 seconds)
2021-03-14 20:34:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-03-14 20:34:36 | INFO | train | epoch 008 | loss 3.321 | nll_loss 1.607 | ppl 3.05 | wps 22564.7 | ups 1.83 | wpb 12340.4 | bsz 426.5 | num_updates 23504 | lr 1.42906e-05 | gnorm 0.846 | train_wall 1564 | wall 0
2021-03-14 20:34:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:42 | INFO | fairseq.trainer | begin training epoch 9
2021-03-14 20:34:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:34:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:34:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 20:34:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 20:35:42 | INFO | train_inner | epoch 009:     96 / 2938 loss=3.301, nll_loss=1.585, ppl=3, wps=13522.9, ups=1.1, wpb=12240.5, bsz=455, num_updates=23600, lr=1.42615e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 20:36:36 | INFO | train_inner | epoch 009:    196 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=22635.2, ups=1.85, wpb=12226.2, bsz=422.8, num_updates=23700, lr=1.42314e-05, gnorm=0.852, train_wall=54, wall=0
2021-03-14 20:37:30 | INFO | train_inner | epoch 009:    296 / 2938 loss=3.311, nll_loss=1.597, ppl=3.02, wps=22807, ups=1.83, wpb=12441.5, bsz=463, num_updates=23800, lr=1.42014e-05, gnorm=0.837, train_wall=54, wall=0
2021-03-14 20:38:24 | INFO | train_inner | epoch 009:    396 / 2938 loss=3.338, nll_loss=1.626, ppl=3.09, wps=22817.5, ups=1.87, wpb=12234.2, bsz=419, num_updates=23900, lr=1.41717e-05, gnorm=0.868, train_wall=53, wall=0
2021-03-14 20:39:18 | INFO | train_inner | epoch 009:    496 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=22790.3, ups=1.85, wpb=12334.6, bsz=442.7, num_updates=24000, lr=1.41421e-05, gnorm=0.843, train_wall=54, wall=0
2021-03-14 20:40:11 | INFO | train_inner | epoch 009:    596 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23242.9, ups=1.87, wpb=12397.7, bsz=428.1, num_updates=24100, lr=1.41128e-05, gnorm=0.838, train_wall=53, wall=0
2021-03-14 20:41:05 | INFO | train_inner | epoch 009:    696 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=22831.2, ups=1.86, wpb=12275.9, bsz=426.5, num_updates=24200, lr=1.40836e-05, gnorm=0.858, train_wall=54, wall=0
2021-03-14 20:41:59 | INFO | train_inner | epoch 009:    796 / 2938 loss=3.314, nll_loss=1.599, ppl=3.03, wps=23062.3, ups=1.87, wpb=12352.6, bsz=413.4, num_updates=24300, lr=1.40546e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 20:42:52 | INFO | train_inner | epoch 009:    896 / 2938 loss=3.312, nll_loss=1.597, ppl=3.03, wps=22890.7, ups=1.86, wpb=12307.5, bsz=433, num_updates=24400, lr=1.40257e-05, gnorm=0.847, train_wall=54, wall=0
2021-03-14 20:43:46 | INFO | train_inner | epoch 009:    996 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=22965.1, ups=1.87, wpb=12298.8, bsz=424.2, num_updates=24500, lr=1.39971e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 20:44:40 | INFO | train_inner | epoch 009:   1096 / 2938 loss=3.329, nll_loss=1.616, ppl=3.07, wps=23035.6, ups=1.86, wpb=12361.1, bsz=431.8, num_updates=24600, lr=1.39686e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 20:45:33 | INFO | train_inner | epoch 009:   1196 / 2938 loss=3.331, nll_loss=1.619, ppl=3.07, wps=23235, ups=1.89, wpb=12306.8, bsz=439.4, num_updates=24700, lr=1.39403e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 20:46:27 | INFO | train_inner | epoch 009:   1296 / 2938 loss=3.311, nll_loss=1.596, ppl=3.02, wps=22930.4, ups=1.84, wpb=12462.1, bsz=427, num_updates=24800, lr=1.39122e-05, gnorm=0.839, train_wall=54, wall=0
2021-03-14 20:47:20 | INFO | train_inner | epoch 009:   1396 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=23294.8, ups=1.88, wpb=12397.5, bsz=422.2, num_updates=24900, lr=1.38842e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 20:48:13 | INFO | train_inner | epoch 009:   1496 / 2938 loss=3.33, nll_loss=1.617, ppl=3.07, wps=23405, ups=1.9, wpb=12328.6, bsz=393.3, num_updates=25000, lr=1.38564e-05, gnorm=0.849, train_wall=52, wall=0
2021-03-14 20:49:07 | INFO | train_inner | epoch 009:   1596 / 2938 loss=3.307, nll_loss=1.592, ppl=3.01, wps=22838.6, ups=1.84, wpb=12426.5, bsz=419.8, num_updates=25100, lr=1.38288e-05, gnorm=0.84, train_wall=54, wall=0
2021-03-14 20:50:01 | INFO | train_inner | epoch 009:   1696 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=22923, ups=1.85, wpb=12396.7, bsz=428.7, num_updates=25200, lr=1.38013e-05, gnorm=0.838, train_wall=54, wall=0
2021-03-14 20:50:55 | INFO | train_inner | epoch 009:   1796 / 2938 loss=3.327, nll_loss=1.615, ppl=3.06, wps=22942.4, ups=1.88, wpb=12221.1, bsz=421.8, num_updates=25300, lr=1.3774e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 20:51:48 | INFO | train_inner | epoch 009:   1896 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=23107.1, ups=1.87, wpb=12324.1, bsz=429.9, num_updates=25400, lr=1.37469e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 20:52:41 | INFO | train_inner | epoch 009:   1996 / 2938 loss=3.307, nll_loss=1.592, ppl=3.02, wps=22980.6, ups=1.87, wpb=12280.3, bsz=437, num_updates=25500, lr=1.37199e-05, gnorm=0.842, train_wall=53, wall=0
2021-03-14 20:53:35 | INFO | train_inner | epoch 009:   2096 / 2938 loss=3.315, nll_loss=1.602, ppl=3.03, wps=23148.1, ups=1.86, wpb=12419.8, bsz=422.3, num_updates=25600, lr=1.36931e-05, gnorm=0.845, train_wall=53, wall=0
2021-03-14 20:54:28 | INFO | train_inner | epoch 009:   2196 / 2938 loss=3.327, nll_loss=1.615, ppl=3.06, wps=23039.6, ups=1.88, wpb=12260.2, bsz=428.7, num_updates=25700, lr=1.36664e-05, gnorm=0.854, train_wall=53, wall=0
2021-03-14 20:55:22 | INFO | train_inner | epoch 009:   2296 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=23006.2, ups=1.87, wpb=12289.3, bsz=424.4, num_updates=25800, lr=1.36399e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 20:56:15 | INFO | train_inner | epoch 009:   2396 / 2938 loss=3.316, nll_loss=1.601, ppl=3.03, wps=23292.6, ups=1.88, wpb=12412.7, bsz=424, num_updates=25900, lr=1.36135e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 20:57:09 | INFO | train_inner | epoch 009:   2496 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=22771.9, ups=1.86, wpb=12250.3, bsz=417.5, num_updates=26000, lr=1.35873e-05, gnorm=0.855, train_wall=54, wall=0
2021-03-14 20:58:03 | INFO | train_inner | epoch 009:   2596 / 2938 loss=3.318, nll_loss=1.605, ppl=3.04, wps=22971.2, ups=1.85, wpb=12385.5, bsz=430.8, num_updates=26100, lr=1.35613e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 20:58:57 | INFO | train_inner | epoch 009:   2696 / 2938 loss=3.335, nll_loss=1.624, ppl=3.08, wps=22994.3, ups=1.85, wpb=12406.1, bsz=421.2, num_updates=26200, lr=1.35354e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-14 20:59:50 | INFO | train_inner | epoch 009:   2796 / 2938 loss=3.324, nll_loss=1.611, ppl=3.06, wps=23420.3, ups=1.88, wpb=12437.5, bsz=399.9, num_updates=26300, lr=1.35096e-05, gnorm=0.842, train_wall=53, wall=0
2021-03-14 21:00:44 | INFO | train_inner | epoch 009:   2896 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23016.4, ups=1.86, wpb=12386.8, bsz=417, num_updates=26400, lr=1.3484e-05, gnorm=0.847, train_wall=54, wall=0
2021-03-14 21:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 21:01:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:01:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:01:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:01:24 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.522 | nll_loss 8.483 | ppl 357.8 | bleu 15.84 | wps 4282.3 | wpb 6344.2 | bsz 166.4 | num_updates 26442 | best_bleu 15.9
2021-03-14 21:01:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 21:01:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 9 @ 26442 updates, score 15.84) (writing took 5.222171084955335 seconds)
2021-03-14 21:01:29 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-03-14 21:01:29 | INFO | train | epoch 009 | loss 3.319 | nll_loss 1.606 | ppl 3.04 | wps 22483.7 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 26442 | lr 1.34733e-05 | gnorm 0.847 | train_wall 1570 | wall 0
2021-03-14 21:01:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:35 | INFO | fairseq.trainer | begin training epoch 10
2021-03-14 21:01:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:01:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:01:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:01:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:02:13 | INFO | train_inner | epoch 010:     58 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=13939.6, ups=1.12, wpb=12408.3, bsz=417.1, num_updates=26500, lr=1.34585e-05, gnorm=0.843, train_wall=52, wall=0
2021-03-14 21:03:07 | INFO | train_inner | epoch 010:    158 / 2938 loss=3.298, nll_loss=1.581, ppl=2.99, wps=23050.9, ups=1.85, wpb=12443.9, bsz=407, num_updates=26600, lr=1.34332e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 21:04:00 | INFO | train_inner | epoch 010:    258 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=22803.1, ups=1.86, wpb=12275.9, bsz=439, num_updates=26700, lr=1.3408e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 21:04:55 | INFO | train_inner | epoch 010:    358 / 2938 loss=3.292, nll_loss=1.574, ppl=2.98, wps=22813.4, ups=1.84, wpb=12391.9, bsz=428.9, num_updates=26800, lr=1.3383e-05, gnorm=0.84, train_wall=54, wall=0
2021-03-14 21:05:48 | INFO | train_inner | epoch 010:    458 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=23277, ups=1.88, wpb=12373.8, bsz=400.4, num_updates=26900, lr=1.33581e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 21:06:43 | INFO | train_inner | epoch 010:    558 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=22395.1, ups=1.82, wpb=12326.7, bsz=473.1, num_updates=27000, lr=1.33333e-05, gnorm=0.843, train_wall=55, wall=0
2021-03-14 21:07:37 | INFO | train_inner | epoch 010:    658 / 2938 loss=3.321, nll_loss=1.607, ppl=3.05, wps=22566.6, ups=1.85, wpb=12204.9, bsz=433.2, num_updates=27100, lr=1.33087e-05, gnorm=0.857, train_wall=54, wall=0
2021-03-14 21:08:31 | INFO | train_inner | epoch 010:    758 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=22769.8, ups=1.85, wpb=12297.7, bsz=450.8, num_updates=27200, lr=1.32842e-05, gnorm=0.851, train_wall=54, wall=0
2021-03-14 21:09:24 | INFO | train_inner | epoch 010:    858 / 2938 loss=3.323, nll_loss=1.611, ppl=3.05, wps=23011.9, ups=1.87, wpb=12315.3, bsz=407.8, num_updates=27300, lr=1.32599e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 21:10:18 | INFO | train_inner | epoch 010:    958 / 2938 loss=3.318, nll_loss=1.605, ppl=3.04, wps=23075, ups=1.87, wpb=12313.8, bsz=425.8, num_updates=27400, lr=1.32357e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 21:11:11 | INFO | train_inner | epoch 010:   1058 / 2938 loss=3.331, nll_loss=1.62, ppl=3.07, wps=23021.3, ups=1.87, wpb=12282.1, bsz=424.2, num_updates=27500, lr=1.32116e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 21:12:05 | INFO | train_inner | epoch 010:   1158 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22987.8, ups=1.86, wpb=12386.1, bsz=436.6, num_updates=27600, lr=1.31876e-05, gnorm=0.842, train_wall=54, wall=0
2021-03-14 21:12:59 | INFO | train_inner | epoch 010:   1258 / 2938 loss=3.326, nll_loss=1.613, ppl=3.06, wps=22896.8, ups=1.85, wpb=12355.9, bsz=422.6, num_updates=27700, lr=1.31638e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-14 21:13:53 | INFO | train_inner | epoch 010:   1358 / 2938 loss=3.289, nll_loss=1.572, ppl=2.97, wps=23015.7, ups=1.86, wpb=12359, bsz=427, num_updates=27800, lr=1.31401e-05, gnorm=0.859, train_wall=54, wall=0
2021-03-14 21:14:47 | INFO | train_inner | epoch 010:   1458 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=22972.9, ups=1.85, wpb=12392, bsz=440.4, num_updates=27900, lr=1.31165e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 21:15:40 | INFO | train_inner | epoch 010:   1558 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=23052.1, ups=1.87, wpb=12295.2, bsz=419.5, num_updates=28000, lr=1.30931e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 21:16:33 | INFO | train_inner | epoch 010:   1658 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=23408.3, ups=1.89, wpb=12370.8, bsz=399.9, num_updates=28100, lr=1.30698e-05, gnorm=0.848, train_wall=53, wall=0
2021-03-14 21:17:26 | INFO | train_inner | epoch 010:   1758 / 2938 loss=3.338, nll_loss=1.627, ppl=3.09, wps=23060.6, ups=1.87, wpb=12346.7, bsz=407.6, num_updates=28200, lr=1.30466e-05, gnorm=0.859, train_wall=53, wall=0
2021-03-14 21:18:21 | INFO | train_inner | epoch 010:   1858 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=22834.8, ups=1.85, wpb=12375.5, bsz=435.8, num_updates=28300, lr=1.30235e-05, gnorm=0.848, train_wall=54, wall=0
2021-03-14 21:19:13 | INFO | train_inner | epoch 010:   1958 / 2938 loss=3.344, nll_loss=1.634, ppl=3.1, wps=23175.5, ups=1.9, wpb=12206.4, bsz=401.4, num_updates=28400, lr=1.30005e-05, gnorm=0.858, train_wall=52, wall=0
2021-03-14 21:20:06 | INFO | train_inner | epoch 010:   2058 / 2938 loss=3.339, nll_loss=1.629, ppl=3.09, wps=23275.1, ups=1.91, wpb=12177.8, bsz=404.9, num_updates=28500, lr=1.29777e-05, gnorm=0.86, train_wall=52, wall=0
2021-03-14 21:20:59 | INFO | train_inner | epoch 010:   2158 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23199, ups=1.88, wpb=12343.9, bsz=423, num_updates=28600, lr=1.2955e-05, gnorm=0.845, train_wall=53, wall=0
2021-03-14 21:21:52 | INFO | train_inner | epoch 010:   2258 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=23395.5, ups=1.88, wpb=12425.3, bsz=428.5, num_updates=28700, lr=1.29324e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 21:22:45 | INFO | train_inner | epoch 010:   2358 / 2938 loss=3.332, nll_loss=1.62, ppl=3.07, wps=23071.9, ups=1.87, wpb=12353.6, bsz=440.2, num_updates=28800, lr=1.29099e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 21:23:39 | INFO | train_inner | epoch 010:   2458 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=23121.5, ups=1.87, wpb=12334.6, bsz=414.8, num_updates=28900, lr=1.28876e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 21:24:32 | INFO | train_inner | epoch 010:   2558 / 2938 loss=3.301, nll_loss=1.585, ppl=3, wps=23240, ups=1.87, wpb=12457.9, bsz=452.5, num_updates=29000, lr=1.28654e-05, gnorm=0.84, train_wall=53, wall=0
2021-03-14 21:25:25 | INFO | train_inner | epoch 010:   2658 / 2938 loss=3.327, nll_loss=1.614, ppl=3.06, wps=23446.4, ups=1.9, wpb=12337.5, bsz=415.8, num_updates=29100, lr=1.28432e-05, gnorm=0.847, train_wall=52, wall=0
2021-03-14 21:26:18 | INFO | train_inner | epoch 010:   2758 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23424.6, ups=1.89, wpb=12408.8, bsz=416.5, num_updates=29200, lr=1.28212e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 21:27:13 | INFO | train_inner | epoch 010:   2858 / 2938 loss=3.321, nll_loss=1.609, ppl=3.05, wps=22500.3, ups=1.83, wpb=12288.7, bsz=459.4, num_updates=29300, lr=1.27993e-05, gnorm=0.855, train_wall=54, wall=0
2021-03-14 21:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 21:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:28:16 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.51 | nll_loss 8.47 | ppl 354.52 | bleu 15.78 | wps 3629.5 | wpb 6344.2 | bsz 166.4 | num_updates 29380 | best_bleu 15.9
2021-03-14 21:28:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 21:28:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 10 @ 29380 updates, score 15.78) (writing took 5.2400094317272305 seconds)
2021-03-14 21:28:22 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-03-14 21:28:22 | INFO | train | epoch 010 | loss 3.317 | nll_loss 1.604 | ppl 3.04 | wps 22480.2 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 29380 | lr 1.27819e-05 | gnorm 0.849 | train_wall 1567 | wall 0
2021-03-14 21:28:27 | INFO | fairseq.trainer | begin training epoch 11
2021-03-14 21:28:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:28:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:28:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:28:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:28:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:28:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:28:45 | INFO | train_inner | epoch 011:     20 / 2938 loss=3.305, nll_loss=1.589, ppl=3.01, wps=13366.1, ups=1.08, wpb=12386.8, bsz=427.3, num_updates=29400, lr=1.27775e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 21:29:37 | INFO | train_inner | epoch 011:    120 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=23835, ups=1.93, wpb=12378.1, bsz=402.5, num_updates=29500, lr=1.27559e-05, gnorm=0.847, train_wall=52, wall=0
2021-03-14 21:30:32 | INFO | train_inner | epoch 011:    220 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=22756.8, ups=1.84, wpb=12390.5, bsz=449.4, num_updates=29600, lr=1.27343e-05, gnorm=0.842, train_wall=54, wall=0
2021-03-14 21:31:26 | INFO | train_inner | epoch 011:    320 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=22935.5, ups=1.86, wpb=12354.1, bsz=452.8, num_updates=29700, lr=1.27128e-05, gnorm=0.87, train_wall=54, wall=0
2021-03-14 21:32:20 | INFO | train_inner | epoch 011:    420 / 2938 loss=3.296, nll_loss=1.579, ppl=2.99, wps=22902.7, ups=1.84, wpb=12422.3, bsz=434.5, num_updates=29800, lr=1.26915e-05, gnorm=0.84, train_wall=54, wall=0
2021-03-14 21:33:13 | INFO | train_inner | epoch 011:    520 / 2938 loss=3.308, nll_loss=1.593, ppl=3.02, wps=23122.5, ups=1.88, wpb=12316.7, bsz=411.8, num_updates=29900, lr=1.26702e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 21:34:07 | INFO | train_inner | epoch 011:    620 / 2938 loss=3.293, nll_loss=1.576, ppl=2.98, wps=22826, ups=1.85, wpb=12351, bsz=435.1, num_updates=30000, lr=1.26491e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-14 21:35:00 | INFO | train_inner | epoch 011:    720 / 2938 loss=3.306, nll_loss=1.59, ppl=3.01, wps=23691.6, ups=1.91, wpb=12430.1, bsz=398.7, num_updates=30100, lr=1.26281e-05, gnorm=0.843, train_wall=52, wall=0
2021-03-14 21:35:53 | INFO | train_inner | epoch 011:    820 / 2938 loss=3.33, nll_loss=1.618, ppl=3.07, wps=23055.7, ups=1.87, wpb=12299.2, bsz=419.9, num_updates=30200, lr=1.26072e-05, gnorm=0.863, train_wall=53, wall=0
2021-03-14 21:36:46 | INFO | train_inner | epoch 011:    920 / 2938 loss=3.319, nll_loss=1.606, ppl=3.04, wps=23424.1, ups=1.89, wpb=12416, bsz=396.6, num_updates=30300, lr=1.25863e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 21:37:39 | INFO | train_inner | epoch 011:   1020 / 2938 loss=3.342, nll_loss=1.631, ppl=3.1, wps=23307, ups=1.9, wpb=12285.8, bsz=425, num_updates=30400, lr=1.25656e-05, gnorm=0.853, train_wall=53, wall=0
2021-03-14 21:38:32 | INFO | train_inner | epoch 011:   1120 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23384.1, ups=1.89, wpb=12375.1, bsz=412.7, num_updates=30500, lr=1.2545e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 21:39:25 | INFO | train_inner | epoch 011:   1220 / 2938 loss=3.3, nll_loss=1.584, ppl=3, wps=23223.8, ups=1.88, wpb=12382.8, bsz=424.8, num_updates=30600, lr=1.25245e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 21:40:18 | INFO | train_inner | epoch 011:   1320 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=23348.8, ups=1.89, wpb=12339.4, bsz=415.2, num_updates=30700, lr=1.25041e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 21:41:11 | INFO | train_inner | epoch 011:   1420 / 2938 loss=3.328, nll_loss=1.617, ppl=3.07, wps=23198.7, ups=1.88, wpb=12335.3, bsz=420.4, num_updates=30800, lr=1.24838e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 21:42:05 | INFO | train_inner | epoch 011:   1520 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=22917.5, ups=1.87, wpb=12272.2, bsz=423, num_updates=30900, lr=1.24635e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 21:42:58 | INFO | train_inner | epoch 011:   1620 / 2938 loss=3.303, nll_loss=1.587, ppl=3.01, wps=23053.4, ups=1.86, wpb=12376.3, bsz=431.5, num_updates=31000, lr=1.24434e-05, gnorm=0.845, train_wall=53, wall=0
2021-03-14 21:43:52 | INFO | train_inner | epoch 011:   1720 / 2938 loss=3.31, nll_loss=1.595, ppl=3.02, wps=23121.3, ups=1.87, wpb=12359.7, bsz=429, num_updates=31100, lr=1.24234e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 21:44:46 | INFO | train_inner | epoch 011:   1820 / 2938 loss=3.295, nll_loss=1.578, ppl=2.99, wps=22697.1, ups=1.84, wpb=12328, bsz=454.4, num_updates=31200, lr=1.24035e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 21:45:39 | INFO | train_inner | epoch 011:   1920 / 2938 loss=3.329, nll_loss=1.617, ppl=3.07, wps=23125, ups=1.87, wpb=12350.4, bsz=431.5, num_updates=31300, lr=1.23836e-05, gnorm=0.848, train_wall=53, wall=0
2021-03-14 21:46:33 | INFO | train_inner | epoch 011:   2020 / 2938 loss=3.335, nll_loss=1.624, ppl=3.08, wps=23218.9, ups=1.88, wpb=12337.1, bsz=414.3, num_updates=31400, lr=1.23639e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 21:47:27 | INFO | train_inner | epoch 011:   2120 / 2938 loss=3.332, nll_loss=1.621, ppl=3.07, wps=22645.3, ups=1.85, wpb=12236.2, bsz=447.4, num_updates=31500, lr=1.23443e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-14 21:48:20 | INFO | train_inner | epoch 011:   2220 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=23031.4, ups=1.87, wpb=12321.4, bsz=430.9, num_updates=31600, lr=1.23247e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 21:49:14 | INFO | train_inner | epoch 011:   2320 / 2938 loss=3.334, nll_loss=1.623, ppl=3.08, wps=22984.3, ups=1.87, wpb=12310.6, bsz=436.9, num_updates=31700, lr=1.23053e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 21:50:08 | INFO | train_inner | epoch 011:   2420 / 2938 loss=3.313, nll_loss=1.598, ppl=3.03, wps=22983.9, ups=1.85, wpb=12438.3, bsz=451.1, num_updates=31800, lr=1.22859e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 21:51:01 | INFO | train_inner | epoch 011:   2520 / 2938 loss=3.34, nll_loss=1.631, ppl=3.1, wps=22632.8, ups=1.86, wpb=12157.6, bsz=415.4, num_updates=31900, lr=1.22666e-05, gnorm=0.863, train_wall=54, wall=0
2021-03-14 21:51:55 | INFO | train_inner | epoch 011:   2620 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=22699.8, ups=1.86, wpb=12229.6, bsz=429.4, num_updates=32000, lr=1.22474e-05, gnorm=0.862, train_wall=54, wall=0
2021-03-14 21:52:50 | INFO | train_inner | epoch 011:   2720 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=22790.3, ups=1.84, wpb=12358.1, bsz=418, num_updates=32100, lr=1.22284e-05, gnorm=0.848, train_wall=54, wall=0
2021-03-14 21:53:43 | INFO | train_inner | epoch 011:   2820 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=23114.6, ups=1.88, wpb=12309.1, bsz=433.8, num_updates=32200, lr=1.22094e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 21:54:37 | INFO | train_inner | epoch 011:   2920 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=23084.4, ups=1.86, wpb=12409.6, bsz=434.7, num_updates=32300, lr=1.21904e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 21:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 21:54:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:54:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:54:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:54:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:54:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:54:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:55:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.515 | nll_loss 8.474 | ppl 355.48 | bleu 15.72 | wps 4328.8 | wpb 6344.2 | bsz 166.4 | num_updates 32318 | best_bleu 15.9
2021-03-14 21:55:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 21:55:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 11 @ 32318 updates, score 15.72) (writing took 5.226111648604274 seconds)
2021-03-14 21:55:09 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-03-14 21:55:09 | INFO | train | epoch 011 | loss 3.315 | nll_loss 1.602 | ppl 3.04 | wps 22550.4 | ups 1.83 | wpb 12340.4 | bsz 426.5 | num_updates 32318 | lr 1.2187e-05 | gnorm 0.851 | train_wall 1565 | wall 0
2021-03-14 21:55:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:55:16 | INFO | fairseq.trainer | begin training epoch 12
2021-03-14 21:55:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:55:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:55:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:55:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 21:55:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 21:56:06 | INFO | train_inner | epoch 012:     82 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=13812, ups=1.12, wpb=12348.7, bsz=427.2, num_updates=32400, lr=1.21716e-05, gnorm=0.846, train_wall=52, wall=0
2021-03-14 21:57:01 | INFO | train_inner | epoch 012:    182 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=22666.2, ups=1.83, wpb=12361.5, bsz=462.2, num_updates=32500, lr=1.21529e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 21:57:54 | INFO | train_inner | epoch 012:    282 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=22832.8, ups=1.86, wpb=12257.5, bsz=433.7, num_updates=32600, lr=1.21342e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 21:58:47 | INFO | train_inner | epoch 012:    382 / 2938 loss=3.298, nll_loss=1.582, ppl=2.99, wps=23206.6, ups=1.88, wpb=12351.4, bsz=407.8, num_updates=32700, lr=1.21157e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 21:59:41 | INFO | train_inner | epoch 012:    482 / 2938 loss=3.316, nll_loss=1.602, ppl=3.03, wps=22861.6, ups=1.85, wpb=12352.3, bsz=426.7, num_updates=32800, lr=1.20972e-05, gnorm=0.854, train_wall=54, wall=0
2021-03-14 22:00:35 | INFO | train_inner | epoch 012:    582 / 2938 loss=3.293, nll_loss=1.576, ppl=2.98, wps=23057.4, ups=1.86, wpb=12400.7, bsz=436.4, num_updates=32900, lr=1.20788e-05, gnorm=0.844, train_wall=54, wall=0
2021-03-14 22:01:29 | INFO | train_inner | epoch 012:    682 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=23132.4, ups=1.87, wpb=12365.6, bsz=426.6, num_updates=33000, lr=1.20605e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 22:02:22 | INFO | train_inner | epoch 012:    782 / 2938 loss=3.294, nll_loss=1.577, ppl=2.98, wps=23313, ups=1.88, wpb=12376, bsz=422.3, num_updates=33100, lr=1.20422e-05, gnorm=0.848, train_wall=53, wall=0
2021-03-14 22:03:15 | INFO | train_inner | epoch 012:    882 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=22932.5, ups=1.87, wpb=12287.8, bsz=430.7, num_updates=33200, lr=1.20241e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 22:04:09 | INFO | train_inner | epoch 012:    982 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=23064.5, ups=1.86, wpb=12388, bsz=448.2, num_updates=33300, lr=1.2006e-05, gnorm=0.841, train_wall=54, wall=0
2021-03-14 22:05:04 | INFO | train_inner | epoch 012:   1082 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=22755.2, ups=1.83, wpb=12435.1, bsz=448.7, num_updates=33400, lr=1.1988e-05, gnorm=0.839, train_wall=54, wall=0
2021-03-14 22:05:57 | INFO | train_inner | epoch 012:   1182 / 2938 loss=3.353, nll_loss=1.644, ppl=3.12, wps=22931.8, ups=1.89, wpb=12135, bsz=419.6, num_updates=33500, lr=1.19701e-05, gnorm=0.872, train_wall=53, wall=0
2021-03-14 22:06:51 | INFO | train_inner | epoch 012:   1282 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22766.5, ups=1.84, wpb=12347.9, bsz=446.2, num_updates=33600, lr=1.19523e-05, gnorm=0.846, train_wall=54, wall=0
2021-03-14 22:07:44 | INFO | train_inner | epoch 012:   1382 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23260.8, ups=1.89, wpb=12333.8, bsz=418.7, num_updates=33700, lr=1.19345e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 22:08:38 | INFO | train_inner | epoch 012:   1482 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=22613.1, ups=1.84, wpb=12280.1, bsz=437.2, num_updates=33800, lr=1.19169e-05, gnorm=0.862, train_wall=54, wall=0
2021-03-14 22:09:32 | INFO | train_inner | epoch 012:   1582 / 2938 loss=3.306, nll_loss=1.591, ppl=3.01, wps=22893.5, ups=1.85, wpb=12368.2, bsz=431.8, num_updates=33900, lr=1.18993e-05, gnorm=0.847, train_wall=54, wall=0
2021-03-14 22:10:25 | INFO | train_inner | epoch 012:   1682 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=23544.8, ups=1.89, wpb=12432.5, bsz=399.8, num_updates=34000, lr=1.18818e-05, gnorm=0.846, train_wall=53, wall=0
2021-03-14 22:11:18 | INFO | train_inner | epoch 012:   1782 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23180.3, ups=1.88, wpb=12358.8, bsz=412.2, num_updates=34100, lr=1.18643e-05, gnorm=0.853, train_wall=53, wall=0
2021-03-14 22:12:12 | INFO | train_inner | epoch 012:   1882 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=23180, ups=1.88, wpb=12360, bsz=419.4, num_updates=34200, lr=1.1847e-05, gnorm=0.848, train_wall=53, wall=0
2021-03-14 22:13:05 | INFO | train_inner | epoch 012:   1982 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=22995.3, ups=1.86, wpb=12340.3, bsz=409.5, num_updates=34300, lr=1.18297e-05, gnorm=0.861, train_wall=53, wall=0
2021-03-14 22:14:00 | INFO | train_inner | epoch 012:   2082 / 2938 loss=3.312, nll_loss=1.6, ppl=3.03, wps=22282.2, ups=1.82, wpb=12254.7, bsz=441.8, num_updates=34400, lr=1.18125e-05, gnorm=0.855, train_wall=55, wall=0
2021-03-14 22:14:54 | INFO | train_inner | epoch 012:   2182 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=23279.6, ups=1.87, wpb=12461.3, bsz=421.6, num_updates=34500, lr=1.17954e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 22:15:47 | INFO | train_inner | epoch 012:   2282 / 2938 loss=3.33, nll_loss=1.618, ppl=3.07, wps=23232.7, ups=1.89, wpb=12293.7, bsz=403.9, num_updates=34600, lr=1.17783e-05, gnorm=0.858, train_wall=53, wall=0
2021-03-14 22:16:40 | INFO | train_inner | epoch 012:   2382 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=22840.9, ups=1.87, wpb=12233.5, bsz=418.3, num_updates=34700, lr=1.17613e-05, gnorm=0.884, train_wall=53, wall=0
2021-03-14 22:17:34 | INFO | train_inner | epoch 012:   2482 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23054.1, ups=1.86, wpb=12382.3, bsz=421.8, num_updates=34800, lr=1.17444e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 22:18:28 | INFO | train_inner | epoch 012:   2582 / 2938 loss=3.341, nll_loss=1.631, ppl=3.1, wps=22627, ups=1.84, wpb=12266, bsz=422.6, num_updates=34900, lr=1.17276e-05, gnorm=0.863, train_wall=54, wall=0
2021-03-14 22:19:22 | INFO | train_inner | epoch 012:   2682 / 2938 loss=3.319, nll_loss=1.606, ppl=3.04, wps=22983.5, ups=1.85, wpb=12449.7, bsz=440.9, num_updates=35000, lr=1.17108e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 22:20:16 | INFO | train_inner | epoch 012:   2782 / 2938 loss=3.327, nll_loss=1.615, ppl=3.06, wps=22775.8, ups=1.86, wpb=12241.9, bsz=422.7, num_updates=35100, lr=1.16941e-05, gnorm=0.856, train_wall=54, wall=0
2021-03-14 22:21:09 | INFO | train_inner | epoch 012:   2882 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=23477.4, ups=1.9, wpb=12384.7, bsz=412.6, num_updates=35200, lr=1.16775e-05, gnorm=0.858, train_wall=53, wall=0
2021-03-14 22:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 22:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:21:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:21:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:21:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:21:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.512 | nll_loss 8.471 | ppl 354.95 | bleu 15.68 | wps 4324 | wpb 6344.2 | bsz 166.4 | num_updates 35256 | best_bleu 15.9
2021-03-14 22:21:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 22:22:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 12 @ 35256 updates, score 15.68) (writing took 5.2681790590286255 seconds)
2021-03-14 22:22:02 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-03-14 22:22:02 | INFO | train | epoch 012 | loss 3.314 | nll_loss 1.6 | ppl 3.03 | wps 22483 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 35256 | lr 1.16682e-05 | gnorm 0.853 | train_wall 1569 | wall 0
2021-03-14 22:22:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:22:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:22:08 | INFO | fairseq.trainer | begin training epoch 13
2021-03-14 22:22:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:22:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:22:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:22:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:22:39 | INFO | train_inner | epoch 013:     44 / 2938 loss=3.333, nll_loss=1.621, ppl=3.08, wps=13761.4, ups=1.11, wpb=12352.1, bsz=421.1, num_updates=35300, lr=1.16609e-05, gnorm=0.858, train_wall=52, wall=0
2021-03-14 22:23:32 | INFO | train_inner | epoch 013:    144 / 2938 loss=3.306, nll_loss=1.591, ppl=3.01, wps=23236.8, ups=1.88, wpb=12328.7, bsz=406.1, num_updates=35400, lr=1.16445e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 22:24:25 | INFO | train_inner | epoch 013:    244 / 2938 loss=3.315, nll_loss=1.601, ppl=3.03, wps=22947.8, ups=1.86, wpb=12308.7, bsz=426.3, num_updates=35500, lr=1.1628e-05, gnorm=0.847, train_wall=53, wall=0
2021-03-14 22:25:21 | INFO | train_inner | epoch 013:    344 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22355.9, ups=1.8, wpb=12401.7, bsz=458.6, num_updates=35600, lr=1.16117e-05, gnorm=0.843, train_wall=55, wall=0
2021-03-14 22:26:15 | INFO | train_inner | epoch 013:    444 / 2938 loss=3.303, nll_loss=1.587, ppl=3, wps=23044.4, ups=1.86, wpb=12402.9, bsz=413.4, num_updates=35700, lr=1.15954e-05, gnorm=0.843, train_wall=54, wall=0
2021-03-14 22:27:08 | INFO | train_inner | epoch 013:    544 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23001.9, ups=1.88, wpb=12238.6, bsz=421.7, num_updates=35800, lr=1.15792e-05, gnorm=0.856, train_wall=53, wall=0
2021-03-14 22:28:02 | INFO | train_inner | epoch 013:    644 / 2938 loss=3.326, nll_loss=1.614, ppl=3.06, wps=22887, ups=1.85, wpb=12343.5, bsz=435, num_updates=35900, lr=1.15631e-05, gnorm=0.857, train_wall=54, wall=0
2021-03-14 22:28:55 | INFO | train_inner | epoch 013:    744 / 2938 loss=3.298, nll_loss=1.582, ppl=2.99, wps=23225.8, ups=1.87, wpb=12426.7, bsz=412.2, num_updates=36000, lr=1.1547e-05, gnorm=0.849, train_wall=53, wall=0
2021-03-14 22:29:49 | INFO | train_inner | epoch 013:    844 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=23275.6, ups=1.87, wpb=12445.5, bsz=426.7, num_updates=36100, lr=1.1531e-05, gnorm=0.837, train_wall=53, wall=0
2021-03-14 22:30:42 | INFO | train_inner | epoch 013:    944 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=23109, ups=1.88, wpb=12308.8, bsz=410.6, num_updates=36200, lr=1.15151e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 22:31:36 | INFO | train_inner | epoch 013:   1044 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=22541.8, ups=1.84, wpb=12252.3, bsz=447, num_updates=36300, lr=1.14992e-05, gnorm=0.862, train_wall=54, wall=0
2021-03-14 22:32:30 | INFO | train_inner | epoch 013:   1144 / 2938 loss=3.321, nll_loss=1.607, ppl=3.05, wps=22794.9, ups=1.86, wpb=12248.4, bsz=425.7, num_updates=36400, lr=1.14834e-05, gnorm=0.86, train_wall=54, wall=0
2021-03-14 22:33:24 | INFO | train_inner | epoch 013:   1244 / 2938 loss=3.332, nll_loss=1.621, ppl=3.08, wps=22551.4, ups=1.84, wpb=12230, bsz=434.8, num_updates=36500, lr=1.14676e-05, gnorm=0.885, train_wall=54, wall=0
2021-03-14 22:34:19 | INFO | train_inner | epoch 013:   1344 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=22720.4, ups=1.84, wpb=12317.5, bsz=448.2, num_updates=36600, lr=1.1452e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-14 22:35:12 | INFO | train_inner | epoch 013:   1444 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23273.6, ups=1.89, wpb=12325.1, bsz=396.7, num_updates=36700, lr=1.14364e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 22:36:06 | INFO | train_inner | epoch 013:   1544 / 2938 loss=3.319, nll_loss=1.605, ppl=3.04, wps=22787, ups=1.84, wpb=12409.3, bsz=426.9, num_updates=36800, lr=1.14208e-05, gnorm=0.852, train_wall=54, wall=0
2021-03-14 22:36:59 | INFO | train_inner | epoch 013:   1644 / 2938 loss=3.331, nll_loss=1.62, ppl=3.07, wps=23339.8, ups=1.9, wpb=12281.6, bsz=403.7, num_updates=36900, lr=1.14053e-05, gnorm=0.858, train_wall=52, wall=0
2021-03-14 22:37:53 | INFO | train_inner | epoch 013:   1744 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=22787.1, ups=1.84, wpb=12407.5, bsz=454.3, num_updates=37000, lr=1.13899e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 22:38:46 | INFO | train_inner | epoch 013:   1844 / 2938 loss=3.3, nll_loss=1.584, ppl=3, wps=23207.7, ups=1.88, wpb=12377.4, bsz=421.8, num_updates=37100, lr=1.13745e-05, gnorm=0.854, train_wall=53, wall=0
2021-03-14 22:39:40 | INFO | train_inner | epoch 013:   1944 / 2938 loss=3.291, nll_loss=1.574, ppl=2.98, wps=23258.5, ups=1.87, wpb=12449.1, bsz=416.6, num_updates=37200, lr=1.13592e-05, gnorm=0.839, train_wall=53, wall=0
2021-03-14 22:40:34 | INFO | train_inner | epoch 013:   2044 / 2938 loss=3.324, nll_loss=1.611, ppl=3.06, wps=22785.8, ups=1.85, wpb=12333.1, bsz=409.6, num_updates=37300, lr=1.1344e-05, gnorm=0.856, train_wall=54, wall=0
2021-03-14 22:41:29 | INFO | train_inner | epoch 013:   2144 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=22464.1, ups=1.83, wpb=12304.5, bsz=443, num_updates=37400, lr=1.13288e-05, gnorm=0.859, train_wall=55, wall=0
2021-03-14 22:42:22 | INFO | train_inner | epoch 013:   2244 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23310.9, ups=1.88, wpb=12386.8, bsz=406.8, num_updates=37500, lr=1.13137e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 22:43:16 | INFO | train_inner | epoch 013:   2344 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=22772.8, ups=1.85, wpb=12319.8, bsz=439.8, num_updates=37600, lr=1.12987e-05, gnorm=0.842, train_wall=54, wall=0
2021-03-14 22:44:09 | INFO | train_inner | epoch 013:   2444 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23080.8, ups=1.89, wpb=12241.8, bsz=416.3, num_updates=37700, lr=1.12837e-05, gnorm=0.865, train_wall=53, wall=0
2021-03-14 22:45:03 | INFO | train_inner | epoch 013:   2544 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23033.4, ups=1.87, wpb=12329.4, bsz=426.6, num_updates=37800, lr=1.12687e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 22:45:56 | INFO | train_inner | epoch 013:   2644 / 2938 loss=3.334, nll_loss=1.623, ppl=3.08, wps=23069.1, ups=1.87, wpb=12344.3, bsz=411.4, num_updates=37900, lr=1.12538e-05, gnorm=0.861, train_wall=53, wall=0
2021-03-14 22:46:50 | INFO | train_inner | epoch 013:   2744 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=22811.1, ups=1.84, wpb=12369.7, bsz=453.7, num_updates=38000, lr=1.1239e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-14 22:47:44 | INFO | train_inner | epoch 013:   2844 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=23025.1, ups=1.86, wpb=12387.8, bsz=434.2, num_updates=38100, lr=1.12243e-05, gnorm=0.856, train_wall=54, wall=0
2021-03-14 22:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 22:48:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:48:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:48:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:48:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:48:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:48:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:48:55 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.513 | nll_loss 8.473 | ppl 355.21 | bleu 15.75 | wps 3844.6 | wpb 6344.2 | bsz 166.4 | num_updates 38194 | best_bleu 15.9
2021-03-14 22:48:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 22:49:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 13 @ 38194 updates, score 15.75) (writing took 5.232200093567371 seconds)
2021-03-14 22:49:00 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-03-14 22:49:00 | INFO | train | epoch 013 | loss 3.313 | nll_loss 1.599 | ppl 3.03 | wps 22402.9 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 38194 | lr 1.12105e-05 | gnorm 0.853 | train_wall 1574 | wall 0
2021-03-14 22:49:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:49:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:49:06 | INFO | fairseq.trainer | begin training epoch 14
2021-03-14 22:49:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:49:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:49:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 22:49:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 22:49:18 | INFO | train_inner | epoch 014:      6 / 2938 loss=3.327, nll_loss=1.616, ppl=3.06, wps=13197.4, ups=1.07, wpb=12331.3, bsz=440.9, num_updates=38200, lr=1.12096e-05, gnorm=0.855, train_wall=54, wall=0
2021-03-14 22:50:10 | INFO | train_inner | epoch 014:    106 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23464, ups=1.9, wpb=12338.3, bsz=439, num_updates=38300, lr=1.11949e-05, gnorm=0.852, train_wall=52, wall=0
2021-03-14 22:51:04 | INFO | train_inner | epoch 014:    206 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22899, ups=1.85, wpb=12368.4, bsz=436.3, num_updates=38400, lr=1.11803e-05, gnorm=0.846, train_wall=54, wall=0
2021-03-14 22:51:59 | INFO | train_inner | epoch 014:    306 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22619.4, ups=1.83, wpb=12362.8, bsz=453.8, num_updates=38500, lr=1.11658e-05, gnorm=0.841, train_wall=54, wall=0
2021-03-14 22:52:53 | INFO | train_inner | epoch 014:    406 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=22831.9, ups=1.85, wpb=12313.9, bsz=414.6, num_updates=38600, lr=1.11513e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 22:53:47 | INFO | train_inner | epoch 014:    506 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=22723.5, ups=1.85, wpb=12311.3, bsz=430, num_updates=38700, lr=1.11369e-05, gnorm=0.864, train_wall=54, wall=0
2021-03-14 22:54:40 | INFO | train_inner | epoch 014:    606 / 2938 loss=3.307, nll_loss=1.592, ppl=3.01, wps=23319.1, ups=1.89, wpb=12342.6, bsz=413.2, num_updates=38800, lr=1.11226e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 22:55:34 | INFO | train_inner | epoch 014:    706 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=22650.1, ups=1.84, wpb=12281.5, bsz=417, num_updates=38900, lr=1.11083e-05, gnorm=0.856, train_wall=54, wall=0
2021-03-14 22:56:27 | INFO | train_inner | epoch 014:    806 / 2938 loss=3.286, nll_loss=1.569, ppl=2.97, wps=23315.3, ups=1.88, wpb=12410.4, bsz=432.8, num_updates=39000, lr=1.1094e-05, gnorm=0.841, train_wall=53, wall=0
2021-03-14 22:57:22 | INFO | train_inner | epoch 014:    906 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=22517.3, ups=1.82, wpb=12353.4, bsz=441.5, num_updates=39100, lr=1.10798e-05, gnorm=0.852, train_wall=55, wall=0
2021-03-14 22:58:18 | INFO | train_inner | epoch 014:   1006 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=22254.9, ups=1.8, wpb=12387.2, bsz=443.8, num_updates=39200, lr=1.10657e-05, gnorm=0.846, train_wall=55, wall=0
2021-03-14 22:59:13 | INFO | train_inner | epoch 014:   1106 / 2938 loss=3.304, nll_loss=1.589, ppl=3.01, wps=22428.6, ups=1.81, wpb=12368.2, bsz=443.6, num_updates=39300, lr=1.10516e-05, gnorm=0.845, train_wall=55, wall=0
2021-03-14 23:00:07 | INFO | train_inner | epoch 014:   1206 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23067.2, ups=1.86, wpb=12421.4, bsz=416.8, num_updates=39400, lr=1.10375e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-14 23:01:01 | INFO | train_inner | epoch 014:   1306 / 2938 loss=3.301, nll_loss=1.585, ppl=3, wps=22977, ups=1.85, wpb=12397.3, bsz=443.7, num_updates=39500, lr=1.10236e-05, gnorm=0.848, train_wall=54, wall=0
2021-03-14 23:01:54 | INFO | train_inner | epoch 014:   1406 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=23114.5, ups=1.88, wpb=12310.4, bsz=416.1, num_updates=39600, lr=1.10096e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 23:02:48 | INFO | train_inner | epoch 014:   1506 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=22752.4, ups=1.85, wpb=12319.2, bsz=437.2, num_updates=39700, lr=1.09958e-05, gnorm=0.852, train_wall=54, wall=0
2021-03-14 23:03:41 | INFO | train_inner | epoch 014:   1606 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23248.4, ups=1.89, wpb=12326.4, bsz=418.2, num_updates=39800, lr=1.09819e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 23:04:35 | INFO | train_inner | epoch 014:   1706 / 2938 loss=3.31, nll_loss=1.595, ppl=3.02, wps=23440.9, ups=1.88, wpb=12481, bsz=403, num_updates=39900, lr=1.09682e-05, gnorm=0.845, train_wall=53, wall=0
2021-03-14 23:05:28 | INFO | train_inner | epoch 014:   1806 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22818.5, ups=1.85, wpb=12314.6, bsz=432.2, num_updates=40000, lr=1.09545e-05, gnorm=0.854, train_wall=54, wall=0
2021-03-14 23:06:23 | INFO | train_inner | epoch 014:   1906 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=22427.9, ups=1.84, wpb=12210.7, bsz=450.5, num_updates=40100, lr=1.09408e-05, gnorm=0.869, train_wall=54, wall=0
2021-03-14 23:07:16 | INFO | train_inner | epoch 014:   2006 / 2938 loss=3.349, nll_loss=1.64, ppl=3.12, wps=23031, ups=1.88, wpb=12254, bsz=405, num_updates=40200, lr=1.09272e-05, gnorm=0.867, train_wall=53, wall=0
2021-03-14 23:08:11 | INFO | train_inner | epoch 014:   2106 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=22710.9, ups=1.82, wpb=12453, bsz=467, num_updates=40300, lr=1.09136e-05, gnorm=0.84, train_wall=55, wall=0
2021-03-14 23:09:04 | INFO | train_inner | epoch 014:   2206 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=22993.5, ups=1.88, wpb=12261.5, bsz=415.1, num_updates=40400, lr=1.09001e-05, gnorm=0.848, train_wall=53, wall=0
2021-03-14 23:09:58 | INFO | train_inner | epoch 014:   2306 / 2938 loss=3.32, nll_loss=1.606, ppl=3.04, wps=23159.3, ups=1.87, wpb=12375.1, bsz=409.6, num_updates=40500, lr=1.08866e-05, gnorm=0.854, train_wall=53, wall=0
2021-03-14 23:10:50 | INFO | train_inner | epoch 014:   2406 / 2938 loss=3.336, nll_loss=1.625, ppl=3.08, wps=23349.5, ups=1.9, wpb=12306.9, bsz=388.9, num_updates=40600, lr=1.08732e-05, gnorm=0.868, train_wall=53, wall=0
2021-03-14 23:11:44 | INFO | train_inner | epoch 014:   2506 / 2938 loss=3.331, nll_loss=1.62, ppl=3.07, wps=22931.4, ups=1.87, wpb=12276.7, bsz=410.6, num_updates=40700, lr=1.08598e-05, gnorm=0.876, train_wall=53, wall=0
2021-03-14 23:12:37 | INFO | train_inner | epoch 014:   2606 / 2938 loss=3.323, nll_loss=1.611, ppl=3.05, wps=23085, ups=1.88, wpb=12268.1, bsz=419, num_updates=40800, lr=1.08465e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 23:13:31 | INFO | train_inner | epoch 014:   2706 / 2938 loss=3.318, nll_loss=1.604, ppl=3.04, wps=23026.1, ups=1.86, wpb=12361.6, bsz=418.1, num_updates=40900, lr=1.08333e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 23:14:25 | INFO | train_inner | epoch 014:   2806 / 2938 loss=3.327, nll_loss=1.616, ppl=3.07, wps=22682.3, ups=1.83, wpb=12368.5, bsz=443.3, num_updates=41000, lr=1.082e-05, gnorm=0.86, train_wall=54, wall=0
2021-03-14 23:15:19 | INFO | train_inner | epoch 014:   2906 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=23116.5, ups=1.88, wpb=12322.3, bsz=421.3, num_updates=41100, lr=1.08069e-05, gnorm=0.874, train_wall=53, wall=0
2021-03-14 23:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 23:15:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:15:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:15:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:15:55 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.506 | nll_loss 8.464 | ppl 353.07 | bleu 15.81 | wps 3917.9 | wpb 6344.2 | bsz 166.4 | num_updates 41132 | best_bleu 15.9
2021-03-14 23:15:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 23:16:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 14 @ 41132 updates, score 15.81) (writing took 5.332006418146193 seconds)
2021-03-14 23:16:00 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-03-14 23:16:00 | INFO | train | epoch 014 | loss 3.311 | nll_loss 1.598 | ppl 3.03 | wps 22382.2 | ups 1.81 | wpb 12340.4 | bsz 426.5 | num_updates 41132 | lr 1.08027e-05 | gnorm 0.855 | train_wall 1575 | wall 0
2021-03-14 23:16:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:16:06 | INFO | fairseq.trainer | begin training epoch 15
2021-03-14 23:16:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:16:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:16:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:16:50 | INFO | train_inner | epoch 015:     68 / 2938 loss=3.31, nll_loss=1.595, ppl=3.02, wps=13511.4, ups=1.09, wpb=12372.1, bsz=433.3, num_updates=41200, lr=1.07937e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 23:17:44 | INFO | train_inner | epoch 015:    168 / 2938 loss=3.31, nll_loss=1.595, ppl=3.02, wps=22930.8, ups=1.86, wpb=12319.3, bsz=416.6, num_updates=41300, lr=1.07807e-05, gnorm=0.86, train_wall=54, wall=0
2021-03-14 23:18:38 | INFO | train_inner | epoch 015:    268 / 2938 loss=3.272, nll_loss=1.553, ppl=2.93, wps=22745.9, ups=1.83, wpb=12395.8, bsz=439.7, num_updates=41400, lr=1.07676e-05, gnorm=0.843, train_wall=54, wall=0
2021-03-14 23:19:33 | INFO | train_inner | epoch 015:    368 / 2938 loss=3.306, nll_loss=1.591, ppl=3.01, wps=22786.2, ups=1.84, wpb=12360.6, bsz=438.3, num_updates=41500, lr=1.07547e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-14 23:20:27 | INFO | train_inner | epoch 015:    468 / 2938 loss=3.292, nll_loss=1.575, ppl=2.98, wps=22914.5, ups=1.86, wpb=12346.6, bsz=445.5, num_updates=41600, lr=1.07417e-05, gnorm=0.852, train_wall=54, wall=0
2021-03-14 23:21:21 | INFO | train_inner | epoch 015:    568 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=22829.6, ups=1.84, wpb=12382.5, bsz=432.8, num_updates=41700, lr=1.07288e-05, gnorm=0.845, train_wall=54, wall=0
2021-03-14 23:22:14 | INFO | train_inner | epoch 015:    668 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23099.2, ups=1.88, wpb=12296.5, bsz=406.2, num_updates=41800, lr=1.0716e-05, gnorm=0.863, train_wall=53, wall=0
2021-03-14 23:23:09 | INFO | train_inner | epoch 015:    768 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=22683.8, ups=1.83, wpb=12394.1, bsz=442.6, num_updates=41900, lr=1.07032e-05, gnorm=0.856, train_wall=54, wall=0
2021-03-14 23:24:02 | INFO | train_inner | epoch 015:    868 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23249.4, ups=1.87, wpb=12401.3, bsz=430, num_updates=42000, lr=1.06904e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 23:24:55 | INFO | train_inner | epoch 015:    968 / 2938 loss=3.323, nll_loss=1.611, ppl=3.05, wps=23095.1, ups=1.88, wpb=12288.7, bsz=427.8, num_updates=42100, lr=1.06777e-05, gnorm=0.862, train_wall=53, wall=0
2021-03-14 23:25:48 | INFO | train_inner | epoch 015:   1068 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23318.4, ups=1.88, wpb=12403, bsz=427.4, num_updates=42200, lr=1.06651e-05, gnorm=0.852, train_wall=53, wall=0
2021-03-14 23:26:41 | INFO | train_inner | epoch 015:   1168 / 2938 loss=3.343, nll_loss=1.634, ppl=3.1, wps=23169.5, ups=1.9, wpb=12196.5, bsz=408.2, num_updates=42300, lr=1.06525e-05, gnorm=0.867, train_wall=52, wall=0
2021-03-14 23:27:33 | INFO | train_inner | epoch 015:   1268 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=23817.8, ups=1.93, wpb=12327.1, bsz=389.7, num_updates=42400, lr=1.06399e-05, gnorm=0.86, train_wall=52, wall=0
2021-03-14 23:28:25 | INFO | train_inner | epoch 015:   1368 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23737, ups=1.93, wpb=12307.3, bsz=394.2, num_updates=42500, lr=1.06274e-05, gnorm=0.864, train_wall=52, wall=0
2021-03-14 23:29:18 | INFO | train_inner | epoch 015:   1468 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23228, ups=1.87, wpb=12405.4, bsz=424.9, num_updates=42600, lr=1.06149e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 23:30:12 | INFO | train_inner | epoch 015:   1568 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22873.9, ups=1.85, wpb=12363, bsz=430.8, num_updates=42700, lr=1.06025e-05, gnorm=0.878, train_wall=54, wall=0
2021-03-14 23:31:06 | INFO | train_inner | epoch 015:   1668 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=22747.5, ups=1.85, wpb=12283.6, bsz=427.8, num_updates=42800, lr=1.05901e-05, gnorm=0.861, train_wall=54, wall=0
2021-03-14 23:32:00 | INFO | train_inner | epoch 015:   1768 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23118.8, ups=1.86, wpb=12431.9, bsz=439.4, num_updates=42900, lr=1.05777e-05, gnorm=0.857, train_wall=54, wall=0
2021-03-14 23:32:54 | INFO | train_inner | epoch 015:   1868 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=22864.5, ups=1.86, wpb=12317.1, bsz=425, num_updates=43000, lr=1.05654e-05, gnorm=0.85, train_wall=54, wall=0
2021-03-14 23:33:49 | INFO | train_inner | epoch 015:   1968 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22306.5, ups=1.82, wpb=12268.7, bsz=448.4, num_updates=43100, lr=1.05531e-05, gnorm=0.868, train_wall=55, wall=0
2021-03-14 23:34:43 | INFO | train_inner | epoch 015:   2068 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22826.7, ups=1.85, wpb=12354.1, bsz=456.2, num_updates=43200, lr=1.05409e-05, gnorm=0.859, train_wall=54, wall=0
2021-03-14 23:35:36 | INFO | train_inner | epoch 015:   2168 / 2938 loss=3.342, nll_loss=1.632, ppl=3.1, wps=23285.2, ups=1.89, wpb=12307.8, bsz=416.1, num_updates=43300, lr=1.05287e-05, gnorm=0.864, train_wall=53, wall=0
2021-03-14 23:36:28 | INFO | train_inner | epoch 015:   2268 / 2938 loss=3.333, nll_loss=1.622, ppl=3.08, wps=23231.8, ups=1.9, wpb=12244.8, bsz=414.5, num_updates=43400, lr=1.05166e-05, gnorm=0.863, train_wall=53, wall=0
2021-03-14 23:37:22 | INFO | train_inner | epoch 015:   2368 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23013.8, ups=1.87, wpb=12296.9, bsz=422.4, num_updates=43500, lr=1.05045e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 23:38:15 | INFO | train_inner | epoch 015:   2468 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23192.2, ups=1.87, wpb=12371.2, bsz=423.2, num_updates=43600, lr=1.04925e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-14 23:39:08 | INFO | train_inner | epoch 015:   2568 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23316.1, ups=1.89, wpb=12326.9, bsz=425.4, num_updates=43700, lr=1.04804e-05, gnorm=0.853, train_wall=53, wall=0
2021-03-14 23:40:02 | INFO | train_inner | epoch 015:   2668 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=22883.7, ups=1.86, wpb=12302.1, bsz=414.5, num_updates=43800, lr=1.04685e-05, gnorm=0.858, train_wall=54, wall=0
2021-03-14 23:40:55 | INFO | train_inner | epoch 015:   2768 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23382, ups=1.88, wpb=12467.1, bsz=415.7, num_updates=43900, lr=1.04565e-05, gnorm=0.838, train_wall=53, wall=0
2021-03-14 23:41:49 | INFO | train_inner | epoch 015:   2868 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23120, ups=1.87, wpb=12381.2, bsz=433.4, num_updates=44000, lr=1.04447e-05, gnorm=0.862, train_wall=53, wall=0
2021-03-14 23:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 23:42:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:42:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:42:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:42:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:42:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:42:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:42:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.517 | nll_loss 8.476 | ppl 356.18 | bleu 15.72 | wps 4320.3 | wpb 6344.2 | bsz 166.4 | num_updates 44070 | best_bleu 15.9
2021-03-14 23:42:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 23:42:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 15 @ 44070 updates, score 15.72) (writing took 5.241454315371811 seconds)
2021-03-14 23:42:50 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-03-14 23:42:50 | INFO | train | epoch 015 | loss 3.31 | nll_loss 1.596 | ppl 3.02 | wps 22524.1 | ups 1.83 | wpb 12340.4 | bsz 426.5 | num_updates 44070 | lr 1.04364e-05 | gnorm 0.857 | train_wall 1567 | wall 0
2021-03-14 23:42:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:42:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:42:56 | INFO | fairseq.trainer | begin training epoch 16
2021-03-14 23:42:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:42:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:43:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-14 23:43:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-14 23:43:20 | INFO | train_inner | epoch 016:     30 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=13445.9, ups=1.09, wpb=12303.7, bsz=437.9, num_updates=44100, lr=1.04328e-05, gnorm=0.865, train_wall=54, wall=0
2021-03-14 23:44:14 | INFO | train_inner | epoch 016:    130 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23231, ups=1.88, wpb=12379.8, bsz=426.1, num_updates=44200, lr=1.0421e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 23:45:08 | INFO | train_inner | epoch 016:    230 / 2938 loss=3.319, nll_loss=1.606, ppl=3.05, wps=22791.8, ups=1.85, wpb=12303.5, bsz=430.2, num_updates=44300, lr=1.04092e-05, gnorm=0.857, train_wall=54, wall=0
2021-03-14 23:46:01 | INFO | train_inner | epoch 016:    330 / 2938 loss=3.309, nll_loss=1.594, ppl=3.02, wps=22690, ups=1.85, wpb=12242.9, bsz=431.5, num_updates=44400, lr=1.03975e-05, gnorm=0.861, train_wall=54, wall=0
2021-03-14 23:46:55 | INFO | train_inner | epoch 016:    430 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=23066.7, ups=1.87, wpb=12348.3, bsz=423, num_updates=44500, lr=1.03858e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 23:47:48 | INFO | train_inner | epoch 016:    530 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23317.2, ups=1.87, wpb=12464, bsz=427.1, num_updates=44600, lr=1.03742e-05, gnorm=0.844, train_wall=53, wall=0
2021-03-14 23:48:42 | INFO | train_inner | epoch 016:    630 / 2938 loss=3.3, nll_loss=1.584, ppl=3, wps=23131.9, ups=1.88, wpb=12298.9, bsz=422.7, num_updates=44700, lr=1.03626e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 23:49:35 | INFO | train_inner | epoch 016:    730 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=23072.9, ups=1.86, wpb=12379.2, bsz=432.1, num_updates=44800, lr=1.0351e-05, gnorm=0.856, train_wall=53, wall=0
2021-03-14 23:50:28 | INFO | train_inner | epoch 016:    830 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23429.6, ups=1.89, wpb=12389.7, bsz=400.6, num_updates=44900, lr=1.03395e-05, gnorm=0.855, train_wall=53, wall=0
2021-03-14 23:51:23 | INFO | train_inner | epoch 016:    930 / 2938 loss=3.282, nll_loss=1.564, ppl=2.96, wps=22678.8, ups=1.82, wpb=12441.5, bsz=455.8, num_updates=45000, lr=1.0328e-05, gnorm=0.863, train_wall=55, wall=0
2021-03-14 23:52:17 | INFO | train_inner | epoch 016:   1030 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23115.1, ups=1.87, wpb=12365.6, bsz=431.3, num_updates=45100, lr=1.03165e-05, gnorm=0.851, train_wall=53, wall=0
2021-03-14 23:53:10 | INFO | train_inner | epoch 016:   1130 / 2938 loss=3.337, nll_loss=1.627, ppl=3.09, wps=22980, ups=1.87, wpb=12313, bsz=422.1, num_updates=45200, lr=1.03051e-05, gnorm=0.866, train_wall=53, wall=0
2021-03-14 23:54:03 | INFO | train_inner | epoch 016:   1230 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23169.1, ups=1.87, wpb=12360.7, bsz=413, num_updates=45300, lr=1.02937e-05, gnorm=0.85, train_wall=53, wall=0
2021-03-14 23:54:57 | INFO | train_inner | epoch 016:   1330 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22858.3, ups=1.86, wpb=12284.2, bsz=432.3, num_updates=45400, lr=1.02824e-05, gnorm=0.854, train_wall=54, wall=0
2021-03-14 23:55:51 | INFO | train_inner | epoch 016:   1430 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=23024.6, ups=1.87, wpb=12333.6, bsz=431.9, num_updates=45500, lr=1.02711e-05, gnorm=0.86, train_wall=53, wall=0
2021-03-14 23:56:45 | INFO | train_inner | epoch 016:   1530 / 2938 loss=3.286, nll_loss=1.569, ppl=2.97, wps=22896.8, ups=1.85, wpb=12354.4, bsz=430.7, num_updates=45600, lr=1.02598e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-14 23:57:38 | INFO | train_inner | epoch 016:   1630 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=23010.1, ups=1.87, wpb=12331.3, bsz=421.8, num_updates=45700, lr=1.02486e-05, gnorm=0.863, train_wall=53, wall=0
2021-03-14 23:58:32 | INFO | train_inner | epoch 016:   1730 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23095.9, ups=1.88, wpb=12314.7, bsz=417.7, num_updates=45800, lr=1.02374e-05, gnorm=0.856, train_wall=53, wall=0
2021-03-14 23:59:25 | INFO | train_inner | epoch 016:   1830 / 2938 loss=3.307, nll_loss=1.592, ppl=3.02, wps=23333.7, ups=1.89, wpb=12373.6, bsz=407.4, num_updates=45900, lr=1.02262e-05, gnorm=0.859, train_wall=53, wall=0
2021-03-15 00:00:19 | INFO | train_inner | epoch 016:   1930 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=22634.9, ups=1.84, wpb=12310.8, bsz=441.6, num_updates=46000, lr=1.02151e-05, gnorm=0.859, train_wall=54, wall=0
2021-03-15 00:01:13 | INFO | train_inner | epoch 016:   2030 / 2938 loss=3.315, nll_loss=1.601, ppl=3.03, wps=22803.9, ups=1.85, wpb=12322.7, bsz=416.8, num_updates=46100, lr=1.0204e-05, gnorm=0.865, train_wall=54, wall=0
2021-03-15 00:02:08 | INFO | train_inner | epoch 016:   2130 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=22482.5, ups=1.83, wpb=12309.2, bsz=466.2, num_updates=46200, lr=1.01929e-05, gnorm=0.862, train_wall=55, wall=0
2021-03-15 00:03:01 | INFO | train_inner | epoch 016:   2230 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=23173.4, ups=1.86, wpb=12431.1, bsz=427.3, num_updates=46300, lr=1.01819e-05, gnorm=0.854, train_wall=53, wall=0
2021-03-15 00:03:55 | INFO | train_inner | epoch 016:   2330 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=23143.6, ups=1.88, wpb=12313.4, bsz=421.4, num_updates=46400, lr=1.0171e-05, gnorm=0.865, train_wall=53, wall=0
2021-03-15 00:04:48 | INFO | train_inner | epoch 016:   2430 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=22877.4, ups=1.87, wpb=12261, bsz=416.5, num_updates=46500, lr=1.016e-05, gnorm=0.864, train_wall=53, wall=0
2021-03-15 00:05:42 | INFO | train_inner | epoch 016:   2530 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=22885.7, ups=1.86, wpb=12287.2, bsz=429.7, num_updates=46600, lr=1.01491e-05, gnorm=0.862, train_wall=53, wall=0
2021-03-15 00:06:36 | INFO | train_inner | epoch 016:   2630 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=23036.7, ups=1.86, wpb=12396.6, bsz=435.5, num_updates=46700, lr=1.01382e-05, gnorm=0.853, train_wall=54, wall=0
2021-03-15 00:07:29 | INFO | train_inner | epoch 016:   2730 / 2938 loss=3.325, nll_loss=1.612, ppl=3.06, wps=22937, ups=1.87, wpb=12297.1, bsz=411.8, num_updates=46800, lr=1.01274e-05, gnorm=0.87, train_wall=53, wall=0
2021-03-15 00:08:23 | INFO | train_inner | epoch 016:   2830 / 2938 loss=3.332, nll_loss=1.621, ppl=3.08, wps=22915.4, ups=1.86, wpb=12337.1, bsz=425.2, num_updates=46900, lr=1.01166e-05, gnorm=0.859, train_wall=54, wall=0
2021-03-15 00:09:16 | INFO | train_inner | epoch 016:   2930 / 2938 loss=3.311, nll_loss=1.598, ppl=3.03, wps=23162.8, ups=1.88, wpb=12333, bsz=418.6, num_updates=47000, lr=1.01058e-05, gnorm=0.856, train_wall=53, wall=0
2021-03-15 00:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 00:09:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:09:38 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.514 | nll_loss 8.474 | ppl 355.61 | bleu 15.71 | wps 4310.1 | wpb 6344.2 | bsz 166.4 | num_updates 47008 | best_bleu 15.9
2021-03-15 00:09:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 00:09:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 16 @ 47008 updates, score 15.71) (writing took 5.24661002587527 seconds)
2021-03-15 00:09:44 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-03-15 00:09:44 | INFO | train | epoch 016 | loss 3.309 | nll_loss 1.595 | ppl 3.02 | wps 22466.8 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 47008 | lr 1.0105e-05 | gnorm 0.858 | train_wall 1571 | wall 0
2021-03-15 00:09:49 | INFO | fairseq.trainer | begin training epoch 17
2021-03-15 00:09:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:09:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:09:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:09:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:10:46 | INFO | train_inner | epoch 017:     92 / 2938 loss=3.29, nll_loss=1.573, ppl=2.98, wps=13908.7, ups=1.12, wpb=12382.7, bsz=427.4, num_updates=47100, lr=1.00951e-05, gnorm=0.855, train_wall=52, wall=0
2021-03-15 00:11:38 | INFO | train_inner | epoch 017:    192 / 2938 loss=3.303, nll_loss=1.587, ppl=3, wps=23334.3, ups=1.89, wpb=12345.7, bsz=394, num_updates=47200, lr=1.00844e-05, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:12:33 | INFO | train_inner | epoch 017:    292 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22912.2, ups=1.85, wpb=12405.7, bsz=439.2, num_updates=47300, lr=1.00737e-05, gnorm=0.873, train_wall=54, wall=0
2021-03-15 00:13:26 | INFO | train_inner | epoch 017:    392 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=23090.7, ups=1.87, wpb=12360.1, bsz=426.7, num_updates=47400, lr=1.00631e-05, gnorm=0.853, train_wall=53, wall=0
2021-03-15 00:14:20 | INFO | train_inner | epoch 017:    492 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23109.5, ups=1.85, wpb=12470.2, bsz=445.9, num_updates=47500, lr=1.00525e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-15 00:15:14 | INFO | train_inner | epoch 017:    592 / 2938 loss=3.291, nll_loss=1.574, ppl=2.98, wps=22801.6, ups=1.84, wpb=12371.1, bsz=441, num_updates=47600, lr=1.00419e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-15 00:16:09 | INFO | train_inner | epoch 017:    692 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22467.4, ups=1.83, wpb=12306.1, bsz=450.2, num_updates=47700, lr=1.00314e-05, gnorm=0.857, train_wall=55, wall=0
2021-03-15 00:17:03 | INFO | train_inner | epoch 017:    792 / 2938 loss=3.307, nll_loss=1.592, ppl=3.02, wps=22936.1, ups=1.85, wpb=12396, bsz=424.9, num_updates=47800, lr=1.00209e-05, gnorm=0.858, train_wall=54, wall=0
2021-03-15 00:17:58 | INFO | train_inner | epoch 017:    892 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=22723.5, ups=1.84, wpb=12360, bsz=432.4, num_updates=47900, lr=1.00104e-05, gnorm=0.849, train_wall=54, wall=0
2021-03-15 00:18:51 | INFO | train_inner | epoch 017:    992 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23124.9, ups=1.87, wpb=12392.3, bsz=428.5, num_updates=48000, lr=1e-05, gnorm=0.862, train_wall=53, wall=0
2021-03-15 00:19:44 | INFO | train_inner | epoch 017:   1092 / 2938 loss=3.323, nll_loss=1.61, ppl=3.05, wps=23149.8, ups=1.87, wpb=12356.9, bsz=403, num_updates=48100, lr=9.9896e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:20:38 | INFO | train_inner | epoch 017:   1192 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=22966.7, ups=1.86, wpb=12319.4, bsz=411.5, num_updates=48200, lr=9.97923e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 00:21:32 | INFO | train_inner | epoch 017:   1292 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=23047.6, ups=1.87, wpb=12321.3, bsz=414.4, num_updates=48300, lr=9.9689e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 00:22:25 | INFO | train_inner | epoch 017:   1392 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23206.9, ups=1.88, wpb=12366.5, bsz=420, num_updates=48400, lr=9.95859e-06, gnorm=0.848, train_wall=53, wall=0
2021-03-15 00:23:19 | INFO | train_inner | epoch 017:   1492 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=22886.1, ups=1.84, wpb=12405.9, bsz=445.5, num_updates=48500, lr=9.94832e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 00:24:13 | INFO | train_inner | epoch 017:   1592 / 2938 loss=3.315, nll_loss=1.602, ppl=3.04, wps=23072.3, ups=1.87, wpb=12336.1, bsz=409.1, num_updates=48600, lr=9.93808e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 00:25:06 | INFO | train_inner | epoch 017:   1692 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23097.5, ups=1.87, wpb=12331.4, bsz=420.1, num_updates=48700, lr=9.92787e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 00:26:00 | INFO | train_inner | epoch 017:   1792 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=22868.7, ups=1.86, wpb=12292.4, bsz=415.9, num_updates=48800, lr=9.91769e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 00:26:54 | INFO | train_inner | epoch 017:   1892 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=22656.8, ups=1.85, wpb=12250.5, bsz=429.2, num_updates=48900, lr=9.90755e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 00:27:48 | INFO | train_inner | epoch 017:   1992 / 2938 loss=3.328, nll_loss=1.617, ppl=3.07, wps=22762.1, ups=1.84, wpb=12344.6, bsz=425.6, num_updates=49000, lr=9.89743e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 00:28:42 | INFO | train_inner | epoch 017:   2092 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22798, ups=1.86, wpb=12271.9, bsz=440, num_updates=49100, lr=9.88735e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 00:29:37 | INFO | train_inner | epoch 017:   2192 / 2938 loss=3.312, nll_loss=1.6, ppl=3.03, wps=22282.9, ups=1.81, wpb=12309.4, bsz=459, num_updates=49200, lr=9.8773e-06, gnorm=0.863, train_wall=55, wall=0
2021-03-15 00:30:31 | INFO | train_inner | epoch 017:   2292 / 2938 loss=3.323, nll_loss=1.611, ppl=3.05, wps=22956, ups=1.87, wpb=12283.9, bsz=414.4, num_updates=49300, lr=9.86727e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 00:31:24 | INFO | train_inner | epoch 017:   2392 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23196.8, ups=1.88, wpb=12367.7, bsz=415.5, num_updates=49400, lr=9.85728e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:32:18 | INFO | train_inner | epoch 017:   2492 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=22729.3, ups=1.85, wpb=12297.3, bsz=432.1, num_updates=49500, lr=9.84732e-06, gnorm=0.853, train_wall=54, wall=0
2021-03-15 00:33:11 | INFO | train_inner | epoch 017:   2592 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=23263.8, ups=1.89, wpb=12332.1, bsz=400.5, num_updates=49600, lr=9.83739e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 00:34:06 | INFO | train_inner | epoch 017:   2692 / 2938 loss=3.329, nll_loss=1.618, ppl=3.07, wps=22569.5, ups=1.83, wpb=12308.5, bsz=461.6, num_updates=49700, lr=9.82749e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 00:34:58 | INFO | train_inner | epoch 017:   2792 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=23484.6, ups=1.9, wpb=12378.6, bsz=404.7, num_updates=49800, lr=9.81761e-06, gnorm=0.856, train_wall=53, wall=0
2021-03-15 00:35:52 | INFO | train_inner | epoch 017:   2892 / 2938 loss=3.323, nll_loss=1.611, ppl=3.05, wps=22846.2, ups=1.88, wpb=12183.1, bsz=426.7, num_updates=49900, lr=9.80777e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 00:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 00:36:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:36:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:36:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:36:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.514 | nll_loss 8.473 | ppl 355.38 | bleu 15.72 | wps 4376.8 | wpb 6344.2 | bsz 166.4 | num_updates 49946 | best_bleu 15.9
2021-03-15 00:36:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 00:36:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 17 @ 49946 updates, score 15.72) (writing took 5.242000591009855 seconds)
2021-03-15 00:36:39 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-03-15 00:36:39 | INFO | train | epoch 017 | loss 3.308 | nll_loss 1.594 | ppl 3.02 | wps 22441.4 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 49946 | lr 9.80325e-06 | gnorm 0.859 | train_wall 1573 | wall 0
2021-03-15 00:36:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:45 | INFO | fairseq.trainer | begin training epoch 18
2021-03-15 00:36:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:36:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:36:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 00:36:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 00:37:22 | INFO | train_inner | epoch 018:     54 / 2938 loss=3.319, nll_loss=1.606, ppl=3.05, wps=13697.8, ups=1.11, wpb=12331.2, bsz=430.3, num_updates=50000, lr=9.79796e-06, gnorm=0.862, train_wall=52, wall=0
2021-03-15 00:38:15 | INFO | train_inner | epoch 018:    154 / 2938 loss=3.293, nll_loss=1.576, ppl=2.98, wps=23181.7, ups=1.88, wpb=12334.4, bsz=426.1, num_updates=50100, lr=9.78818e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:39:10 | INFO | train_inner | epoch 018:    254 / 2938 loss=3.269, nll_loss=1.55, ppl=2.93, wps=22533.1, ups=1.82, wpb=12349.6, bsz=462.1, num_updates=50200, lr=9.77842e-06, gnorm=0.844, train_wall=55, wall=0
2021-03-15 00:40:03 | INFO | train_inner | epoch 018:    354 / 2938 loss=3.286, nll_loss=1.568, ppl=2.97, wps=23328.9, ups=1.87, wpb=12472.3, bsz=398.7, num_updates=50300, lr=9.7687e-06, gnorm=0.855, train_wall=53, wall=0
2021-03-15 00:40:57 | INFO | train_inner | epoch 018:    454 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23020.2, ups=1.87, wpb=12305.3, bsz=410.7, num_updates=50400, lr=9.759e-06, gnorm=0.851, train_wall=53, wall=0
2021-03-15 00:41:51 | INFO | train_inner | epoch 018:    554 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=22650.1, ups=1.84, wpb=12327.3, bsz=439.4, num_updates=50500, lr=9.74933e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 00:42:45 | INFO | train_inner | epoch 018:    654 / 2938 loss=3.291, nll_loss=1.574, ppl=2.98, wps=22934.6, ups=1.84, wpb=12462.9, bsz=421.8, num_updates=50600, lr=9.7397e-06, gnorm=0.848, train_wall=54, wall=0
2021-03-15 00:43:39 | INFO | train_inner | epoch 018:    754 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=22675, ups=1.85, wpb=12276.1, bsz=452.3, num_updates=50700, lr=9.73009e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 00:44:34 | INFO | train_inner | epoch 018:    854 / 2938 loss=3.31, nll_loss=1.597, ppl=3.02, wps=22673.1, ups=1.85, wpb=12260.7, bsz=436.9, num_updates=50800, lr=9.7205e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 00:45:27 | INFO | train_inner | epoch 018:    954 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=22790.5, ups=1.86, wpb=12284.3, bsz=418.1, num_updates=50900, lr=9.71095e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 00:46:21 | INFO | train_inner | epoch 018:   1054 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=22860.3, ups=1.86, wpb=12283.9, bsz=417.5, num_updates=51000, lr=9.70143e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 00:47:15 | INFO | train_inner | epoch 018:   1154 / 2938 loss=3.287, nll_loss=1.57, ppl=2.97, wps=23224.4, ups=1.87, wpb=12416.3, bsz=429, num_updates=51100, lr=9.69193e-06, gnorm=0.846, train_wall=53, wall=0
2021-03-15 00:48:08 | INFO | train_inner | epoch 018:   1254 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23085.8, ups=1.87, wpb=12328.1, bsz=413.5, num_updates=51200, lr=9.68246e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 00:49:02 | INFO | train_inner | epoch 018:   1354 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=22617.3, ups=1.85, wpb=12251.7, bsz=419.1, num_updates=51300, lr=9.67302e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 00:49:55 | INFO | train_inner | epoch 018:   1454 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=23277, ups=1.88, wpb=12367, bsz=413.2, num_updates=51400, lr=9.6636e-06, gnorm=0.856, train_wall=53, wall=0
2021-03-15 00:50:49 | INFO | train_inner | epoch 018:   1554 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=23256.4, ups=1.88, wpb=12367.2, bsz=403, num_updates=51500, lr=9.65422e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 00:51:43 | INFO | train_inner | epoch 018:   1654 / 2938 loss=3.329, nll_loss=1.618, ppl=3.07, wps=22689.6, ups=1.84, wpb=12331.2, bsz=436, num_updates=51600, lr=9.64486e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 00:52:36 | INFO | train_inner | epoch 018:   1754 / 2938 loss=3.308, nll_loss=1.593, ppl=3.02, wps=23171.5, ups=1.87, wpb=12414.7, bsz=414.8, num_updates=51700, lr=9.63552e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 00:53:31 | INFO | train_inner | epoch 018:   1854 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22826.9, ups=1.84, wpb=12379.5, bsz=451.8, num_updates=51800, lr=9.62622e-06, gnorm=0.85, train_wall=54, wall=0
2021-03-15 00:54:24 | INFO | train_inner | epoch 018:   1954 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=23038, ups=1.86, wpb=12381, bsz=415, num_updates=51900, lr=9.61694e-06, gnorm=0.856, train_wall=54, wall=0
2021-03-15 00:55:18 | INFO | train_inner | epoch 018:   2054 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=23069.6, ups=1.87, wpb=12344.2, bsz=411, num_updates=52000, lr=9.60769e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 00:56:12 | INFO | train_inner | epoch 018:   2154 / 2938 loss=3.331, nll_loss=1.621, ppl=3.08, wps=22652.1, ups=1.84, wpb=12315.7, bsz=448.5, num_updates=52100, lr=9.59846e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 00:57:07 | INFO | train_inner | epoch 018:   2254 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=22642.1, ups=1.83, wpb=12353.1, bsz=433.6, num_updates=52200, lr=9.58927e-06, gnorm=0.85, train_wall=54, wall=0
2021-03-15 00:58:00 | INFO | train_inner | epoch 018:   2354 / 2938 loss=3.308, nll_loss=1.593, ppl=3.02, wps=23135.8, ups=1.87, wpb=12370.7, bsz=434.6, num_updates=52300, lr=9.58009e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:58:53 | INFO | train_inner | epoch 018:   2454 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=23316.4, ups=1.89, wpb=12328.7, bsz=396.2, num_updates=52400, lr=9.57095e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 00:59:46 | INFO | train_inner | epoch 018:   2554 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=23100.3, ups=1.88, wpb=12305.9, bsz=423, num_updates=52500, lr=9.56183e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 01:00:41 | INFO | train_inner | epoch 018:   2654 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22696.3, ups=1.84, wpb=12365.9, bsz=455.5, num_updates=52600, lr=9.55274e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 01:01:35 | INFO | train_inner | epoch 018:   2754 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=22948, ups=1.87, wpb=12302.8, bsz=414.6, num_updates=52700, lr=9.54367e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 01:02:28 | INFO | train_inner | epoch 018:   2854 / 2938 loss=3.337, nll_loss=1.627, ppl=3.09, wps=22998.1, ups=1.88, wpb=12265.4, bsz=427.8, num_updates=52800, lr=9.53463e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 01:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 01:03:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:31 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.524 | nll_loss 8.483 | ppl 357.69 | bleu 15.7 | wps 4327.3 | wpb 6344.2 | bsz 166.4 | num_updates 52884 | best_bleu 15.9
2021-03-15 01:03:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 01:03:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 18 @ 52884 updates, score 15.7) (writing took 5.261682561598718 seconds)
2021-03-15 01:03:37 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-03-15 01:03:37 | INFO | train | epoch 018 | loss 3.308 | nll_loss 1.594 | ppl 3.02 | wps 22413.6 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 52884 | lr 9.52705e-06 | gnorm 0.859 | train_wall 1575 | wall 0
2021-03-15 01:03:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:43 | INFO | fairseq.trainer | begin training epoch 19
2021-03-15 01:03:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:03:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:03:59 | INFO | train_inner | epoch 019:     16 / 2938 loss=3.307, nll_loss=1.592, ppl=3.01, wps=13588.9, ups=1.1, wpb=12370.8, bsz=444.2, num_updates=52900, lr=9.52561e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 01:04:52 | INFO | train_inner | epoch 019:    116 / 2938 loss=3.271, nll_loss=1.553, ppl=2.93, wps=23448.9, ups=1.89, wpb=12422.4, bsz=418.2, num_updates=53000, lr=9.51662e-06, gnorm=0.845, train_wall=53, wall=0
2021-03-15 01:05:45 | INFO | train_inner | epoch 019:    216 / 2938 loss=3.281, nll_loss=1.563, ppl=2.95, wps=23398.5, ups=1.89, wpb=12357.7, bsz=421, num_updates=53100, lr=9.50765e-06, gnorm=0.851, train_wall=53, wall=0
2021-03-15 01:06:39 | INFO | train_inner | epoch 019:    316 / 2938 loss=3.28, nll_loss=1.562, ppl=2.95, wps=22964.6, ups=1.85, wpb=12384.8, bsz=427.4, num_updates=53200, lr=9.49871e-06, gnorm=0.847, train_wall=54, wall=0
2021-03-15 01:07:31 | INFO | train_inner | epoch 019:    416 / 2938 loss=3.321, nll_loss=1.608, ppl=3.05, wps=23246, ups=1.9, wpb=12255.3, bsz=418.2, num_updates=53300, lr=9.4898e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 01:08:24 | INFO | train_inner | epoch 019:    516 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=23312.3, ups=1.9, wpb=12286.1, bsz=396.6, num_updates=53400, lr=9.48091e-06, gnorm=0.857, train_wall=53, wall=0
2021-03-15 01:09:17 | INFO | train_inner | epoch 019:    616 / 2938 loss=3.317, nll_loss=1.603, ppl=3.04, wps=23295, ups=1.89, wpb=12336.7, bsz=409.7, num_updates=53500, lr=9.47204e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 01:10:12 | INFO | train_inner | epoch 019:    716 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22731.9, ups=1.84, wpb=12381.7, bsz=452.4, num_updates=53600, lr=9.4632e-06, gnorm=0.854, train_wall=54, wall=0
2021-03-15 01:11:06 | INFO | train_inner | epoch 019:    816 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=22811.1, ups=1.83, wpb=12457.2, bsz=437.9, num_updates=53700, lr=9.45439e-06, gnorm=0.846, train_wall=54, wall=0
2021-03-15 01:12:01 | INFO | train_inner | epoch 019:    916 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=22496.8, ups=1.83, wpb=12290.6, bsz=440.2, num_updates=53800, lr=9.4456e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 01:12:54 | INFO | train_inner | epoch 019:   1016 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23044.1, ups=1.87, wpb=12317.7, bsz=421.2, num_updates=53900, lr=9.43683e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 01:13:48 | INFO | train_inner | epoch 019:   1116 / 2938 loss=3.291, nll_loss=1.574, ppl=2.98, wps=22783.6, ups=1.84, wpb=12351, bsz=453.2, num_updates=54000, lr=9.42809e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 01:14:42 | INFO | train_inner | epoch 019:   1216 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23192.4, ups=1.87, wpb=12389.6, bsz=435.8, num_updates=54100, lr=9.41937e-06, gnorm=0.853, train_wall=53, wall=0
2021-03-15 01:15:36 | INFO | train_inner | epoch 019:   1316 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=22936, ups=1.85, wpb=12373.8, bsz=416.3, num_updates=54200, lr=9.41068e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 01:16:30 | INFO | train_inner | epoch 019:   1416 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=22713.1, ups=1.86, wpb=12231.9, bsz=431.4, num_updates=54300, lr=9.40201e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 01:17:22 | INFO | train_inner | epoch 019:   1516 / 2938 loss=3.324, nll_loss=1.611, ppl=3.05, wps=23253.2, ups=1.9, wpb=12261.7, bsz=410.9, num_updates=54400, lr=9.39336e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 01:18:16 | INFO | train_inner | epoch 019:   1616 / 2938 loss=3.315, nll_loss=1.602, ppl=3.04, wps=22972.9, ups=1.85, wpb=12386.4, bsz=428.5, num_updates=54500, lr=9.38474e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 01:19:10 | INFO | train_inner | epoch 019:   1716 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22807.8, ups=1.86, wpb=12245, bsz=440.7, num_updates=54600, lr=9.37614e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 01:20:04 | INFO | train_inner | epoch 019:   1816 / 2938 loss=3.329, nll_loss=1.618, ppl=3.07, wps=22425.9, ups=1.83, wpb=12222.5, bsz=431.2, num_updates=54700, lr=9.36757e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 01:20:58 | INFO | train_inner | epoch 019:   1916 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23031.2, ups=1.86, wpb=12395.1, bsz=410.8, num_updates=54800, lr=9.35902e-06, gnorm=0.853, train_wall=54, wall=0
2021-03-15 01:21:52 | INFO | train_inner | epoch 019:   2016 / 2938 loss=3.316, nll_loss=1.604, ppl=3.04, wps=22740.4, ups=1.85, wpb=12305.6, bsz=416.5, num_updates=54900, lr=9.35049e-06, gnorm=0.856, train_wall=54, wall=0
2021-03-15 01:22:45 | INFO | train_inner | epoch 019:   2116 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23224.3, ups=1.89, wpb=12288.2, bsz=399.4, num_updates=55000, lr=9.34199e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 01:23:39 | INFO | train_inner | epoch 019:   2216 / 2938 loss=3.322, nll_loss=1.609, ppl=3.05, wps=23165.9, ups=1.88, wpb=12340.6, bsz=404.7, num_updates=55100, lr=9.33351e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 01:24:32 | INFO | train_inner | epoch 019:   2316 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=23090.4, ups=1.86, wpb=12443.9, bsz=425.7, num_updates=55200, lr=9.32505e-06, gnorm=0.856, train_wall=54, wall=0
2021-03-15 01:25:26 | INFO | train_inner | epoch 019:   2416 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23098.8, ups=1.87, wpb=12362.1, bsz=448.4, num_updates=55300, lr=9.31661e-06, gnorm=0.854, train_wall=53, wall=0
2021-03-15 01:26:20 | INFO | train_inner | epoch 019:   2516 / 2938 loss=3.318, nll_loss=1.605, ppl=3.04, wps=22953.4, ups=1.86, wpb=12334.8, bsz=427.4, num_updates=55400, lr=9.3082e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 01:27:13 | INFO | train_inner | epoch 019:   2616 / 2938 loss=3.344, nll_loss=1.634, ppl=3.1, wps=23005.3, ups=1.88, wpb=12244.4, bsz=415.8, num_updates=55500, lr=9.29981e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 01:28:07 | INFO | train_inner | epoch 019:   2716 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=22775.2, ups=1.84, wpb=12363.2, bsz=458.3, num_updates=55600, lr=9.29144e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 01:29:01 | INFO | train_inner | epoch 019:   2816 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23055.9, ups=1.86, wpb=12424.4, bsz=441.8, num_updates=55700, lr=9.2831e-06, gnorm=0.851, train_wall=54, wall=0
2021-03-15 01:29:55 | INFO | train_inner | epoch 019:   2916 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22910.3, ups=1.84, wpb=12424.1, bsz=430.4, num_updates=55800, lr=9.27478e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 01:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 01:30:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:30:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:30:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:30:25 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.516 | nll_loss 8.475 | ppl 355.93 | bleu 15.69 | wps 4278.4 | wpb 6344.2 | bsz 166.4 | num_updates 55822 | best_bleu 15.9
2021-03-15 01:30:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 01:30:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 19 @ 55822 updates, score 15.69) (writing took 5.211662204004824 seconds)
2021-03-15 01:30:30 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-03-15 01:30:30 | INFO | train | epoch 019 | loss 3.306 | nll_loss 1.592 | ppl 3.01 | wps 22470.2 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 55822 | lr 9.27295e-06 | gnorm 0.861 | train_wall 1571 | wall 0
2021-03-15 01:30:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:36 | INFO | fairseq.trainer | begin training epoch 20
2021-03-15 01:30:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:30:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:30:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:31:25 | INFO | train_inner | epoch 020:     78 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=13741.6, ups=1.12, wpb=12293.1, bsz=411, num_updates=55900, lr=9.26648e-06, gnorm=0.865, train_wall=52, wall=0
2021-03-15 01:32:19 | INFO | train_inner | epoch 020:    178 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=22619.1, ups=1.84, wpb=12286.3, bsz=441, num_updates=56000, lr=9.2582e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 01:33:14 | INFO | train_inner | epoch 020:    278 / 2938 loss=3.278, nll_loss=1.56, ppl=2.95, wps=22484.9, ups=1.81, wpb=12416.6, bsz=457.4, num_updates=56100, lr=9.24995e-06, gnorm=0.849, train_wall=55, wall=0
2021-03-15 01:34:09 | INFO | train_inner | epoch 020:    378 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=22729.8, ups=1.84, wpb=12328.8, bsz=426, num_updates=56200, lr=9.24171e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 01:35:02 | INFO | train_inner | epoch 020:    478 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23179.6, ups=1.87, wpb=12410.6, bsz=416.8, num_updates=56300, lr=9.2335e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 01:35:56 | INFO | train_inner | epoch 020:    578 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=23060.2, ups=1.87, wpb=12317.1, bsz=438.6, num_updates=56400, lr=9.22531e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 01:36:49 | INFO | train_inner | epoch 020:    678 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=23046.8, ups=1.87, wpb=12335.6, bsz=420.5, num_updates=56500, lr=9.21714e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 01:37:42 | INFO | train_inner | epoch 020:    778 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23343.3, ups=1.88, wpb=12413.7, bsz=413.1, num_updates=56600, lr=9.209e-06, gnorm=0.855, train_wall=53, wall=0
2021-03-15 01:38:36 | INFO | train_inner | epoch 020:    878 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=22788.1, ups=1.85, wpb=12314.6, bsz=430.4, num_updates=56700, lr=9.20087e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 01:39:30 | INFO | train_inner | epoch 020:    978 / 2938 loss=3.289, nll_loss=1.572, ppl=2.97, wps=23069.4, ups=1.86, wpb=12409.4, bsz=414.6, num_updates=56800, lr=9.19277e-06, gnorm=0.851, train_wall=54, wall=0
2021-03-15 01:40:25 | INFO | train_inner | epoch 020:   1078 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22356.9, ups=1.81, wpb=12342.6, bsz=464.5, num_updates=56900, lr=9.18469e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 01:41:19 | INFO | train_inner | epoch 020:   1178 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=22842.3, ups=1.86, wpb=12298, bsz=409.4, num_updates=57000, lr=9.17663e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 01:42:12 | INFO | train_inner | epoch 020:   1278 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23192.4, ups=1.88, wpb=12358.8, bsz=414.6, num_updates=57100, lr=9.16859e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 01:43:06 | INFO | train_inner | epoch 020:   1378 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22910.8, ups=1.86, wpb=12288.7, bsz=439.5, num_updates=57200, lr=9.16057e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 01:44:00 | INFO | train_inner | epoch 020:   1478 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22713.7, ups=1.85, wpb=12257, bsz=408.7, num_updates=57300, lr=9.15258e-06, gnorm=0.869, train_wall=54, wall=0
2021-03-15 01:44:54 | INFO | train_inner | epoch 020:   1578 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=22819.1, ups=1.84, wpb=12369.9, bsz=457, num_updates=57400, lr=9.1446e-06, gnorm=0.855, train_wall=54, wall=0
2021-03-15 01:45:48 | INFO | train_inner | epoch 020:   1678 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22753.4, ups=1.85, wpb=12322.7, bsz=436.7, num_updates=57500, lr=9.13664e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 01:46:42 | INFO | train_inner | epoch 020:   1778 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=23204.8, ups=1.87, wpb=12400.5, bsz=428.6, num_updates=57600, lr=9.12871e-06, gnorm=0.853, train_wall=53, wall=0
2021-03-15 01:47:35 | INFO | train_inner | epoch 020:   1878 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23298.1, ups=1.87, wpb=12427.4, bsz=428.7, num_updates=57700, lr=9.1208e-06, gnorm=0.854, train_wall=53, wall=0
2021-03-15 01:48:29 | INFO | train_inner | epoch 020:   1978 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23059.2, ups=1.86, wpb=12391.3, bsz=426.1, num_updates=57800, lr=9.1129e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 01:49:23 | INFO | train_inner | epoch 020:   2078 / 2938 loss=3.331, nll_loss=1.62, ppl=3.07, wps=22739.8, ups=1.86, wpb=12196.5, bsz=416.2, num_updates=57900, lr=9.10503e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 01:50:17 | INFO | train_inner | epoch 020:   2178 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22912.4, ups=1.85, wpb=12362.6, bsz=412.4, num_updates=58000, lr=9.09718e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 01:51:09 | INFO | train_inner | epoch 020:   2278 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23298.1, ups=1.9, wpb=12280.6, bsz=393.7, num_updates=58100, lr=9.08934e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 01:52:02 | INFO | train_inner | epoch 020:   2378 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=23225.9, ups=1.89, wpb=12311.6, bsz=415, num_updates=58200, lr=9.08153e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 01:52:55 | INFO | train_inner | epoch 020:   2478 / 2938 loss=3.344, nll_loss=1.635, ppl=3.1, wps=23174.4, ups=1.89, wpb=12271.3, bsz=400.8, num_updates=58300, lr=9.07374e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 01:53:49 | INFO | train_inner | epoch 020:   2578 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=23025.4, ups=1.86, wpb=12407.2, bsz=439.3, num_updates=58400, lr=9.06597e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 01:54:44 | INFO | train_inner | epoch 020:   2678 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22623, ups=1.83, wpb=12338.8, bsz=441.7, num_updates=58500, lr=9.05822e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 01:55:36 | INFO | train_inner | epoch 020:   2778 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23389, ups=1.9, wpb=12323.1, bsz=412.4, num_updates=58600, lr=9.05048e-06, gnorm=0.865, train_wall=52, wall=0
2021-03-15 01:56:30 | INFO | train_inner | epoch 020:   2878 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=23122.9, ups=1.88, wpb=12328.9, bsz=423, num_updates=58700, lr=9.04277e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 01:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 01:57:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:57:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:57:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:57:22 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.518 | nll_loss 8.479 | ppl 356.75 | bleu 15.65 | wps 3924.7 | wpb 6344.2 | bsz 166.4 | num_updates 58760 | best_bleu 15.9
2021-03-15 01:57:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 01:57:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 20 @ 58760 updates, score 15.65) (writing took 5.285449626855552 seconds)
2021-03-15 01:57:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-03-15 01:57:27 | INFO | train | epoch 020 | loss 3.306 | nll_loss 1.592 | ppl 3.01 | wps 22422.4 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 58760 | lr 9.03815e-06 | gnorm 0.862 | train_wall 1573 | wall 0
2021-03-15 01:57:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:33 | INFO | fairseq.trainer | begin training epoch 21
2021-03-15 01:57:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:57:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:57:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 01:57:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 01:58:01 | INFO | train_inner | epoch 021:     40 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=13545.6, ups=1.09, wpb=12422.3, bsz=442.1, num_updates=58800, lr=9.03508e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 01:58:53 | INFO | train_inner | epoch 021:    140 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23690.9, ups=1.92, wpb=12332.5, bsz=413, num_updates=58900, lr=9.02741e-06, gnorm=0.851, train_wall=52, wall=0
2021-03-15 01:59:46 | INFO | train_inner | epoch 021:    240 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=23246.6, ups=1.89, wpb=12310.8, bsz=408, num_updates=59000, lr=9.01975e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 02:00:41 | INFO | train_inner | epoch 021:    340 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=22626.5, ups=1.85, wpb=12256.8, bsz=445, num_updates=59100, lr=9.01212e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 02:01:34 | INFO | train_inner | epoch 021:    440 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23103.9, ups=1.88, wpb=12315.9, bsz=414.9, num_updates=59200, lr=9.0045e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 02:02:27 | INFO | train_inner | epoch 021:    540 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=23193.3, ups=1.88, wpb=12361.4, bsz=436.1, num_updates=59300, lr=8.99691e-06, gnorm=0.856, train_wall=53, wall=0
2021-03-15 02:03:22 | INFO | train_inner | epoch 021:    640 / 2938 loss=3.282, nll_loss=1.565, ppl=2.96, wps=22501.9, ups=1.81, wpb=12414, bsz=442.4, num_updates=59400, lr=8.98933e-06, gnorm=0.857, train_wall=55, wall=0
2021-03-15 02:04:16 | INFO | train_inner | epoch 021:    740 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=22767.4, ups=1.86, wpb=12270.2, bsz=431.8, num_updates=59500, lr=8.98177e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 02:05:10 | INFO | train_inner | epoch 021:    840 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=23131.2, ups=1.87, wpb=12387.7, bsz=418.2, num_updates=59600, lr=8.97424e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 02:06:04 | INFO | train_inner | epoch 021:    940 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=22860.9, ups=1.85, wpb=12378.7, bsz=433.8, num_updates=59700, lr=8.96672e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 02:06:57 | INFO | train_inner | epoch 021:   1040 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=23407.2, ups=1.87, wpb=12493.4, bsz=419.5, num_updates=59800, lr=8.95922e-06, gnorm=0.844, train_wall=53, wall=0
2021-03-15 02:07:51 | INFO | train_inner | epoch 021:   1140 / 2938 loss=3.322, nll_loss=1.611, ppl=3.05, wps=23185.6, ups=1.88, wpb=12340.9, bsz=385.4, num_updates=59900, lr=8.95173e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 02:08:44 | INFO | train_inner | epoch 021:   1240 / 2938 loss=3.3, nll_loss=1.584, ppl=3, wps=23099.1, ups=1.86, wpb=12395.6, bsz=426.7, num_updates=60000, lr=8.94427e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 02:09:37 | INFO | train_inner | epoch 021:   1340 / 2938 loss=3.32, nll_loss=1.607, ppl=3.05, wps=23280.4, ups=1.9, wpb=12263.9, bsz=403, num_updates=60100, lr=8.93683e-06, gnorm=0.872, train_wall=52, wall=0
2021-03-15 02:10:31 | INFO | train_inner | epoch 021:   1440 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=22767.9, ups=1.86, wpb=12221.4, bsz=426.3, num_updates=60200, lr=8.9294e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 02:11:25 | INFO | train_inner | epoch 021:   1540 / 2938 loss=3.279, nll_loss=1.561, ppl=2.95, wps=22891, ups=1.85, wpb=12399.7, bsz=441.9, num_updates=60300, lr=8.92199e-06, gnorm=0.853, train_wall=54, wall=0
2021-03-15 02:12:18 | INFO | train_inner | epoch 021:   1640 / 2938 loss=3.307, nll_loss=1.594, ppl=3.02, wps=22953, ups=1.87, wpb=12265.5, bsz=420.6, num_updates=60400, lr=8.91461e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 02:13:10 | INFO | train_inner | epoch 021:   1740 / 2938 loss=3.331, nll_loss=1.619, ppl=3.07, wps=23285.1, ups=1.91, wpb=12192.1, bsz=400.2, num_updates=60500, lr=8.90724e-06, gnorm=0.875, train_wall=52, wall=0
2021-03-15 02:14:04 | INFO | train_inner | epoch 021:   1840 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23103.9, ups=1.88, wpb=12293.6, bsz=427, num_updates=60600, lr=8.89988e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 02:14:58 | INFO | train_inner | epoch 021:   1940 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22771.7, ups=1.84, wpb=12389.8, bsz=449.8, num_updates=60700, lr=8.89255e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 02:15:51 | INFO | train_inner | epoch 021:   2040 / 2938 loss=3.335, nll_loss=1.625, ppl=3.08, wps=23214.3, ups=1.9, wpb=12197.3, bsz=398.8, num_updates=60800, lr=8.88523e-06, gnorm=0.875, train_wall=52, wall=0
2021-03-15 02:16:45 | INFO | train_inner | epoch 021:   2140 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=22920.2, ups=1.84, wpb=12469, bsz=461.4, num_updates=60900, lr=8.87794e-06, gnorm=0.853, train_wall=54, wall=0
2021-03-15 02:17:39 | INFO | train_inner | epoch 021:   2240 / 2938 loss=3.315, nll_loss=1.602, ppl=3.03, wps=22774.7, ups=1.85, wpb=12293.5, bsz=438.7, num_updates=61000, lr=8.87066e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 02:18:33 | INFO | train_inner | epoch 021:   2340 / 2938 loss=3.303, nll_loss=1.587, ppl=3, wps=23225.1, ups=1.87, wpb=12416.3, bsz=420, num_updates=61100, lr=8.86339e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 02:19:27 | INFO | train_inner | epoch 021:   2440 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22824, ups=1.84, wpb=12375.8, bsz=441.5, num_updates=61200, lr=8.85615e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 02:20:20 | INFO | train_inner | epoch 021:   2540 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23103.1, ups=1.87, wpb=12366.8, bsz=430.6, num_updates=61300, lr=8.84892e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 02:21:14 | INFO | train_inner | epoch 021:   2640 / 2938 loss=3.313, nll_loss=1.599, ppl=3.03, wps=23068.2, ups=1.86, wpb=12432.9, bsz=436.5, num_updates=61400, lr=8.84171e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 02:22:09 | INFO | train_inner | epoch 021:   2740 / 2938 loss=3.326, nll_loss=1.615, ppl=3.06, wps=22524.6, ups=1.84, wpb=12248.8, bsz=450.4, num_updates=61500, lr=8.83452e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 02:23:02 | INFO | train_inner | epoch 021:   2840 / 2938 loss=3.279, nll_loss=1.561, ppl=2.95, wps=23106.8, ups=1.86, wpb=12415.9, bsz=431.2, num_updates=61600, lr=8.82735e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 02:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 02:23:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:23:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:23:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:23:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:23:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:23:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:24:15 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.509 | nll_loss 8.469 | ppl 354.41 | bleu 15.66 | wps 3636.4 | wpb 6344.2 | bsz 166.4 | num_updates 61698 | best_bleu 15.9
2021-03-15 02:24:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 02:24:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 21 @ 61698 updates, score 15.66) (writing took 5.2389920288696885 seconds)
2021-03-15 02:24:20 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-03-15 02:24:20 | INFO | train | epoch 021 | loss 3.305 | nll_loss 1.591 | ppl 3.01 | wps 22483.1 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 61698 | lr 8.82033e-06 | gnorm 0.864 | train_wall 1568 | wall 0
2021-03-15 02:24:26 | INFO | fairseq.trainer | begin training epoch 22
2021-03-15 02:24:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:24:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:24:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:24:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:24:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:24:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:24:35 | INFO | train_inner | epoch 022:      2 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=13322.4, ups=1.08, wpb=12319.8, bsz=424.4, num_updates=61700, lr=8.82019e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 02:25:26 | INFO | train_inner | epoch 022:    102 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23996.9, ups=1.94, wpb=12358, bsz=419.9, num_updates=61800, lr=8.81305e-06, gnorm=0.854, train_wall=51, wall=0
2021-03-15 02:26:20 | INFO | train_inner | epoch 022:    202 / 2938 loss=3.307, nll_loss=1.592, ppl=3.02, wps=22793.7, ups=1.86, wpb=12256.6, bsz=427.2, num_updates=61900, lr=8.80593e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 02:27:13 | INFO | train_inner | epoch 022:    302 / 2938 loss=3.327, nll_loss=1.615, ppl=3.06, wps=23007.2, ups=1.87, wpb=12281.4, bsz=413.4, num_updates=62000, lr=8.79883e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 02:28:07 | INFO | train_inner | epoch 022:    402 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22649.9, ups=1.85, wpb=12239.8, bsz=449.4, num_updates=62100, lr=8.79174e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 02:29:02 | INFO | train_inner | epoch 022:    502 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=22586.4, ups=1.82, wpb=12389.5, bsz=445.8, num_updates=62200, lr=8.78467e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 02:29:56 | INFO | train_inner | epoch 022:    602 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=22814.7, ups=1.86, wpb=12276.1, bsz=434.2, num_updates=62300, lr=8.77762e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 02:30:49 | INFO | train_inner | epoch 022:    702 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23377.4, ups=1.88, wpb=12438.6, bsz=405.2, num_updates=62400, lr=8.77058e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 02:31:44 | INFO | train_inner | epoch 022:    802 / 2938 loss=3.272, nll_loss=1.554, ppl=2.94, wps=22642.3, ups=1.83, wpb=12404.6, bsz=446.6, num_updates=62500, lr=8.76356e-06, gnorm=0.848, train_wall=55, wall=0
2021-03-15 02:32:37 | INFO | train_inner | epoch 022:    902 / 2938 loss=3.308, nll_loss=1.593, ppl=3.02, wps=23291, ups=1.89, wpb=12307, bsz=397.8, num_updates=62600, lr=8.75656e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 02:33:31 | INFO | train_inner | epoch 022:   1002 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=23009.8, ups=1.86, wpb=12384.5, bsz=438.9, num_updates=62700, lr=8.74957e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 02:34:23 | INFO | train_inner | epoch 022:   1102 / 2938 loss=3.315, nll_loss=1.602, ppl=3.04, wps=23287.8, ups=1.9, wpb=12272, bsz=409.8, num_updates=62800, lr=8.7426e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 02:35:16 | INFO | train_inner | epoch 022:   1202 / 2938 loss=3.336, nll_loss=1.625, ppl=3.09, wps=23157.3, ups=1.89, wpb=12274.8, bsz=422.2, num_updates=62900, lr=8.73565e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 02:36:10 | INFO | train_inner | epoch 022:   1302 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=22983.4, ups=1.86, wpb=12389.7, bsz=435.4, num_updates=63000, lr=8.72872e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 02:37:04 | INFO | train_inner | epoch 022:   1402 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22731.7, ups=1.86, wpb=12231, bsz=433.6, num_updates=63100, lr=8.7218e-06, gnorm=0.897, train_wall=54, wall=0
2021-03-15 02:37:58 | INFO | train_inner | epoch 022:   1502 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22782.2, ups=1.84, wpb=12359.7, bsz=443.2, num_updates=63200, lr=8.71489e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 02:38:52 | INFO | train_inner | epoch 022:   1602 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=22868.2, ups=1.85, wpb=12351.4, bsz=459.4, num_updates=63300, lr=8.70801e-06, gnorm=0.855, train_wall=54, wall=0
2021-03-15 02:39:46 | INFO | train_inner | epoch 022:   1702 / 2938 loss=3.306, nll_loss=1.591, ppl=3.01, wps=23365.9, ups=1.88, wpb=12402.8, bsz=417.4, num_updates=63400, lr=8.70114e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 02:40:39 | INFO | train_inner | epoch 022:   1802 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23201.4, ups=1.87, wpb=12406.2, bsz=419.4, num_updates=63500, lr=8.69428e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 02:41:32 | INFO | train_inner | epoch 022:   1902 / 2938 loss=3.302, nll_loss=1.586, ppl=3, wps=23460, ups=1.89, wpb=12402.2, bsz=395.9, num_updates=63600, lr=8.68744e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 02:42:27 | INFO | train_inner | epoch 022:   2002 / 2938 loss=3.324, nll_loss=1.613, ppl=3.06, wps=22233.6, ups=1.82, wpb=12205.9, bsz=442.6, num_updates=63700, lr=8.68062e-06, gnorm=0.872, train_wall=55, wall=0
2021-03-15 02:43:20 | INFO | train_inner | epoch 022:   2102 / 2938 loss=3.315, nll_loss=1.602, ppl=3.04, wps=23266.7, ups=1.89, wpb=12283.2, bsz=415.2, num_updates=63800, lr=8.67382e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 02:44:13 | INFO | train_inner | epoch 022:   2202 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23079, ups=1.86, wpb=12380.9, bsz=414.6, num_updates=63900, lr=8.66703e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 02:45:07 | INFO | train_inner | epoch 022:   2302 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22857.6, ups=1.85, wpb=12366.5, bsz=441.4, num_updates=64000, lr=8.66025e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 02:46:02 | INFO | train_inner | epoch 022:   2402 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=22578.8, ups=1.83, wpb=12344.6, bsz=439.7, num_updates=64100, lr=8.6535e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 02:46:56 | INFO | train_inner | epoch 022:   2502 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=22884.8, ups=1.85, wpb=12399.1, bsz=415.8, num_updates=64200, lr=8.64675e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 02:47:50 | INFO | train_inner | epoch 022:   2602 / 2938 loss=3.289, nll_loss=1.573, ppl=2.97, wps=23029.1, ups=1.85, wpb=12473.6, bsz=439.7, num_updates=64300, lr=8.64003e-06, gnorm=0.852, train_wall=54, wall=0
2021-03-15 02:48:44 | INFO | train_inner | epoch 022:   2702 / 2938 loss=3.301, nll_loss=1.585, ppl=3, wps=23074, ups=1.87, wpb=12361.8, bsz=411.7, num_updates=64400, lr=8.63332e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 02:49:38 | INFO | train_inner | epoch 022:   2802 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23114.8, ups=1.86, wpb=12443.8, bsz=433.2, num_updates=64500, lr=8.62662e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 02:50:31 | INFO | train_inner | epoch 022:   2902 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=23067.3, ups=1.88, wpb=12240.1, bsz=393.1, num_updates=64600, lr=8.61994e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 02:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 02:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:51:08 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.501 | nll_loss 8.461 | ppl 352.31 | bleu 15.65 | wps 4290.7 | wpb 6344.2 | bsz 166.4 | num_updates 64636 | best_bleu 15.9
2021-03-15 02:51:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 02:51:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 22 @ 64636 updates, score 15.65) (writing took 5.257154765538871 seconds)
2021-03-15 02:51:13 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-03-15 02:51:13 | INFO | train | epoch 022 | loss 3.304 | nll_loss 1.59 | ppl 3.01 | wps 22471.3 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 64636 | lr 8.61754e-06 | gnorm 0.864 | train_wall 1571 | wall 0
2021-03-15 02:51:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:51:19 | INFO | fairseq.trainer | begin training epoch 23
2021-03-15 02:51:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:51:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:51:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:51:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 02:51:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 02:52:01 | INFO | train_inner | epoch 023:     64 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=13686.9, ups=1.11, wpb=12281.9, bsz=441, num_updates=64700, lr=8.61328e-06, gnorm=0.865, train_wall=53, wall=0
2021-03-15 02:52:54 | INFO | train_inner | epoch 023:    164 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23144, ups=1.87, wpb=12349.5, bsz=421.9, num_updates=64800, lr=8.60663e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 02:53:48 | INFO | train_inner | epoch 023:    264 / 2938 loss=3.28, nll_loss=1.563, ppl=2.95, wps=22870.5, ups=1.86, wpb=12323.8, bsz=423.4, num_updates=64900, lr=8.6e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 02:54:42 | INFO | train_inner | epoch 023:    364 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22598.4, ups=1.85, wpb=12238.8, bsz=419.7, num_updates=65000, lr=8.59338e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 02:55:35 | INFO | train_inner | epoch 023:    464 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=23125.6, ups=1.88, wpb=12291.3, bsz=410.2, num_updates=65100, lr=8.58678e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 02:56:29 | INFO | train_inner | epoch 023:    564 / 2938 loss=3.297, nll_loss=1.581, ppl=2.99, wps=23073.8, ups=1.87, wpb=12329.1, bsz=410.6, num_updates=65200, lr=8.58019e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 02:57:23 | INFO | train_inner | epoch 023:    664 / 2938 loss=3.31, nll_loss=1.597, ppl=3.02, wps=22745.7, ups=1.84, wpb=12358.7, bsz=440.8, num_updates=65300, lr=8.57362e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 02:58:16 | INFO | train_inner | epoch 023:    764 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23204.3, ups=1.87, wpb=12398.9, bsz=401.1, num_updates=65400, lr=8.56706e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 02:59:10 | INFO | train_inner | epoch 023:    864 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22850.2, ups=1.84, wpb=12387, bsz=432.7, num_updates=65500, lr=8.56052e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 03:00:04 | INFO | train_inner | epoch 023:    964 / 2938 loss=3.306, nll_loss=1.591, ppl=3.01, wps=22962.6, ups=1.87, wpb=12297.1, bsz=425.6, num_updates=65600, lr=8.55399e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 03:00:58 | INFO | train_inner | epoch 023:   1064 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22937.8, ups=1.85, wpb=12380.2, bsz=446.2, num_updates=65700, lr=8.54748e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 03:01:51 | INFO | train_inner | epoch 023:   1164 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=23375.8, ups=1.89, wpb=12374.7, bsz=427.4, num_updates=65800, lr=8.54098e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 03:02:44 | INFO | train_inner | epoch 023:   1264 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23137.4, ups=1.88, wpb=12323.9, bsz=431.5, num_updates=65900, lr=8.5345e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 03:03:37 | INFO | train_inner | epoch 023:   1364 / 2938 loss=3.329, nll_loss=1.617, ppl=3.07, wps=23118.1, ups=1.89, wpb=12253.2, bsz=405.2, num_updates=66000, lr=8.52803e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 03:04:31 | INFO | train_inner | epoch 023:   1464 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23018.6, ups=1.87, wpb=12334.2, bsz=426.7, num_updates=66100, lr=8.52158e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 03:05:24 | INFO | train_inner | epoch 023:   1564 / 2938 loss=3.331, nll_loss=1.62, ppl=3.07, wps=23338.1, ups=1.89, wpb=12344.9, bsz=403.9, num_updates=66200, lr=8.51514e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 03:06:18 | INFO | train_inner | epoch 023:   1664 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23058.5, ups=1.86, wpb=12406.6, bsz=414.4, num_updates=66300, lr=8.50871e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 03:07:12 | INFO | train_inner | epoch 023:   1764 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=22824.7, ups=1.84, wpb=12372.5, bsz=444.2, num_updates=66400, lr=8.5023e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 03:08:04 | INFO | train_inner | epoch 023:   1864 / 2938 loss=3.327, nll_loss=1.615, ppl=3.06, wps=23341.5, ups=1.9, wpb=12299.9, bsz=394.5, num_updates=66500, lr=8.49591e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 03:08:59 | INFO | train_inner | epoch 023:   1964 / 2938 loss=3.325, nll_loss=1.615, ppl=3.06, wps=22473.8, ups=1.84, wpb=12220.1, bsz=460.7, num_updates=66600, lr=8.48953e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 03:09:52 | INFO | train_inner | epoch 023:   2064 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23224.8, ups=1.88, wpb=12348.5, bsz=407, num_updates=66700, lr=8.48316e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 03:10:46 | INFO | train_inner | epoch 023:   2164 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=22988.5, ups=1.86, wpb=12370.8, bsz=436, num_updates=66800, lr=8.47681e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 03:11:40 | INFO | train_inner | epoch 023:   2264 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22750, ups=1.84, wpb=12347.3, bsz=445.1, num_updates=66900, lr=8.47047e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 03:12:35 | INFO | train_inner | epoch 023:   2364 / 2938 loss=3.329, nll_loss=1.617, ppl=3.07, wps=22290.7, ups=1.82, wpb=12245.6, bsz=436.8, num_updates=67000, lr=8.46415e-06, gnorm=0.88, train_wall=55, wall=0
2021-03-15 03:13:30 | INFO | train_inner | epoch 023:   2464 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22314.5, ups=1.81, wpb=12326.1, bsz=456.5, num_updates=67100, lr=8.45784e-06, gnorm=0.868, train_wall=55, wall=0
2021-03-15 03:14:23 | INFO | train_inner | epoch 023:   2564 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=23407.2, ups=1.88, wpb=12435.1, bsz=417, num_updates=67200, lr=8.45154e-06, gnorm=0.854, train_wall=53, wall=0
2021-03-15 03:15:17 | INFO | train_inner | epoch 023:   2664 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23219.4, ups=1.87, wpb=12403.3, bsz=432.6, num_updates=67300, lr=8.44526e-06, gnorm=0.854, train_wall=53, wall=0
2021-03-15 03:16:11 | INFO | train_inner | epoch 023:   2764 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=22812.5, ups=1.83, wpb=12436.8, bsz=432, num_updates=67400, lr=8.43899e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 03:17:06 | INFO | train_inner | epoch 023:   2864 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=22604.1, ups=1.82, wpb=12417.8, bsz=443.9, num_updates=67500, lr=8.43274e-06, gnorm=0.861, train_wall=55, wall=0
2021-03-15 03:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 03:17:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:17:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:17:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:17:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:17:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:17:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:18:03 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.517 | nll_loss 8.477 | ppl 356.29 | bleu 15.74 | wps 4325.6 | wpb 6344.2 | bsz 166.4 | num_updates 67574 | best_bleu 15.9
2021-03-15 03:18:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 03:18:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 23 @ 67574 updates, score 15.74) (writing took 5.210713332518935 seconds)
2021-03-15 03:18:08 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-03-15 03:18:08 | INFO | train | epoch 023 | loss 3.304 | nll_loss 1.589 | ppl 3.01 | wps 22451.9 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 67574 | lr 8.42812e-06 | gnorm 0.865 | train_wall 1572 | wall 0
2021-03-15 03:18:14 | INFO | fairseq.trainer | begin training epoch 24
2021-03-15 03:18:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:18:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:18:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:18:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:18:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:18:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:18:35 | INFO | train_inner | epoch 024:     26 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=13834.2, ups=1.13, wpb=12279.7, bsz=413, num_updates=67600, lr=8.4265e-06, gnorm=0.869, train_wall=52, wall=0
2021-03-15 03:19:30 | INFO | train_inner | epoch 024:    126 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=22574.1, ups=1.83, wpb=12355.5, bsz=474, num_updates=67700, lr=8.42028e-06, gnorm=0.869, train_wall=55, wall=0
2021-03-15 03:20:24 | INFO | train_inner | epoch 024:    226 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=22713.6, ups=1.84, wpb=12370.8, bsz=460.3, num_updates=67800, lr=8.41406e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 03:21:18 | INFO | train_inner | epoch 024:    326 / 2938 loss=3.277, nll_loss=1.559, ppl=2.95, wps=23082.9, ups=1.87, wpb=12339.3, bsz=431, num_updates=67900, lr=8.40787e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 03:22:11 | INFO | train_inner | epoch 024:    426 / 2938 loss=3.28, nll_loss=1.562, ppl=2.95, wps=23147.3, ups=1.87, wpb=12372.5, bsz=443.4, num_updates=68000, lr=8.40168e-06, gnorm=0.855, train_wall=53, wall=0
2021-03-15 03:23:05 | INFO | train_inner | epoch 024:    526 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22820.9, ups=1.85, wpb=12339.1, bsz=417.1, num_updates=68100, lr=8.39551e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 03:23:59 | INFO | train_inner | epoch 024:    626 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=22925.5, ups=1.84, wpb=12427.8, bsz=441.8, num_updates=68200, lr=8.38935e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 03:24:53 | INFO | train_inner | epoch 024:    726 / 2938 loss=3.316, nll_loss=1.602, ppl=3.04, wps=23123.7, ups=1.87, wpb=12334.6, bsz=406.4, num_updates=68300, lr=8.38321e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 03:25:46 | INFO | train_inner | epoch 024:    826 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23062.4, ups=1.88, wpb=12287.8, bsz=407.5, num_updates=68400, lr=8.37708e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 03:26:40 | INFO | train_inner | epoch 024:    926 / 2938 loss=3.326, nll_loss=1.614, ppl=3.06, wps=22634, ups=1.85, wpb=12220.7, bsz=414.1, num_updates=68500, lr=8.37096e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 03:27:34 | INFO | train_inner | epoch 024:   1026 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22603.5, ups=1.84, wpb=12311.1, bsz=437, num_updates=68600, lr=8.36486e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 03:28:29 | INFO | train_inner | epoch 024:   1126 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22563.5, ups=1.84, wpb=12262.4, bsz=438.5, num_updates=68700, lr=8.35877e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 03:29:22 | INFO | train_inner | epoch 024:   1226 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22840.6, ups=1.86, wpb=12258.3, bsz=421.5, num_updates=68800, lr=8.35269e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 03:30:15 | INFO | train_inner | epoch 024:   1326 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=23431.4, ups=1.9, wpb=12356, bsz=390.4, num_updates=68900, lr=8.34663e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 03:31:09 | INFO | train_inner | epoch 024:   1426 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23185.7, ups=1.87, wpb=12378.3, bsz=427.8, num_updates=69000, lr=8.34058e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 03:32:02 | INFO | train_inner | epoch 024:   1526 / 2938 loss=3.326, nll_loss=1.614, ppl=3.06, wps=23060.7, ups=1.86, wpb=12375.9, bsz=440.9, num_updates=69100, lr=8.33454e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 03:32:56 | INFO | train_inner | epoch 024:   1626 / 2938 loss=3.323, nll_loss=1.612, ppl=3.06, wps=22697.7, ups=1.85, wpb=12301.8, bsz=440.7, num_updates=69200, lr=8.32851e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 03:33:51 | INFO | train_inner | epoch 024:   1726 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22932.8, ups=1.85, wpb=12420.9, bsz=440.1, num_updates=69300, lr=8.3225e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 03:34:44 | INFO | train_inner | epoch 024:   1826 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=23015.5, ups=1.86, wpb=12345.4, bsz=431, num_updates=69400, lr=8.31651e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 03:35:38 | INFO | train_inner | epoch 024:   1926 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23129, ups=1.87, wpb=12346.1, bsz=420.6, num_updates=69500, lr=8.31052e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 03:36:31 | INFO | train_inner | epoch 024:   2026 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=23228.9, ups=1.87, wpb=12404.7, bsz=419, num_updates=69600, lr=8.30455e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 03:37:26 | INFO | train_inner | epoch 024:   2126 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22588.1, ups=1.82, wpb=12379.8, bsz=438.6, num_updates=69700, lr=8.29859e-06, gnorm=0.872, train_wall=55, wall=0
2021-03-15 03:38:19 | INFO | train_inner | epoch 024:   2226 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=22830.4, ups=1.87, wpb=12240.1, bsz=429.5, num_updates=69800, lr=8.29264e-06, gnorm=0.889, train_wall=53, wall=0
2021-03-15 03:39:14 | INFO | train_inner | epoch 024:   2326 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22871.5, ups=1.85, wpb=12370.4, bsz=425.5, num_updates=69900, lr=8.28671e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 03:40:07 | INFO | train_inner | epoch 024:   2426 / 2938 loss=3.311, nll_loss=1.598, ppl=3.03, wps=22863.3, ups=1.86, wpb=12269.2, bsz=410.5, num_updates=70000, lr=8.28079e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 03:41:00 | INFO | train_inner | epoch 024:   2526 / 2938 loss=3.326, nll_loss=1.615, ppl=3.06, wps=23223.2, ups=1.9, wpb=12217.5, bsz=391.8, num_updates=70100, lr=8.27488e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 03:41:53 | INFO | train_inner | epoch 024:   2626 / 2938 loss=3.318, nll_loss=1.606, ppl=3.04, wps=23317.5, ups=1.89, wpb=12350.1, bsz=400.8, num_updates=70200, lr=8.26898e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 03:42:46 | INFO | train_inner | epoch 024:   2726 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=23437.4, ups=1.89, wpb=12378.5, bsz=413, num_updates=70300, lr=8.2631e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 03:43:39 | INFO | train_inner | epoch 024:   2826 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23212.6, ups=1.87, wpb=12403.7, bsz=419, num_updates=70400, lr=8.25723e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 03:44:33 | INFO | train_inner | epoch 024:   2926 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=23152.2, ups=1.85, wpb=12500.5, bsz=446.5, num_updates=70500, lr=8.25137e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 03:44:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 03:44:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:44:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:44:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:44:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:44:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:44:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:44:58 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.509 | nll_loss 8.47 | ppl 354.52 | bleu 15.77 | wps 3982.6 | wpb 6344.2 | bsz 166.4 | num_updates 70512 | best_bleu 15.9
2021-03-15 03:44:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 03:45:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 24 @ 70512 updates, score 15.77) (writing took 5.2744820499792695 seconds)
2021-03-15 03:45:04 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-03-15 03:45:04 | INFO | train | epoch 024 | loss 3.303 | nll_loss 1.588 | ppl 3.01 | wps 22442.9 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 70512 | lr 8.25067e-06 | gnorm 0.868 | train_wall 1572 | wall 0
2021-03-15 03:45:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:45:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:45:10 | INFO | fairseq.trainer | begin training epoch 25
2021-03-15 03:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 03:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 03:46:04 | INFO | train_inner | epoch 025:     88 / 2938 loss=3.304, nll_loss=1.589, ppl=3.01, wps=13599.6, ups=1.1, wpb=12325.3, bsz=413.3, num_updates=70600, lr=8.24552e-06, gnorm=0.866, train_wall=52, wall=0
2021-03-15 03:46:57 | INFO | train_inner | epoch 025:    188 / 2938 loss=3.318, nll_loss=1.605, ppl=3.04, wps=23082.3, ups=1.87, wpb=12322.5, bsz=430.2, num_updates=70700, lr=8.23969e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 03:47:50 | INFO | train_inner | epoch 025:    288 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23035, ups=1.88, wpb=12250.4, bsz=422.5, num_updates=70800, lr=8.23387e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 03:48:43 | INFO | train_inner | epoch 025:    388 / 2938 loss=3.294, nll_loss=1.578, ppl=2.98, wps=23372.8, ups=1.89, wpb=12377.1, bsz=415.8, num_updates=70900, lr=8.22806e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 03:49:37 | INFO | train_inner | epoch 025:    488 / 2938 loss=3.317, nll_loss=1.604, ppl=3.04, wps=22975, ups=1.87, wpb=12304.4, bsz=405.8, num_updates=71000, lr=8.22226e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 03:50:31 | INFO | train_inner | epoch 025:    588 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22806.2, ups=1.85, wpb=12354, bsz=438.8, num_updates=71100, lr=8.21648e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 03:51:25 | INFO | train_inner | epoch 025:    688 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=22762.8, ups=1.85, wpb=12301, bsz=414.2, num_updates=71200, lr=8.21071e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 03:52:18 | INFO | train_inner | epoch 025:    788 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23223.2, ups=1.87, wpb=12389, bsz=416.1, num_updates=71300, lr=8.20495e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 03:53:12 | INFO | train_inner | epoch 025:    888 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23217, ups=1.88, wpb=12364, bsz=401, num_updates=71400, lr=8.1992e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 03:54:07 | INFO | train_inner | epoch 025:    988 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=22459.4, ups=1.82, wpb=12345.1, bsz=452.2, num_updates=71500, lr=8.19346e-06, gnorm=0.862, train_wall=55, wall=0
2021-03-15 03:55:00 | INFO | train_inner | epoch 025:   1088 / 2938 loss=3.323, nll_loss=1.611, ppl=3.06, wps=22902.4, ups=1.87, wpb=12247.6, bsz=423.3, num_updates=71600, lr=8.18774e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 03:55:54 | INFO | train_inner | epoch 025:   1188 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=22794.4, ups=1.84, wpb=12390, bsz=430, num_updates=71700, lr=8.18203e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 03:56:48 | INFO | train_inner | epoch 025:   1288 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=23263.9, ups=1.88, wpb=12382, bsz=417.8, num_updates=71800, lr=8.17633e-06, gnorm=0.865, train_wall=53, wall=0
2021-03-15 03:57:42 | INFO | train_inner | epoch 025:   1388 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22709.4, ups=1.83, wpb=12400.2, bsz=439.9, num_updates=71900, lr=8.17064e-06, gnorm=0.856, train_wall=54, wall=0
2021-03-15 03:58:36 | INFO | train_inner | epoch 025:   1488 / 2938 loss=3.262, nll_loss=1.543, ppl=2.91, wps=23000.2, ups=1.84, wpb=12475.6, bsz=447, num_updates=72000, lr=8.16497e-06, gnorm=0.846, train_wall=54, wall=0
2021-03-15 03:59:30 | INFO | train_inner | epoch 025:   1588 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22993.8, ups=1.87, wpb=12309.8, bsz=422.1, num_updates=72100, lr=8.1593e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:00:24 | INFO | train_inner | epoch 025:   1688 / 2938 loss=3.313, nll_loss=1.6, ppl=3.03, wps=22754, ups=1.85, wpb=12279.8, bsz=431.1, num_updates=72200, lr=8.15365e-06, gnorm=0.869, train_wall=54, wall=0
2021-03-15 04:01:18 | INFO | train_inner | epoch 025:   1788 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22898.5, ups=1.86, wpb=12303.3, bsz=436.3, num_updates=72300, lr=8.14801e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 04:02:11 | INFO | train_inner | epoch 025:   1888 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=23148.8, ups=1.87, wpb=12350, bsz=418.8, num_updates=72400, lr=8.14238e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 04:03:04 | INFO | train_inner | epoch 025:   1988 / 2938 loss=3.289, nll_loss=1.572, ppl=2.97, wps=23218.5, ups=1.88, wpb=12372.1, bsz=421.6, num_updates=72500, lr=8.13676e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 04:03:59 | INFO | train_inner | epoch 025:   2088 / 2938 loss=3.289, nll_loss=1.574, ppl=2.98, wps=22446.7, ups=1.81, wpb=12387.5, bsz=453.4, num_updates=72600, lr=8.13116e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 04:04:54 | INFO | train_inner | epoch 025:   2188 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22824.6, ups=1.84, wpb=12392.2, bsz=423.1, num_updates=72700, lr=8.12556e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 04:05:47 | INFO | train_inner | epoch 025:   2288 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=23188.2, ups=1.87, wpb=12426.8, bsz=427.5, num_updates=72800, lr=8.11998e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 04:06:40 | INFO | train_inner | epoch 025:   2388 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=23290.9, ups=1.88, wpb=12371.1, bsz=418.6, num_updates=72900, lr=8.11441e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 04:07:35 | INFO | train_inner | epoch 025:   2488 / 2938 loss=3.282, nll_loss=1.566, ppl=2.96, wps=22812.3, ups=1.83, wpb=12455.6, bsz=454.8, num_updates=73000, lr=8.10885e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 04:08:29 | INFO | train_inner | epoch 025:   2588 / 2938 loss=3.31, nll_loss=1.597, ppl=3.03, wps=22805.7, ups=1.86, wpb=12291.2, bsz=420.1, num_updates=73100, lr=8.1033e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 04:09:23 | INFO | train_inner | epoch 025:   2688 / 2938 loss=3.328, nll_loss=1.617, ppl=3.07, wps=22787.7, ups=1.86, wpb=12228.5, bsz=418.7, num_updates=73200, lr=8.09776e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 04:10:15 | INFO | train_inner | epoch 025:   2788 / 2938 loss=3.306, nll_loss=1.593, ppl=3.02, wps=23321.4, ups=1.9, wpb=12257.7, bsz=402, num_updates=73300, lr=8.09224e-06, gnorm=0.875, train_wall=52, wall=0
2021-03-15 04:11:10 | INFO | train_inner | epoch 025:   2888 / 2938 loss=3.305, nll_loss=1.592, ppl=3.02, wps=22338.2, ups=1.82, wpb=12241.6, bsz=453, num_updates=73400, lr=8.08672e-06, gnorm=0.872, train_wall=55, wall=0
2021-03-15 04:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 04:11:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:11:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:11:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:11:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:11:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:11:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:11:57 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.514 | nll_loss 8.475 | ppl 355.7 | bleu 15.69 | wps 3586.3 | wpb 6344.2 | bsz 166.4 | num_updates 73450 | best_bleu 15.9
2021-03-15 04:11:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 04:12:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 25 @ 73450 updates, score 15.69) (writing took 5.280132895335555 seconds)
2021-03-15 04:12:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-03-15 04:12:02 | INFO | train | epoch 025 | loss 3.302 | nll_loss 1.587 | ppl 3 | wps 22394.8 | ups 1.81 | wpb 12340.4 | bsz 426.5 | num_updates 73450 | lr 8.08397e-06 | gnorm 0.867 | train_wall 1574 | wall 0
2021-03-15 04:12:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:12:08 | INFO | fairseq.trainer | begin training epoch 26
2021-03-15 04:12:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:12:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:12:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:12:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:12:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:12:44 | INFO | train_inner | epoch 026:     50 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=13098.4, ups=1.07, wpb=12257.2, bsz=429.3, num_updates=73500, lr=8.08122e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:13:37 | INFO | train_inner | epoch 026:    150 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22944.8, ups=1.87, wpb=12250.6, bsz=437.4, num_updates=73600, lr=8.07573e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 04:14:31 | INFO | train_inner | epoch 026:    250 / 2938 loss=3.266, nll_loss=1.547, ppl=2.92, wps=22940.5, ups=1.85, wpb=12399.1, bsz=439.9, num_updates=73700, lr=8.07025e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 04:15:26 | INFO | train_inner | epoch 026:    350 / 2938 loss=3.277, nll_loss=1.559, ppl=2.95, wps=22674.3, ups=1.83, wpb=12411, bsz=461, num_updates=73800, lr=8.06478e-06, gnorm=0.854, train_wall=55, wall=0
2021-03-15 04:16:20 | INFO | train_inner | epoch 026:    450 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=22603.7, ups=1.83, wpb=12341.3, bsz=448.4, num_updates=73900, lr=8.05932e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 04:17:13 | INFO | train_inner | epoch 026:    550 / 2938 loss=3.304, nll_loss=1.589, ppl=3.01, wps=23569.9, ups=1.9, wpb=12402.5, bsz=408.1, num_updates=74000, lr=8.05387e-06, gnorm=0.867, train_wall=52, wall=0
2021-03-15 04:18:08 | INFO | train_inner | epoch 026:    650 / 2938 loss=3.304, nll_loss=1.591, ppl=3.01, wps=22371.2, ups=1.82, wpb=12303.9, bsz=451.2, num_updates=74100, lr=8.04844e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 04:19:02 | INFO | train_inner | epoch 026:    750 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=23007.3, ups=1.86, wpb=12360.6, bsz=419, num_updates=74200, lr=8.04301e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 04:19:55 | INFO | train_inner | epoch 026:    850 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23346.9, ups=1.88, wpb=12396.9, bsz=390.6, num_updates=74300, lr=8.0376e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 04:20:49 | INFO | train_inner | epoch 026:    950 / 2938 loss=3.297, nll_loss=1.581, ppl=2.99, wps=22994.5, ups=1.85, wpb=12410.1, bsz=433.9, num_updates=74400, lr=8.03219e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 04:21:42 | INFO | train_inner | epoch 026:   1050 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=23528.8, ups=1.89, wpb=12422.3, bsz=413, num_updates=74500, lr=8.0268e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 04:22:35 | INFO | train_inner | epoch 026:   1150 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=23030.1, ups=1.87, wpb=12287.8, bsz=412.6, num_updates=74600, lr=8.02142e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 04:23:28 | INFO | train_inner | epoch 026:   1250 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23305.7, ups=1.89, wpb=12312.6, bsz=420, num_updates=74700, lr=8.01605e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 04:24:21 | INFO | train_inner | epoch 026:   1350 / 2938 loss=3.324, nll_loss=1.613, ppl=3.06, wps=23071.7, ups=1.88, wpb=12295.9, bsz=409.8, num_updates=74800, lr=8.01069e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 04:25:15 | INFO | train_inner | epoch 026:   1450 / 2938 loss=3.28, nll_loss=1.562, ppl=2.95, wps=22801, ups=1.84, wpb=12400.7, bsz=453.4, num_updates=74900, lr=8.00534e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 04:26:09 | INFO | train_inner | epoch 026:   1550 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=22982.7, ups=1.86, wpb=12343.4, bsz=420.2, num_updates=75000, lr=8e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 04:27:02 | INFO | train_inner | epoch 026:   1650 / 2938 loss=3.316, nll_loss=1.603, ppl=3.04, wps=23260, ups=1.89, wpb=12308.5, bsz=415.4, num_updates=75100, lr=7.99467e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:27:57 | INFO | train_inner | epoch 026:   1750 / 2938 loss=3.321, nll_loss=1.609, ppl=3.05, wps=22428.5, ups=1.83, wpb=12257.6, bsz=426.9, num_updates=75200, lr=7.98935e-06, gnorm=0.879, train_wall=54, wall=0
2021-03-15 04:28:50 | INFO | train_inner | epoch 026:   1850 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=23045.8, ups=1.87, wpb=12339.9, bsz=414.6, num_updates=75300, lr=7.98405e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:29:44 | INFO | train_inner | epoch 026:   1950 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=22994.7, ups=1.87, wpb=12274.3, bsz=438.4, num_updates=75400, lr=7.97875e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 04:30:37 | INFO | train_inner | epoch 026:   2050 / 2938 loss=3.277, nll_loss=1.56, ppl=2.95, wps=23207.3, ups=1.87, wpb=12395.6, bsz=408.2, num_updates=75500, lr=7.97347e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 04:31:32 | INFO | train_inner | epoch 026:   2150 / 2938 loss=3.286, nll_loss=1.57, ppl=2.97, wps=22705.3, ups=1.84, wpb=12373, bsz=451.8, num_updates=75600, lr=7.96819e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 04:32:25 | INFO | train_inner | epoch 026:   2250 / 2938 loss=3.329, nll_loss=1.618, ppl=3.07, wps=23086.4, ups=1.87, wpb=12331.9, bsz=411.8, num_updates=75700, lr=7.96293e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 04:33:19 | INFO | train_inner | epoch 026:   2350 / 2938 loss=3.318, nll_loss=1.606, ppl=3.04, wps=22910.5, ups=1.85, wpb=12366.2, bsz=417.4, num_updates=75800, lr=7.95767e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 04:34:13 | INFO | train_inner | epoch 026:   2450 / 2938 loss=3.286, nll_loss=1.569, ppl=2.97, wps=22965.7, ups=1.86, wpb=12333.9, bsz=428.2, num_updates=75900, lr=7.95243e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 04:35:06 | INFO | train_inner | epoch 026:   2550 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=23044.5, ups=1.88, wpb=12232.8, bsz=394.2, num_updates=76000, lr=7.94719e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 04:36:00 | INFO | train_inner | epoch 026:   2650 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22948, ups=1.85, wpb=12375.2, bsz=428.9, num_updates=76100, lr=7.94197e-06, gnorm=0.887, train_wall=54, wall=0
2021-03-15 04:36:53 | INFO | train_inner | epoch 026:   2750 / 2938 loss=3.312, nll_loss=1.598, ppl=3.03, wps=23014.4, ups=1.88, wpb=12262.2, bsz=413, num_updates=76200, lr=7.93676e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 04:37:47 | INFO | train_inner | epoch 026:   2850 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=22781.6, ups=1.85, wpb=12343.1, bsz=449.1, num_updates=76300, lr=7.93156e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 04:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 04:38:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:38:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:38:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:38:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:38:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:38:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:38:52 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.526 | nll_loss 8.488 | ppl 358.94 | bleu 15.71 | wps 4320.8 | wpb 6344.2 | bsz 166.4 | num_updates 76388 | best_bleu 15.9
2021-03-15 04:38:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 04:38:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 26 @ 76388 updates, score 15.71) (writing took 5.307004840113223 seconds)
2021-03-15 04:38:58 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-03-15 04:38:58 | INFO | train | epoch 026 | loss 3.301 | nll_loss 1.587 | ppl 3 | wps 22447.6 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 76388 | lr 7.92699e-06 | gnorm 0.869 | train_wall 1572 | wall 0
2021-03-15 04:39:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:39:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:39:04 | INFO | fairseq.trainer | begin training epoch 27
2021-03-15 04:39:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:39:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:39:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 04:39:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 04:39:18 | INFO | train_inner | epoch 027:     12 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=13588.5, ups=1.1, wpb=12337, bsz=441.7, num_updates=76400, lr=7.92636e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:40:10 | INFO | train_inner | epoch 027:    112 / 2938 loss=3.292, nll_loss=1.575, ppl=2.98, wps=23744.1, ups=1.92, wpb=12366, bsz=420.6, num_updates=76500, lr=7.92118e-06, gnorm=0.865, train_wall=52, wall=0
2021-03-15 04:41:04 | INFO | train_inner | epoch 027:    212 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=22872, ups=1.85, wpb=12336.4, bsz=446.7, num_updates=76600, lr=7.91601e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 04:41:58 | INFO | train_inner | epoch 027:    312 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23122.9, ups=1.86, wpb=12420.7, bsz=426.5, num_updates=76700, lr=7.91085e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 04:42:51 | INFO | train_inner | epoch 027:    412 / 2938 loss=3.279, nll_loss=1.561, ppl=2.95, wps=23144.6, ups=1.87, wpb=12409, bsz=422.8, num_updates=76800, lr=7.90569e-06, gnorm=0.858, train_wall=53, wall=0
2021-03-15 04:43:45 | INFO | train_inner | epoch 027:    512 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=22694.7, ups=1.85, wpb=12255.1, bsz=445.6, num_updates=76900, lr=7.90055e-06, gnorm=0.879, train_wall=54, wall=0
2021-03-15 04:44:40 | INFO | train_inner | epoch 027:    612 / 2938 loss=3.279, nll_loss=1.562, ppl=2.95, wps=22906.6, ups=1.84, wpb=12422.6, bsz=431.2, num_updates=77000, lr=7.89542e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 04:45:34 | INFO | train_inner | epoch 027:    712 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=22875.4, ups=1.85, wpb=12361.4, bsz=419.5, num_updates=77100, lr=7.8903e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 04:46:27 | INFO | train_inner | epoch 027:    812 / 2938 loss=3.313, nll_loss=1.6, ppl=3.03, wps=22803.5, ups=1.86, wpb=12265.6, bsz=430.8, num_updates=77200, lr=7.88519e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 04:47:22 | INFO | train_inner | epoch 027:    912 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22804.3, ups=1.84, wpb=12371.6, bsz=425.6, num_updates=77300, lr=7.88008e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 04:48:16 | INFO | train_inner | epoch 027:   1012 / 2938 loss=3.314, nll_loss=1.602, ppl=3.03, wps=22785.7, ups=1.85, wpb=12325, bsz=442.7, num_updates=77400, lr=7.87499e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 04:49:10 | INFO | train_inner | epoch 027:   1112 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=22715.6, ups=1.83, wpb=12395.1, bsz=441.2, num_updates=77500, lr=7.86991e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 04:50:03 | INFO | train_inner | epoch 027:   1212 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23379.4, ups=1.89, wpb=12366.3, bsz=405, num_updates=77600, lr=7.86484e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 04:50:57 | INFO | train_inner | epoch 027:   1312 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22943.6, ups=1.87, wpb=12301.4, bsz=434.4, num_updates=77700, lr=7.85977e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 04:51:51 | INFO | train_inner | epoch 027:   1412 / 2938 loss=3.305, nll_loss=1.592, ppl=3.01, wps=22540.2, ups=1.83, wpb=12302.6, bsz=446, num_updates=77800, lr=7.85472e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 04:52:45 | INFO | train_inner | epoch 027:   1512 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=22943.1, ups=1.86, wpb=12330.2, bsz=423.8, num_updates=77900, lr=7.84968e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 04:53:38 | INFO | train_inner | epoch 027:   1612 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=22986.8, ups=1.88, wpb=12253, bsz=417.9, num_updates=78000, lr=7.84465e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 04:54:33 | INFO | train_inner | epoch 027:   1712 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=22785.7, ups=1.84, wpb=12352.7, bsz=448.6, num_updates=78100, lr=7.83962e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 04:55:26 | INFO | train_inner | epoch 027:   1812 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=23307.9, ups=1.87, wpb=12459.7, bsz=419.6, num_updates=78200, lr=7.83461e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 04:56:19 | INFO | train_inner | epoch 027:   1912 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=23032.7, ups=1.87, wpb=12289.2, bsz=410.1, num_updates=78300, lr=7.8296e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 04:57:14 | INFO | train_inner | epoch 027:   2012 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=22760.2, ups=1.84, wpb=12399.7, bsz=423.4, num_updates=78400, lr=7.82461e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 04:58:07 | INFO | train_inner | epoch 027:   2112 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23252.9, ups=1.89, wpb=12277.5, bsz=402.6, num_updates=78500, lr=7.81962e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 04:59:00 | INFO | train_inner | epoch 027:   2212 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23129.4, ups=1.88, wpb=12327.7, bsz=406.2, num_updates=78600, lr=7.81465e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 04:59:54 | INFO | train_inner | epoch 027:   2312 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=22748.2, ups=1.84, wpb=12369.7, bsz=441.7, num_updates=78700, lr=7.80968e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 05:00:49 | INFO | train_inner | epoch 027:   2412 / 2938 loss=3.293, nll_loss=1.578, ppl=2.98, wps=22622.1, ups=1.84, wpb=12294.8, bsz=446.7, num_updates=78800, lr=7.80472e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 05:01:41 | INFO | train_inner | epoch 027:   2512 / 2938 loss=3.323, nll_loss=1.612, ppl=3.06, wps=23439.7, ups=1.91, wpb=12301.2, bsz=396.3, num_updates=78900, lr=7.79978e-06, gnorm=0.876, train_wall=52, wall=0
2021-03-15 05:02:34 | INFO | train_inner | epoch 027:   2612 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23097.5, ups=1.88, wpb=12268.3, bsz=410, num_updates=79000, lr=7.79484e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 05:03:28 | INFO | train_inner | epoch 027:   2712 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22870.5, ups=1.86, wpb=12283, bsz=427.4, num_updates=79100, lr=7.78991e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 05:04:22 | INFO | train_inner | epoch 027:   2812 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23034.8, ups=1.86, wpb=12407.5, bsz=425.8, num_updates=79200, lr=7.78499e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 05:05:14 | INFO | train_inner | epoch 027:   2912 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=23493, ups=1.91, wpb=12316.8, bsz=402.9, num_updates=79300, lr=7.78008e-06, gnorm=0.874, train_wall=52, wall=0
2021-03-15 05:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 05:05:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:05:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:05:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:05:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:05:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:05:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:05:46 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.517 | nll_loss 8.476 | ppl 356.15 | bleu 15.76 | wps 4324.8 | wpb 6344.2 | bsz 166.4 | num_updates 79326 | best_bleu 15.9
2021-03-15 05:05:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 05:05:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 27 @ 79326 updates, score 15.76) (writing took 5.27322678361088 seconds)
2021-03-15 05:05:52 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-03-15 05:05:52 | INFO | train | epoch 027 | loss 3.3 | nll_loss 1.586 | ppl 3 | wps 22462.3 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 79326 | lr 7.7788e-06 | gnorm 0.87 | train_wall 1571 | wall 0
2021-03-15 05:05:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:05:58 | INFO | fairseq.trainer | begin training epoch 28
2021-03-15 05:05:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:05:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:05:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:06:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:06:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:06:44 | INFO | train_inner | epoch 028:     74 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=13748.7, ups=1.12, wpb=12307.1, bsz=424.8, num_updates=79400, lr=7.77518e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 05:07:37 | INFO | train_inner | epoch 028:    174 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23438.7, ups=1.9, wpb=12354.2, bsz=411.4, num_updates=79500, lr=7.77029e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 05:08:31 | INFO | train_inner | epoch 028:    274 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=22487.1, ups=1.83, wpb=12281.9, bsz=431.6, num_updates=79600, lr=7.7654e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 05:09:25 | INFO | train_inner | epoch 028:    374 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23053.8, ups=1.87, wpb=12311.2, bsz=409.1, num_updates=79700, lr=7.76053e-06, gnorm=0.887, train_wall=53, wall=0
2021-03-15 05:10:19 | INFO | train_inner | epoch 028:    474 / 2938 loss=3.28, nll_loss=1.563, ppl=2.95, wps=23111.9, ups=1.85, wpb=12468.5, bsz=439.5, num_updates=79800, lr=7.75567e-06, gnorm=0.858, train_wall=54, wall=0
2021-03-15 05:11:12 | INFO | train_inner | epoch 028:    574 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23209.3, ups=1.88, wpb=12354.4, bsz=422.8, num_updates=79900, lr=7.75081e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 05:12:06 | INFO | train_inner | epoch 028:    674 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22825.1, ups=1.85, wpb=12313, bsz=437.7, num_updates=80000, lr=7.74597e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 05:13:00 | INFO | train_inner | epoch 028:    774 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=22773.6, ups=1.85, wpb=12316.8, bsz=449.8, num_updates=80100, lr=7.74113e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 05:13:54 | INFO | train_inner | epoch 028:    874 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=22850.9, ups=1.84, wpb=12416.9, bsz=441.8, num_updates=80200, lr=7.7363e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 05:14:48 | INFO | train_inner | epoch 028:    974 / 2938 loss=3.287, nll_loss=1.57, ppl=2.97, wps=23119.7, ups=1.87, wpb=12367.5, bsz=423.2, num_updates=80300, lr=7.73148e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 05:15:41 | INFO | train_inner | epoch 028:   1074 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22844, ups=1.87, wpb=12243.3, bsz=414.9, num_updates=80400, lr=7.72667e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 05:16:34 | INFO | train_inner | epoch 028:   1174 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23451.9, ups=1.88, wpb=12472.6, bsz=416.6, num_updates=80500, lr=7.72187e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 05:17:29 | INFO | train_inner | epoch 028:   1274 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=22329.8, ups=1.82, wpb=12255.7, bsz=442, num_updates=80600, lr=7.71708e-06, gnorm=0.875, train_wall=55, wall=0
2021-03-15 05:18:22 | INFO | train_inner | epoch 028:   1374 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=23321.4, ups=1.89, wpb=12325.6, bsz=411, num_updates=80700, lr=7.7123e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 05:19:16 | INFO | train_inner | epoch 028:   1474 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23068.8, ups=1.86, wpb=12426.1, bsz=453.9, num_updates=80800, lr=7.70752e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 05:20:09 | INFO | train_inner | epoch 028:   1574 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23370.6, ups=1.89, wpb=12395.4, bsz=402.6, num_updates=80900, lr=7.70276e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 05:21:03 | INFO | train_inner | epoch 028:   1674 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=22964.8, ups=1.85, wpb=12446.6, bsz=437.8, num_updates=81000, lr=7.698e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 05:21:57 | INFO | train_inner | epoch 028:   1774 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23088.9, ups=1.87, wpb=12341, bsz=421.1, num_updates=81100, lr=7.69326e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 05:22:50 | INFO | train_inner | epoch 028:   1874 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23194.5, ups=1.88, wpb=12356.3, bsz=420.2, num_updates=81200, lr=7.68852e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 05:23:44 | INFO | train_inner | epoch 028:   1974 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22901.7, ups=1.86, wpb=12308.2, bsz=405.8, num_updates=81300, lr=7.68379e-06, gnorm=0.869, train_wall=54, wall=0
2021-03-15 05:24:37 | INFO | train_inner | epoch 028:   2074 / 2938 loss=3.327, nll_loss=1.616, ppl=3.07, wps=23058.3, ups=1.89, wpb=12226.6, bsz=404.2, num_updates=81400, lr=7.67907e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 05:25:30 | INFO | train_inner | epoch 028:   2174 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23065.2, ups=1.86, wpb=12376.8, bsz=432.1, num_updates=81500, lr=7.67435e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 05:26:24 | INFO | train_inner | epoch 028:   2274 / 2938 loss=3.312, nll_loss=1.6, ppl=3.03, wps=22762.4, ups=1.86, wpb=12250.7, bsz=424.6, num_updates=81600, lr=7.66965e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 05:27:19 | INFO | train_inner | epoch 028:   2374 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22447.5, ups=1.83, wpb=12294.7, bsz=459.7, num_updates=81700, lr=7.66495e-06, gnorm=0.871, train_wall=55, wall=0
2021-03-15 05:28:12 | INFO | train_inner | epoch 028:   2474 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23112.6, ups=1.87, wpb=12336.9, bsz=412.7, num_updates=81800, lr=7.66027e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 05:29:06 | INFO | train_inner | epoch 028:   2574 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23073.8, ups=1.87, wpb=12327.6, bsz=431.5, num_updates=81900, lr=7.65559e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 05:29:59 | INFO | train_inner | epoch 028:   2674 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=23155.3, ups=1.86, wpb=12420.3, bsz=412.9, num_updates=82000, lr=7.65092e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 05:30:55 | INFO | train_inner | epoch 028:   2774 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=22259.9, ups=1.81, wpb=12314.7, bsz=448.6, num_updates=82100, lr=7.64626e-06, gnorm=0.875, train_wall=55, wall=0
2021-03-15 05:31:49 | INFO | train_inner | epoch 028:   2874 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=22698.6, ups=1.86, wpb=12222.1, bsz=425, num_updates=82200, lr=7.64161e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 05:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 05:32:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:32:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:32:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:32:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:32:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:32:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:32:43 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.525 | nll_loss 8.485 | ppl 358.26 | bleu 15.73 | wps 3946.6 | wpb 6344.2 | bsz 166.4 | num_updates 82264 | best_bleu 15.9
2021-03-15 05:32:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 05:32:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 28 @ 82264 updates, score 15.73) (writing took 5.297759012319148 seconds)
2021-03-15 05:32:48 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-03-15 05:32:48 | INFO | train | epoch 028 | loss 3.3 | nll_loss 1.585 | ppl 3 | wps 22433.9 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 82264 | lr 7.63863e-06 | gnorm 0.871 | train_wall 1572 | wall 0
2021-03-15 05:32:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:32:54 | INFO | fairseq.trainer | begin training epoch 29
2021-03-15 05:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:32:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:33:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:33:20 | INFO | train_inner | epoch 029:     36 / 2938 loss=3.275, nll_loss=1.557, ppl=2.94, wps=13561.6, ups=1.09, wpb=12463.5, bsz=444.1, num_updates=82300, lr=7.63696e-06, gnorm=0.854, train_wall=53, wall=0
2021-03-15 05:34:14 | INFO | train_inner | epoch 029:    136 / 2938 loss=3.268, nll_loss=1.549, ppl=2.93, wps=23165.7, ups=1.87, wpb=12370.3, bsz=444.2, num_updates=82400, lr=7.63233e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 05:35:07 | INFO | train_inner | epoch 029:    236 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=22947.6, ups=1.87, wpb=12290.3, bsz=431, num_updates=82500, lr=7.6277e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 05:36:01 | INFO | train_inner | epoch 029:    336 / 2938 loss=3.27, nll_loss=1.551, ppl=2.93, wps=23242.1, ups=1.86, wpb=12491, bsz=430.2, num_updates=82600, lr=7.62308e-06, gnorm=0.855, train_wall=54, wall=0
2021-03-15 05:36:54 | INFO | train_inner | epoch 029:    436 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23253.7, ups=1.88, wpb=12387.1, bsz=403.4, num_updates=82700, lr=7.61847e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 05:37:48 | INFO | train_inner | epoch 029:    536 / 2938 loss=3.281, nll_loss=1.565, ppl=2.96, wps=23173.8, ups=1.86, wpb=12448.7, bsz=431.2, num_updates=82800, lr=7.61387e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 05:38:42 | INFO | train_inner | epoch 029:    636 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=22860.4, ups=1.86, wpb=12282.3, bsz=422.6, num_updates=82900, lr=7.60928e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 05:39:35 | INFO | train_inner | epoch 029:    736 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23068.4, ups=1.87, wpb=12329.7, bsz=423.6, num_updates=83000, lr=7.60469e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 05:40:29 | INFO | train_inner | epoch 029:    836 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=22955.7, ups=1.87, wpb=12266, bsz=430.2, num_updates=83100, lr=7.60011e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 05:41:22 | INFO | train_inner | epoch 029:    936 / 2938 loss=3.312, nll_loss=1.599, ppl=3.03, wps=23123.7, ups=1.88, wpb=12285, bsz=409.8, num_updates=83200, lr=7.59555e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 05:42:15 | INFO | train_inner | epoch 029:   1036 / 2938 loss=3.298, nll_loss=1.582, ppl=2.99, wps=23526.7, ups=1.89, wpb=12419.2, bsz=401.6, num_updates=83300, lr=7.59098e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 05:43:09 | INFO | train_inner | epoch 029:   1136 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22623.9, ups=1.84, wpb=12306.6, bsz=447.5, num_updates=83400, lr=7.58643e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 05:44:02 | INFO | train_inner | epoch 029:   1236 / 2938 loss=3.298, nll_loss=1.583, ppl=2.99, wps=23348.2, ups=1.89, wpb=12372.7, bsz=407.3, num_updates=83500, lr=7.58189e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 05:44:55 | INFO | train_inner | epoch 029:   1336 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23028.5, ups=1.88, wpb=12223.1, bsz=423.7, num_updates=83600, lr=7.57735e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 05:45:48 | INFO | train_inner | epoch 029:   1436 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23091.9, ups=1.88, wpb=12303.5, bsz=422.2, num_updates=83700, lr=7.57282e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 05:46:43 | INFO | train_inner | epoch 029:   1536 / 2938 loss=3.294, nll_loss=1.578, ppl=2.98, wps=22787, ups=1.84, wpb=12386.1, bsz=420.7, num_updates=83800, lr=7.5683e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 05:47:37 | INFO | train_inner | epoch 029:   1636 / 2938 loss=3.304, nll_loss=1.591, ppl=3.01, wps=22743.7, ups=1.84, wpb=12335.4, bsz=439.8, num_updates=83900, lr=7.56379e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 05:48:31 | INFO | train_inner | epoch 029:   1736 / 2938 loss=3.286, nll_loss=1.57, ppl=2.97, wps=23059.4, ups=1.87, wpb=12336.2, bsz=437.9, num_updates=84000, lr=7.55929e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 05:49:24 | INFO | train_inner | epoch 029:   1836 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23180.7, ups=1.87, wpb=12409.8, bsz=411.2, num_updates=84100, lr=7.55479e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 05:50:17 | INFO | train_inner | epoch 029:   1936 / 2938 loss=3.337, nll_loss=1.627, ppl=3.09, wps=23076.1, ups=1.9, wpb=12168.5, bsz=401.7, num_updates=84200, lr=7.55031e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 05:51:10 | INFO | train_inner | epoch 029:   2036 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=23182.2, ups=1.87, wpb=12405.6, bsz=417.8, num_updates=84300, lr=7.54583e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 05:52:05 | INFO | train_inner | epoch 029:   2136 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=22516.9, ups=1.83, wpb=12303.8, bsz=442.8, num_updates=84400, lr=7.54136e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 05:53:00 | INFO | train_inner | epoch 029:   2236 / 2938 loss=3.275, nll_loss=1.557, ppl=2.94, wps=22873.5, ups=1.83, wpb=12477.7, bsz=439, num_updates=84500, lr=7.53689e-06, gnorm=0.86, train_wall=54, wall=0
2021-03-15 05:53:54 | INFO | train_inner | epoch 029:   2336 / 2938 loss=3.31, nll_loss=1.597, ppl=3.03, wps=22797.4, ups=1.85, wpb=12333.7, bsz=426.7, num_updates=84600, lr=7.53244e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 05:54:47 | INFO | train_inner | epoch 029:   2436 / 2938 loss=3.318, nll_loss=1.606, ppl=3.05, wps=22851.4, ups=1.87, wpb=12225.2, bsz=438.5, num_updates=84700, lr=7.52799e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 05:55:42 | INFO | train_inner | epoch 029:   2536 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=22768.2, ups=1.83, wpb=12408.2, bsz=422.2, num_updates=84800, lr=7.52355e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 05:56:35 | INFO | train_inner | epoch 029:   2636 / 2938 loss=3.271, nll_loss=1.553, ppl=2.94, wps=23124.4, ups=1.86, wpb=12413.5, bsz=439, num_updates=84900, lr=7.51912e-06, gnorm=0.859, train_wall=53, wall=0
2021-03-15 05:57:28 | INFO | train_inner | epoch 029:   2736 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23516.8, ups=1.91, wpb=12334.8, bsz=406.4, num_updates=85000, lr=7.51469e-06, gnorm=0.88, train_wall=52, wall=0
2021-03-15 05:58:21 | INFO | train_inner | epoch 029:   2836 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=22920.4, ups=1.87, wpb=12277.4, bsz=437.2, num_updates=85100, lr=7.51027e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 05:59:16 | INFO | train_inner | epoch 029:   2936 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=22443, ups=1.83, wpb=12237.8, bsz=462.2, num_updates=85200, lr=7.50587e-06, gnorm=0.891, train_wall=54, wall=0
2021-03-15 05:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 05:59:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:59:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:59:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:59:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.519 | nll_loss 8.479 | ppl 356.85 | bleu 15.69 | wps 3981.6 | wpb 6344.2 | bsz 166.4 | num_updates 85202 | best_bleu 15.9
2021-03-15 05:59:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 05:59:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 29 @ 85202 updates, score 15.69) (writing took 5.267988516017795 seconds)
2021-03-15 05:59:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-03-15 05:59:41 | INFO | train | epoch 029 | loss 3.299 | nll_loss 1.585 | ppl 3 | wps 22473.8 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 85202 | lr 7.50578e-06 | gnorm 0.873 | train_wall 1570 | wall 0
2021-03-15 05:59:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:47 | INFO | fairseq.trainer | begin training epoch 30
2021-03-15 05:59:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:59:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 05:59:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 05:59:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:00:47 | INFO | train_inner | epoch 030:     98 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=13531, ups=1.1, wpb=12316.5, bsz=440.5, num_updates=85300, lr=7.50147e-06, gnorm=0.86, train_wall=53, wall=0
2021-03-15 06:01:41 | INFO | train_inner | epoch 030:    198 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=22574.3, ups=1.84, wpb=12263.1, bsz=466.4, num_updates=85400, lr=7.49707e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 06:02:34 | INFO | train_inner | epoch 030:    298 / 2938 loss=3.299, nll_loss=1.583, ppl=3, wps=23449.5, ups=1.91, wpb=12302.5, bsz=406.3, num_updates=85500, lr=7.49269e-06, gnorm=0.874, train_wall=52, wall=0
2021-03-15 06:03:29 | INFO | train_inner | epoch 030:    398 / 2938 loss=3.26, nll_loss=1.541, ppl=2.91, wps=22634.6, ups=1.82, wpb=12433.6, bsz=476, num_updates=85600, lr=7.48831e-06, gnorm=0.855, train_wall=55, wall=0
2021-03-15 06:04:21 | INFO | train_inner | epoch 030:    498 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23728.8, ups=1.92, wpb=12382.1, bsz=401.2, num_updates=85700, lr=7.48394e-06, gnorm=0.867, train_wall=52, wall=0
2021-03-15 06:05:15 | INFO | train_inner | epoch 030:    598 / 2938 loss=3.282, nll_loss=1.565, ppl=2.96, wps=23040.4, ups=1.86, wpb=12390, bsz=418.6, num_updates=85800, lr=7.47958e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 06:06:08 | INFO | train_inner | epoch 030:    698 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=22872.8, ups=1.86, wpb=12265.8, bsz=435.3, num_updates=85900, lr=7.47522e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 06:07:02 | INFO | train_inner | epoch 030:    798 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22580.3, ups=1.84, wpb=12254.8, bsz=456.2, num_updates=86000, lr=7.47087e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 06:07:56 | INFO | train_inner | epoch 030:    898 / 2938 loss=3.289, nll_loss=1.573, ppl=2.97, wps=22990, ups=1.86, wpb=12353.9, bsz=428.2, num_updates=86100, lr=7.46653e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 06:08:49 | INFO | train_inner | epoch 030:    998 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23554, ups=1.9, wpb=12405.7, bsz=396.2, num_updates=86200, lr=7.4622e-06, gnorm=0.872, train_wall=52, wall=0
2021-03-15 06:09:43 | INFO | train_inner | epoch 030:   1098 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=22927.8, ups=1.86, wpb=12325.1, bsz=420.6, num_updates=86300, lr=7.45788e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 06:10:36 | INFO | train_inner | epoch 030:   1198 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23193.6, ups=1.89, wpb=12289.9, bsz=413.6, num_updates=86400, lr=7.45356e-06, gnorm=0.893, train_wall=53, wall=0
2021-03-15 06:11:29 | INFO | train_inner | epoch 030:   1298 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=23067.8, ups=1.86, wpb=12408.3, bsz=443.4, num_updates=86500, lr=7.44925e-06, gnorm=0.862, train_wall=54, wall=0
2021-03-15 06:12:23 | INFO | train_inner | epoch 030:   1398 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=22705.8, ups=1.85, wpb=12281.4, bsz=431.7, num_updates=86600, lr=7.44495e-06, gnorm=0.884, train_wall=54, wall=0
2021-03-15 06:13:16 | INFO | train_inner | epoch 030:   1498 / 2938 loss=3.304, nll_loss=1.589, ppl=3.01, wps=23497.5, ups=1.9, wpb=12389.2, bsz=392, num_updates=86700, lr=7.44065e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 06:14:11 | INFO | train_inner | epoch 030:   1598 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=22749.6, ups=1.83, wpb=12427.2, bsz=442.6, num_updates=86800, lr=7.43637e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 06:15:04 | INFO | train_inner | epoch 030:   1698 / 2938 loss=3.319, nll_loss=1.606, ppl=3.04, wps=23350.1, ups=1.9, wpb=12320.7, bsz=405.4, num_updates=86900, lr=7.43209e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 06:15:57 | INFO | train_inner | epoch 030:   1798 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23098.6, ups=1.87, wpb=12376.9, bsz=417.5, num_updates=87000, lr=7.42781e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 06:16:51 | INFO | train_inner | epoch 030:   1898 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=22757.8, ups=1.84, wpb=12356.6, bsz=429.8, num_updates=87100, lr=7.42355e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 06:17:46 | INFO | train_inner | epoch 030:   1998 / 2938 loss=3.314, nll_loss=1.602, ppl=3.03, wps=22796.5, ups=1.85, wpb=12340.1, bsz=441.8, num_updates=87200, lr=7.41929e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 06:18:39 | INFO | train_inner | epoch 030:   2098 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23049.3, ups=1.87, wpb=12326.1, bsz=415.3, num_updates=87300, lr=7.41504e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 06:19:33 | INFO | train_inner | epoch 030:   2198 / 2938 loss=3.287, nll_loss=1.572, ppl=2.97, wps=23059.1, ups=1.87, wpb=12335.7, bsz=422.3, num_updates=87400, lr=7.4108e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 06:20:27 | INFO | train_inner | epoch 030:   2298 / 2938 loss=3.27, nll_loss=1.552, ppl=2.93, wps=22788.1, ups=1.84, wpb=12363.8, bsz=412.5, num_updates=87500, lr=7.40656e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 06:21:20 | INFO | train_inner | epoch 030:   2398 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23239.4, ups=1.87, wpb=12425.3, bsz=419.3, num_updates=87600, lr=7.40233e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 06:22:14 | INFO | train_inner | epoch 030:   2498 / 2938 loss=3.329, nll_loss=1.619, ppl=3.07, wps=22673.9, ups=1.86, wpb=12203.6, bsz=434.1, num_updates=87700, lr=7.39811e-06, gnorm=0.888, train_wall=54, wall=0
2021-03-15 06:23:08 | INFO | train_inner | epoch 030:   2598 / 2938 loss=3.322, nll_loss=1.611, ppl=3.05, wps=23104, ups=1.87, wpb=12345.9, bsz=416.3, num_updates=87800, lr=7.3939e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 06:24:01 | INFO | train_inner | epoch 030:   2698 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23067.4, ups=1.87, wpb=12330.5, bsz=431, num_updates=87900, lr=7.38969e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 06:24:55 | INFO | train_inner | epoch 030:   2798 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22958.1, ups=1.87, wpb=12290.1, bsz=425.8, num_updates=88000, lr=7.38549e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 06:25:47 | INFO | train_inner | epoch 030:   2898 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23686.6, ups=1.91, wpb=12411.7, bsz=409.9, num_updates=88100, lr=7.3813e-06, gnorm=0.87, train_wall=52, wall=0
2021-03-15 06:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 06:26:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:26:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:26:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:26:28 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.525 | nll_loss 8.485 | ppl 358.35 | bleu 15.71 | wps 3966.8 | wpb 6344.2 | bsz 166.4 | num_updates 88140 | best_bleu 15.9
2021-03-15 06:26:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 06:26:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 30 @ 88140 updates, score 15.71) (writing took 5.165600708685815 seconds)
2021-03-15 06:26:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-03-15 06:26:33 | INFO | train | epoch 030 | loss 3.299 | nll_loss 1.584 | ppl 3 | wps 22495.8 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 88140 | lr 7.37962e-06 | gnorm 0.873 | train_wall 1568 | wall 0
2021-03-15 06:26:39 | INFO | fairseq.trainer | begin training epoch 31
2021-03-15 06:26:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:26:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:26:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:26:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:27:18 | INFO | train_inner | epoch 031:     60 / 2938 loss=3.33, nll_loss=1.619, ppl=3.07, wps=13413.8, ups=1.09, wpb=12252.3, bsz=443.8, num_updates=88200, lr=7.37711e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 06:28:12 | INFO | train_inner | epoch 031:    160 / 2938 loss=3.289, nll_loss=1.572, ppl=2.97, wps=22916.2, ups=1.85, wpb=12380.9, bsz=432.2, num_updates=88300, lr=7.37293e-06, gnorm=0.868, train_wall=54, wall=0
2021-03-15 06:29:06 | INFO | train_inner | epoch 031:    260 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23044, ups=1.87, wpb=12335.6, bsz=436.8, num_updates=88400, lr=7.36876e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 06:29:59 | INFO | train_inner | epoch 031:    360 / 2938 loss=3.287, nll_loss=1.57, ppl=2.97, wps=23223.8, ups=1.87, wpb=12421, bsz=397.7, num_updates=88500, lr=7.3646e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 06:30:52 | INFO | train_inner | epoch 031:    460 / 2938 loss=3.273, nll_loss=1.555, ppl=2.94, wps=23394.7, ups=1.89, wpb=12380.6, bsz=400.3, num_updates=88600, lr=7.36044e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 06:31:47 | INFO | train_inner | epoch 031:    560 / 2938 loss=3.269, nll_loss=1.55, ppl=2.93, wps=22860.4, ups=1.83, wpb=12461.5, bsz=431.4, num_updates=88700, lr=7.35629e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 06:32:40 | INFO | train_inner | epoch 031:    660 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23500.2, ups=1.89, wpb=12423.3, bsz=407.4, num_updates=88800, lr=7.35215e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 06:33:33 | INFO | train_inner | epoch 031:    760 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23515.1, ups=1.89, wpb=12430.7, bsz=396.2, num_updates=88900, lr=7.34801e-06, gnorm=0.865, train_wall=53, wall=0
2021-03-15 06:34:26 | INFO | train_inner | epoch 031:    860 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=23183.8, ups=1.88, wpb=12303.3, bsz=423.7, num_updates=89000, lr=7.34388e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 06:35:19 | INFO | train_inner | epoch 031:    960 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=23083.7, ups=1.89, wpb=12234.4, bsz=410.8, num_updates=89100, lr=7.33976e-06, gnorm=0.896, train_wall=53, wall=0
2021-03-15 06:36:13 | INFO | train_inner | epoch 031:   1060 / 2938 loss=3.275, nll_loss=1.558, ppl=2.94, wps=22817.6, ups=1.83, wpb=12445.8, bsz=447.3, num_updates=89200, lr=7.33564e-06, gnorm=0.857, train_wall=54, wall=0
2021-03-15 06:37:07 | INFO | train_inner | epoch 031:   1160 / 2938 loss=3.279, nll_loss=1.561, ppl=2.95, wps=22991.2, ups=1.85, wpb=12401.2, bsz=424.7, num_updates=89300, lr=7.33153e-06, gnorm=0.866, train_wall=54, wall=0
2021-03-15 06:38:01 | INFO | train_inner | epoch 031:   1260 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22911.1, ups=1.85, wpb=12375.9, bsz=430.1, num_updates=89400, lr=7.32743e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 06:38:55 | INFO | train_inner | epoch 031:   1360 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=23168.4, ups=1.87, wpb=12408.3, bsz=422.8, num_updates=89500, lr=7.32334e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 06:39:48 | INFO | train_inner | epoch 031:   1460 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23070.6, ups=1.87, wpb=12369.2, bsz=442.4, num_updates=89600, lr=7.31925e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 06:40:44 | INFO | train_inner | epoch 031:   1560 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22257.6, ups=1.81, wpb=12322.7, bsz=452.2, num_updates=89700, lr=7.31517e-06, gnorm=0.88, train_wall=55, wall=0
2021-03-15 06:41:38 | INFO | train_inner | epoch 031:   1660 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22154.7, ups=1.82, wpb=12143.8, bsz=466.6, num_updates=89800, lr=7.3111e-06, gnorm=0.886, train_wall=55, wall=0
2021-03-15 06:42:32 | INFO | train_inner | epoch 031:   1760 / 2938 loss=3.27, nll_loss=1.552, ppl=2.93, wps=23246.9, ups=1.87, wpb=12402.4, bsz=435.2, num_updates=89900, lr=7.30703e-06, gnorm=0.861, train_wall=53, wall=0
2021-03-15 06:43:25 | INFO | train_inner | epoch 031:   1860 / 2938 loss=3.324, nll_loss=1.612, ppl=3.06, wps=23282.4, ups=1.9, wpb=12279.5, bsz=420.9, num_updates=90000, lr=7.30297e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 06:44:18 | INFO | train_inner | epoch 031:   1960 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23242.2, ups=1.88, wpb=12340.9, bsz=425.8, num_updates=90100, lr=7.29891e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 06:45:11 | INFO | train_inner | epoch 031:   2060 / 2938 loss=3.319, nll_loss=1.607, ppl=3.05, wps=23330.7, ups=1.89, wpb=12354.2, bsz=410.2, num_updates=90200, lr=7.29487e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 06:46:04 | INFO | train_inner | epoch 031:   2160 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=22898.9, ups=1.88, wpb=12171.1, bsz=406.4, num_updates=90300, lr=7.29083e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 06:46:57 | INFO | train_inner | epoch 031:   2260 / 2938 loss=3.306, nll_loss=1.593, ppl=3.02, wps=22849, ups=1.86, wpb=12275.5, bsz=433.5, num_updates=90400, lr=7.28679e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 06:47:50 | INFO | train_inner | epoch 031:   2360 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23484.3, ups=1.89, wpb=12396, bsz=414.8, num_updates=90500, lr=7.28277e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 06:48:43 | INFO | train_inner | epoch 031:   2460 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23374.5, ups=1.89, wpb=12370.9, bsz=422.7, num_updates=90600, lr=7.27875e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 06:49:37 | INFO | train_inner | epoch 031:   2560 / 2938 loss=3.319, nll_loss=1.608, ppl=3.05, wps=22568.6, ups=1.85, wpb=12181.2, bsz=439.4, num_updates=90700, lr=7.27473e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 06:50:32 | INFO | train_inner | epoch 031:   2660 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=22527.3, ups=1.82, wpb=12373.2, bsz=465.9, num_updates=90800, lr=7.27072e-06, gnorm=0.869, train_wall=55, wall=0
2021-03-15 06:51:26 | INFO | train_inner | epoch 031:   2760 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22771.5, ups=1.85, wpb=12296.1, bsz=423.3, num_updates=90900, lr=7.26672e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 06:52:19 | INFO | train_inner | epoch 031:   2860 / 2938 loss=3.333, nll_loss=1.622, ppl=3.08, wps=22963.6, ups=1.87, wpb=12248.6, bsz=420.3, num_updates=91000, lr=7.26273e-06, gnorm=0.888, train_wall=53, wall=0
2021-03-15 06:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 06:53:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:20 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.522 | nll_loss 8.483 | ppl 357.69 | bleu 15.74 | wps 3965 | wpb 6344.2 | bsz 166.4 | num_updates 91078 | best_bleu 15.9
2021-03-15 06:53:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 06:53:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 31 @ 91078 updates, score 15.74) (writing took 5.259896581992507 seconds)
2021-03-15 06:53:26 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-03-15 06:53:26 | INFO | train | epoch 031 | loss 3.298 | nll_loss 1.583 | ppl 3 | wps 22481.3 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 91078 | lr 7.25962e-06 | gnorm 0.874 | train_wall 1569 | wall 0
2021-03-15 06:53:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:31 | INFO | fairseq.trainer | begin training epoch 32
2021-03-15 06:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 06:53:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 06:53:51 | INFO | train_inner | epoch 032:     22 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=13601.7, ups=1.1, wpb=12397.4, bsz=422.8, num_updates=91100, lr=7.25874e-06, gnorm=0.862, train_wall=53, wall=0
2021-03-15 06:54:43 | INFO | train_inner | epoch 032:    122 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=23384.7, ups=1.9, wpb=12317.5, bsz=410.2, num_updates=91200, lr=7.25476e-06, gnorm=0.87, train_wall=52, wall=0
2021-03-15 06:55:36 | INFO | train_inner | epoch 032:    222 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23183.9, ups=1.88, wpb=12343.9, bsz=431.5, num_updates=91300, lr=7.25079e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 06:56:31 | INFO | train_inner | epoch 032:    322 / 2938 loss=3.269, nll_loss=1.551, ppl=2.93, wps=22740.6, ups=1.84, wpb=12349.6, bsz=442.7, num_updates=91400, lr=7.24682e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 06:57:26 | INFO | train_inner | epoch 032:    422 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22295.8, ups=1.81, wpb=12339.5, bsz=458.5, num_updates=91500, lr=7.24286e-06, gnorm=0.874, train_wall=55, wall=0
2021-03-15 06:58:19 | INFO | train_inner | epoch 032:    522 / 2938 loss=3.314, nll_loss=1.602, ppl=3.03, wps=23242.6, ups=1.89, wpb=12266.5, bsz=404.6, num_updates=91600, lr=7.23891e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 06:59:11 | INFO | train_inner | epoch 032:    622 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23307.5, ups=1.9, wpb=12259.9, bsz=406.7, num_updates=91700, lr=7.23496e-06, gnorm=0.877, train_wall=52, wall=0
2021-03-15 07:00:05 | INFO | train_inner | epoch 032:    722 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=22989.9, ups=1.88, wpb=12260.8, bsz=424.8, num_updates=91800, lr=7.23102e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 07:00:58 | INFO | train_inner | epoch 032:    822 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23154.4, ups=1.87, wpb=12388.6, bsz=411.4, num_updates=91900, lr=7.22708e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 07:01:51 | INFO | train_inner | epoch 032:    922 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=23391.5, ups=1.88, wpb=12420.7, bsz=425.3, num_updates=92000, lr=7.22315e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 07:02:45 | INFO | train_inner | epoch 032:   1022 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=22988.5, ups=1.86, wpb=12347, bsz=434.6, num_updates=92100, lr=7.21923e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 07:03:38 | INFO | train_inner | epoch 032:   1122 / 2938 loss=3.286, nll_loss=1.569, ppl=2.97, wps=23374, ups=1.88, wpb=12441.7, bsz=415.2, num_updates=92200, lr=7.21531e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 07:04:32 | INFO | train_inner | epoch 032:   1222 / 2938 loss=3.293, nll_loss=1.578, ppl=2.98, wps=23079.9, ups=1.88, wpb=12305.9, bsz=417.8, num_updates=92300, lr=7.2114e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 07:05:25 | INFO | train_inner | epoch 032:   1322 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23051.4, ups=1.87, wpb=12313.1, bsz=413.3, num_updates=92400, lr=7.2075e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 07:06:19 | INFO | train_inner | epoch 032:   1422 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22835.6, ups=1.85, wpb=12345.5, bsz=431.7, num_updates=92500, lr=7.2036e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 07:07:13 | INFO | train_inner | epoch 032:   1522 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=22879.2, ups=1.87, wpb=12262.8, bsz=420, num_updates=92600, lr=7.19971e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 07:08:07 | INFO | train_inner | epoch 032:   1622 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=22809.1, ups=1.85, wpb=12361.7, bsz=426.4, num_updates=92700, lr=7.19583e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 07:09:02 | INFO | train_inner | epoch 032:   1722 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=22586.1, ups=1.82, wpb=12402.7, bsz=470.8, num_updates=92800, lr=7.19195e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 07:09:56 | INFO | train_inner | epoch 032:   1822 / 2938 loss=3.332, nll_loss=1.621, ppl=3.08, wps=22764.2, ups=1.86, wpb=12215, bsz=413.4, num_updates=92900, lr=7.18808e-06, gnorm=0.89, train_wall=53, wall=0
2021-03-15 07:10:49 | INFO | train_inner | epoch 032:   1922 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23408.8, ups=1.88, wpb=12447.8, bsz=402.9, num_updates=93000, lr=7.18421e-06, gnorm=0.866, train_wall=53, wall=0
2021-03-15 07:11:43 | INFO | train_inner | epoch 032:   2022 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=22769.5, ups=1.84, wpb=12390.4, bsz=447.2, num_updates=93100, lr=7.18035e-06, gnorm=0.887, train_wall=54, wall=0
2021-03-15 07:12:37 | INFO | train_inner | epoch 032:   2122 / 2938 loss=3.331, nll_loss=1.621, ppl=3.08, wps=22656.2, ups=1.85, wpb=12217.3, bsz=430.1, num_updates=93200, lr=7.1765e-06, gnorm=0.887, train_wall=54, wall=0
2021-03-15 07:13:30 | INFO | train_inner | epoch 032:   2222 / 2938 loss=3.315, nll_loss=1.602, ppl=3.04, wps=23454.9, ups=1.9, wpb=12329.3, bsz=406.4, num_updates=93300, lr=7.17265e-06, gnorm=0.873, train_wall=52, wall=0
2021-03-15 07:14:24 | INFO | train_inner | epoch 032:   2322 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=22899, ups=1.85, wpb=12373.1, bsz=476.8, num_updates=93400, lr=7.16881e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 07:15:17 | INFO | train_inner | epoch 032:   2422 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23232.3, ups=1.88, wpb=12333, bsz=416.3, num_updates=93500, lr=7.16498e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 07:16:10 | INFO | train_inner | epoch 032:   2522 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23419.9, ups=1.89, wpb=12414.1, bsz=411.7, num_updates=93600, lr=7.16115e-06, gnorm=0.867, train_wall=53, wall=0
2021-03-15 07:17:03 | INFO | train_inner | epoch 032:   2622 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23270.2, ups=1.89, wpb=12336.5, bsz=402.1, num_updates=93700, lr=7.15733e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 07:17:56 | INFO | train_inner | epoch 032:   2722 / 2938 loss=3.286, nll_loss=1.569, ppl=2.97, wps=23350.1, ups=1.89, wpb=12340.1, bsz=406.4, num_updates=93800, lr=7.15351e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 07:18:50 | INFO | train_inner | epoch 032:   2822 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=22742.7, ups=1.84, wpb=12378.2, bsz=441, num_updates=93900, lr=7.1497e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 07:19:45 | INFO | train_inner | epoch 032:   2922 / 2938 loss=3.283, nll_loss=1.567, ppl=2.96, wps=22568.2, ups=1.83, wpb=12338.2, bsz=466.5, num_updates=94000, lr=7.1459e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 07:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 07:19:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:19:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:19:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:20:14 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.531 | nll_loss 8.492 | ppl 360.07 | bleu 15.7 | wps 3576.8 | wpb 6344.2 | bsz 166.4 | num_updates 94016 | best_bleu 15.9
2021-03-15 07:20:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 07:20:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 32 @ 94016 updates, score 15.7) (writing took 5.172251174226403 seconds)
2021-03-15 07:20:19 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-03-15 07:20:19 | INFO | train | epoch 032 | loss 3.298 | nll_loss 1.583 | ppl 3 | wps 22470.3 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 94016 | lr 7.14529e-06 | gnorm 0.874 | train_wall 1568 | wall 0
2021-03-15 07:20:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:20:25 | INFO | fairseq.trainer | begin training epoch 33
2021-03-15 07:20:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:20:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:20:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:20:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:20:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:21:17 | INFO | train_inner | epoch 033:     84 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=13426.3, ups=1.09, wpb=12347.5, bsz=425.1, num_updates=94100, lr=7.1421e-06, gnorm=0.878, train_wall=52, wall=0
2021-03-15 07:22:12 | INFO | train_inner | epoch 033:    184 / 2938 loss=3.301, nll_loss=1.588, ppl=3.01, wps=22047.8, ups=1.81, wpb=12212.4, bsz=488.1, num_updates=94200, lr=7.13831e-06, gnorm=0.881, train_wall=55, wall=0
2021-03-15 07:23:05 | INFO | train_inner | epoch 033:    284 / 2938 loss=3.278, nll_loss=1.56, ppl=2.95, wps=23328.5, ups=1.89, wpb=12368.7, bsz=415.8, num_updates=94300, lr=7.13452e-06, gnorm=0.865, train_wall=53, wall=0
2021-03-15 07:23:59 | INFO | train_inner | epoch 033:    384 / 2938 loss=3.272, nll_loss=1.553, ppl=2.94, wps=23118.3, ups=1.86, wpb=12425.4, bsz=413.8, num_updates=94400, lr=7.13074e-06, gnorm=0.863, train_wall=54, wall=0
2021-03-15 07:24:52 | INFO | train_inner | epoch 033:    484 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23432.9, ups=1.89, wpb=12431.2, bsz=440.8, num_updates=94500, lr=7.12697e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 07:25:45 | INFO | train_inner | epoch 033:    584 / 2938 loss=3.314, nll_loss=1.6, ppl=3.03, wps=23051.8, ups=1.87, wpb=12301.5, bsz=404.5, num_updates=94600, lr=7.1232e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 07:26:40 | INFO | train_inner | epoch 033:    684 / 2938 loss=3.266, nll_loss=1.547, ppl=2.92, wps=22965.8, ups=1.84, wpb=12459.2, bsz=424.5, num_updates=94700, lr=7.11944e-06, gnorm=0.861, train_wall=54, wall=0
2021-03-15 07:27:33 | INFO | train_inner | epoch 033:    784 / 2938 loss=3.307, nll_loss=1.594, ppl=3.02, wps=23009.2, ups=1.88, wpb=12207.2, bsz=407, num_updates=94800, lr=7.11568e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 07:28:26 | INFO | train_inner | epoch 033:    884 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23208.2, ups=1.88, wpb=12315.7, bsz=419, num_updates=94900, lr=7.11193e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 07:29:20 | INFO | train_inner | epoch 033:    984 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22414.2, ups=1.83, wpb=12261.4, bsz=454.4, num_updates=95000, lr=7.10819e-06, gnorm=0.895, train_wall=55, wall=0
2021-03-15 07:30:13 | INFO | train_inner | epoch 033:   1084 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23306, ups=1.89, wpb=12333.7, bsz=400.4, num_updates=95100, lr=7.10445e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 07:31:06 | INFO | train_inner | epoch 033:   1184 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23187, ups=1.89, wpb=12295.5, bsz=390.7, num_updates=95200, lr=7.10072e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 07:32:00 | INFO | train_inner | epoch 033:   1284 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22977.3, ups=1.86, wpb=12321.2, bsz=435.6, num_updates=95300, lr=7.09699e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 07:32:53 | INFO | train_inner | epoch 033:   1384 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23345.3, ups=1.88, wpb=12400.3, bsz=436.4, num_updates=95400, lr=7.09327e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 07:33:47 | INFO | train_inner | epoch 033:   1484 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22658.1, ups=1.84, wpb=12281.4, bsz=429.2, num_updates=95500, lr=7.08955e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 07:34:40 | INFO | train_inner | epoch 033:   1584 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=23365.5, ups=1.89, wpb=12394.9, bsz=398.5, num_updates=95600, lr=7.08585e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 07:35:35 | INFO | train_inner | epoch 033:   1684 / 2938 loss=3.26, nll_loss=1.541, ppl=2.91, wps=22465.6, ups=1.82, wpb=12376.1, bsz=475.1, num_updates=95700, lr=7.08214e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 07:36:29 | INFO | train_inner | epoch 033:   1784 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22902.7, ups=1.87, wpb=12263.5, bsz=425.1, num_updates=95800, lr=7.07845e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 07:37:23 | INFO | train_inner | epoch 033:   1884 / 2938 loss=3.319, nll_loss=1.606, ppl=3.04, wps=22920.3, ups=1.86, wpb=12294.1, bsz=436.2, num_updates=95900, lr=7.07475e-06, gnorm=0.89, train_wall=53, wall=0
2021-03-15 07:38:17 | INFO | train_inner | epoch 033:   1984 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=22733.1, ups=1.85, wpb=12310, bsz=441.5, num_updates=96000, lr=7.07107e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 07:39:10 | INFO | train_inner | epoch 033:   2084 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23193.6, ups=1.86, wpb=12453.2, bsz=414.1, num_updates=96100, lr=7.06739e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 07:40:03 | INFO | train_inner | epoch 033:   2184 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23203.9, ups=1.88, wpb=12312, bsz=394.2, num_updates=96200, lr=7.06371e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 07:40:57 | INFO | train_inner | epoch 033:   2284 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23127.4, ups=1.86, wpb=12419.2, bsz=442.1, num_updates=96300, lr=7.06005e-06, gnorm=0.871, train_wall=54, wall=0
2021-03-15 07:41:51 | INFO | train_inner | epoch 033:   2384 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=22910.3, ups=1.85, wpb=12352.9, bsz=430.6, num_updates=96400, lr=7.05638e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 07:42:44 | INFO | train_inner | epoch 033:   2484 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=23308.1, ups=1.89, wpb=12353.5, bsz=409, num_updates=96500, lr=7.05273e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 07:43:39 | INFO | train_inner | epoch 033:   2584 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=22725.4, ups=1.83, wpb=12399.5, bsz=460.1, num_updates=96600, lr=7.04907e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 07:44:33 | INFO | train_inner | epoch 033:   2684 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22545.4, ups=1.84, wpb=12281.8, bsz=436.6, num_updates=96700, lr=7.04543e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 07:45:27 | INFO | train_inner | epoch 033:   2784 / 2938 loss=3.301, nll_loss=1.588, ppl=3.01, wps=22891.5, ups=1.85, wpb=12388.7, bsz=425.4, num_updates=96800, lr=7.04179e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 07:46:21 | INFO | train_inner | epoch 033:   2884 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22891.7, ups=1.86, wpb=12292.2, bsz=409.3, num_updates=96900, lr=7.03815e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 07:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 07:46:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:46:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:46:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:46:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:46:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:46:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:47:09 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.518 | nll_loss 8.479 | ppl 356.69 | bleu 15.8 | wps 3811.3 | wpb 6344.2 | bsz 166.4 | num_updates 96954 | best_bleu 15.9
2021-03-15 07:47:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 07:47:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 33 @ 96954 updates, score 15.8) (writing took 5.247084102593362 seconds)
2021-03-15 07:47:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-03-15 07:47:14 | INFO | train | epoch 033 | loss 3.297 | nll_loss 1.582 | ppl 2.99 | wps 22449.1 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 96954 | lr 7.03619e-06 | gnorm 0.876 | train_wall 1571 | wall 0
2021-03-15 07:47:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:47:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:47:20 | INFO | fairseq.trainer | begin training epoch 34
2021-03-15 07:47:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:47:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:47:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 07:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 07:47:53 | INFO | train_inner | epoch 034:     46 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=13533.7, ups=1.09, wpb=12410.1, bsz=428.4, num_updates=97000, lr=7.03452e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 07:48:46 | INFO | train_inner | epoch 034:    146 / 2938 loss=3.274, nll_loss=1.557, ppl=2.94, wps=23100.8, ups=1.87, wpb=12369.3, bsz=443.3, num_updates=97100, lr=7.0309e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 07:49:40 | INFO | train_inner | epoch 034:    246 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=22932.2, ups=1.85, wpb=12411.6, bsz=449.4, num_updates=97200, lr=7.02728e-06, gnorm=0.864, train_wall=54, wall=0
2021-03-15 07:50:34 | INFO | train_inner | epoch 034:    346 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=23081.2, ups=1.87, wpb=12354.1, bsz=421.9, num_updates=97300, lr=7.02367e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 07:51:27 | INFO | train_inner | epoch 034:    446 / 2938 loss=3.328, nll_loss=1.617, ppl=3.07, wps=23148.5, ups=1.88, wpb=12280.9, bsz=406.3, num_updates=97400, lr=7.02007e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 07:52:20 | INFO | train_inner | epoch 034:    546 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=23330.9, ups=1.88, wpb=12386.5, bsz=435.8, num_updates=97500, lr=7.01646e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 07:53:13 | INFO | train_inner | epoch 034:    646 / 2938 loss=3.275, nll_loss=1.557, ppl=2.94, wps=23314.2, ups=1.88, wpb=12373.8, bsz=406.9, num_updates=97600, lr=7.01287e-06, gnorm=0.863, train_wall=53, wall=0
2021-03-15 07:54:07 | INFO | train_inner | epoch 034:    746 / 2938 loss=3.311, nll_loss=1.598, ppl=3.03, wps=22898.1, ups=1.86, wpb=12288.7, bsz=424.7, num_updates=97700, lr=7.00928e-06, gnorm=0.887, train_wall=53, wall=0
2021-03-15 07:55:00 | INFO | train_inner | epoch 034:    846 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23098.8, ups=1.87, wpb=12329.2, bsz=423.4, num_updates=97800, lr=7.00569e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 07:55:54 | INFO | train_inner | epoch 034:    946 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23191.7, ups=1.87, wpb=12401.5, bsz=421.8, num_updates=97900, lr=7.00212e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 07:56:48 | INFO | train_inner | epoch 034:   1046 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22492.4, ups=1.83, wpb=12309.2, bsz=453.8, num_updates=98000, lr=6.99854e-06, gnorm=0.886, train_wall=55, wall=0
2021-03-15 07:57:42 | INFO | train_inner | epoch 034:   1146 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=22902.4, ups=1.86, wpb=12311.4, bsz=429.8, num_updates=98100, lr=6.99497e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 07:58:36 | INFO | train_inner | epoch 034:   1246 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=23104.9, ups=1.87, wpb=12364.6, bsz=433.8, num_updates=98200, lr=6.99141e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 07:59:31 | INFO | train_inner | epoch 034:   1346 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=22377.3, ups=1.81, wpb=12368.8, bsz=455.9, num_updates=98300, lr=6.98785e-06, gnorm=0.868, train_wall=55, wall=0
2021-03-15 08:00:24 | INFO | train_inner | epoch 034:   1446 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=22942.1, ups=1.87, wpb=12291.2, bsz=413.4, num_updates=98400, lr=6.9843e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 08:01:18 | INFO | train_inner | epoch 034:   1546 / 2938 loss=3.332, nll_loss=1.622, ppl=3.08, wps=23069.6, ups=1.88, wpb=12255, bsz=416.5, num_updates=98500, lr=6.98076e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 08:02:10 | INFO | train_inner | epoch 034:   1646 / 2938 loss=3.311, nll_loss=1.597, ppl=3.03, wps=23176.4, ups=1.89, wpb=12239.8, bsz=414.6, num_updates=98600, lr=6.97722e-06, gnorm=0.888, train_wall=53, wall=0
2021-03-15 08:03:05 | INFO | train_inner | epoch 034:   1746 / 2938 loss=3.301, nll_loss=1.588, ppl=3.01, wps=22738.4, ups=1.84, wpb=12347.6, bsz=452.6, num_updates=98700, lr=6.97368e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 08:03:58 | INFO | train_inner | epoch 034:   1846 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=23067.7, ups=1.88, wpb=12249.5, bsz=397.8, num_updates=98800, lr=6.97015e-06, gnorm=0.909, train_wall=53, wall=0
2021-03-15 08:04:51 | INFO | train_inner | epoch 034:   1946 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=23042.4, ups=1.87, wpb=12311.7, bsz=435.4, num_updates=98900, lr=6.96663e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 08:05:44 | INFO | train_inner | epoch 034:   2046 / 2938 loss=3.284, nll_loss=1.567, ppl=2.96, wps=23464.8, ups=1.89, wpb=12433.4, bsz=393.4, num_updates=99000, lr=6.96311e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 08:06:38 | INFO | train_inner | epoch 034:   2146 / 2938 loss=3.305, nll_loss=1.592, ppl=3.01, wps=22922.4, ups=1.86, wpb=12353.9, bsz=419.4, num_updates=99100, lr=6.95959e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 08:07:31 | INFO | train_inner | epoch 034:   2246 / 2938 loss=3.318, nll_loss=1.606, ppl=3.04, wps=23243.5, ups=1.89, wpb=12301.5, bsz=407, num_updates=99200, lr=6.95608e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 08:08:24 | INFO | train_inner | epoch 034:   2346 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=23630.9, ups=1.9, wpb=12416.5, bsz=399, num_updates=99300, lr=6.95258e-06, gnorm=0.875, train_wall=52, wall=0
2021-03-15 08:09:18 | INFO | train_inner | epoch 034:   2446 / 2938 loss=3.322, nll_loss=1.611, ppl=3.05, wps=22644, ups=1.85, wpb=12266.2, bsz=430.3, num_updates=99400, lr=6.94908e-06, gnorm=0.884, train_wall=54, wall=0
2021-03-15 08:10:11 | INFO | train_inner | epoch 034:   2546 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22998.6, ups=1.86, wpb=12362.2, bsz=437.4, num_updates=99500, lr=6.94559e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 08:11:05 | INFO | train_inner | epoch 034:   2646 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22861.2, ups=1.85, wpb=12338.8, bsz=421.3, num_updates=99600, lr=6.9421e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 08:11:59 | INFO | train_inner | epoch 034:   2746 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=23065.3, ups=1.88, wpb=12278.7, bsz=431.2, num_updates=99700, lr=6.93862e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 08:12:53 | INFO | train_inner | epoch 034:   2846 / 2938 loss=3.261, nll_loss=1.543, ppl=2.91, wps=22730.6, ups=1.83, wpb=12431.4, bsz=457, num_updates=99800, lr=6.93514e-06, gnorm=0.859, train_wall=54, wall=0
2021-03-15 08:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 08:13:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:13:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:13:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:13:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:13:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:13:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:14:01 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.533 | nll_loss 8.494 | ppl 360.44 | bleu 15.66 | wps 4315.5 | wpb 6344.2 | bsz 166.4 | num_updates 99892 | best_bleu 15.9
2021-03-15 08:14:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 08:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 34 @ 99892 updates, score 15.66) (writing took 5.183324578218162 seconds)
2021-03-15 08:14:06 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-03-15 08:14:06 | INFO | train | epoch 034 | loss 3.297 | nll_loss 1.582 | ppl 2.99 | wps 22493.7 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 99892 | lr 6.93195e-06 | gnorm 0.876 | train_wall 1569 | wall 0
2021-03-15 08:14:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:14:12 | INFO | fairseq.trainer | begin training epoch 35
2021-03-15 08:14:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:14:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:14:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:14:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:14:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:14:24 | INFO | train_inner | epoch 035:      8 / 2938 loss=3.28, nll_loss=1.563, ppl=2.95, wps=13672.9, ups=1.1, wpb=12394.2, bsz=426.9, num_updates=99900, lr=6.93167e-06, gnorm=0.867, train_wall=54, wall=0
2021-03-15 08:15:18 | INFO | train_inner | epoch 035:    108 / 2938 loss=3.261, nll_loss=1.542, ppl=2.91, wps=22906.5, ups=1.85, wpb=12349.8, bsz=470.9, num_updates=100000, lr=6.9282e-06, gnorm=0.869, train_wall=54, wall=0
2021-03-15 08:16:11 | INFO | train_inner | epoch 035:    208 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=23200.3, ups=1.88, wpb=12343.9, bsz=427.8, num_updates=100100, lr=6.92474e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 08:17:05 | INFO | train_inner | epoch 035:    308 / 2938 loss=3.306, nll_loss=1.593, ppl=3.02, wps=22983.3, ups=1.87, wpb=12311.6, bsz=411.9, num_updates=100200, lr=6.92129e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 08:17:58 | INFO | train_inner | epoch 035:    408 / 2938 loss=3.275, nll_loss=1.557, ppl=2.94, wps=23241.1, ups=1.87, wpb=12447.4, bsz=413.9, num_updates=100300, lr=6.91783e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 08:18:52 | INFO | train_inner | epoch 035:    508 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23116.5, ups=1.86, wpb=12438.4, bsz=432.2, num_updates=100400, lr=6.91439e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 08:19:45 | INFO | train_inner | epoch 035:    608 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=23325.9, ups=1.88, wpb=12416.4, bsz=423.9, num_updates=100500, lr=6.91095e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 08:20:38 | INFO | train_inner | epoch 035:    708 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23298.9, ups=1.9, wpb=12268.6, bsz=407.2, num_updates=100600, lr=6.90751e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 08:21:31 | INFO | train_inner | epoch 035:    808 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23530.1, ups=1.9, wpb=12367.5, bsz=405.1, num_updates=100700, lr=6.90408e-06, gnorm=0.88, train_wall=52, wall=0
2021-03-15 08:22:24 | INFO | train_inner | epoch 035:    908 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23051.6, ups=1.88, wpb=12267.4, bsz=407.5, num_updates=100800, lr=6.90066e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 08:23:18 | INFO | train_inner | epoch 035:   1008 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=22748.7, ups=1.85, wpb=12294.6, bsz=444.3, num_updates=100900, lr=6.89724e-06, gnorm=0.885, train_wall=54, wall=0
2021-03-15 08:24:12 | INFO | train_inner | epoch 035:   1108 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=22465.7, ups=1.83, wpb=12271.5, bsz=416.7, num_updates=101000, lr=6.89382e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 08:25:05 | INFO | train_inner | epoch 035:   1208 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23734.8, ups=1.92, wpb=12383.7, bsz=389.8, num_updates=101100, lr=6.89041e-06, gnorm=0.872, train_wall=52, wall=0
2021-03-15 08:25:59 | INFO | train_inner | epoch 035:   1308 / 2938 loss=3.304, nll_loss=1.591, ppl=3.01, wps=22719.8, ups=1.84, wpb=12367.1, bsz=434.6, num_updates=101200, lr=6.887e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 08:26:54 | INFO | train_inner | epoch 035:   1408 / 2938 loss=3.283, nll_loss=1.567, ppl=2.96, wps=22608.2, ups=1.82, wpb=12456.1, bsz=451.9, num_updates=101300, lr=6.8836e-06, gnorm=0.869, train_wall=55, wall=0
2021-03-15 08:27:49 | INFO | train_inner | epoch 035:   1508 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=22636.1, ups=1.84, wpb=12316.7, bsz=438, num_updates=101400, lr=6.88021e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 08:28:42 | INFO | train_inner | epoch 035:   1608 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22754, ups=1.86, wpb=12261.2, bsz=430.4, num_updates=101500, lr=6.87682e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 08:29:35 | INFO | train_inner | epoch 035:   1708 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=23424.4, ups=1.89, wpb=12412.4, bsz=408.6, num_updates=101600, lr=6.87343e-06, gnorm=0.868, train_wall=53, wall=0
2021-03-15 08:30:30 | INFO | train_inner | epoch 035:   1808 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=22418.8, ups=1.83, wpb=12263.1, bsz=455.4, num_updates=101700, lr=6.87005e-06, gnorm=0.885, train_wall=55, wall=0
2021-03-15 08:31:24 | INFO | train_inner | epoch 035:   1908 / 2938 loss=3.289, nll_loss=1.573, ppl=2.97, wps=22683.5, ups=1.84, wpb=12307.5, bsz=445.6, num_updates=101800, lr=6.86668e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 08:32:18 | INFO | train_inner | epoch 035:   2008 / 2938 loss=3.286, nll_loss=1.57, ppl=2.97, wps=23060.1, ups=1.86, wpb=12394, bsz=438.6, num_updates=101900, lr=6.86331e-06, gnorm=0.885, train_wall=54, wall=0
2021-03-15 08:33:12 | INFO | train_inner | epoch 035:   2108 / 2938 loss=3.334, nll_loss=1.625, ppl=3.08, wps=22637.4, ups=1.85, wpb=12204.1, bsz=450.6, num_updates=102000, lr=6.85994e-06, gnorm=0.896, train_wall=54, wall=0
2021-03-15 08:34:06 | INFO | train_inner | epoch 035:   2208 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22957.9, ups=1.87, wpb=12285.3, bsz=419.8, num_updates=102100, lr=6.85658e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 08:34:58 | INFO | train_inner | epoch 035:   2308 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23310.3, ups=1.89, wpb=12338.5, bsz=406.9, num_updates=102200, lr=6.85323e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 08:35:53 | INFO | train_inner | epoch 035:   2408 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22743.3, ups=1.84, wpb=12382.6, bsz=438.4, num_updates=102300, lr=6.84988e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 08:36:46 | INFO | train_inner | epoch 035:   2508 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23289.4, ups=1.88, wpb=12394.9, bsz=411.2, num_updates=102400, lr=6.84653e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 08:37:39 | INFO | train_inner | epoch 035:   2608 / 2938 loss=3.297, nll_loss=1.583, ppl=3, wps=23403.8, ups=1.9, wpb=12317.1, bsz=404, num_updates=102500, lr=6.84319e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 08:38:32 | INFO | train_inner | epoch 035:   2708 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=22935.5, ups=1.87, wpb=12255, bsz=414.2, num_updates=102600, lr=6.83986e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 08:39:26 | INFO | train_inner | epoch 035:   2808 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23038.4, ups=1.86, wpb=12396.2, bsz=435.4, num_updates=102700, lr=6.83652e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 08:40:20 | INFO | train_inner | epoch 035:   2908 / 2938 loss=3.287, nll_loss=1.572, ppl=2.97, wps=23071, ups=1.87, wpb=12358.2, bsz=430.3, num_updates=102800, lr=6.8332e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 08:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 08:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:40:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:40:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:40:53 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.514 | nll_loss 8.475 | ppl 355.78 | bleu 15.68 | wps 4295.2 | wpb 6344.2 | bsz 166.4 | num_updates 102830 | best_bleu 15.9
2021-03-15 08:40:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 08:40:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 35 @ 102830 updates, score 15.68) (writing took 5.173988954164088 seconds)
2021-03-15 08:40:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-03-15 08:40:58 | INFO | train | epoch 035 | loss 3.296 | nll_loss 1.581 | ppl 2.99 | wps 22484.7 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 102830 | lr 6.8322e-06 | gnorm 0.878 | train_wall 1570 | wall 0
2021-03-15 08:41:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:41:04 | INFO | fairseq.trainer | begin training epoch 36
2021-03-15 08:41:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:41:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:41:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 08:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 08:41:49 | INFO | train_inner | epoch 036:     70 / 2938 loss=3.305, nll_loss=1.59, ppl=3.01, wps=13893.7, ups=1.12, wpb=12377, bsz=406.8, num_updates=102900, lr=6.82988e-06, gnorm=0.878, train_wall=52, wall=0
2021-03-15 08:42:43 | INFO | train_inner | epoch 036:    170 / 2938 loss=3.28, nll_loss=1.563, ppl=2.95, wps=23146.8, ups=1.86, wpb=12471.2, bsz=440.6, num_updates=103000, lr=6.82656e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 08:43:36 | INFO | train_inner | epoch 036:    270 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=22892.6, ups=1.86, wpb=12289.8, bsz=451, num_updates=103100, lr=6.82325e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 08:44:29 | INFO | train_inner | epoch 036:    370 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23255.4, ups=1.88, wpb=12358.7, bsz=416.9, num_updates=103200, lr=6.81994e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 08:45:24 | INFO | train_inner | epoch 036:    470 / 2938 loss=3.304, nll_loss=1.589, ppl=3.01, wps=22659.8, ups=1.83, wpb=12352.8, bsz=432.4, num_updates=103300, lr=6.81664e-06, gnorm=0.885, train_wall=54, wall=0
2021-03-15 08:46:17 | INFO | train_inner | epoch 036:    570 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23138.8, ups=1.87, wpb=12362.7, bsz=425.6, num_updates=103400, lr=6.81334e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 08:47:11 | INFO | train_inner | epoch 036:    670 / 2938 loss=3.279, nll_loss=1.562, ppl=2.95, wps=23272.3, ups=1.87, wpb=12466.8, bsz=439.6, num_updates=103500, lr=6.81005e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 08:48:04 | INFO | train_inner | epoch 036:    770 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23063.7, ups=1.87, wpb=12365.3, bsz=424.8, num_updates=103600, lr=6.80676e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 08:48:59 | INFO | train_inner | epoch 036:    870 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=22888.6, ups=1.84, wpb=12429.9, bsz=452, num_updates=103700, lr=6.80348e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 08:49:53 | INFO | train_inner | epoch 036:    970 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=22756.8, ups=1.84, wpb=12364.7, bsz=436.6, num_updates=103800, lr=6.8002e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 08:50:47 | INFO | train_inner | epoch 036:   1070 / 2938 loss=3.286, nll_loss=1.571, ppl=2.97, wps=22755.6, ups=1.84, wpb=12342.1, bsz=447, num_updates=103900, lr=6.79693e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 08:51:41 | INFO | train_inner | epoch 036:   1170 / 2938 loss=3.318, nll_loss=1.605, ppl=3.04, wps=23120.5, ups=1.88, wpb=12312.6, bsz=420.6, num_updates=104000, lr=6.79366e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 08:52:35 | INFO | train_inner | epoch 036:   1270 / 2938 loss=3.27, nll_loss=1.552, ppl=2.93, wps=22794.2, ups=1.84, wpb=12372.2, bsz=440.6, num_updates=104100, lr=6.7904e-06, gnorm=0.87, train_wall=54, wall=0
2021-03-15 08:53:29 | INFO | train_inner | epoch 036:   1370 / 2938 loss=3.301, nll_loss=1.587, ppl=3, wps=22921.4, ups=1.86, wpb=12345.7, bsz=437.9, num_updates=104200, lr=6.78714e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 08:54:23 | INFO | train_inner | epoch 036:   1470 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=22906.1, ups=1.86, wpb=12335, bsz=416.1, num_updates=104300, lr=6.78388e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 08:55:16 | INFO | train_inner | epoch 036:   1570 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=23047.1, ups=1.87, wpb=12354.7, bsz=419.6, num_updates=104400, lr=6.78064e-06, gnorm=0.883, train_wall=53, wall=0
2021-03-15 08:56:10 | INFO | train_inner | epoch 036:   1670 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22926.9, ups=1.85, wpb=12402.5, bsz=425.1, num_updates=104500, lr=6.77739e-06, gnorm=0.874, train_wall=54, wall=0
2021-03-15 08:57:04 | INFO | train_inner | epoch 036:   1770 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=23067.6, ups=1.87, wpb=12359.2, bsz=415.9, num_updates=104600, lr=6.77415e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 08:57:58 | INFO | train_inner | epoch 036:   1870 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=22954.7, ups=1.86, wpb=12342.3, bsz=422.6, num_updates=104700, lr=6.77091e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 08:58:52 | INFO | train_inner | epoch 036:   1970 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23030.2, ups=1.85, wpb=12434.6, bsz=419, num_updates=104800, lr=6.76768e-06, gnorm=0.879, train_wall=54, wall=0
2021-03-15 08:59:45 | INFO | train_inner | epoch 036:   2070 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23164.9, ups=1.89, wpb=12246.2, bsz=411.5, num_updates=104900, lr=6.76446e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 09:00:39 | INFO | train_inner | epoch 036:   2170 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=22736.9, ups=1.85, wpb=12279.8, bsz=439.8, num_updates=105000, lr=6.76123e-06, gnorm=0.888, train_wall=54, wall=0
2021-03-15 09:01:32 | INFO | train_inner | epoch 036:   2270 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=22920.7, ups=1.86, wpb=12324.9, bsz=436.6, num_updates=105100, lr=6.75802e-06, gnorm=0.901, train_wall=54, wall=0
2021-03-15 09:02:27 | INFO | train_inner | epoch 036:   2370 / 2938 loss=3.281, nll_loss=1.566, ppl=2.96, wps=22553.7, ups=1.83, wpb=12308.6, bsz=438, num_updates=105200, lr=6.7548e-06, gnorm=0.869, train_wall=54, wall=0
2021-03-15 09:03:20 | INFO | train_inner | epoch 036:   2470 / 2938 loss=3.313, nll_loss=1.6, ppl=3.03, wps=22971.4, ups=1.87, wpb=12276.5, bsz=401, num_updates=105300, lr=6.7516e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 09:04:14 | INFO | train_inner | epoch 036:   2570 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=22979.5, ups=1.86, wpb=12333.5, bsz=417, num_updates=105400, lr=6.74839e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 09:05:07 | INFO | train_inner | epoch 036:   2670 / 2938 loss=3.315, nll_loss=1.603, ppl=3.04, wps=23276, ups=1.9, wpb=12240.4, bsz=394.4, num_updates=105500, lr=6.74519e-06, gnorm=0.885, train_wall=52, wall=0
2021-03-15 09:06:00 | INFO | train_inner | epoch 036:   2770 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22900.4, ups=1.87, wpb=12271, bsz=424.2, num_updates=105600, lr=6.742e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 09:06:53 | INFO | train_inner | epoch 036:   2870 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23424.9, ups=1.9, wpb=12324, bsz=394.9, num_updates=105700, lr=6.73881e-06, gnorm=0.887, train_wall=52, wall=0
2021-03-15 09:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:07:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:07:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:07:48 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.526 | nll_loss 8.487 | ppl 358.9 | bleu 15.67 | wps 4149.9 | wpb 6344.2 | bsz 166.4 | num_updates 105768 | best_bleu 15.9
2021-03-15 09:07:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 09:07:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 36 @ 105768 updates, score 15.67) (writing took 5.26901035849005 seconds)
2021-03-15 09:07:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-03-15 09:07:53 | INFO | train | epoch 036 | loss 3.296 | nll_loss 1.581 | ppl 2.99 | wps 22457 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 105768 | lr 6.73664e-06 | gnorm 0.878 | train_wall 1571 | wall 0
2021-03-15 09:07:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:07:59 | INFO | fairseq.trainer | begin training epoch 37
2021-03-15 09:07:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:08:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:08:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:08:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:08:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:08:24 | INFO | train_inner | epoch 037:     32 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=13403.5, ups=1.09, wpb=12255.9, bsz=458, num_updates=105800, lr=6.73562e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 09:09:17 | INFO | train_inner | epoch 037:    132 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23211.9, ups=1.88, wpb=12369.1, bsz=431, num_updates=105900, lr=6.73244e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 09:10:12 | INFO | train_inner | epoch 037:    232 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22861.5, ups=1.85, wpb=12366.1, bsz=464.6, num_updates=106000, lr=6.72927e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 09:11:07 | INFO | train_inner | epoch 037:    332 / 2938 loss=3.271, nll_loss=1.553, ppl=2.93, wps=22395.5, ups=1.81, wpb=12344.1, bsz=460.6, num_updates=106100, lr=6.72609e-06, gnorm=0.865, train_wall=55, wall=0
2021-03-15 09:12:00 | INFO | train_inner | epoch 037:    432 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23090.4, ups=1.87, wpb=12338.3, bsz=412.2, num_updates=106200, lr=6.72293e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 09:12:53 | INFO | train_inner | epoch 037:    532 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=23520.9, ups=1.9, wpb=12354.2, bsz=396.4, num_updates=106300, lr=6.71976e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 09:13:46 | INFO | train_inner | epoch 037:    632 / 2938 loss=3.313, nll_loss=1.6, ppl=3.03, wps=22807.5, ups=1.87, wpb=12191.8, bsz=414.5, num_updates=106400, lr=6.7166e-06, gnorm=0.895, train_wall=53, wall=0
2021-03-15 09:14:39 | INFO | train_inner | epoch 037:    732 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23294.9, ups=1.89, wpb=12305.7, bsz=427.8, num_updates=106500, lr=6.71345e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 09:15:32 | INFO | train_inner | epoch 037:    832 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23283.5, ups=1.88, wpb=12358.3, bsz=401.9, num_updates=106600, lr=6.7103e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 09:16:25 | INFO | train_inner | epoch 037:    932 / 2938 loss=3.308, nll_loss=1.594, ppl=3.02, wps=23212.1, ups=1.88, wpb=12326.6, bsz=418.1, num_updates=106700, lr=6.70716e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 09:17:19 | INFO | train_inner | epoch 037:   1032 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=22646.2, ups=1.85, wpb=12227.9, bsz=434.2, num_updates=106800, lr=6.70402e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 09:18:13 | INFO | train_inner | epoch 037:   1132 / 2938 loss=3.318, nll_loss=1.606, ppl=3.04, wps=22834.9, ups=1.87, wpb=12218.8, bsz=414.4, num_updates=106900, lr=6.70088e-06, gnorm=0.893, train_wall=53, wall=0
2021-03-15 09:19:08 | INFO | train_inner | epoch 037:   1232 / 2938 loss=3.259, nll_loss=1.54, ppl=2.91, wps=22665.7, ups=1.81, wpb=12515.9, bsz=473.6, num_updates=107000, lr=6.69775e-06, gnorm=0.863, train_wall=55, wall=0
2021-03-15 09:20:02 | INFO | train_inner | epoch 037:   1332 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22933.4, ups=1.85, wpb=12375.9, bsz=422.3, num_updates=107100, lr=6.69462e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 09:20:55 | INFO | train_inner | epoch 037:   1432 / 2938 loss=3.309, nll_loss=1.595, ppl=3.02, wps=22986.8, ups=1.87, wpb=12311.2, bsz=408.6, num_updates=107200, lr=6.6915e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 09:21:50 | INFO | train_inner | epoch 037:   1532 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=22924.8, ups=1.84, wpb=12429, bsz=422.3, num_updates=107300, lr=6.68838e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 09:22:43 | INFO | train_inner | epoch 037:   1632 / 2938 loss=3.296, nll_loss=1.58, ppl=2.99, wps=23288.2, ups=1.89, wpb=12353.1, bsz=393.9, num_updates=107400, lr=6.68526e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 09:23:37 | INFO | train_inner | epoch 037:   1732 / 2938 loss=3.272, nll_loss=1.554, ppl=2.94, wps=22794.8, ups=1.85, wpb=12339.1, bsz=439.1, num_updates=107500, lr=6.68215e-06, gnorm=0.891, train_wall=54, wall=0
2021-03-15 09:24:30 | INFO | train_inner | epoch 037:   1832 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=23140.8, ups=1.86, wpb=12408.4, bsz=433.9, num_updates=107600, lr=6.67905e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 09:25:24 | INFO | train_inner | epoch 037:   1932 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23048.1, ups=1.87, wpb=12354, bsz=433.1, num_updates=107700, lr=6.67595e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 09:26:19 | INFO | train_inner | epoch 037:   2032 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=22484.5, ups=1.82, wpb=12361.1, bsz=458, num_updates=107800, lr=6.67285e-06, gnorm=0.881, train_wall=55, wall=0
2021-03-15 09:27:14 | INFO | train_inner | epoch 037:   2132 / 2938 loss=3.28, nll_loss=1.564, ppl=2.96, wps=22606.6, ups=1.82, wpb=12408, bsz=473.7, num_updates=107900, lr=6.66976e-06, gnorm=0.867, train_wall=55, wall=0
2021-03-15 09:28:07 | INFO | train_inner | epoch 037:   2232 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=23347, ups=1.89, wpb=12367, bsz=418.4, num_updates=108000, lr=6.66667e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 09:29:02 | INFO | train_inner | epoch 037:   2332 / 2938 loss=3.279, nll_loss=1.563, ppl=2.95, wps=22674.8, ups=1.83, wpb=12398.9, bsz=437.3, num_updates=108100, lr=6.66358e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 09:29:55 | INFO | train_inner | epoch 037:   2432 / 2938 loss=3.315, nll_loss=1.603, ppl=3.04, wps=23151, ups=1.88, wpb=12307, bsz=415.4, num_updates=108200, lr=6.6605e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 09:30:48 | INFO | train_inner | epoch 037:   2532 / 2938 loss=3.33, nll_loss=1.619, ppl=3.07, wps=22992.7, ups=1.88, wpb=12206.3, bsz=416.5, num_updates=108300, lr=6.65743e-06, gnorm=0.892, train_wall=53, wall=0
2021-03-15 09:31:41 | INFO | train_inner | epoch 037:   2632 / 2938 loss=3.319, nll_loss=1.606, ppl=3.05, wps=23220.3, ups=1.89, wpb=12292.5, bsz=398.3, num_updates=108400, lr=6.65436e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 09:32:35 | INFO | train_inner | epoch 037:   2732 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=22553.4, ups=1.84, wpb=12227.9, bsz=411, num_updates=108500, lr=6.65129e-06, gnorm=0.888, train_wall=54, wall=0
2021-03-15 09:33:29 | INFO | train_inner | epoch 037:   2832 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22776.1, ups=1.85, wpb=12321.2, bsz=426.5, num_updates=108600, lr=6.64822e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 09:34:22 | INFO | train_inner | epoch 037:   2932 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=23346.1, ups=1.88, wpb=12391.4, bsz=400.8, num_updates=108700, lr=6.64517e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 09:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:34:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:34:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:34:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:34:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:34:43 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.531 | nll_loss 8.492 | ppl 360.1 | bleu 15.84 | wps 4234.4 | wpb 6344.2 | bsz 166.4 | num_updates 108706 | best_bleu 15.9
2021-03-15 09:34:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 09:34:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 37 @ 108706 updates, score 15.84) (writing took 5.253773327916861 seconds)
2021-03-15 09:34:48 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-03-15 09:34:48 | INFO | train | epoch 037 | loss 3.296 | nll_loss 1.581 | ppl 2.99 | wps 22442.3 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 108706 | lr 6.64498e-06 | gnorm 0.879 | train_wall 1573 | wall 0
2021-03-15 09:34:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:34:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:34:54 | INFO | fairseq.trainer | begin training epoch 38
2021-03-15 09:34:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:34:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:34:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 09:35:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 09:35:51 | INFO | train_inner | epoch 038:     94 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=13917.5, ups=1.12, wpb=12387.2, bsz=417.8, num_updates=108800, lr=6.64211e-06, gnorm=0.875, train_wall=52, wall=0
2021-03-15 09:36:44 | INFO | train_inner | epoch 038:    194 / 2938 loss=3.334, nll_loss=1.624, ppl=3.08, wps=22992.8, ups=1.88, wpb=12230.1, bsz=396.8, num_updates=108900, lr=6.63906e-06, gnorm=0.894, train_wall=53, wall=0
2021-03-15 09:37:39 | INFO | train_inner | epoch 038:    294 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=22657.6, ups=1.84, wpb=12303.8, bsz=466.3, num_updates=109000, lr=6.63602e-06, gnorm=0.891, train_wall=54, wall=0
2021-03-15 09:38:33 | INFO | train_inner | epoch 038:    394 / 2938 loss=3.31, nll_loss=1.597, ppl=3.02, wps=22691.3, ups=1.85, wpb=12270.8, bsz=415, num_updates=109100, lr=6.63297e-06, gnorm=0.888, train_wall=54, wall=0
2021-03-15 09:39:26 | INFO | train_inner | epoch 038:    494 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22973.6, ups=1.86, wpb=12343.6, bsz=417.5, num_updates=109200, lr=6.62994e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 09:40:20 | INFO | train_inner | epoch 038:    594 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=23141.4, ups=1.87, wpb=12362.8, bsz=416.4, num_updates=109300, lr=6.6269e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 09:41:14 | INFO | train_inner | epoch 038:    694 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23014.2, ups=1.86, wpb=12368.7, bsz=435, num_updates=109400, lr=6.62387e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 09:42:07 | INFO | train_inner | epoch 038:    794 / 2938 loss=3.283, nll_loss=1.567, ppl=2.96, wps=23033.7, ups=1.87, wpb=12348.6, bsz=436.3, num_updates=109500, lr=6.62085e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 09:43:02 | INFO | train_inner | epoch 038:    894 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22668.5, ups=1.84, wpb=12331, bsz=419.4, num_updates=109600, lr=6.61783e-06, gnorm=0.88, train_wall=54, wall=0
2021-03-15 09:43:56 | INFO | train_inner | epoch 038:    994 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22973.9, ups=1.85, wpb=12415.6, bsz=431.9, num_updates=109700, lr=6.61481e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 09:44:50 | INFO | train_inner | epoch 038:   1094 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=22931, ups=1.85, wpb=12380.1, bsz=439.4, num_updates=109800, lr=6.6118e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 09:45:45 | INFO | train_inner | epoch 038:   1194 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=22201.1, ups=1.79, wpb=12387.9, bsz=465.2, num_updates=109900, lr=6.60879e-06, gnorm=0.874, train_wall=56, wall=0
2021-03-15 09:46:38 | INFO | train_inner | epoch 038:   1294 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23519.1, ups=1.89, wpb=12474.9, bsz=406.6, num_updates=110000, lr=6.60578e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 09:47:32 | INFO | train_inner | epoch 038:   1394 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23129.1, ups=1.87, wpb=12395, bsz=420.6, num_updates=110100, lr=6.60278e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 09:48:25 | INFO | train_inner | epoch 038:   1494 / 2938 loss=3.281, nll_loss=1.565, ppl=2.96, wps=23109.4, ups=1.87, wpb=12351.4, bsz=430.6, num_updates=110200, lr=6.59979e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 09:49:19 | INFO | train_inner | epoch 038:   1594 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=22996.9, ups=1.87, wpb=12307.2, bsz=443.7, num_updates=110300, lr=6.59679e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 09:50:14 | INFO | train_inner | epoch 038:   1694 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=22336.2, ups=1.81, wpb=12338.8, bsz=453.6, num_updates=110400, lr=6.5938e-06, gnorm=0.883, train_wall=55, wall=0
2021-03-15 09:51:08 | INFO | train_inner | epoch 038:   1794 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23258.9, ups=1.87, wpb=12413.3, bsz=413.8, num_updates=110500, lr=6.59082e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 09:52:01 | INFO | train_inner | epoch 038:   1894 / 2938 loss=3.317, nll_loss=1.605, ppl=3.04, wps=22939.1, ups=1.87, wpb=12274, bsz=434.3, num_updates=110600, lr=6.58784e-06, gnorm=0.888, train_wall=53, wall=0
2021-03-15 09:52:54 | INFO | train_inner | epoch 038:   1994 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23045.7, ups=1.88, wpb=12288.9, bsz=398.7, num_updates=110700, lr=6.58486e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 09:53:49 | INFO | train_inner | epoch 038:   2094 / 2938 loss=3.287, nll_loss=1.572, ppl=2.97, wps=22663.2, ups=1.84, wpb=12300.1, bsz=440, num_updates=110800, lr=6.58189e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 09:54:42 | INFO | train_inner | epoch 038:   2194 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23357.2, ups=1.89, wpb=12345.5, bsz=408.6, num_updates=110900, lr=6.57892e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 09:55:34 | INFO | train_inner | epoch 038:   2294 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23232, ups=1.89, wpb=12281.1, bsz=424.9, num_updates=111000, lr=6.57596e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 09:56:28 | INFO | train_inner | epoch 038:   2394 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=22957.6, ups=1.86, wpb=12317.3, bsz=403.7, num_updates=111100, lr=6.573e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 09:57:23 | INFO | train_inner | epoch 038:   2494 / 2938 loss=3.283, nll_loss=1.567, ppl=2.96, wps=22212, ups=1.81, wpb=12258.8, bsz=465.3, num_updates=111200, lr=6.57004e-06, gnorm=0.893, train_wall=55, wall=0
2021-03-15 09:58:17 | INFO | train_inner | epoch 038:   2594 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23273.5, ups=1.87, wpb=12419.4, bsz=413.8, num_updates=111300, lr=6.56709e-06, gnorm=0.869, train_wall=53, wall=0
2021-03-15 09:59:10 | INFO | train_inner | epoch 038:   2694 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=22997.9, ups=1.86, wpb=12382.2, bsz=438.5, num_updates=111400, lr=6.56414e-06, gnorm=0.903, train_wall=54, wall=0
2021-03-15 10:00:04 | INFO | train_inner | epoch 038:   2794 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23317, ups=1.88, wpb=12426.9, bsz=412.8, num_updates=111500, lr=6.5612e-06, gnorm=0.875, train_wall=53, wall=0
2021-03-15 10:00:57 | INFO | train_inner | epoch 038:   2894 / 2938 loss=3.329, nll_loss=1.619, ppl=3.07, wps=22921.1, ups=1.87, wpb=12263.4, bsz=418, num_updates=111600, lr=6.55826e-06, gnorm=0.893, train_wall=53, wall=0
2021-03-15 10:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 10:01:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:01:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:01:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:01:38 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.529 | nll_loss 8.491 | ppl 359.75 | bleu 15.66 | wps 4318.7 | wpb 6344.2 | bsz 166.4 | num_updates 111644 | best_bleu 15.9
2021-03-15 10:01:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 10:01:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 38 @ 111644 updates, score 15.66) (writing took 5.278372198343277 seconds)
2021-03-15 10:01:44 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-03-15 10:01:44 | INFO | train | epoch 038 | loss 3.295 | nll_loss 1.58 | ppl 2.99 | wps 22445.7 | ups 1.82 | wpb 12340.4 | bsz 426.5 | num_updates 111644 | lr 6.55697e-06 | gnorm 0.881 | train_wall 1573 | wall 0
2021-03-15 10:01:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:49 | INFO | fairseq.trainer | begin training epoch 39
2021-03-15 10:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:01:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:01:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:02:27 | INFO | train_inner | epoch 039:     56 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=13653.2, ups=1.12, wpb=12204.4, bsz=398.4, num_updates=111700, lr=6.55532e-06, gnorm=0.891, train_wall=52, wall=0
2021-03-15 10:03:20 | INFO | train_inner | epoch 039:    156 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=22939.3, ups=1.87, wpb=12292.1, bsz=410.6, num_updates=111800, lr=6.55239e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 10:04:13 | INFO | train_inner | epoch 039:    256 / 2938 loss=3.325, nll_loss=1.614, ppl=3.06, wps=23327.3, ups=1.9, wpb=12266.5, bsz=391.5, num_updates=111900, lr=6.54946e-06, gnorm=0.885, train_wall=52, wall=0
2021-03-15 10:05:07 | INFO | train_inner | epoch 039:    356 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=22749.9, ups=1.85, wpb=12275.5, bsz=436.6, num_updates=112000, lr=6.54654e-06, gnorm=0.889, train_wall=54, wall=0
2021-03-15 10:06:01 | INFO | train_inner | epoch 039:    456 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22725.5, ups=1.85, wpb=12310.9, bsz=406.5, num_updates=112100, lr=6.54362e-06, gnorm=0.889, train_wall=54, wall=0
2021-03-15 10:06:55 | INFO | train_inner | epoch 039:    556 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22757.5, ups=1.85, wpb=12319.9, bsz=440.1, num_updates=112200, lr=6.5407e-06, gnorm=0.884, train_wall=54, wall=0
2021-03-15 10:07:49 | INFO | train_inner | epoch 039:    656 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=23067.9, ups=1.87, wpb=12348.8, bsz=406.4, num_updates=112300, lr=6.53779e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 10:08:43 | INFO | train_inner | epoch 039:    756 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22637.6, ups=1.83, wpb=12341.3, bsz=457.8, num_updates=112400, lr=6.53488e-06, gnorm=0.887, train_wall=54, wall=0
2021-03-15 10:09:37 | INFO | train_inner | epoch 039:    856 / 2938 loss=3.281, nll_loss=1.563, ppl=2.96, wps=22860.9, ups=1.84, wpb=12410.4, bsz=423.1, num_updates=112500, lr=6.53197e-06, gnorm=0.879, train_wall=54, wall=0
2021-03-15 10:10:31 | INFO | train_inner | epoch 039:    956 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=22744, ups=1.86, wpb=12243.2, bsz=418.9, num_updates=112600, lr=6.52907e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 10:11:25 | INFO | train_inner | epoch 039:   1056 / 2938 loss=3.305, nll_loss=1.592, ppl=3.02, wps=22647.9, ups=1.85, wpb=12239.2, bsz=429.8, num_updates=112700, lr=6.52617e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 10:12:18 | INFO | train_inner | epoch 039:   1156 / 2938 loss=3.32, nll_loss=1.608, ppl=3.05, wps=23036.4, ups=1.89, wpb=12205.5, bsz=402.1, num_updates=112800, lr=6.52328e-06, gnorm=0.89, train_wall=53, wall=0
2021-03-15 10:13:12 | INFO | train_inner | epoch 039:   1256 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=23281.4, ups=1.87, wpb=12430.2, bsz=408.2, num_updates=112900, lr=6.52039e-06, gnorm=0.87, train_wall=53, wall=0
2021-03-15 10:14:06 | INFO | train_inner | epoch 039:   1356 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22910.7, ups=1.85, wpb=12363.8, bsz=419.4, num_updates=113000, lr=6.51751e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 10:15:01 | INFO | train_inner | epoch 039:   1456 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=22479.6, ups=1.82, wpb=12332.4, bsz=464.7, num_updates=113100, lr=6.51462e-06, gnorm=0.873, train_wall=55, wall=0
2021-03-15 10:15:54 | INFO | train_inner | epoch 039:   1556 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23190, ups=1.87, wpb=12375.5, bsz=419.4, num_updates=113200, lr=6.51175e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 10:16:48 | INFO | train_inner | epoch 039:   1656 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=22967.8, ups=1.85, wpb=12413.8, bsz=423, num_updates=113300, lr=6.50887e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 10:17:43 | INFO | train_inner | epoch 039:   1756 / 2938 loss=3.288, nll_loss=1.573, ppl=2.98, wps=22497.5, ups=1.83, wpb=12273.1, bsz=441.9, num_updates=113400, lr=6.506e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 10:18:37 | INFO | train_inner | epoch 039:   1856 / 2938 loss=3.283, nll_loss=1.567, ppl=2.96, wps=22777, ups=1.84, wpb=12396.5, bsz=462.1, num_updates=113500, lr=6.50313e-06, gnorm=0.894, train_wall=54, wall=0
2021-03-15 10:19:31 | INFO | train_inner | epoch 039:   1956 / 2938 loss=3.269, nll_loss=1.551, ppl=2.93, wps=23114.5, ups=1.85, wpb=12468.5, bsz=446.7, num_updates=113600, lr=6.50027e-06, gnorm=0.865, train_wall=54, wall=0
2021-03-15 10:20:26 | INFO | train_inner | epoch 039:   2056 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=22327.2, ups=1.8, wpb=12419.7, bsz=451.7, num_updates=113700, lr=6.49741e-06, gnorm=0.869, train_wall=55, wall=0
2021-03-15 10:21:21 | INFO | train_inner | epoch 039:   2156 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=22502.1, ups=1.82, wpb=12345.1, bsz=448.9, num_updates=113800, lr=6.49456e-06, gnorm=0.881, train_wall=55, wall=0
2021-03-15 10:22:16 | INFO | train_inner | epoch 039:   2256 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22760.4, ups=1.85, wpb=12322.1, bsz=426.1, num_updates=113900, lr=6.4917e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 10:23:10 | INFO | train_inner | epoch 039:   2356 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=22652.9, ups=1.84, wpb=12342.8, bsz=429.4, num_updates=114000, lr=6.48886e-06, gnorm=0.895, train_wall=54, wall=0
2021-03-15 10:24:04 | INFO | train_inner | epoch 039:   2456 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=23147.6, ups=1.87, wpb=12391.6, bsz=412.9, num_updates=114100, lr=6.48601e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 10:24:57 | INFO | train_inner | epoch 039:   2556 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=22990.1, ups=1.87, wpb=12303.9, bsz=417.4, num_updates=114200, lr=6.48317e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 10:25:51 | INFO | train_inner | epoch 039:   2656 / 2938 loss=3.31, nll_loss=1.597, ppl=3.02, wps=23178.9, ups=1.86, wpb=12444.8, bsz=427.4, num_updates=114300, lr=6.48034e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 10:26:45 | INFO | train_inner | epoch 039:   2756 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=22977.6, ups=1.86, wpb=12383.7, bsz=410.7, num_updates=114400, lr=6.4775e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 10:27:37 | INFO | train_inner | epoch 039:   2856 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23355.1, ups=1.9, wpb=12305.2, bsz=409.8, num_updates=114500, lr=6.47467e-06, gnorm=0.885, train_wall=52, wall=0
2021-03-15 10:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 10:28:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:28:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:28:40 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.53 | nll_loss 8.491 | ppl 359.87 | bleu 15.8 | wps 4322.3 | wpb 6344.2 | bsz 166.4 | num_updates 114582 | best_bleu 15.9
2021-03-15 10:28:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 10:28:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 39 @ 114582 updates, score 15.8) (writing took 5.249300776980817 seconds)
2021-03-15 10:28:45 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-03-15 10:28:45 | INFO | train | epoch 039 | loss 3.295 | nll_loss 1.58 | ppl 2.99 | wps 22364.2 | ups 1.81 | wpb 12340.4 | bsz 426.5 | num_updates 114582 | lr 6.47236e-06 | gnorm 0.881 | train_wall 1579 | wall 0
2021-03-15 10:28:50 | INFO | fairseq.trainer | begin training epoch 40
2021-03-15 10:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:28:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:28:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:29:08 | INFO | train_inner | epoch 040:     18 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=13561, ups=1.1, wpb=12341.1, bsz=438.5, num_updates=114600, lr=6.47185e-06, gnorm=0.877, train_wall=54, wall=0
2021-03-15 10:30:02 | INFO | train_inner | epoch 040:    118 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=22990.9, ups=1.86, wpb=12333.3, bsz=433.8, num_updates=114700, lr=6.46903e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 10:30:56 | INFO | train_inner | epoch 040:    218 / 2938 loss=3.282, nll_loss=1.565, ppl=2.96, wps=22712.7, ups=1.83, wpb=12384.4, bsz=442.6, num_updates=114800, lr=6.46621e-06, gnorm=0.875, train_wall=54, wall=0
2021-03-15 10:31:51 | INFO | train_inner | epoch 040:    318 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=22633.4, ups=1.83, wpb=12398.2, bsz=437.8, num_updates=114900, lr=6.46339e-06, gnorm=0.872, train_wall=55, wall=0
2021-03-15 10:32:45 | INFO | train_inner | epoch 040:    418 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=22953.6, ups=1.86, wpb=12373.4, bsz=408.6, num_updates=115000, lr=6.46058e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 10:33:39 | INFO | train_inner | epoch 040:    518 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23117.3, ups=1.87, wpb=12336.5, bsz=419, num_updates=115100, lr=6.45778e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 10:34:33 | INFO | train_inner | epoch 040:    618 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=22842.5, ups=1.85, wpb=12344.8, bsz=421.6, num_updates=115200, lr=6.45497e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 10:35:27 | INFO | train_inner | epoch 040:    718 / 2938 loss=3.303, nll_loss=1.588, ppl=3.01, wps=22726, ups=1.85, wpb=12270.1, bsz=425.8, num_updates=115300, lr=6.45217e-06, gnorm=0.891, train_wall=54, wall=0
2021-03-15 10:36:21 | INFO | train_inner | epoch 040:    818 / 2938 loss=3.276, nll_loss=1.558, ppl=2.95, wps=22814.6, ups=1.84, wpb=12425.1, bsz=428.3, num_updates=115400, lr=6.44938e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 10:37:14 | INFO | train_inner | epoch 040:    918 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=23076, ups=1.87, wpb=12330.8, bsz=416.4, num_updates=115500, lr=6.44658e-06, gnorm=0.878, train_wall=53, wall=0
2021-03-15 10:38:08 | INFO | train_inner | epoch 040:   1018 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=23034.3, ups=1.88, wpb=12225.9, bsz=412.3, num_updates=115600, lr=6.44379e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 10:39:01 | INFO | train_inner | epoch 040:   1118 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=22953.2, ups=1.86, wpb=12352.2, bsz=410.8, num_updates=115700, lr=6.44101e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 10:39:55 | INFO | train_inner | epoch 040:   1218 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=22962.5, ups=1.86, wpb=12327.9, bsz=422.3, num_updates=115800, lr=6.43823e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 10:40:50 | INFO | train_inner | epoch 040:   1318 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22416.7, ups=1.82, wpb=12303.1, bsz=470.9, num_updates=115900, lr=6.43545e-06, gnorm=0.883, train_wall=55, wall=0
2021-03-15 10:41:44 | INFO | train_inner | epoch 040:   1418 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=22615, ups=1.83, wpb=12329.2, bsz=438.9, num_updates=116000, lr=6.43268e-06, gnorm=0.888, train_wall=54, wall=0
2021-03-15 10:42:39 | INFO | train_inner | epoch 040:   1518 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=22803.5, ups=1.85, wpb=12332.4, bsz=424.7, num_updates=116100, lr=6.4299e-06, gnorm=0.884, train_wall=54, wall=0
2021-03-15 10:43:33 | INFO | train_inner | epoch 040:   1618 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=22850.5, ups=1.85, wpb=12361.5, bsz=430, num_updates=116200, lr=6.42714e-06, gnorm=0.894, train_wall=54, wall=0
2021-03-15 10:44:26 | INFO | train_inner | epoch 040:   1718 / 2938 loss=3.271, nll_loss=1.553, ppl=2.93, wps=23356.4, ups=1.87, wpb=12468.4, bsz=412.7, num_updates=116300, lr=6.42437e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 10:45:20 | INFO | train_inner | epoch 040:   1818 / 2938 loss=3.286, nll_loss=1.57, ppl=2.97, wps=22843.3, ups=1.84, wpb=12384.5, bsz=425.3, num_updates=116400, lr=6.42161e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 10:46:14 | INFO | train_inner | epoch 040:   1918 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=22949.6, ups=1.86, wpb=12349, bsz=417.6, num_updates=116500, lr=6.41886e-06, gnorm=0.886, train_wall=54, wall=0
2021-03-15 10:47:07 | INFO | train_inner | epoch 040:   2018 / 2938 loss=3.267, nll_loss=1.548, ppl=2.92, wps=23464.6, ups=1.88, wpb=12487.1, bsz=404.3, num_updates=116600, lr=6.4161e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 10:48:02 | INFO | train_inner | epoch 040:   2118 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=22389.4, ups=1.81, wpb=12340.1, bsz=451.9, num_updates=116700, lr=6.41335e-06, gnorm=0.883, train_wall=55, wall=0
2021-03-15 10:48:56 | INFO | train_inner | epoch 040:   2218 / 2938 loss=3.325, nll_loss=1.613, ppl=3.06, wps=22882.6, ups=1.87, wpb=12260, bsz=421.9, num_updates=116800, lr=6.41061e-06, gnorm=0.89, train_wall=53, wall=0
2021-03-15 10:49:50 | INFO | train_inner | epoch 040:   2318 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=22625.1, ups=1.84, wpb=12305.6, bsz=412.1, num_updates=116900, lr=6.40787e-06, gnorm=0.879, train_wall=54, wall=0
2021-03-15 10:50:43 | INFO | train_inner | epoch 040:   2418 / 2938 loss=3.335, nll_loss=1.625, ppl=3.08, wps=23050.3, ups=1.9, wpb=12136.9, bsz=397.8, num_updates=117000, lr=6.40513e-06, gnorm=0.897, train_wall=52, wall=0
2021-03-15 10:51:37 | INFO | train_inner | epoch 040:   2518 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=22749.2, ups=1.84, wpb=12380, bsz=447.4, num_updates=117100, lr=6.40239e-06, gnorm=0.876, train_wall=54, wall=0
2021-03-15 10:52:36 | INFO | train_inner | epoch 040:   2618 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=21186.4, ups=1.72, wpb=12351.6, bsz=426.7, num_updates=117200, lr=6.39966e-06, gnorm=0.881, train_wall=58, wall=0
2021-03-15 10:53:35 | INFO | train_inner | epoch 040:   2718 / 2938 loss=3.307, nll_loss=1.594, ppl=3.02, wps=20754.1, ups=1.68, wpb=12335.8, bsz=424.2, num_updates=117300, lr=6.39693e-06, gnorm=0.881, train_wall=59, wall=0
2021-03-15 10:54:36 | INFO | train_inner | epoch 040:   2818 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=20544, ups=1.66, wpb=12406.3, bsz=454.2, num_updates=117400, lr=6.39421e-06, gnorm=0.874, train_wall=60, wall=0
2021-03-15 10:55:35 | INFO | train_inner | epoch 040:   2918 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=20774.7, ups=1.69, wpb=12288, bsz=436, num_updates=117500, lr=6.39148e-06, gnorm=0.89, train_wall=59, wall=0
2021-03-15 10:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 10:55:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:55:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:55:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:55:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:55:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:55:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:56:15 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.532 | nll_loss 8.493 | ppl 360.31 | bleu 15.74 | wps 2526.4 | wpb 6344.2 | bsz 166.4 | num_updates 117520 | best_bleu 15.9
2021-03-15 10:56:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 10:56:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 40 @ 117520 updates, score 15.74) (writing took 5.528257745318115 seconds)
2021-03-15 10:56:21 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-03-15 10:56:21 | INFO | train | epoch 040 | loss 3.294 | nll_loss 1.579 | ppl 2.99 | wps 21895.2 | ups 1.77 | wpb 12340.4 | bsz 426.5 | num_updates 117520 | lr 6.39094e-06 | gnorm 0.881 | train_wall 1601 | wall 0
2021-03-15 10:56:32 | INFO | fairseq.trainer | begin training epoch 41
2021-03-15 10:56:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:56:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:56:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:56:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:56:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 10:56:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 10:57:32 | INFO | train_inner | epoch 041:     80 / 2938 loss=3.31, nll_loss=1.597, ppl=3.02, wps=10517.5, ups=0.85, wpb=12303.6, bsz=398.4, num_updates=117600, lr=6.38877e-06, gnorm=0.887, train_wall=57, wall=0
2021-03-15 10:58:29 | INFO | train_inner | epoch 041:    180 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=21318.3, ups=1.73, wpb=12291, bsz=425.8, num_updates=117700, lr=6.38605e-06, gnorm=0.882, train_wall=57, wall=0
2021-03-15 10:59:29 | INFO | train_inner | epoch 041:    280 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=20817.2, ups=1.68, wpb=12407, bsz=448.1, num_updates=117800, lr=6.38334e-06, gnorm=0.874, train_wall=59, wall=0
2021-03-15 11:00:28 | INFO | train_inner | epoch 041:    380 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=20759.2, ups=1.69, wpb=12274, bsz=436.1, num_updates=117900, lr=6.38063e-06, gnorm=0.892, train_wall=59, wall=0
2021-03-15 11:01:28 | INFO | train_inner | epoch 041:    480 / 2938 loss=3.287, nll_loss=1.572, ppl=2.97, wps=20685.6, ups=1.68, wpb=12316, bsz=432.3, num_updates=118000, lr=6.37793e-06, gnorm=0.878, train_wall=59, wall=0
2021-03-15 11:02:25 | INFO | train_inner | epoch 041:    580 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=21423, ups=1.74, wpb=12299.9, bsz=416.6, num_updates=118100, lr=6.37523e-06, gnorm=0.879, train_wall=57, wall=0
2021-03-15 11:03:25 | INFO | train_inner | epoch 041:    680 / 2938 loss=3.275, nll_loss=1.558, ppl=2.94, wps=20683.6, ups=1.67, wpb=12359.5, bsz=449.4, num_updates=118200, lr=6.37253e-06, gnorm=0.876, train_wall=59, wall=0
2021-03-15 11:04:24 | INFO | train_inner | epoch 041:    780 / 2938 loss=3.276, nll_loss=1.559, ppl=2.95, wps=20901.2, ups=1.67, wpb=12478.6, bsz=439.1, num_updates=118300, lr=6.36984e-06, gnorm=0.869, train_wall=59, wall=0
2021-03-15 11:05:23 | INFO | train_inner | epoch 041:    880 / 2938 loss=3.288, nll_loss=1.571, ppl=2.97, wps=21381.8, ups=1.72, wpb=12417.6, bsz=413.5, num_updates=118400, lr=6.36715e-06, gnorm=0.872, train_wall=58, wall=0
2021-03-15 11:06:21 | INFO | train_inner | epoch 041:    980 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=21166.5, ups=1.72, wpb=12326.5, bsz=451.5, num_updates=118500, lr=6.36446e-06, gnorm=0.904, train_wall=58, wall=0
2021-03-15 11:07:20 | INFO | train_inner | epoch 041:   1080 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=20905.8, ups=1.69, wpb=12337.9, bsz=442.6, num_updates=118600, lr=6.36177e-06, gnorm=0.886, train_wall=59, wall=0
2021-03-15 11:08:17 | INFO | train_inner | epoch 041:   1180 / 2938 loss=3.284, nll_loss=1.568, ppl=2.97, wps=21600.3, ups=1.75, wpb=12355.5, bsz=400.7, num_updates=118700, lr=6.35909e-06, gnorm=0.879, train_wall=57, wall=0
2021-03-15 11:09:11 | INFO | train_inner | epoch 041:   1280 / 2938 loss=3.322, nll_loss=1.61, ppl=3.05, wps=22673.7, ups=1.86, wpb=12192.5, bsz=435.3, num_updates=118800, lr=6.35642e-06, gnorm=0.892, train_wall=54, wall=0
2021-03-15 11:10:03 | INFO | train_inner | epoch 041:   1380 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23694.6, ups=1.92, wpb=12318.3, bsz=407.4, num_updates=118900, lr=6.35374e-06, gnorm=0.883, train_wall=52, wall=0
2021-03-15 11:10:55 | INFO | train_inner | epoch 041:   1480 / 2938 loss=3.279, nll_loss=1.562, ppl=2.95, wps=23492.4, ups=1.91, wpb=12311.2, bsz=408.7, num_updates=119000, lr=6.35107e-06, gnorm=0.88, train_wall=52, wall=0
2021-03-15 11:11:48 | INFO | train_inner | epoch 041:   1580 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=23207, ups=1.88, wpb=12335.8, bsz=424.6, num_updates=119100, lr=6.34841e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 11:12:41 | INFO | train_inner | epoch 041:   1680 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=23255.1, ups=1.89, wpb=12336.5, bsz=404.1, num_updates=119200, lr=6.34574e-06, gnorm=0.887, train_wall=53, wall=0
2021-03-15 11:13:35 | INFO | train_inner | epoch 041:   1780 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23115.5, ups=1.88, wpb=12313.3, bsz=419, num_updates=119300, lr=6.34308e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 11:14:27 | INFO | train_inner | epoch 041:   1880 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=23422.1, ups=1.9, wpb=12326.8, bsz=412.2, num_updates=119400, lr=6.34043e-06, gnorm=0.884, train_wall=52, wall=0
2021-03-15 11:15:21 | INFO | train_inner | epoch 041:   1980 / 2938 loss=3.295, nll_loss=1.579, ppl=2.99, wps=23218, ups=1.88, wpb=12361.8, bsz=414.1, num_updates=119500, lr=6.33777e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 11:16:14 | INFO | train_inner | epoch 041:   2080 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23106.4, ups=1.87, wpb=12388.5, bsz=435.7, num_updates=119600, lr=6.33512e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 11:17:07 | INFO | train_inner | epoch 041:   2180 / 2938 loss=3.313, nll_loss=1.6, ppl=3.03, wps=23222.3, ups=1.89, wpb=12274.6, bsz=407.9, num_updates=119700, lr=6.33248e-06, gnorm=0.896, train_wall=53, wall=0
2021-03-15 11:18:01 | INFO | train_inner | epoch 041:   2280 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=23121.5, ups=1.87, wpb=12371.6, bsz=453.3, num_updates=119800, lr=6.32983e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 11:18:55 | INFO | train_inner | epoch 041:   2380 / 2938 loss=3.269, nll_loss=1.551, ppl=2.93, wps=22816.5, ups=1.84, wpb=12431.3, bsz=441.1, num_updates=119900, lr=6.32719e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 11:19:49 | INFO | train_inner | epoch 041:   2480 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=22696.3, ups=1.84, wpb=12342.8, bsz=461.6, num_updates=120000, lr=6.32456e-06, gnorm=0.892, train_wall=54, wall=0
2021-03-15 11:20:43 | INFO | train_inner | epoch 041:   2580 / 2938 loss=3.305, nll_loss=1.591, ppl=3.01, wps=23187.5, ups=1.88, wpb=12343.6, bsz=408.5, num_updates=120100, lr=6.32192e-06, gnorm=0.876, train_wall=53, wall=0
2021-03-15 11:21:37 | INFO | train_inner | epoch 041:   2680 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22881.7, ups=1.85, wpb=12349.5, bsz=453.7, num_updates=120200, lr=6.31929e-06, gnorm=0.878, train_wall=54, wall=0
2021-03-15 11:22:29 | INFO | train_inner | epoch 041:   2780 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23762.1, ups=1.92, wpb=12390.1, bsz=396, num_updates=120300, lr=6.31666e-06, gnorm=0.892, train_wall=52, wall=0
2021-03-15 11:23:22 | INFO | train_inner | epoch 041:   2880 / 2938 loss=3.301, nll_loss=1.586, ppl=3, wps=22924.4, ups=1.87, wpb=12255.6, bsz=427.4, num_updates=120400, lr=6.31404e-06, gnorm=0.887, train_wall=53, wall=0
2021-03-15 11:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 11:23:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:23:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:23:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:23:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:23:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:23:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:24:12 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.527 | nll_loss 8.487 | ppl 358.78 | bleu 15.75 | wps 3992.7 | wpb 6344.2 | bsz 166.4 | num_updates 120458 | best_bleu 15.9
2021-03-15 11:24:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 11:24:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 41 @ 120458 updates, score 15.75) (writing took 5.1832173792645335 seconds)
2021-03-15 11:24:17 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-03-15 11:24:17 | INFO | train | epoch 041 | loss 3.294 | nll_loss 1.578 | ppl 2.99 | wps 21627.1 | ups 1.75 | wpb 12340.4 | bsz 426.5 | num_updates 120458 | lr 6.31252e-06 | gnorm 0.882 | train_wall 1620 | wall 0
2021-03-15 11:24:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:24:23 | INFO | fairseq.trainer | begin training epoch 42
2021-03-15 11:24:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:24:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:24:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:24:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:24:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:24:52 | INFO | train_inner | epoch 042:     42 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=13727.8, ups=1.11, wpb=12373.1, bsz=403.9, num_updates=120500, lr=6.31142e-06, gnorm=0.876, train_wall=52, wall=0
2021-03-15 11:25:45 | INFO | train_inner | epoch 042:    142 / 2938 loss=3.314, nll_loss=1.601, ppl=3.03, wps=23125.1, ups=1.9, wpb=12168.9, bsz=427, num_updates=120600, lr=6.3088e-06, gnorm=0.89, train_wall=52, wall=0
2021-03-15 11:26:38 | INFO | train_inner | epoch 042:    242 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=23110.2, ups=1.88, wpb=12289.3, bsz=451.8, num_updates=120700, lr=6.30619e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 11:27:32 | INFO | train_inner | epoch 042:    342 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=22627.9, ups=1.85, wpb=12237.4, bsz=440.2, num_updates=120800, lr=6.30358e-06, gnorm=0.885, train_wall=54, wall=0
2021-03-15 11:28:25 | INFO | train_inner | epoch 042:    442 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23705.6, ups=1.91, wpb=12409.4, bsz=407.4, num_updates=120900, lr=6.30097e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 11:29:17 | INFO | train_inner | epoch 042:    542 / 2938 loss=3.293, nll_loss=1.577, ppl=2.98, wps=23519, ups=1.89, wpb=12431.2, bsz=406.6, num_updates=121000, lr=6.29837e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 11:30:11 | INFO | train_inner | epoch 042:    642 / 2938 loss=3.298, nll_loss=1.584, ppl=3, wps=22977.3, ups=1.86, wpb=12329.1, bsz=461.2, num_updates=121100, lr=6.29577e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 11:31:05 | INFO | train_inner | epoch 042:    742 / 2938 loss=3.277, nll_loss=1.56, ppl=2.95, wps=23015, ups=1.86, wpb=12398.8, bsz=438.7, num_updates=121200, lr=6.29317e-06, gnorm=0.881, train_wall=54, wall=0
2021-03-15 11:31:58 | INFO | train_inner | epoch 042:    842 / 2938 loss=3.311, nll_loss=1.598, ppl=3.03, wps=23344.7, ups=1.9, wpb=12309.4, bsz=401.8, num_updates=121300, lr=6.29057e-06, gnorm=0.888, train_wall=53, wall=0
2021-03-15 11:32:50 | INFO | train_inner | epoch 042:    942 / 2938 loss=3.33, nll_loss=1.619, ppl=3.07, wps=23446.3, ups=1.91, wpb=12283.4, bsz=381, num_updates=121400, lr=6.28798e-06, gnorm=0.894, train_wall=52, wall=0
2021-03-15 11:33:42 | INFO | train_inner | epoch 042:   1042 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23571.9, ups=1.91, wpb=12311.5, bsz=406.2, num_updates=121500, lr=6.28539e-06, gnorm=0.886, train_wall=52, wall=0
2021-03-15 11:34:36 | INFO | train_inner | epoch 042:   1142 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=22778.2, ups=1.85, wpb=12319.4, bsz=440.2, num_updates=121600, lr=6.28281e-06, gnorm=0.904, train_wall=54, wall=0
2021-03-15 11:35:30 | INFO | train_inner | epoch 042:   1242 / 2938 loss=3.292, nll_loss=1.576, ppl=2.98, wps=23167.3, ups=1.88, wpb=12334.4, bsz=427.8, num_updates=121700, lr=6.28023e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 11:36:23 | INFO | train_inner | epoch 042:   1342 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23162.3, ups=1.88, wpb=12338.4, bsz=436.2, num_updates=121800, lr=6.27765e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 11:37:17 | INFO | train_inner | epoch 042:   1442 / 2938 loss=3.282, nll_loss=1.567, ppl=2.96, wps=23030.8, ups=1.86, wpb=12396, bsz=444.2, num_updates=121900, lr=6.27507e-06, gnorm=0.872, train_wall=54, wall=0
2021-03-15 11:38:10 | INFO | train_inner | epoch 042:   1542 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23395, ups=1.89, wpb=12381.1, bsz=435.4, num_updates=122000, lr=6.2725e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 11:39:03 | INFO | train_inner | epoch 042:   1642 / 2938 loss=3.28, nll_loss=1.564, ppl=2.96, wps=23238.4, ups=1.87, wpb=12422.2, bsz=453.3, num_updates=122100, lr=6.26993e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 11:39:56 | INFO | train_inner | epoch 042:   1742 / 2938 loss=3.27, nll_loss=1.552, ppl=2.93, wps=23166.4, ups=1.88, wpb=12342.8, bsz=423.4, num_updates=122200, lr=6.26737e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 11:40:49 | INFO | train_inner | epoch 042:   1842 / 2938 loss=3.293, nll_loss=1.578, ppl=2.99, wps=23275.2, ups=1.89, wpb=12285.4, bsz=435.7, num_updates=122300, lr=6.2648e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 11:41:41 | INFO | train_inner | epoch 042:   1942 / 2938 loss=3.282, nll_loss=1.565, ppl=2.96, wps=23941.9, ups=1.94, wpb=12355.2, bsz=406.9, num_updates=122400, lr=6.26224e-06, gnorm=0.875, train_wall=51, wall=0
2021-03-15 11:42:34 | INFO | train_inner | epoch 042:   2042 / 2938 loss=3.305, nll_loss=1.592, ppl=3.01, wps=23297.4, ups=1.89, wpb=12340.9, bsz=425.4, num_updates=122500, lr=6.25969e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 11:43:28 | INFO | train_inner | epoch 042:   2142 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=22788.7, ups=1.85, wpb=12320.2, bsz=456.2, num_updates=122600, lr=6.25713e-06, gnorm=0.883, train_wall=54, wall=0
2021-03-15 11:44:21 | INFO | train_inner | epoch 042:   2242 / 2938 loss=3.279, nll_loss=1.562, ppl=2.95, wps=23443.4, ups=1.88, wpb=12441.8, bsz=443.2, num_updates=122700, lr=6.25458e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 11:45:12 | INFO | train_inner | epoch 042:   2342 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23942.8, ups=1.94, wpb=12349.9, bsz=413.4, num_updates=122800, lr=6.25204e-06, gnorm=0.883, train_wall=51, wall=0
2021-03-15 11:46:05 | INFO | train_inner | epoch 042:   2442 / 2938 loss=3.283, nll_loss=1.566, ppl=2.96, wps=23741.6, ups=1.92, wpb=12389.5, bsz=412.6, num_updates=122900, lr=6.24949e-06, gnorm=0.883, train_wall=52, wall=0
2021-03-15 11:46:56 | INFO | train_inner | epoch 042:   2542 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23690.9, ups=1.93, wpb=12259.2, bsz=415.4, num_updates=123000, lr=6.24695e-06, gnorm=0.886, train_wall=52, wall=0
2021-03-15 11:47:48 | INFO | train_inner | epoch 042:   2642 / 2938 loss=3.308, nll_loss=1.595, ppl=3.02, wps=23876.9, ups=1.93, wpb=12362, bsz=405.1, num_updates=123100, lr=6.24441e-06, gnorm=0.88, train_wall=52, wall=0
2021-03-15 11:48:40 | INFO | train_inner | epoch 042:   2742 / 2938 loss=3.284, nll_loss=1.568, ppl=2.97, wps=23622.2, ups=1.91, wpb=12360, bsz=413.4, num_updates=123200, lr=6.24188e-06, gnorm=0.884, train_wall=52, wall=0
2021-03-15 11:49:33 | INFO | train_inner | epoch 042:   2842 / 2938 loss=3.316, nll_loss=1.604, ppl=3.04, wps=23564.7, ups=1.92, wpb=12302, bsz=416.3, num_updates=123300, lr=6.23935e-06, gnorm=0.887, train_wall=52, wall=0
2021-03-15 11:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 11:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:50:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:50:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:50:42 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.526 | nll_loss 8.487 | ppl 358.86 | bleu 15.68 | wps 4381.8 | wpb 6344.2 | bsz 166.4 | num_updates 123396 | best_bleu 15.9
2021-03-15 11:50:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 11:50:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 42 @ 123396 updates, score 15.68) (writing took 5.2071537636220455 seconds)
2021-03-15 11:50:47 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-03-15 11:50:47 | INFO | train | epoch 042 | loss 3.293 | nll_loss 1.578 | ppl 2.99 | wps 22805 | ups 1.85 | wpb 12340.4 | bsz 426.5 | num_updates 123396 | lr 6.23692e-06 | gnorm 0.883 | train_wall 1548 | wall 0
2021-03-15 11:50:53 | INFO | fairseq.trainer | begin training epoch 43
2021-03-15 11:50:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:50:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:50:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 11:50:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 11:51:02 | INFO | train_inner | epoch 043:      4 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=13837.5, ups=1.12, wpb=12400.3, bsz=452.8, num_updates=123400, lr=6.23682e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 11:51:54 | INFO | train_inner | epoch 043:    104 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=23873.8, ups=1.94, wpb=12317.7, bsz=424.9, num_updates=123500, lr=6.23429e-06, gnorm=0.885, train_wall=51, wall=0
2021-03-15 11:52:45 | INFO | train_inner | epoch 043:    204 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23904.2, ups=1.95, wpb=12281, bsz=409, num_updates=123600, lr=6.23177e-06, gnorm=0.886, train_wall=51, wall=0
2021-03-15 11:53:38 | INFO | train_inner | epoch 043:    304 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23467.6, ups=1.9, wpb=12325.7, bsz=433.5, num_updates=123700, lr=6.22925e-06, gnorm=0.878, train_wall=52, wall=0
2021-03-15 11:54:30 | INFO | train_inner | epoch 043:    404 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=23609.9, ups=1.9, wpb=12402.3, bsz=428.2, num_updates=123800, lr=6.22673e-06, gnorm=0.878, train_wall=52, wall=0
2021-03-15 11:55:22 | INFO | train_inner | epoch 043:    504 / 2938 loss=3.281, nll_loss=1.564, ppl=2.96, wps=24222, ups=1.95, wpb=12412.6, bsz=388.6, num_updates=123900, lr=6.22422e-06, gnorm=0.875, train_wall=51, wall=0
2021-03-15 11:56:15 | INFO | train_inner | epoch 043:    604 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=22914.8, ups=1.87, wpb=12256.1, bsz=455.4, num_updates=124000, lr=6.22171e-06, gnorm=0.894, train_wall=53, wall=0
2021-03-15 11:57:07 | INFO | train_inner | epoch 043:    704 / 2938 loss=3.294, nll_loss=1.578, ppl=2.99, wps=23874.9, ups=1.92, wpb=12440.2, bsz=428.9, num_updates=124100, lr=6.2192e-06, gnorm=0.881, train_wall=52, wall=0
2021-03-15 11:58:00 | INFO | train_inner | epoch 043:    804 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23329.4, ups=1.9, wpb=12290.6, bsz=424.5, num_updates=124200, lr=6.2167e-06, gnorm=0.883, train_wall=53, wall=0
2021-03-15 11:58:52 | INFO | train_inner | epoch 043:    904 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=23248.8, ups=1.91, wpb=12200.8, bsz=415.4, num_updates=124300, lr=6.2142e-06, gnorm=0.892, train_wall=52, wall=0
2021-03-15 11:59:46 | INFO | train_inner | epoch 043:   1004 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=22959.4, ups=1.86, wpb=12360.4, bsz=448.4, num_updates=124400, lr=6.2117e-06, gnorm=0.882, train_wall=54, wall=0
2021-03-15 12:00:38 | INFO | train_inner | epoch 043:   1104 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23897.7, ups=1.93, wpb=12408.3, bsz=411.8, num_updates=124500, lr=6.2092e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 12:01:30 | INFO | train_inner | epoch 043:   1204 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=23761.6, ups=1.92, wpb=12365.1, bsz=419.1, num_updates=124600, lr=6.20671e-06, gnorm=0.907, train_wall=52, wall=0
2021-03-15 12:02:23 | INFO | train_inner | epoch 043:   1304 / 2938 loss=3.318, nll_loss=1.606, ppl=3.04, wps=23294.4, ups=1.9, wpb=12259.6, bsz=418.3, num_updates=124700, lr=6.20422e-06, gnorm=0.89, train_wall=52, wall=0
2021-03-15 12:03:15 | INFO | train_inner | epoch 043:   1404 / 2938 loss=3.316, nll_loss=1.602, ppl=3.04, wps=23613.9, ups=1.92, wpb=12276.8, bsz=403.7, num_updates=124800, lr=6.20174e-06, gnorm=0.897, train_wall=52, wall=0
2021-03-15 12:04:07 | INFO | train_inner | epoch 043:   1504 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23794.7, ups=1.93, wpb=12347, bsz=414.8, num_updates=124900, lr=6.19925e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 12:04:58 | INFO | train_inner | epoch 043:   1604 / 2938 loss=3.25, nll_loss=1.529, ppl=2.89, wps=24250.3, ups=1.94, wpb=12507.2, bsz=397.7, num_updates=125000, lr=6.19677e-06, gnorm=0.864, train_wall=51, wall=0
2021-03-15 12:05:51 | INFO | train_inner | epoch 043:   1704 / 2938 loss=3.269, nll_loss=1.552, ppl=2.93, wps=23424.9, ups=1.89, wpb=12424.7, bsz=448.1, num_updates=125100, lr=6.1943e-06, gnorm=0.871, train_wall=53, wall=0
2021-03-15 12:06:44 | INFO | train_inner | epoch 043:   1804 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=23592.7, ups=1.9, wpb=12400.6, bsz=432.5, num_updates=125200, lr=6.19182e-06, gnorm=0.887, train_wall=52, wall=0
2021-03-15 12:07:36 | INFO | train_inner | epoch 043:   1904 / 2938 loss=3.295, nll_loss=1.581, ppl=2.99, wps=23496.8, ups=1.9, wpb=12344.5, bsz=427.1, num_updates=125300, lr=6.18935e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 12:08:29 | INFO | train_inner | epoch 043:   2004 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23531, ups=1.91, wpb=12297.2, bsz=416.1, num_updates=125400, lr=6.18688e-06, gnorm=0.89, train_wall=52, wall=0
2021-03-15 12:09:21 | INFO | train_inner | epoch 043:   2104 / 2938 loss=3.297, nll_loss=1.582, ppl=2.99, wps=23783.2, ups=1.92, wpb=12411.1, bsz=419.3, num_updates=125500, lr=6.18442e-06, gnorm=0.877, train_wall=52, wall=0
2021-03-15 12:10:13 | INFO | train_inner | epoch 043:   2204 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=23778, ups=1.93, wpb=12343.7, bsz=412.3, num_updates=125600, lr=6.18195e-06, gnorm=0.886, train_wall=52, wall=0
2021-03-15 12:11:05 | INFO | train_inner | epoch 043:   2304 / 2938 loss=3.29, nll_loss=1.574, ppl=2.98, wps=23270, ups=1.9, wpb=12277.6, bsz=420.1, num_updates=125700, lr=6.17949e-06, gnorm=0.891, train_wall=53, wall=0
2021-03-15 12:11:58 | INFO | train_inner | epoch 043:   2404 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=23196.1, ups=1.89, wpb=12278.2, bsz=434.4, num_updates=125800, lr=6.17704e-06, gnorm=0.886, train_wall=53, wall=0
2021-03-15 12:12:51 | INFO | train_inner | epoch 043:   2504 / 2938 loss=3.281, nll_loss=1.565, ppl=2.96, wps=23341.3, ups=1.9, wpb=12311.8, bsz=438.7, num_updates=125900, lr=6.17458e-06, gnorm=0.877, train_wall=53, wall=0
2021-03-15 12:13:45 | INFO | train_inner | epoch 043:   2604 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=22748, ups=1.85, wpb=12268.6, bsz=466.2, num_updates=126000, lr=6.17213e-06, gnorm=0.894, train_wall=54, wall=0
2021-03-15 12:14:38 | INFO | train_inner | epoch 043:   2704 / 2938 loss=3.3, nll_loss=1.585, ppl=3, wps=23348.6, ups=1.9, wpb=12299.5, bsz=428.2, num_updates=126100, lr=6.16969e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 12:15:31 | INFO | train_inner | epoch 043:   2804 / 2938 loss=3.288, nll_loss=1.572, ppl=2.97, wps=23382.2, ups=1.88, wpb=12427.2, bsz=454.6, num_updates=126200, lr=6.16724e-06, gnorm=0.872, train_wall=53, wall=0
2021-03-15 12:16:24 | INFO | train_inner | epoch 043:   2904 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23373.4, ups=1.89, wpb=12336.9, bsz=447.9, num_updates=126300, lr=6.1648e-06, gnorm=0.883, train_wall=53, wall=0
2021-03-15 12:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 12:16:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:16:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:16:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:16:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:16:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:16:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:16:59 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.526 | nll_loss 8.487 | ppl 358.69 | bleu 15.67 | wps 4449.8 | wpb 6344.2 | bsz 166.4 | num_updates 126334 | best_bleu 15.9
2021-03-15 12:16:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 12:17:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 43 @ 126334 updates, score 15.67) (writing took 5.176986822858453 seconds)
2021-03-15 12:17:04 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-03-15 12:17:04 | INFO | train | epoch 043 | loss 3.293 | nll_loss 1.578 | ppl 2.98 | wps 22990 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 126334 | lr 6.16397e-06 | gnorm 0.884 | train_wall 1536 | wall 0
2021-03-15 12:17:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:17:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:17:10 | INFO | fairseq.trainer | begin training epoch 44
2021-03-15 12:17:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:17:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:17:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:17:51 | INFO | train_inner | epoch 044:     66 / 2938 loss=3.284, nll_loss=1.568, ppl=2.97, wps=13963.6, ups=1.14, wpb=12231.7, bsz=433.4, num_updates=126400, lr=6.16236e-06, gnorm=0.89, train_wall=51, wall=0
2021-03-15 12:18:44 | INFO | train_inner | epoch 044:    166 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23481, ups=1.9, wpb=12361.4, bsz=428, num_updates=126500, lr=6.15992e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 12:19:37 | INFO | train_inner | epoch 044:    266 / 2938 loss=3.294, nll_loss=1.579, ppl=2.99, wps=23546.4, ups=1.9, wpb=12382.2, bsz=428.6, num_updates=126600, lr=6.15749e-06, gnorm=0.883, train_wall=52, wall=0
2021-03-15 12:20:29 | INFO | train_inner | epoch 044:    366 / 2938 loss=3.257, nll_loss=1.538, ppl=2.9, wps=23713.1, ups=1.91, wpb=12392.2, bsz=413.2, num_updates=126700, lr=6.15506e-06, gnorm=0.873, train_wall=52, wall=0
2021-03-15 12:21:22 | INFO | train_inner | epoch 044:    466 / 2938 loss=3.279, nll_loss=1.562, ppl=2.95, wps=23074.4, ups=1.87, wpb=12347.4, bsz=447.2, num_updates=126800, lr=6.15263e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 12:22:15 | INFO | train_inner | epoch 044:    566 / 2938 loss=3.306, nll_loss=1.592, ppl=3.01, wps=23137.6, ups=1.9, wpb=12206.1, bsz=443.8, num_updates=126900, lr=6.15021e-06, gnorm=0.895, train_wall=53, wall=0
2021-03-15 12:23:08 | INFO | train_inner | epoch 044:    666 / 2938 loss=3.261, nll_loss=1.542, ppl=2.91, wps=23533.9, ups=1.89, wpb=12424.5, bsz=419.4, num_updates=127000, lr=6.14779e-06, gnorm=0.864, train_wall=53, wall=0
2021-03-15 12:24:01 | INFO | train_inner | epoch 044:    766 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=22943.2, ups=1.87, wpb=12280.4, bsz=444.8, num_updates=127100, lr=6.14537e-06, gnorm=0.885, train_wall=53, wall=0
2021-03-15 12:24:54 | INFO | train_inner | epoch 044:    866 / 2938 loss=3.291, nll_loss=1.575, ppl=2.98, wps=23591.1, ups=1.9, wpb=12385.3, bsz=422.4, num_updates=127200, lr=6.14295e-06, gnorm=0.879, train_wall=52, wall=0
2021-03-15 12:25:46 | INFO | train_inner | epoch 044:    966 / 2938 loss=3.314, nll_loss=1.602, ppl=3.03, wps=23537.7, ups=1.92, wpb=12235.1, bsz=416.2, num_updates=127300, lr=6.14054e-06, gnorm=0.893, train_wall=52, wall=0
2021-03-15 12:26:39 | INFO | train_inner | epoch 044:   1066 / 2938 loss=3.289, nll_loss=1.573, ppl=2.98, wps=23311.6, ups=1.89, wpb=12324.9, bsz=447.4, num_updates=127400, lr=6.13813e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 12:27:31 | INFO | train_inner | epoch 044:   1166 / 2938 loss=3.305, nll_loss=1.592, ppl=3.01, wps=23352.8, ups=1.9, wpb=12280, bsz=425, num_updates=127500, lr=6.13572e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 12:28:23 | INFO | train_inner | epoch 044:   1266 / 2938 loss=3.287, nll_loss=1.57, ppl=2.97, wps=23901.2, ups=1.92, wpb=12429.2, bsz=403.7, num_updates=127600, lr=6.13332e-06, gnorm=0.876, train_wall=52, wall=0
2021-03-15 12:29:16 | INFO | train_inner | epoch 044:   1366 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=23609.4, ups=1.9, wpb=12423.6, bsz=433.3, num_updates=127700, lr=6.13091e-06, gnorm=0.874, train_wall=52, wall=0
2021-03-15 12:30:09 | INFO | train_inner | epoch 044:   1466 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23251.3, ups=1.88, wpb=12370.2, bsz=431.2, num_updates=127800, lr=6.12851e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 12:31:01 | INFO | train_inner | epoch 044:   1566 / 2938 loss=3.296, nll_loss=1.581, ppl=2.99, wps=23793.6, ups=1.93, wpb=12304.7, bsz=395.5, num_updates=127900, lr=6.12612e-06, gnorm=0.89, train_wall=52, wall=0
2021-03-15 12:31:54 | INFO | train_inner | epoch 044:   1666 / 2938 loss=3.297, nll_loss=1.583, ppl=2.99, wps=23205.8, ups=1.9, wpb=12234.6, bsz=426.7, num_updates=128000, lr=6.12372e-06, gnorm=0.893, train_wall=53, wall=0
2021-03-15 12:32:46 | INFO | train_inner | epoch 044:   1766 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=23299.6, ups=1.91, wpb=12193.3, bsz=436, num_updates=128100, lr=6.12133e-06, gnorm=0.892, train_wall=52, wall=0
2021-03-15 12:33:38 | INFO | train_inner | epoch 044:   1866 / 2938 loss=3.278, nll_loss=1.561, ppl=2.95, wps=23863.4, ups=1.93, wpb=12390.3, bsz=390.4, num_updates=128200, lr=6.11895e-06, gnorm=0.878, train_wall=52, wall=0
2021-03-15 12:34:31 | INFO | train_inner | epoch 044:   1966 / 2938 loss=3.285, nll_loss=1.568, ppl=2.97, wps=23241.4, ups=1.89, wpb=12318, bsz=441.1, num_updates=128300, lr=6.11656e-06, gnorm=0.894, train_wall=53, wall=0
2021-03-15 12:35:24 | INFO | train_inner | epoch 044:   2066 / 2938 loss=3.295, nll_loss=1.58, ppl=2.99, wps=23277.4, ups=1.88, wpb=12354.6, bsz=442.7, num_updates=128400, lr=6.11418e-06, gnorm=0.883, train_wall=53, wall=0
2021-03-15 12:36:17 | INFO | train_inner | epoch 044:   2166 / 2938 loss=3.31, nll_loss=1.596, ppl=3.02, wps=23241.6, ups=1.87, wpb=12400, bsz=441, num_updates=128500, lr=6.1118e-06, gnorm=0.889, train_wall=53, wall=0
2021-03-15 12:37:10 | INFO | train_inner | epoch 044:   2266 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=23546.4, ups=1.91, wpb=12345.3, bsz=411.9, num_updates=128600, lr=6.10942e-06, gnorm=0.903, train_wall=52, wall=0
2021-03-15 12:38:02 | INFO | train_inner | epoch 044:   2366 / 2938 loss=3.304, nll_loss=1.59, ppl=3.01, wps=23519.3, ups=1.9, wpb=12364.8, bsz=418.5, num_updates=128700, lr=6.10705e-06, gnorm=0.89, train_wall=52, wall=0
2021-03-15 12:38:54 | INFO | train_inner | epoch 044:   2466 / 2938 loss=3.302, nll_loss=1.588, ppl=3.01, wps=23927.2, ups=1.94, wpb=12343.5, bsz=399.8, num_updates=128800, lr=6.10468e-06, gnorm=0.883, train_wall=51, wall=0
2021-03-15 12:39:47 | INFO | train_inner | epoch 044:   2566 / 2938 loss=3.275, nll_loss=1.558, ppl=2.95, wps=23552.9, ups=1.89, wpb=12450.8, bsz=433.9, num_updates=128900, lr=6.10231e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 12:40:42 | INFO | train_inner | epoch 044:   2666 / 2938 loss=3.274, nll_loss=1.557, ppl=2.94, wps=22549.8, ups=1.82, wpb=12409, bsz=460.9, num_updates=129000, lr=6.09994e-06, gnorm=0.876, train_wall=55, wall=0
2021-03-15 12:41:34 | INFO | train_inner | epoch 044:   2766 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23702.2, ups=1.91, wpb=12424.7, bsz=411.5, num_updates=129100, lr=6.09758e-06, gnorm=0.882, train_wall=52, wall=0
2021-03-15 12:42:27 | INFO | train_inner | epoch 044:   2866 / 2938 loss=3.328, nll_loss=1.617, ppl=3.07, wps=23212.3, ups=1.9, wpb=12237.8, bsz=412.4, num_updates=129200, lr=6.09522e-06, gnorm=0.896, train_wall=53, wall=0
2021-03-15 12:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 12:43:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:22 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.522 | nll_loss 8.483 | ppl 357.89 | bleu 15.78 | wps 4373.6 | wpb 6344.2 | bsz 166.4 | num_updates 129272 | best_bleu 15.9
2021-03-15 12:43:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 12:43:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 44 @ 129272 updates, score 15.78) (writing took 5.200801329687238 seconds)
2021-03-15 12:43:28 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-03-15 12:43:28 | INFO | train | epoch 044 | loss 3.293 | nll_loss 1.578 | ppl 2.98 | wps 22892 | ups 1.86 | wpb 12340.4 | bsz 426.5 | num_updates 129272 | lr 6.09352e-06 | gnorm 0.884 | train_wall 1542 | wall 0
2021-03-15 12:43:33 | INFO | fairseq.trainer | begin training epoch 45
2021-03-15 12:43:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 12:43:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 12:43:55 | INFO | train_inner | epoch 045:     28 / 2938 loss=3.301, nll_loss=1.588, ppl=3.01, wps=13983.5, ups=1.14, wpb=12287.6, bsz=415.4, num_updates=129300, lr=6.09286e-06, gnorm=0.893, train_wall=52, wall=0
2021-03-15 12:44:47 | INFO | train_inner | epoch 045:    128 / 2938 loss=3.29, nll_loss=1.575, ppl=2.98, wps=23502.5, ups=1.92, wpb=12229.4, bsz=423, num_updates=129400, lr=6.09051e-06, gnorm=0.885, train_wall=52, wall=0
2021-03-15 12:45:39 | INFO | train_inner | epoch 045:    228 / 2938 loss=3.292, nll_loss=1.577, ppl=2.98, wps=23633.6, ups=1.91, wpb=12360, bsz=426.2, num_updates=129500, lr=6.08816e-06, gnorm=0.884, train_wall=52, wall=0
2021-03-15 12:46:32 | INFO | train_inner | epoch 045:    328 / 2938 loss=3.268, nll_loss=1.549, ppl=2.93, wps=23321.8, ups=1.88, wpb=12410.6, bsz=441.5, num_updates=129600, lr=6.08581e-06, gnorm=0.873, train_wall=53, wall=0
2021-03-15 12:47:24 | INFO | train_inner | epoch 045:    428 / 2938 loss=3.271, nll_loss=1.553, ppl=2.93, wps=23834.8, ups=1.92, wpb=12426.5, bsz=408.3, num_updates=129700, lr=6.08346e-06, gnorm=0.869, train_wall=52, wall=0
2021-03-15 12:48:18 | INFO | train_inner | epoch 045:    528 / 2938 loss=3.268, nll_loss=1.55, ppl=2.93, wps=23135.3, ups=1.87, wpb=12401.7, bsz=450.6, num_updates=129800, lr=6.08112e-06, gnorm=0.874, train_wall=53, wall=0
2021-03-15 12:49:11 | INFO | train_inner | epoch 045:    628 / 2938 loss=3.27, nll_loss=1.552, ppl=2.93, wps=23481, ups=1.9, wpb=12368, bsz=439, num_updates=129900, lr=6.07877e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 12:50:03 | INFO | train_inner | epoch 045:    728 / 2938 loss=3.291, nll_loss=1.576, ppl=2.98, wps=23498.5, ups=1.9, wpb=12360.8, bsz=431.8, num_updates=130000, lr=6.07644e-06, gnorm=0.886, train_wall=52, wall=0
2021-03-15 12:50:55 | INFO | train_inner | epoch 045:    828 / 2938 loss=3.298, nll_loss=1.583, ppl=3, wps=23666.3, ups=1.93, wpb=12247.3, bsz=407.4, num_updates=130100, lr=6.0741e-06, gnorm=0.893, train_wall=52, wall=0
2021-03-15 12:51:47 | INFO | train_inner | epoch 045:    928 / 2938 loss=3.307, nll_loss=1.594, ppl=3.02, wps=23604, ups=1.93, wpb=12246.2, bsz=409.1, num_updates=130200, lr=6.07177e-06, gnorm=0.901, train_wall=52, wall=0
2021-03-15 12:52:40 | INFO | train_inner | epoch 045:   1028 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23412.6, ups=1.9, wpb=12343.2, bsz=426.8, num_updates=130300, lr=6.06944e-06, gnorm=0.882, train_wall=53, wall=0
2021-03-15 12:53:35 | INFO | train_inner | epoch 045:   1128 / 2938 loss=3.286, nll_loss=1.57, ppl=2.97, wps=22198.5, ups=1.8, wpb=12347.4, bsz=466.3, num_updates=130400, lr=6.06711e-06, gnorm=0.907, train_wall=55, wall=0
2021-03-15 12:54:28 | INFO | train_inner | epoch 045:   1228 / 2938 loss=3.3, nll_loss=1.586, ppl=3, wps=23315.3, ups=1.9, wpb=12301, bsz=442.5, num_updates=130500, lr=6.06478e-06, gnorm=0.895, train_wall=53, wall=0
2021-03-15 12:55:22 | INFO | train_inner | epoch 045:   1328 / 2938 loss=3.27, nll_loss=1.551, ppl=2.93, wps=23170.5, ups=1.87, wpb=12407.8, bsz=432.2, num_updates=130600, lr=6.06246e-06, gnorm=0.879, train_wall=53, wall=0
2021-03-15 12:56:14 | INFO | train_inner | epoch 045:   1428 / 2938 loss=3.287, nll_loss=1.571, ppl=2.97, wps=23441.2, ups=1.9, wpb=12327.2, bsz=421.3, num_updates=130700, lr=6.06014e-06, gnorm=0.887, train_wall=52, wall=0
2021-03-15 12:57:07 | INFO | train_inner | epoch 045:   1528 / 2938 loss=3.306, nll_loss=1.592, ppl=3.02, wps=23419.1, ups=1.9, wpb=12300.1, bsz=409.8, num_updates=130800, lr=6.05783e-06, gnorm=0.887, train_wall=52, wall=0
2021-03-15 12:57:59 | INFO | train_inner | epoch 045:   1628 / 2938 loss=3.309, nll_loss=1.596, ppl=3.02, wps=23676.8, ups=1.92, wpb=12356.3, bsz=415.4, num_updates=130900, lr=6.05551e-06, gnorm=0.886, train_wall=52, wall=0
2021-03-15 12:58:53 | INFO | train_inner | epoch 045:   1728 / 2938 loss=3.28, nll_loss=1.563, ppl=2.95, wps=23016.9, ups=1.86, wpb=12381.4, bsz=440.5, num_updates=131000, lr=6.0532e-06, gnorm=0.873, train_wall=54, wall=0
2021-03-15 12:59:45 | INFO | train_inner | epoch 045:   1828 / 2938 loss=3.302, nll_loss=1.587, ppl=3, wps=23477.1, ups=1.91, wpb=12287, bsz=417, num_updates=131100, lr=6.05089e-06, gnorm=0.892, train_wall=52, wall=0
2021-03-15 13:00:37 | INFO | train_inner | epoch 045:   1928 / 2938 loss=3.303, nll_loss=1.589, ppl=3.01, wps=23491.5, ups=1.91, wpb=12267.3, bsz=409.7, num_updates=131200, lr=6.04858e-06, gnorm=0.9, train_wall=52, wall=0
2021-03-15 13:01:29 | INFO | train_inner | epoch 045:   2028 / 2938 loss=3.273, nll_loss=1.555, ppl=2.94, wps=23873.7, ups=1.92, wpb=12464, bsz=432.7, num_updates=131300, lr=6.04628e-06, gnorm=0.869, train_wall=52, wall=0
2021-03-15 13:02:22 | INFO | train_inner | epoch 045:   2128 / 2938 loss=3.307, nll_loss=1.593, ppl=3.02, wps=23366.6, ups=1.89, wpb=12335.4, bsz=415.8, num_updates=131400, lr=6.04398e-06, gnorm=0.888, train_wall=53, wall=0
2021-03-15 13:03:16 | INFO | train_inner | epoch 045:   2228 / 2938 loss=3.288, nll_loss=1.574, ppl=2.98, wps=23227.1, ups=1.88, wpb=12381.8, bsz=447, num_updates=131500, lr=6.04168e-06, gnorm=0.881, train_wall=53, wall=0
2021-03-15 13:04:09 | INFO | train_inner | epoch 045:   2328 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=23043.2, ups=1.88, wpb=12280.6, bsz=437, num_updates=131600, lr=6.03938e-06, gnorm=0.892, train_wall=53, wall=0
2021-03-15 13:05:01 | INFO | train_inner | epoch 045:   2428 / 2938 loss=3.284, nll_loss=1.568, ppl=2.96, wps=23906.3, ups=1.93, wpb=12392.9, bsz=402.9, num_updates=131700, lr=6.03709e-06, gnorm=0.88, train_wall=52, wall=0
2021-03-15 13:05:53 | INFO | train_inner | epoch 045:   2528 / 2938 loss=3.285, nll_loss=1.569, ppl=2.97, wps=23574.2, ups=1.9, wpb=12419.1, bsz=418.7, num_updates=131800, lr=6.0348e-06, gnorm=0.88, train_wall=53, wall=0
2021-03-15 13:06:47 | INFO | train_inner | epoch 045:   2628 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=22967.1, ups=1.87, wpb=12303.5, bsz=467.3, num_updates=131900, lr=6.03251e-06, gnorm=0.884, train_wall=53, wall=0
2021-03-15 13:07:40 | INFO | train_inner | epoch 045:   2728 / 2938 loss=3.313, nll_loss=1.601, ppl=3.03, wps=23473.6, ups=1.9, wpb=12340.1, bsz=420.2, num_updates=132000, lr=6.03023e-06, gnorm=0.888, train_wall=52, wall=0
2021-03-15 13:08:33 | INFO | train_inner | epoch 045:   2828 / 2938 loss=3.296, nll_loss=1.582, ppl=2.99, wps=22997.2, ups=1.86, wpb=12353.4, bsz=421.4, num_updates=132100, lr=6.02794e-06, gnorm=0.886, train_wall=54, wall=0
2021-03-15 13:09:25 | INFO | train_inner | epoch 045:   2928 / 2938 loss=3.299, nll_loss=1.585, ppl=3, wps=23745.4, ups=1.93, wpb=12294.3, bsz=398.3, num_updates=132200, lr=6.02566e-06, gnorm=0.892, train_wall=52, wall=0
2021-03-15 13:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 13:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:09:48 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.513 | nll_loss 8.475 | ppl 355.74 | bleu 15.7 | wps 4420.1 | wpb 6344.2 | bsz 166.4 | num_updates 132210 | best_bleu 15.9
2021-03-15 13:09:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 13:09:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ././examples/_transformer_base/bash/../bash/../checkpoints/remove_dirty_s1/checkpoint_last.pt (epoch 45 @ 132210 updates, score 15.7) (writing took 4.699732978828251 seconds)
2021-03-15 13:09:52 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-03-15 13:09:52 | INFO | train | epoch 045 | loss 3.292 | nll_loss 1.577 | ppl 2.98 | wps 22879.5 | ups 1.85 | wpb 12340.4 | bsz 426.5 | num_updates 132210 | lr 6.02544e-06 | gnorm 0.885 | train_wall 1544 | wall 0
2021-03-15 13:09:58 | INFO | fairseq.trainer | begin training epoch 46
2021-03-15 13:09:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:09:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:10:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:10:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:10:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-03-15 13:10:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-03-15 13:10:52 | INFO | train_inner | epoch 046:     90 / 2938 loss=3.299, nll_loss=1.584, ppl=3, wps=14186.2, ups=1.15, wpb=12284.1, bsz=425.5, num_updates=132300, lr=6.02339e-06, gnorm=0.887, train_wall=51, wall=0
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 276 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
