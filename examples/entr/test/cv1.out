nohup: ignoring input
save_dir=./examples/entr/bash/../checkpoints/closer_gap
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.0000125
lrscheduler=fixed
warmup_updates=0
max_epoch=100
r3f_lambda=1
extr='--noised-no-grad --cv 0.05'
2020-12-18 23:13:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:13:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:13:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:13:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:13:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:13:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:13:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:13:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:13:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:13:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:13:56 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:17052
2020-12-18 23:13:56 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:17052
2020-12-18 23:13:56 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:17052
2020-12-18 23:13:56 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:17052
2020-12-18 23:13:57 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-18 23:13:57 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-18 23:13:57 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-18 23:13:57 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-18 23:14:01 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=True, data='./examples/entr/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:17052', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[1.25e-05], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/entr/bash/../checkpoints/closer_gap', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='tr', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, weight_decay=0.0, zero_sharding='none')
2020-12-18 23:14:01 | INFO | fairseq.tasks.translation | [en] dictionary: 19784 types
2020-12-18 23:14:01 | INFO | fairseq.tasks.translation | [tr] dictionary: 19784 types
2020-12-18 23:14:01 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.en
2020-12-18 23:14:01 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.tr
2020-12-18 23:14:01 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin valid en-tr 3000 examples
2020-12-18 23:14:02 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19784, bias=False)
  )
)
2020-12-18 23:14:02 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-18 23:14:02 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2020-12-18 23:14:02 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2020-12-18 23:14:02 | INFO | fairseq_cli.train | num. model params: 54267904 (num. trained: 54267904)
2020-12-18 23:14:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2020-12-18 23:14:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2020-12-18 23:14:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-18 23:14:03 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-18 23:14:03 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-18 23:14:03 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-18 23:14:03 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-18 23:14:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-18 23:14:03 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2020-12-18 23:14:03 | INFO | fairseq_cli.train | max tokens per GPU = 4000 and max sentences per GPU = None
2020-12-18 23:14:03 | INFO | fairseq.checkpoint_utils | loading pretrained model from ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2020-12-18 23:14:03 | INFO | fairseq.trainer | loaded checkpoint ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt (epoch 106 @ 0 updates)
2020-12-18 23:14:03 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-18 23:14:03 | INFO | fairseq.trainer | loading train data for epoch 1
2020-12-18 23:14:03 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.en
2020-12-18 23:14:03 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.tr
2020-12-18 23:14:03 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin train en-tr 207373 examples
2020-12-18 23:14:04 | INFO | fairseq.trainer | begin training epoch 1
2020-12-18 23:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:14:59 | INFO | train_inner | epoch 001:    100 / 421 symm_kl=0.901, self_kl=0, self_cv=17.236, loss=5.277, nll_loss=1.049, ppl=2.07, wps=27585, ups=1.95, wpb=14145.4, bsz=485.9, num_updates=100, lr=1.25e-05, gnorm=1.394, train_wall=52, wall=56
2020-12-18 23:15:50 | INFO | train_inner | epoch 001:    200 / 421 symm_kl=0.786, self_kl=0, self_cv=16.058, loss=5.056, nll_loss=1.117, ppl=2.17, wps=27576.9, ups=1.97, wpb=13995.2, bsz=501.2, num_updates=200, lr=1.25e-05, gnorm=1.103, train_wall=51, wall=107
2020-12-18 23:16:41 | INFO | train_inner | epoch 001:    300 / 421 symm_kl=0.751, self_kl=0, self_cv=15.766, loss=4.994, nll_loss=1.134, ppl=2.19, wps=27235.1, ups=1.95, wpb=13972.8, bsz=508.7, num_updates=300, lr=1.25e-05, gnorm=1.045, train_wall=51, wall=158
2020-12-18 23:17:32 | INFO | train_inner | epoch 001:    400 / 421 symm_kl=0.738, self_kl=0, self_cv=15.703, loss=4.981, nll_loss=1.145, ppl=2.21, wps=27170.4, ups=1.96, wpb=13886.9, bsz=487.4, num_updates=400, lr=1.25e-05, gnorm=1.026, train_wall=51, wall=210
2020-12-18 23:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:17:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:17:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:17:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:17:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:17:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:17:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:17:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:17:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:17:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:17:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:17:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:17:59 | INFO | valid | epoch 001 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.382 | nll_loss 3.96 | ppl 15.56 | bleu 22.47 | wps 6277.9 | wpb 10324.2 | bsz 375 | num_updates 421
2020-12-18 23:17:59 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:18:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:18:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:18:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:18:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 1 @ 421 updates, score 22.47) (writing took 2.4246052503585815 seconds)
2020-12-18 23:18:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-12-18 23:18:01 | INFO | train | epoch 001 | symm_kl 0.792 | self_kl 0 | self_cv 16.177 | loss 5.074 | nll_loss 1.113 | ppl 2.16 | wps 25155.5 | ups 1.8 | wpb 13969.5 | bsz 492.6 | num_updates 421 | lr 1.25e-05 | gnorm 1.138 | train_wall 215 | wall 239
2020-12-18 23:18:01 | INFO | fairseq.trainer | begin training epoch 2
2020-12-18 23:18:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:18:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:18:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:18:44 | INFO | train_inner | epoch 002:     79 / 421 symm_kl=0.726, self_kl=0, self_cv=15.658, loss=4.955, nll_loss=1.139, ppl=2.2, wps=19142.1, ups=1.38, wpb=13861.1, bsz=487.7, num_updates=500, lr=1.25e-05, gnorm=1.009, train_wall=51, wall=282
2020-12-18 23:19:36 | INFO | train_inner | epoch 002:    179 / 421 symm_kl=0.705, self_kl=0, self_cv=15.545, loss=4.907, nll_loss=1.128, ppl=2.19, wps=27324.6, ups=1.95, wpb=14007.7, bsz=489.9, num_updates=600, lr=1.25e-05, gnorm=0.979, train_wall=51, wall=333
2020-12-18 23:20:27 | INFO | train_inner | epoch 002:    279 / 421 symm_kl=0.7, self_kl=0, self_cv=15.547, loss=4.904, nll_loss=1.134, ppl=2.19, wps=27414, ups=1.95, wpb=14033.1, bsz=489, num_updates=700, lr=1.25e-05, gnorm=0.972, train_wall=51, wall=384
2020-12-18 23:21:18 | INFO | train_inner | epoch 002:    379 / 421 symm_kl=0.701, self_kl=0, self_cv=15.543, loss=4.922, nll_loss=1.153, ppl=2.22, wps=27286.2, ups=1.96, wpb=13928.4, bsz=496.1, num_updates=800, lr=1.25e-05, gnorm=0.967, train_wall=51, wall=435
2020-12-18 23:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:21:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:21:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:21:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:21:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:21:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:21:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:21:57 | INFO | valid | epoch 002 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.346 | nll_loss 3.928 | ppl 15.22 | bleu 22.39 | wps 5418.2 | wpb 10324.2 | bsz 375 | num_updates 842 | best_bleu 22.47
2020-12-18 23:21:57 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:21:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:21:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:22:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:22:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:22:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:22:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 2 @ 842 updates, score 22.39) (writing took 3.083586746826768 seconds)
2020-12-18 23:22:00 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-12-18 23:22:00 | INFO | train | epoch 002 | symm_kl 0.705 | self_kl 0 | self_cv 15.55 | loss 4.915 | nll_loss 1.138 | ppl 2.2 | wps 24613.4 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 842 | lr 1.25e-05 | gnorm 0.978 | train_wall 214 | wall 478
2020-12-18 23:22:00 | INFO | fairseq.trainer | begin training epoch 3
2020-12-18 23:22:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:22:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:22:32 | INFO | train_inner | epoch 003:     58 / 421 symm_kl=0.685, self_kl=0, self_cv=15.405, loss=4.874, nll_loss=1.136, ppl=2.2, wps=18651.5, ups=1.34, wpb=13895.5, bsz=482.9, num_updates=900, lr=1.25e-05, gnorm=0.966, train_wall=50, wall=510
2020-12-18 23:23:24 | INFO | train_inner | epoch 003:    158 / 421 symm_kl=0.682, self_kl=0, self_cv=15.46, loss=4.879, nll_loss=1.141, ppl=2.21, wps=27203.6, ups=1.95, wpb=13938, bsz=507, num_updates=1000, lr=1.25e-05, gnorm=0.943, train_wall=51, wall=561
2020-12-18 23:24:15 | INFO | train_inner | epoch 003:    258 / 421 symm_kl=0.685, self_kl=0, self_cv=15.433, loss=4.885, nll_loss=1.147, ppl=2.21, wps=27391.7, ups=1.96, wpb=13957.9, bsz=482.5, num_updates=1100, lr=1.25e-05, gnorm=0.95, train_wall=51, wall=612
2020-12-18 23:25:06 | INFO | train_inner | epoch 003:    358 / 421 symm_kl=0.669, self_kl=0, self_cv=15.385, loss=4.851, nll_loss=1.138, ppl=2.2, wps=27537.2, ups=1.95, wpb=14135, bsz=507.8, num_updates=1200, lr=1.25e-05, gnorm=0.924, train_wall=51, wall=663
2020-12-18 23:25:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:25:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:25:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:25:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:25:54 | INFO | valid | epoch 003 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.322 | nll_loss 3.899 | ppl 14.92 | bleu 22.46 | wps 6164.8 | wpb 10324.2 | bsz 375 | num_updates 1263 | best_bleu 22.47
2020-12-18 23:25:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:25:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:25:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:25:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 3 @ 1263 updates, score 22.46) (writing took 2.99568491615355 seconds)
2020-12-18 23:25:57 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-12-18 23:25:57 | INFO | train | epoch 003 | symm_kl 0.678 | self_kl 0 | self_cv 15.409 | loss 4.867 | nll_loss 1.139 | ppl 2.2 | wps 24821.5 | ups 1.78 | wpb 13969.5 | bsz 492.6 | num_updates 1263 | lr 1.25e-05 | gnorm 0.943 | train_wall 214 | wall 715
2020-12-18 23:25:57 | INFO | fairseq.trainer | begin training epoch 4
2020-12-18 23:25:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:26:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:26:19 | INFO | train_inner | epoch 004:     37 / 421 symm_kl=0.674, self_kl=0, self_cv=15.398, loss=4.86, nll_loss=1.138, ppl=2.2, wps=19094.8, ups=1.37, wpb=13896.1, bsz=467.7, num_updates=1300, lr=1.25e-05, gnorm=0.951, train_wall=50, wall=736
2020-12-18 23:27:10 | INFO | train_inner | epoch 004:    137 / 421 symm_kl=0.668, self_kl=0, self_cv=15.396, loss=4.849, nll_loss=1.136, ppl=2.2, wps=26950.6, ups=1.96, wpb=13735.4, bsz=496.9, num_updates=1400, lr=1.25e-05, gnorm=0.944, train_wall=51, wall=787
2020-12-18 23:28:01 | INFO | train_inner | epoch 004:    237 / 421 symm_kl=0.663, self_kl=0, self_cv=15.4, loss=4.844, nll_loss=1.138, ppl=2.2, wps=27680.6, ups=1.96, wpb=14090.6, bsz=475.5, num_updates=1500, lr=1.25e-05, gnorm=0.922, train_wall=51, wall=838
2020-12-18 23:28:52 | INFO | train_inner | epoch 004:    337 / 421 symm_kl=0.653, self_kl=0, self_cv=15.287, loss=4.818, nll_loss=1.134, ppl=2.19, wps=27545.1, ups=1.96, wpb=14057, bsz=499.7, num_updates=1600, lr=1.25e-05, gnorm=0.906, train_wall=51, wall=889
2020-12-18 23:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:29:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:29:51 | INFO | valid | epoch 004 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.311 | nll_loss 3.888 | ppl 14.8 | bleu 22.48 | wps 6060.7 | wpb 10324.2 | bsz 375 | num_updates 1684 | best_bleu 22.48
2020-12-18 23:29:51 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:29:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:29:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 4 @ 1684 updates, score 22.48) (writing took 5.186820320785046 seconds)
2020-12-18 23:29:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-12-18 23:29:56 | INFO | train | epoch 004 | symm_kl 0.659 | self_kl 0 | self_cv 15.337 | loss 4.833 | nll_loss 1.137 | ppl 2.2 | wps 24611.8 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 1684 | lr 1.25e-05 | gnorm 0.923 | train_wall 213 | wall 954
2020-12-18 23:29:56 | INFO | fairseq.trainer | begin training epoch 5
2020-12-18 23:29:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:29:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:30:07 | INFO | train_inner | epoch 005:     16 / 421 symm_kl=0.648, self_kl=0, self_cv=15.224, loss=4.808, nll_loss=1.137, ppl=2.2, wps=18477.3, ups=1.32, wpb=13973, bsz=503, num_updates=1700, lr=1.25e-05, gnorm=0.91, train_wall=51, wall=965
2020-12-18 23:30:58 | INFO | train_inner | epoch 005:    116 / 421 symm_kl=0.646, self_kl=0, self_cv=15.298, loss=4.806, nll_loss=1.13, ppl=2.19, wps=27540.2, ups=1.97, wpb=13947.8, bsz=499.7, num_updates=1800, lr=1.25e-05, gnorm=0.909, train_wall=50, wall=1015
2020-12-18 23:31:49 | INFO | train_inner | epoch 005:    216 / 421 symm_kl=0.648, self_kl=0, self_cv=15.281, loss=4.816, nll_loss=1.14, ppl=2.2, wps=27506.6, ups=1.96, wpb=14054.4, bsz=484.6, num_updates=1900, lr=1.25e-05, gnorm=0.906, train_wall=51, wall=1066
2020-12-18 23:32:40 | INFO | train_inner | epoch 005:    316 / 421 symm_kl=0.646, self_kl=0, self_cv=15.213, loss=4.809, nll_loss=1.141, ppl=2.21, wps=27183, ups=1.95, wpb=13937.1, bsz=501.2, num_updates=2000, lr=1.25e-05, gnorm=0.908, train_wall=51, wall=1118
2020-12-18 23:33:32 | INFO | train_inner | epoch 005:    416 / 421 symm_kl=0.638, self_kl=0, self_cv=15.237, loss=4.786, nll_loss=1.127, ppl=2.18, wps=27324.4, ups=1.95, wpb=14006.7, bsz=492.6, num_updates=2100, lr=1.25e-05, gnorm=0.897, train_wall=51, wall=1169
2020-12-18 23:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:33:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:33:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:33:50 | INFO | valid | epoch 005 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.302 | nll_loss 3.88 | ppl 14.72 | bleu 22.54 | wps 6163.8 | wpb 10324.2 | bsz 375 | num_updates 2105 | best_bleu 22.54
2020-12-18 23:33:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:33:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:33:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 5 @ 2105 updates, score 22.54) (writing took 4.931237364187837 seconds)
2020-12-18 23:33:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-12-18 23:33:55 | INFO | train | epoch 005 | symm_kl 0.645 | self_kl 0 | self_cv 15.259 | loss 4.806 | nll_loss 1.135 | ppl 2.2 | wps 24601.6 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 2105 | lr 1.25e-05 | gnorm 0.907 | train_wall 214 | wall 1193
2020-12-18 23:33:55 | INFO | fairseq.trainer | begin training epoch 6
2020-12-18 23:33:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:33:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:34:47 | INFO | train_inner | epoch 006:     95 / 421 symm_kl=0.637, self_kl=0, self_cv=15.166, loss=4.782, nll_loss=1.13, ppl=2.19, wps=18384.7, ups=1.33, wpb=13827.8, bsz=506.6, num_updates=2200, lr=1.25e-05, gnorm=0.908, train_wall=51, wall=1244
2020-12-18 23:35:38 | INFO | train_inner | epoch 006:    195 / 421 symm_kl=0.636, self_kl=0, self_cv=15.234, loss=4.792, nll_loss=1.136, ppl=2.2, wps=27491, ups=1.95, wpb=14087.8, bsz=489.6, num_updates=2300, lr=1.25e-05, gnorm=0.889, train_wall=51, wall=1295
2020-12-18 23:36:29 | INFO | train_inner | epoch 006:    295 / 421 symm_kl=0.638, self_kl=0, self_cv=15.271, loss=4.8, nll_loss=1.14, ppl=2.2, wps=27608.7, ups=1.97, wpb=14036.1, bsz=477.8, num_updates=2400, lr=1.25e-05, gnorm=0.897, train_wall=51, wall=1346
2020-12-18 23:37:20 | INFO | train_inner | epoch 006:    395 / 421 symm_kl=0.624, self_kl=0, self_cv=15.118, loss=4.756, nll_loss=1.125, ppl=2.18, wps=27350, ups=1.95, wpb=13994.5, bsz=506.2, num_updates=2500, lr=1.25e-05, gnorm=0.879, train_wall=51, wall=1397
2020-12-18 23:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:37:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:37:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:37:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:37:49 | INFO | valid | epoch 006 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.293 | nll_loss 3.871 | ppl 14.63 | bleu 22.62 | wps 6440.3 | wpb 10324.2 | bsz 375 | num_updates 2526 | best_bleu 22.62
2020-12-18 23:37:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:37:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 6 @ 2526 updates, score 22.62) (writing took 5.272247923538089 seconds)
2020-12-18 23:37:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-12-18 23:37:54 | INFO | train | epoch 006 | symm_kl 0.634 | self_kl 0 | self_cv 15.207 | loss 4.785 | nll_loss 1.134 | ppl 2.19 | wps 24594.6 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 2526 | lr 1.25e-05 | gnorm 0.894 | train_wall 214 | wall 1432
2020-12-18 23:37:54 | INFO | fairseq.trainer | begin training epoch 7
2020-12-18 23:37:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:37:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:38:35 | INFO | train_inner | epoch 007:     74 / 421 symm_kl=0.631, self_kl=0, self_cv=15.218, loss=4.784, nll_loss=1.138, ppl=2.2, wps=18401.9, ups=1.34, wpb=13772.9, bsz=486.4, num_updates=2600, lr=1.25e-05, gnorm=0.898, train_wall=50, wall=1472
2020-12-18 23:39:26 | INFO | train_inner | epoch 007:    174 / 421 symm_kl=0.629, self_kl=0, self_cv=15.164, loss=4.778, nll_loss=1.137, ppl=2.2, wps=27178.6, ups=1.95, wpb=13910.1, bsz=482.8, num_updates=2700, lr=1.25e-05, gnorm=0.884, train_wall=51, wall=1524
2020-12-18 23:40:17 | INFO | train_inner | epoch 007:    274 / 421 symm_kl=0.627, self_kl=0, self_cv=15.194, loss=4.773, nll_loss=1.134, ppl=2.19, wps=27220.8, ups=1.96, wpb=13879.3, bsz=492.2, num_updates=2800, lr=1.25e-05, gnorm=0.884, train_wall=51, wall=1575
2020-12-18 23:41:09 | INFO | train_inner | epoch 007:    374 / 421 symm_kl=0.622, self_kl=0, self_cv=15.158, loss=4.761, nll_loss=1.13, ppl=2.19, wps=27497.6, ups=1.94, wpb=14151.4, bsz=491.7, num_updates=2900, lr=1.25e-05, gnorm=0.879, train_wall=51, wall=1626
2020-12-18 23:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:41:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:41:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:41:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:41:51 | INFO | valid | epoch 007 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.288 | nll_loss 3.865 | ppl 14.57 | bleu 22.46 | wps 5397.3 | wpb 10324.2 | bsz 375 | num_updates 2947 | best_bleu 22.62
2020-12-18 23:41:51 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:41:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:41:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 7 @ 2947 updates, score 22.46) (writing took 3.0184978954494 seconds)
2020-12-18 23:41:54 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-12-18 23:41:54 | INFO | train | epoch 007 | symm_kl 0.625 | self_kl 0 | self_cv 15.159 | loss 4.768 | nll_loss 1.133 | ppl 2.19 | wps 24584.8 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 2947 | lr 1.25e-05 | gnorm 0.883 | train_wall 214 | wall 1671
2020-12-18 23:41:54 | INFO | fairseq.trainer | begin training epoch 8
2020-12-18 23:41:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:41:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:42:24 | INFO | train_inner | epoch 008:     53 / 421 symm_kl=0.616, self_kl=0, self_cv=15.039, loss=4.742, nll_loss=1.129, ppl=2.19, wps=18780.7, ups=1.33, wpb=14109.9, bsz=506.2, num_updates=3000, lr=1.25e-05, gnorm=0.874, train_wall=51, wall=1701
2020-12-18 23:43:15 | INFO | train_inner | epoch 008:    153 / 421 symm_kl=0.625, self_kl=0, self_cv=15.209, loss=4.77, nll_loss=1.131, ppl=2.19, wps=27323.8, ups=1.96, wpb=13958.9, bsz=475.6, num_updates=3100, lr=1.25e-05, gnorm=0.884, train_wall=51, wall=1752
2020-12-18 23:44:06 | INFO | train_inner | epoch 008:    253 / 421 symm_kl=0.616, self_kl=0, self_cv=15.158, loss=4.753, nll_loss=1.131, ppl=2.19, wps=27157.1, ups=1.96, wpb=13843, bsz=502.1, num_updates=3200, lr=1.25e-05, gnorm=0.878, train_wall=51, wall=1803
2020-12-18 23:44:57 | INFO | train_inner | epoch 008:    353 / 421 symm_kl=0.607, self_kl=0, self_cv=15.048, loss=4.723, nll_loss=1.121, ppl=2.18, wps=27526.4, ups=1.95, wpb=14141.4, bsz=514.8, num_updates=3300, lr=1.25e-05, gnorm=0.857, train_wall=51, wall=1855
2020-12-18 23:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:45:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:45:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:45:48 | INFO | valid | epoch 008 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.278 | nll_loss 3.856 | ppl 14.48 | bleu 22.61 | wps 5995.4 | wpb 10324.2 | bsz 375 | num_updates 3368 | best_bleu 22.62
2020-12-18 23:45:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:45:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 8 @ 3368 updates, score 22.61) (writing took 2.7026965525001287 seconds)
2020-12-18 23:45:51 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-12-18 23:45:51 | INFO | train | epoch 008 | symm_kl 0.617 | self_kl 0 | self_cv 15.131 | loss 4.752 | nll_loss 1.13 | ppl 2.19 | wps 24760 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 3368 | lr 1.25e-05 | gnorm 0.875 | train_wall 214 | wall 1909
2020-12-18 23:45:51 | INFO | fairseq.trainer | begin training epoch 9
2020-12-18 23:45:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:45:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:46:11 | INFO | train_inner | epoch 009:     32 / 421 symm_kl=0.622, self_kl=0, self_cv=15.183, loss=4.772, nll_loss=1.142, ppl=2.21, wps=18809.3, ups=1.36, wpb=13812.4, bsz=478.6, num_updates=3400, lr=1.25e-05, gnorm=0.887, train_wall=51, wall=1928
2020-12-18 23:47:01 | INFO | train_inner | epoch 009:    132 / 421 symm_kl=0.617, self_kl=0, self_cv=15.098, loss=4.75, nll_loss=1.131, ppl=2.19, wps=27440.6, ups=1.96, wpb=13981.2, bsz=478.7, num_updates=3500, lr=1.25e-05, gnorm=0.871, train_wall=51, wall=1979
2020-12-18 23:47:53 | INFO | train_inner | epoch 009:    232 / 421 symm_kl=0.606, self_kl=0, self_cv=15.014, loss=4.723, nll_loss=1.126, ppl=2.18, wps=27326.1, ups=1.95, wpb=14040.5, bsz=491.4, num_updates=3600, lr=1.25e-05, gnorm=0.86, train_wall=51, wall=2030
2020-12-18 23:48:44 | INFO | train_inner | epoch 009:    332 / 421 symm_kl=0.606, self_kl=0, self_cv=15.083, loss=4.731, nll_loss=1.129, ppl=2.19, wps=27221.9, ups=1.94, wpb=14010.8, bsz=506.9, num_updates=3700, lr=1.25e-05, gnorm=0.861, train_wall=51, wall=2082
2020-12-18 23:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:49:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:49:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:49:47 | INFO | valid | epoch 009 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.277 | nll_loss 3.854 | ppl 14.46 | bleu 22.68 | wps 6069.6 | wpb 10324.2 | bsz 375 | num_updates 3789 | best_bleu 22.68
2020-12-18 23:49:47 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:49:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:49:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 9 @ 3789 updates, score 22.68) (writing took 5.295949386432767 seconds)
2020-12-18 23:49:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-12-18 23:49:52 | INFO | train | epoch 009 | symm_kl 0.61 | self_kl 0 | self_cv 15.078 | loss 4.738 | nll_loss 1.13 | ppl 2.19 | wps 24413.6 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 3789 | lr 1.25e-05 | gnorm 0.867 | train_wall 215 | wall 2149
2020-12-18 23:49:52 | INFO | fairseq.trainer | begin training epoch 10
2020-12-18 23:49:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:50:01 | INFO | train_inner | epoch 010:     11 / 421 symm_kl=0.609, self_kl=0, self_cv=15.106, loss=4.744, nll_loss=1.136, ppl=2.2, wps=17989.5, ups=1.31, wpb=13765.2, bsz=485.4, num_updates=3800, lr=1.25e-05, gnorm=0.876, train_wall=51, wall=2158
2020-12-18 23:50:52 | INFO | train_inner | epoch 010:    111 / 421 symm_kl=0.607, self_kl=0, self_cv=15.117, loss=4.738, nll_loss=1.133, ppl=2.19, wps=27772.9, ups=1.97, wpb=14110.2, bsz=485.5, num_updates=3900, lr=1.25e-05, gnorm=0.861, train_wall=51, wall=2209
2020-12-18 23:51:43 | INFO | train_inner | epoch 010:    211 / 421 symm_kl=0.612, self_kl=0, self_cv=15.12, loss=4.75, nll_loss=1.137, ppl=2.2, wps=27004.7, ups=1.94, wpb=13947.9, bsz=478.8, num_updates=4000, lr=1.25e-05, gnorm=0.87, train_wall=51, wall=2261
2020-12-18 23:52:35 | INFO | train_inner | epoch 010:    311 / 421 symm_kl=0.594, self_kl=0, self_cv=14.961, loss=4.693, nll_loss=1.114, ppl=2.16, wps=27198.9, ups=1.94, wpb=14032.4, bsz=515.1, num_updates=4100, lr=1.25e-05, gnorm=0.85, train_wall=51, wall=2312
2020-12-18 23:53:26 | INFO | train_inner | epoch 010:    411 / 421 symm_kl=0.601, self_kl=0, self_cv=15.055, loss=4.723, nll_loss=1.129, ppl=2.19, wps=27161.3, ups=1.95, wpb=13937.4, bsz=501.3, num_updates=4200, lr=1.25e-05, gnorm=0.858, train_wall=51, wall=2364
2020-12-18 23:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:53:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:53:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:53:48 | INFO | valid | epoch 010 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.269 | nll_loss 3.846 | ppl 14.38 | bleu 22.56 | wps 6003.8 | wpb 10324.2 | bsz 375 | num_updates 4210 | best_bleu 22.68
2020-12-18 23:53:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:53:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:53:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 10 @ 4210 updates, score 22.56) (writing took 3.0801872946321964 seconds)
2020-12-18 23:53:51 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-12-18 23:53:51 | INFO | train | epoch 010 | symm_kl 0.604 | self_kl 0 | self_cv 15.065 | loss 4.727 | nll_loss 1.129 | ppl 2.19 | wps 24613.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 4210 | lr 1.25e-05 | gnorm 0.862 | train_wall 215 | wall 2388
2020-12-18 23:53:51 | INFO | fairseq.trainer | begin training epoch 11
2020-12-18 23:53:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:53:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:54:40 | INFO | train_inner | epoch 011:     90 / 421 symm_kl=0.604, self_kl=0, self_cv=15.038, loss=4.726, nll_loss=1.129, ppl=2.19, wps=18794.1, ups=1.36, wpb=13795, bsz=468.2, num_updates=4300, lr=1.25e-05, gnorm=0.873, train_wall=50, wall=2437
2020-12-18 23:55:31 | INFO | train_inner | epoch 011:    190 / 421 symm_kl=0.592, self_kl=0, self_cv=14.908, loss=4.691, nll_loss=1.12, ppl=2.17, wps=27280.9, ups=1.94, wpb=14072.6, bsz=503.6, num_updates=4400, lr=1.25e-05, gnorm=0.847, train_wall=51, wall=2489
2020-12-18 23:56:23 | INFO | train_inner | epoch 011:    290 / 421 symm_kl=0.608, self_kl=0, self_cv=15.076, loss=4.751, nll_loss=1.149, ppl=2.22, wps=26876.4, ups=1.94, wpb=13821.1, bsz=488.1, num_updates=4500, lr=1.25e-05, gnorm=0.864, train_wall=51, wall=2540
2020-12-18 23:57:14 | INFO | train_inner | epoch 011:    390 / 421 symm_kl=0.592, self_kl=0, self_cv=15.025, loss=4.703, nll_loss=1.124, ppl=2.18, wps=27476.2, ups=1.94, wpb=14171.3, bsz=501.5, num_updates=4600, lr=1.25e-05, gnorm=0.843, train_wall=51, wall=2592
2020-12-18 23:57:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-18 23:57:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-18 23:57:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-18 23:57:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-18 23:57:48 | INFO | valid | epoch 011 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.269 | nll_loss 3.846 | ppl 14.38 | bleu 22.68 | wps 5594.1 | wpb 10324.2 | bsz 375 | num_updates 4631 | best_bleu 22.68
2020-12-18 23:57:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-18 23:57:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:57:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 11 @ 4631 updates, score 22.68) (writing took 5.042265772819519 seconds)
2020-12-18 23:57:53 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-12-18 23:57:53 | INFO | train | epoch 011 | symm_kl 0.598 | self_kl 0 | self_cv 15.007 | loss 4.715 | nll_loss 1.13 | ppl 2.19 | wps 24305.6 | ups 1.74 | wpb 13969.5 | bsz 492.6 | num_updates 4631 | lr 1.25e-05 | gnorm 0.855 | train_wall 215 | wall 2630
2020-12-18 23:57:53 | INFO | fairseq.trainer | begin training epoch 12
2020-12-18 23:57:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-18 23:57:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-18 23:58:31 | INFO | train_inner | epoch 012:     69 / 421 symm_kl=0.592, self_kl=0, self_cv=14.991, loss=4.7, nll_loss=1.124, ppl=2.18, wps=18084.5, ups=1.3, wpb=13876.4, bsz=488.4, num_updates=4700, lr=1.25e-05, gnorm=0.855, train_wall=51, wall=2668
2020-12-18 23:59:22 | INFO | train_inner | epoch 012:    169 / 421 symm_kl=0.596, self_kl=0, self_cv=14.987, loss=4.714, nll_loss=1.133, ppl=2.19, wps=27223.6, ups=1.96, wpb=13884.5, bsz=497.5, num_updates=4800, lr=1.25e-05, gnorm=0.853, train_wall=51, wall=2719
2020-12-19 00:00:14 | INFO | train_inner | epoch 012:    269 / 421 symm_kl=0.586, self_kl=0, self_cv=14.965, loss=4.685, nll_loss=1.118, ppl=2.17, wps=27467.7, ups=1.93, wpb=14222.4, bsz=501.7, num_updates=4900, lr=1.25e-05, gnorm=0.839, train_wall=52, wall=2771
2020-12-19 00:01:05 | INFO | train_inner | epoch 012:    369 / 421 symm_kl=0.595, self_kl=0, self_cv=14.986, loss=4.716, nll_loss=1.138, ppl=2.2, wps=27055.8, ups=1.95, wpb=13899.9, bsz=487.4, num_updates=5000, lr=1.25e-05, gnorm=0.851, train_wall=51, wall=2823
2020-12-19 00:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:01:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:01:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:01:48 | INFO | valid | epoch 012 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.265 | nll_loss 3.841 | ppl 14.33 | bleu 22.73 | wps 6167.3 | wpb 10324.2 | bsz 375 | num_updates 5052 | best_bleu 22.73
2020-12-19 00:01:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:01:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:01:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 12 @ 5052 updates, score 22.73) (writing took 5.281740289181471 seconds)
2020-12-19 00:01:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-12-19 00:01:53 | INFO | train | epoch 012 | symm_kl 0.593 | self_kl 0 | self_cv 14.982 | loss 4.704 | nll_loss 1.129 | ppl 2.19 | wps 24451.9 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 5052 | lr 1.25e-05 | gnorm 0.85 | train_wall 215 | wall 2871
2020-12-19 00:01:53 | INFO | fairseq.trainer | begin training epoch 13
2020-12-19 00:01:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:01:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:02:20 | INFO | train_inner | epoch 013:     48 / 421 symm_kl=0.592, self_kl=0, self_cv=14.946, loss=4.698, nll_loss=1.126, ppl=2.18, wps=18418, ups=1.33, wpb=13889.5, bsz=482.8, num_updates=5100, lr=1.25e-05, gnorm=0.855, train_wall=51, wall=2898
2020-12-19 00:03:12 | INFO | train_inner | epoch 013:    148 / 421 symm_kl=0.591, self_kl=0, self_cv=15.055, loss=4.709, nll_loss=1.13, ppl=2.19, wps=27351.2, ups=1.94, wpb=14105.2, bsz=473, num_updates=5200, lr=1.25e-05, gnorm=0.84, train_wall=51, wall=2950
2020-12-19 00:04:03 | INFO | train_inner | epoch 013:    248 / 421 symm_kl=0.586, self_kl=0, self_cv=14.917, loss=4.685, nll_loss=1.122, ppl=2.18, wps=27118.1, ups=1.94, wpb=13944.9, bsz=504.8, num_updates=5300, lr=1.25e-05, gnorm=0.846, train_wall=51, wall=3001
2020-12-19 00:04:55 | INFO | train_inner | epoch 013:    348 / 421 symm_kl=0.583, self_kl=0, self_cv=14.941, loss=4.683, nll_loss=1.124, ppl=2.18, wps=27553.7, ups=1.96, wpb=14073.3, bsz=500.6, num_updates=5400, lr=1.25e-05, gnorm=0.832, train_wall=51, wall=3052
2020-12-19 00:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:05:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:05:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:05:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:05:48 | INFO | valid | epoch 013 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.257 | nll_loss 3.832 | ppl 14.24 | bleu 22.69 | wps 6135.6 | wpb 10324.2 | bsz 375 | num_updates 5473 | best_bleu 22.73
2020-12-19 00:05:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:05:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:05:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 13 @ 5473 updates, score 22.69) (writing took 3.0605596974492073 seconds)
2020-12-19 00:05:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-12-19 00:05:51 | INFO | train | epoch 013 | symm_kl 0.588 | self_kl 0 | self_cv 14.97 | loss 4.695 | nll_loss 1.127 | ppl 2.18 | wps 24738.7 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 5473 | lr 1.25e-05 | gnorm 0.844 | train_wall 215 | wall 3109
2020-12-19 00:05:51 | INFO | fairseq.trainer | begin training epoch 14
2020-12-19 00:05:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:05:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:06:08 | INFO | train_inner | epoch 014:     27 / 421 symm_kl=0.588, self_kl=0, self_cv=14.987, loss=4.701, nll_loss=1.131, ppl=2.19, wps=18843.4, ups=1.37, wpb=13804.5, bsz=491.3, num_updates=5500, lr=1.25e-05, gnorm=0.853, train_wall=51, wall=3125
2020-12-19 00:06:59 | INFO | train_inner | epoch 014:    127 / 421 symm_kl=0.585, self_kl=0, self_cv=14.944, loss=4.688, nll_loss=1.124, ppl=2.18, wps=27737.3, ups=1.96, wpb=14140.2, bsz=491.6, num_updates=5600, lr=1.25e-05, gnorm=0.838, train_wall=51, wall=3176
2020-12-19 00:07:50 | INFO | train_inner | epoch 014:    227 / 421 symm_kl=0.582, self_kl=0, self_cv=14.93, loss=4.681, nll_loss=1.123, ppl=2.18, wps=27197, ups=1.96, wpb=13893.4, bsz=488.5, num_updates=5700, lr=1.25e-05, gnorm=0.844, train_wall=51, wall=3227
2020-12-19 00:08:41 | INFO | train_inner | epoch 014:    327 / 421 symm_kl=0.589, self_kl=0, self_cv=14.998, loss=4.707, nll_loss=1.135, ppl=2.2, wps=26935.3, ups=1.94, wpb=13861.2, bsz=485.7, num_updates=5800, lr=1.25e-05, gnorm=0.851, train_wall=51, wall=3279
2020-12-19 00:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:09:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:09:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:09:48 | INFO | valid | epoch 014 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.257 | nll_loss 3.831 | ppl 14.23 | bleu 22.69 | wps 5460.4 | wpb 10324.2 | bsz 375 | num_updates 5894 | best_bleu 22.73
2020-12-19 00:09:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:09:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 14 @ 5894 updates, score 22.69) (writing took 3.0352785028517246 seconds)
2020-12-19 00:09:51 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-12-19 00:09:51 | INFO | train | epoch 014 | symm_kl 0.583 | self_kl 0 | self_cv 14.949 | loss 4.686 | nll_loss 1.126 | ppl 2.18 | wps 24556.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 5894 | lr 1.25e-05 | gnorm 0.844 | train_wall 215 | wall 3348
2020-12-19 00:09:51 | INFO | fairseq.trainer | begin training epoch 15
2020-12-19 00:09:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:09:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:09:57 | INFO | train_inner | epoch 015:      6 / 421 symm_kl=0.577, self_kl=0, self_cv=14.918, loss=4.674, nll_loss=1.125, ppl=2.18, wps=18476.5, ups=1.32, wpb=13964.8, bsz=507.2, num_updates=5900, lr=1.25e-05, gnorm=0.841, train_wall=51, wall=3354
2020-12-19 00:10:48 | INFO | train_inner | epoch 015:    106 / 421 symm_kl=0.584, self_kl=0, self_cv=14.974, loss=4.696, nll_loss=1.134, ppl=2.19, wps=27371.6, ups=1.97, wpb=13909.8, bsz=489.7, num_updates=6000, lr=1.25e-05, gnorm=0.835, train_wall=51, wall=3405
2020-12-19 00:11:39 | INFO | train_inner | epoch 015:    206 / 421 symm_kl=0.573, self_kl=0, self_cv=14.898, loss=4.656, nll_loss=1.113, ppl=2.16, wps=27267.6, ups=1.94, wpb=14025.9, bsz=508.1, num_updates=6100, lr=1.25e-05, gnorm=0.832, train_wall=51, wall=3457
2020-12-19 00:12:31 | INFO | train_inner | epoch 015:    306 / 421 symm_kl=0.578, self_kl=0, self_cv=14.943, loss=4.682, nll_loss=1.128, ppl=2.19, wps=27216.4, ups=1.95, wpb=13965.9, bsz=486.5, num_updates=6200, lr=1.25e-05, gnorm=0.834, train_wall=51, wall=3508
2020-12-19 00:13:22 | INFO | train_inner | epoch 015:    406 / 421 symm_kl=0.582, self_kl=0, self_cv=14.941, loss=4.693, nll_loss=1.135, ppl=2.2, wps=27277, ups=1.95, wpb=14000.5, bsz=488.7, num_updates=6300, lr=1.25e-05, gnorm=0.843, train_wall=51, wall=3559
2020-12-19 00:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:13:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:13:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:13:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:13:46 | INFO | valid | epoch 015 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.257 | nll_loss 3.83 | ppl 14.22 | bleu 22.75 | wps 5912.5 | wpb 10324.2 | bsz 375 | num_updates 6315 | best_bleu 22.75
2020-12-19 00:13:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:13:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:13:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 15 @ 6315 updates, score 22.75) (writing took 4.968021165579557 seconds)
2020-12-19 00:13:51 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-12-19 00:13:51 | INFO | train | epoch 015 | symm_kl 0.578 | self_kl 0 | self_cv 14.934 | loss 4.678 | nll_loss 1.126 | ppl 2.18 | wps 24456.9 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 6315 | lr 1.25e-05 | gnorm 0.837 | train_wall 215 | wall 3589
2020-12-19 00:13:51 | INFO | fairseq.trainer | begin training epoch 16
2020-12-19 00:13:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:13:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:14:37 | INFO | train_inner | epoch 016:     85 / 421 symm_kl=0.573, self_kl=0, self_cv=14.9, loss=4.661, nll_loss=1.118, ppl=2.17, wps=18403.9, ups=1.32, wpb=13920.5, bsz=499.7, num_updates=6400, lr=1.25e-05, gnorm=0.829, train_wall=51, wall=3635
2020-12-19 00:15:29 | INFO | train_inner | epoch 016:    185 / 421 symm_kl=0.579, self_kl=0, self_cv=14.911, loss=4.679, nll_loss=1.128, ppl=2.18, wps=27264.3, ups=1.95, wpb=13953.5, bsz=496.1, num_updates=6500, lr=1.25e-05, gnorm=0.835, train_wall=51, wall=3686
2020-12-19 00:16:20 | INFO | train_inner | epoch 016:    285 / 421 symm_kl=0.568, self_kl=0, self_cv=14.846, loss=4.647, nll_loss=1.114, ppl=2.17, wps=27338.1, ups=1.94, wpb=14059.6, bsz=504.2, num_updates=6600, lr=1.25e-05, gnorm=0.825, train_wall=51, wall=3738
2020-12-19 00:17:11 | INFO | train_inner | epoch 016:    385 / 421 symm_kl=0.578, self_kl=0, self_cv=14.954, loss=4.682, nll_loss=1.129, ppl=2.19, wps=27225, ups=1.95, wpb=13933.8, bsz=478.3, num_updates=6700, lr=1.25e-05, gnorm=0.833, train_wall=51, wall=3789
2020-12-19 00:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:17:48 | INFO | valid | epoch 016 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.251 | nll_loss 3.825 | ppl 14.17 | bleu 22.61 | wps 5492 | wpb 10324.2 | bsz 375 | num_updates 6736 | best_bleu 22.75
2020-12-19 00:17:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:17:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:17:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 16 @ 6736 updates, score 22.61) (writing took 3.0415022652596235 seconds)
2020-12-19 00:17:51 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-12-19 00:17:51 | INFO | train | epoch 016 | symm_kl 0.575 | self_kl 0 | self_cv 14.899 | loss 4.671 | nll_loss 1.125 | ppl 2.18 | wps 24564.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 6736 | lr 1.25e-05 | gnorm 0.832 | train_wall 215 | wall 3828
2020-12-19 00:17:51 | INFO | fairseq.trainer | begin training epoch 17
2020-12-19 00:17:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:17:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:18:26 | INFO | train_inner | epoch 017:     64 / 421 symm_kl=0.576, self_kl=0, self_cv=14.907, loss=4.68, nll_loss=1.133, ppl=2.19, wps=18555.5, ups=1.34, wpb=13884.8, bsz=477.7, num_updates=6800, lr=1.25e-05, gnorm=0.844, train_wall=51, wall=3864
2020-12-19 00:19:18 | INFO | train_inner | epoch 017:    164 / 421 symm_kl=0.561, self_kl=0, self_cv=14.766, loss=4.619, nll_loss=1.101, ppl=2.14, wps=27498, ups=1.94, wpb=14155.6, bsz=509.1, num_updates=6900, lr=1.25e-05, gnorm=0.812, train_wall=51, wall=3915
2020-12-19 00:20:09 | INFO | train_inner | epoch 017:    264 / 421 symm_kl=0.569, self_kl=0, self_cv=14.87, loss=4.654, nll_loss=1.118, ppl=2.17, wps=27454.7, ups=1.96, wpb=14019.6, bsz=491.8, num_updates=7000, lr=1.25e-05, gnorm=0.822, train_wall=51, wall=3966
2020-12-19 00:21:00 | INFO | train_inner | epoch 017:    364 / 421 symm_kl=0.576, self_kl=0, self_cv=14.944, loss=4.685, nll_loss=1.137, ppl=2.2, wps=27135.4, ups=1.95, wpb=13911.3, bsz=494.4, num_updates=7100, lr=1.25e-05, gnorm=0.834, train_wall=51, wall=4017
2020-12-19 00:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:21:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:21:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:21:46 | INFO | valid | epoch 017 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.25 | nll_loss 3.824 | ppl 14.16 | bleu 22.72 | wps 6033.1 | wpb 10324.2 | bsz 375 | num_updates 7157 | best_bleu 22.75
2020-12-19 00:21:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:21:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:21:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 17 @ 7157 updates, score 22.72) (writing took 3.0639655366539955 seconds)
2020-12-19 00:21:49 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-12-19 00:21:49 | INFO | train | epoch 017 | symm_kl 0.572 | self_kl 0 | self_cv 14.887 | loss 4.664 | nll_loss 1.124 | ppl 2.18 | wps 24674.2 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 7157 | lr 1.25e-05 | gnorm 0.828 | train_wall 215 | wall 4066
2020-12-19 00:21:49 | INFO | fairseq.trainer | begin training epoch 18
2020-12-19 00:21:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:21:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:22:14 | INFO | train_inner | epoch 018:     43 / 421 symm_kl=0.576, self_kl=0, self_cv=14.977, loss=4.684, nll_loss=1.132, ppl=2.19, wps=18794.6, ups=1.35, wpb=13876, bsz=478.1, num_updates=7200, lr=1.25e-05, gnorm=0.843, train_wall=51, wall=4091
2020-12-19 00:23:05 | INFO | train_inner | epoch 018:    143 / 421 symm_kl=0.568, self_kl=0, self_cv=14.86, loss=4.653, nll_loss=1.12, ppl=2.17, wps=27342.7, ups=1.95, wpb=14024.4, bsz=489.7, num_updates=7300, lr=1.25e-05, gnorm=0.829, train_wall=51, wall=4142
2020-12-19 00:23:57 | INFO | train_inner | epoch 018:    243 / 421 symm_kl=0.569, self_kl=0, self_cv=14.837, loss=4.656, nll_loss=1.123, ppl=2.18, wps=26838.7, ups=1.94, wpb=13842.7, bsz=494.3, num_updates=7400, lr=1.25e-05, gnorm=0.827, train_wall=51, wall=4194
2020-12-19 00:24:48 | INFO | train_inner | epoch 018:    343 / 421 symm_kl=0.564, self_kl=0, self_cv=14.803, loss=4.646, nll_loss=1.122, ppl=2.18, wps=27468.5, ups=1.95, wpb=14074.6, bsz=501.3, num_updates=7500, lr=1.25e-05, gnorm=0.816, train_wall=51, wall=4245
2020-12-19 00:25:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:25:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:25:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:25:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:25:44 | INFO | valid | epoch 018 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.247 | nll_loss 3.821 | ppl 14.13 | bleu 22.77 | wps 6341.2 | wpb 10324.2 | bsz 375 | num_updates 7578 | best_bleu 22.77
2020-12-19 00:25:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:25:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 18 @ 7578 updates, score 22.77) (writing took 4.937866257503629 seconds)
2020-12-19 00:25:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-12-19 00:25:49 | INFO | train | epoch 018 | symm_kl 0.568 | self_kl 0 | self_cv 14.871 | loss 4.657 | nll_loss 1.123 | ppl 2.18 | wps 24519.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 7578 | lr 1.25e-05 | gnorm 0.828 | train_wall 215 | wall 4306
2020-12-19 00:25:49 | INFO | fairseq.trainer | begin training epoch 19
2020-12-19 00:25:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:25:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:26:03 | INFO | train_inner | epoch 019:     22 / 421 symm_kl=0.568, self_kl=0, self_cv=14.905, loss=4.666, nll_loss=1.131, ppl=2.19, wps=18398.3, ups=1.33, wpb=13829.2, bsz=486.7, num_updates=7600, lr=1.25e-05, gnorm=0.839, train_wall=51, wall=4320
2020-12-19 00:26:54 | INFO | train_inner | epoch 019:    122 / 421 symm_kl=0.563, self_kl=0, self_cv=14.881, loss=4.646, nll_loss=1.118, ppl=2.17, wps=27592.8, ups=1.96, wpb=14075, bsz=504.1, num_updates=7700, lr=1.25e-05, gnorm=0.821, train_wall=51, wall=4371
2020-12-19 00:27:45 | INFO | train_inner | epoch 019:    222 / 421 symm_kl=0.564, self_kl=0, self_cv=14.849, loss=4.647, nll_loss=1.12, ppl=2.17, wps=27376.9, ups=1.95, wpb=14017.6, bsz=488.3, num_updates=7800, lr=1.25e-05, gnorm=0.819, train_wall=51, wall=4423
2020-12-19 00:28:37 | INFO | train_inner | epoch 019:    322 / 421 symm_kl=0.57, self_kl=0, self_cv=14.927, loss=4.67, nll_loss=1.13, ppl=2.19, wps=26918.3, ups=1.93, wpb=13925.5, bsz=485.6, num_updates=7900, lr=1.25e-05, gnorm=0.828, train_wall=52, wall=4474
2020-12-19 00:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:29:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:29:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:29:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:29:45 | INFO | valid | epoch 019 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.247 | nll_loss 3.821 | ppl 14.14 | bleu 22.85 | wps 5752.3 | wpb 10324.2 | bsz 375 | num_updates 7999 | best_bleu 22.85
2020-12-19 00:29:45 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:29:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 19 @ 7999 updates, score 22.85) (writing took 4.980282189324498 seconds)
2020-12-19 00:29:50 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-12-19 00:29:50 | INFO | train | epoch 019 | symm_kl 0.564 | self_kl 0 | self_cv 14.86 | loss 4.65 | nll_loss 1.122 | ppl 2.18 | wps 24422.3 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 7999 | lr 1.25e-05 | gnorm 0.828 | train_wall 215 | wall 4547
2020-12-19 00:29:50 | INFO | fairseq.trainer | begin training epoch 20
2020-12-19 00:29:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:29:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:29:53 | INFO | train_inner | epoch 020:      1 / 421 symm_kl=0.56, self_kl=0, self_cv=14.778, loss=4.637, nll_loss=1.121, ppl=2.18, wps=18256.1, ups=1.31, wpb=13936.5, bsz=492.6, num_updates=8000, lr=1.25e-05, gnorm=0.84, train_wall=51, wall=4551
2020-12-19 00:30:44 | INFO | train_inner | epoch 020:    101 / 421 symm_kl=0.564, self_kl=0, self_cv=14.85, loss=4.65, nll_loss=1.124, ppl=2.18, wps=27698.9, ups=1.98, wpb=14022.1, bsz=493.9, num_updates=8100, lr=1.25e-05, gnorm=0.816, train_wall=50, wall=4601
2020-12-19 00:31:35 | INFO | train_inner | epoch 020:    201 / 421 symm_kl=0.561, self_kl=0, self_cv=14.857, loss=4.641, nll_loss=1.118, ppl=2.17, wps=27151, ups=1.94, wpb=13989.7, bsz=488, num_updates=8200, lr=1.25e-05, gnorm=0.824, train_wall=51, wall=4653
2020-12-19 00:32:27 | INFO | train_inner | epoch 020:    301 / 421 symm_kl=0.563, self_kl=0, self_cv=14.847, loss=4.65, nll_loss=1.126, ppl=2.18, wps=27538.4, ups=1.95, wpb=14118.4, bsz=497.3, num_updates=8300, lr=1.25e-05, gnorm=0.814, train_wall=51, wall=4704
2020-12-19 00:33:18 | INFO | train_inner | epoch 020:    401 / 421 symm_kl=0.563, self_kl=0, self_cv=14.848, loss=4.648, nll_loss=1.123, ppl=2.18, wps=26957, ups=1.95, wpb=13791.4, bsz=493.2, num_updates=8400, lr=1.25e-05, gnorm=0.829, train_wall=51, wall=4755
2020-12-19 00:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:33:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:33:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:33:44 | INFO | valid | epoch 020 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.244 | nll_loss 3.819 | ppl 14.11 | bleu 22.68 | wps 6202.3 | wpb 10324.2 | bsz 375 | num_updates 8420 | best_bleu 22.85
2020-12-19 00:33:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:33:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:33:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 20 @ 8420 updates, score 22.68) (writing took 3.0699119959026575 seconds)
2020-12-19 00:33:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-12-19 00:33:47 | INFO | train | epoch 020 | symm_kl 0.562 | self_kl 0 | self_cv 14.85 | loss 4.646 | nll_loss 1.122 | ppl 2.18 | wps 24727.2 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 8420 | lr 1.25e-05 | gnorm 0.821 | train_wall 215 | wall 4785
2020-12-19 00:33:47 | INFO | fairseq.trainer | begin training epoch 21
2020-12-19 00:33:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:33:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:34:31 | INFO | train_inner | epoch 021:     80 / 421 symm_kl=0.563, self_kl=0, self_cv=14.881, loss=4.654, nll_loss=1.128, ppl=2.18, wps=18685.9, ups=1.36, wpb=13696.4, bsz=490.3, num_updates=8500, lr=1.25e-05, gnorm=0.833, train_wall=51, wall=4829
2020-12-19 00:35:22 | INFO | train_inner | epoch 021:    180 / 421 symm_kl=0.559, self_kl=0, self_cv=14.816, loss=4.637, nll_loss=1.12, ppl=2.17, wps=27433.7, ups=1.95, wpb=14078.8, bsz=487.9, num_updates=8600, lr=1.25e-05, gnorm=0.814, train_wall=51, wall=4880
2020-12-19 00:36:14 | INFO | train_inner | epoch 021:    280 / 421 symm_kl=0.548, self_kl=0, self_cv=14.722, loss=4.601, nll_loss=1.106, ppl=2.15, wps=27572.4, ups=1.95, wpb=14138.2, bsz=508.5, num_updates=8700, lr=1.25e-05, gnorm=0.802, train_wall=51, wall=4931
2020-12-19 00:37:05 | INFO | train_inner | epoch 021:    380 / 421 symm_kl=0.561, self_kl=0, self_cv=14.832, loss=4.648, nll_loss=1.128, ppl=2.19, wps=27232, ups=1.94, wpb=14011.6, bsz=493.4, num_updates=8800, lr=1.25e-05, gnorm=0.814, train_wall=51, wall=4983
2020-12-19 00:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:37:43 | INFO | valid | epoch 021 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.241 | nll_loss 3.814 | ppl 14.06 | bleu 22.71 | wps 5653.3 | wpb 10324.2 | bsz 375 | num_updates 8841 | best_bleu 22.85
2020-12-19 00:37:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:37:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:37:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 21 @ 8841 updates, score 22.71) (writing took 3.090290565043688 seconds)
2020-12-19 00:37:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-12-19 00:37:46 | INFO | train | epoch 021 | symm_kl 0.558 | self_kl 0 | self_cv 14.816 | loss 4.638 | nll_loss 1.122 | ppl 2.18 | wps 24605.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 8841 | lr 1.25e-05 | gnorm 0.817 | train_wall 215 | wall 5024
2020-12-19 00:37:46 | INFO | fairseq.trainer | begin training epoch 22
2020-12-19 00:37:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:37:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:38:19 | INFO | train_inner | epoch 022:     59 / 421 symm_kl=0.56, self_kl=0, self_cv=14.869, loss=4.649, nll_loss=1.127, ppl=2.18, wps=18773.1, ups=1.35, wpb=13937.8, bsz=479, num_updates=8900, lr=1.25e-05, gnorm=0.821, train_wall=50, wall=5057
2020-12-19 00:39:11 | INFO | train_inner | epoch 022:    159 / 421 symm_kl=0.548, self_kl=0, self_cv=14.795, loss=4.612, nll_loss=1.109, ppl=2.16, wps=27267.7, ups=1.94, wpb=14049.6, bsz=507.4, num_updates=9000, lr=1.25e-05, gnorm=0.804, train_wall=51, wall=5108
2020-12-19 00:40:03 | INFO | train_inner | epoch 022:    259 / 421 symm_kl=0.559, self_kl=0, self_cv=14.781, loss=4.642, nll_loss=1.128, ppl=2.19, wps=26952.1, ups=1.94, wpb=13902.5, bsz=489.7, num_updates=9100, lr=1.25e-05, gnorm=0.818, train_wall=51, wall=5160
2020-12-19 00:40:54 | INFO | train_inner | epoch 022:    359 / 421 symm_kl=0.554, self_kl=0, self_cv=14.845, loss=4.63, nll_loss=1.118, ppl=2.17, wps=27391.4, ups=1.95, wpb=14032.6, bsz=487.8, num_updates=9200, lr=1.25e-05, gnorm=0.81, train_wall=51, wall=5211
2020-12-19 00:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:41:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:41:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:41:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:41:42 | INFO | valid | epoch 022 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.237 | nll_loss 3.812 | ppl 14.04 | bleu 22.86 | wps 6330.8 | wpb 10324.2 | bsz 375 | num_updates 9262 | best_bleu 22.86
2020-12-19 00:41:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:41:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:41:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 22 @ 9262 updates, score 22.86) (writing took 4.981477016583085 seconds)
2020-12-19 00:41:47 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-12-19 00:41:47 | INFO | train | epoch 022 | symm_kl 0.555 | self_kl 0 | self_cv 14.814 | loss 4.632 | nll_loss 1.12 | ppl 2.17 | wps 24471.6 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 9262 | lr 1.25e-05 | gnorm 0.813 | train_wall 216 | wall 5264
2020-12-19 00:41:47 | INFO | fairseq.trainer | begin training epoch 23
2020-12-19 00:41:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:41:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:42:09 | INFO | train_inner | epoch 023:     38 / 421 symm_kl=0.566, self_kl=0, self_cv=14.856, loss=4.663, nll_loss=1.134, ppl=2.2, wps=18363.8, ups=1.33, wpb=13834.9, bsz=470.7, num_updates=9300, lr=1.25e-05, gnorm=0.831, train_wall=51, wall=5287
2020-12-19 00:43:01 | INFO | train_inner | epoch 023:    138 / 421 symm_kl=0.552, self_kl=0, self_cv=14.83, loss=4.628, nll_loss=1.119, ppl=2.17, wps=27102.2, ups=1.94, wpb=13964.3, bsz=496.2, num_updates=9400, lr=1.25e-05, gnorm=0.813, train_wall=51, wall=5338
2020-12-19 00:43:52 | INFO | train_inner | epoch 023:    238 / 421 symm_kl=0.557, self_kl=0, self_cv=14.784, loss=4.64, nll_loss=1.129, ppl=2.19, wps=27223.5, ups=1.95, wpb=13991.9, bsz=478, num_updates=9500, lr=1.25e-05, gnorm=0.819, train_wall=51, wall=5390
2020-12-19 00:44:44 | INFO | train_inner | epoch 023:    338 / 421 symm_kl=0.55, self_kl=0, self_cv=14.814, loss=4.619, nll_loss=1.114, ppl=2.17, wps=27141.6, ups=1.94, wpb=13972.2, bsz=506.8, num_updates=9600, lr=1.25e-05, gnorm=0.805, train_wall=51, wall=5441
2020-12-19 00:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:45:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:45:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:45:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:45:42 | INFO | valid | epoch 023 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.24 | nll_loss 3.813 | ppl 14.05 | bleu 22.71 | wps 6209.4 | wpb 10324.2 | bsz 375 | num_updates 9683 | best_bleu 22.86
2020-12-19 00:45:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:45:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 23 @ 9683 updates, score 22.71) (writing took 3.097334034740925 seconds)
2020-12-19 00:45:45 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-12-19 00:45:45 | INFO | train | epoch 023 | symm_kl 0.553 | self_kl 0 | self_cv 14.804 | loss 4.627 | nll_loss 1.119 | ppl 2.17 | wps 24644.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 9683 | lr 1.25e-05 | gnorm 0.814 | train_wall 215 | wall 5503
2020-12-19 00:45:45 | INFO | fairseq.trainer | begin training epoch 24
2020-12-19 00:45:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:45:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:45:57 | INFO | train_inner | epoch 024:     17 / 421 symm_kl=0.545, self_kl=0, self_cv=14.772, loss=4.604, nll_loss=1.109, ppl=2.16, wps=18964.2, ups=1.36, wpb=13990.7, bsz=508.2, num_updates=9700, lr=1.25e-05, gnorm=0.808, train_wall=51, wall=5515
2020-12-19 00:46:49 | INFO | train_inner | epoch 024:    117 / 421 symm_kl=0.554, self_kl=0, self_cv=14.816, loss=4.632, nll_loss=1.122, ppl=2.18, wps=27433.1, ups=1.95, wpb=14043.6, bsz=489.9, num_updates=9800, lr=1.25e-05, gnorm=0.815, train_wall=51, wall=5566
2020-12-19 00:47:40 | INFO | train_inner | epoch 024:    217 / 421 symm_kl=0.549, self_kl=0, self_cv=14.843, loss=4.62, nll_loss=1.114, ppl=2.16, wps=27188.7, ups=1.94, wpb=13992.3, bsz=488.8, num_updates=9900, lr=1.25e-05, gnorm=0.806, train_wall=51, wall=5617
2020-12-19 00:48:32 | INFO | train_inner | epoch 024:    317 / 421 symm_kl=0.554, self_kl=0, self_cv=14.813, loss=4.639, nll_loss=1.129, ppl=2.19, wps=26574.5, ups=1.94, wpb=13726.7, bsz=487.9, num_updates=10000, lr=1.25e-05, gnorm=0.817, train_wall=51, wall=5669
2020-12-19 00:49:23 | INFO | train_inner | epoch 024:    417 / 421 symm_kl=0.545, self_kl=0, self_cv=14.704, loss=4.605, nll_loss=1.116, ppl=2.17, wps=27627.2, ups=1.95, wpb=14165.6, bsz=504.5, num_updates=10100, lr=1.25e-05, gnorm=0.801, train_wall=51, wall=5720
2020-12-19 00:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:49:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:49:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:49:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:49:40 | INFO | valid | epoch 024 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.237 | nll_loss 3.81 | ppl 14.03 | bleu 22.77 | wps 6528.9 | wpb 10324.2 | bsz 375 | num_updates 10104 | best_bleu 22.86
2020-12-19 00:49:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:49:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:49:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 24 @ 10104 updates, score 22.77) (writing took 3.06290246732533 seconds)
2020-12-19 00:49:44 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-12-19 00:49:44 | INFO | train | epoch 024 | symm_kl 0.55 | self_kl 0 | self_cv 14.797 | loss 4.623 | nll_loss 1.12 | ppl 2.17 | wps 24701.6 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 10104 | lr 1.25e-05 | gnorm 0.811 | train_wall 215 | wall 5741
2020-12-19 00:49:44 | INFO | fairseq.trainer | begin training epoch 25
2020-12-19 00:49:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:49:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:50:36 | INFO | train_inner | epoch 025:     96 / 421 symm_kl=0.55, self_kl=0, self_cv=14.795, loss=4.615, nll_loss=1.112, ppl=2.16, wps=19222.9, ups=1.38, wpb=13965.8, bsz=477.5, num_updates=10200, lr=1.25e-05, gnorm=0.816, train_wall=51, wall=5793
2020-12-19 00:51:27 | INFO | train_inner | epoch 025:    196 / 421 symm_kl=0.549, self_kl=0, self_cv=14.804, loss=4.626, nll_loss=1.124, ppl=2.18, wps=27100, ups=1.95, wpb=13916.1, bsz=500.1, num_updates=10300, lr=1.25e-05, gnorm=0.811, train_wall=51, wall=5844
2020-12-19 00:52:18 | INFO | train_inner | epoch 025:    296 / 421 symm_kl=0.549, self_kl=0, self_cv=14.816, loss=4.628, nll_loss=1.125, ppl=2.18, wps=27582.9, ups=1.96, wpb=14064.9, bsz=487, num_updates=10400, lr=1.25e-05, gnorm=0.805, train_wall=51, wall=5895
2020-12-19 00:53:09 | INFO | train_inner | epoch 025:    396 / 421 symm_kl=0.543, self_kl=0, self_cv=14.718, loss=4.603, nll_loss=1.116, ppl=2.17, wps=27400.6, ups=1.96, wpb=14008.2, bsz=508.2, num_updates=10500, lr=1.25e-05, gnorm=0.798, train_wall=51, wall=5946
2020-12-19 00:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:53:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:53:39 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.235 | nll_loss 3.809 | ppl 14.01 | bleu 22.81 | wps 5742.2 | wpb 10324.2 | bsz 375 | num_updates 10525 | best_bleu 22.86
2020-12-19 00:53:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:53:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 25 @ 10525 updates, score 22.81) (writing took 2.7484568804502487 seconds)
2020-12-19 00:53:42 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-12-19 00:53:42 | INFO | train | epoch 025 | symm_kl 0.548 | self_kl 0 | self_cv 14.775 | loss 4.618 | nll_loss 1.12 | ppl 2.17 | wps 24679.7 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 10525 | lr 1.25e-05 | gnorm 0.809 | train_wall 214 | wall 5979
2020-12-19 00:53:42 | INFO | fairseq.trainer | begin training epoch 26
2020-12-19 00:53:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:53:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:54:23 | INFO | train_inner | epoch 026:     75 / 421 symm_kl=0.541, self_kl=0, self_cv=14.684, loss=4.592, nll_loss=1.108, ppl=2.16, wps=18562.3, ups=1.35, wpb=13766.8, bsz=507.2, num_updates=10600, lr=1.25e-05, gnorm=0.808, train_wall=51, wall=6021
2020-12-19 00:55:15 | INFO | train_inner | epoch 026:    175 / 421 symm_kl=0.544, self_kl=0, self_cv=14.801, loss=4.608, nll_loss=1.111, ppl=2.16, wps=27375.7, ups=1.95, wpb=14063.1, bsz=499.9, num_updates=10700, lr=1.25e-05, gnorm=0.8, train_wall=51, wall=6072
2020-12-19 00:56:06 | INFO | train_inner | epoch 026:    275 / 421 symm_kl=0.546, self_kl=0, self_cv=14.757, loss=4.618, nll_loss=1.124, ppl=2.18, wps=27417.6, ups=1.95, wpb=14095.9, bsz=494.4, num_updates=10800, lr=1.25e-05, gnorm=0.797, train_wall=51, wall=6123
2020-12-19 00:56:58 | INFO | train_inner | epoch 026:    375 / 421 symm_kl=0.55, self_kl=0, self_cv=14.801, loss=4.628, nll_loss=1.125, ppl=2.18, wps=26903.3, ups=1.93, wpb=13928.6, bsz=473.6, num_updates=10900, lr=1.25e-05, gnorm=0.811, train_wall=52, wall=6175
2020-12-19 00:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 00:57:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 00:57:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 00:57:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 00:57:37 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.234 | nll_loss 3.809 | ppl 14.01 | bleu 22.78 | wps 6533.6 | wpb 10324.2 | bsz 375 | num_updates 10946 | best_bleu 22.86
2020-12-19 00:57:37 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 00:57:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:57:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 26 @ 10946 updates, score 22.78) (writing took 3.2251535430550575 seconds)
2020-12-19 00:57:40 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-12-19 00:57:40 | INFO | train | epoch 026 | symm_kl 0.546 | self_kl 0 | self_cv 14.772 | loss 4.613 | nll_loss 1.118 | ppl 2.17 | wps 24708.6 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 10946 | lr 1.25e-05 | gnorm 0.804 | train_wall 215 | wall 6217
2020-12-19 00:57:40 | INFO | fairseq.trainer | begin training epoch 27
2020-12-19 00:57:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 00:57:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 00:58:11 | INFO | train_inner | epoch 027:     54 / 421 symm_kl=0.548, self_kl=0, self_cv=14.77, loss=4.625, nll_loss=1.127, ppl=2.18, wps=19084, ups=1.37, wpb=13886.4, bsz=483.5, num_updates=11000, lr=1.25e-05, gnorm=0.813, train_wall=51, wall=6248
2020-12-19 00:59:02 | INFO | train_inner | epoch 027:    154 / 421 symm_kl=0.548, self_kl=0, self_cv=14.762, loss=4.617, nll_loss=1.119, ppl=2.17, wps=27302.9, ups=1.95, wpb=14008.5, bsz=483.7, num_updates=11100, lr=1.25e-05, gnorm=0.809, train_wall=51, wall=6299
2020-12-19 00:59:53 | INFO | train_inner | epoch 027:    254 / 421 symm_kl=0.539, self_kl=0, self_cv=14.716, loss=4.596, nll_loss=1.112, ppl=2.16, wps=27445.9, ups=1.95, wpb=14065.1, bsz=498.8, num_updates=11200, lr=1.25e-05, gnorm=0.802, train_wall=51, wall=6351
2020-12-19 01:00:45 | INFO | train_inner | epoch 027:    354 / 421 symm_kl=0.542, self_kl=0, self_cv=14.81, loss=4.608, nll_loss=1.114, ppl=2.17, wps=27009.3, ups=1.94, wpb=13936.2, bsz=501.4, num_updates=11300, lr=1.25e-05, gnorm=0.811, train_wall=51, wall=6402
2020-12-19 01:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:01:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:01:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:01:36 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.231 | nll_loss 3.805 | ppl 13.98 | bleu 22.82 | wps 6147.1 | wpb 10324.2 | bsz 375 | num_updates 11367 | best_bleu 22.86
2020-12-19 01:01:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:01:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 27 @ 11367 updates, score 22.82) (writing took 3.269075185060501 seconds)
2020-12-19 01:01:39 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-12-19 01:01:39 | INFO | train | epoch 027 | symm_kl 0.544 | self_kl 0 | self_cv 14.761 | loss 4.61 | nll_loss 1.118 | ppl 2.17 | wps 24608.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 11367 | lr 1.25e-05 | gnorm 0.808 | train_wall 215 | wall 6456
2020-12-19 01:01:39 | INFO | fairseq.trainer | begin training epoch 28
2020-12-19 01:01:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:01:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:01:58 | INFO | train_inner | epoch 028:     33 / 421 symm_kl=0.539, self_kl=0, self_cv=14.708, loss=4.59, nll_loss=1.109, ppl=2.16, wps=18608.3, ups=1.35, wpb=13736.5, bsz=489.8, num_updates=11400, lr=1.25e-05, gnorm=0.81, train_wall=51, wall=6476
2020-12-19 01:02:50 | INFO | train_inner | epoch 028:    133 / 421 symm_kl=0.544, self_kl=0, self_cv=14.795, loss=4.614, nll_loss=1.118, ppl=2.17, wps=27294.3, ups=1.95, wpb=13970.3, bsz=473.9, num_updates=11500, lr=1.25e-05, gnorm=0.801, train_wall=51, wall=6527
2020-12-19 01:03:41 | INFO | train_inner | epoch 028:    233 / 421 symm_kl=0.54, self_kl=0, self_cv=14.785, loss=4.602, nll_loss=1.113, ppl=2.16, wps=27166.3, ups=1.93, wpb=14051.6, bsz=492.8, num_updates=11600, lr=1.25e-05, gnorm=0.792, train_wall=52, wall=6579
2020-12-19 01:04:33 | INFO | train_inner | epoch 028:    333 / 421 symm_kl=0.542, self_kl=0, self_cv=14.722, loss=4.611, nll_loss=1.126, ppl=2.18, wps=27287, ups=1.94, wpb=14062.4, bsz=500.3, num_updates=11700, lr=1.25e-05, gnorm=0.794, train_wall=51, wall=6630
2020-12-19 01:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:05:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:05:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:05:35 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.231 | nll_loss 3.802 | ppl 13.95 | bleu 22.81 | wps 6019.2 | wpb 10324.2 | bsz 375 | num_updates 11788 | best_bleu 22.86
2020-12-19 01:05:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 28 @ 11788 updates, score 22.81) (writing took 3.1058975905179977 seconds)
2020-12-19 01:05:38 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-12-19 01:05:38 | INFO | train | epoch 028 | symm_kl 0.541 | self_kl 0 | self_cv 14.756 | loss 4.604 | nll_loss 1.117 | ppl 2.17 | wps 24578.9 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 11788 | lr 1.25e-05 | gnorm 0.798 | train_wall 216 | wall 6696
2020-12-19 01:05:38 | INFO | fairseq.trainer | begin training epoch 29
2020-12-19 01:05:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:05:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:05:47 | INFO | train_inner | epoch 029:     12 / 421 symm_kl=0.541, self_kl=0, self_cv=14.758, loss=4.608, nll_loss=1.12, ppl=2.17, wps=18656.7, ups=1.34, wpb=13890.5, bsz=495.7, num_updates=11800, lr=1.25e-05, gnorm=0.805, train_wall=51, wall=6705
2020-12-19 01:06:39 | INFO | train_inner | epoch 029:    112 / 421 symm_kl=0.536, self_kl=0, self_cv=14.758, loss=4.598, nll_loss=1.117, ppl=2.17, wps=27577.2, ups=1.95, wpb=14129.1, bsz=498.7, num_updates=11900, lr=1.25e-05, gnorm=0.792, train_wall=51, wall=6756
2020-12-19 01:07:30 | INFO | train_inner | epoch 029:    212 / 421 symm_kl=0.542, self_kl=0, self_cv=14.76, loss=4.607, nll_loss=1.116, ppl=2.17, wps=27413.5, ups=1.96, wpb=14014.8, bsz=486.4, num_updates=12000, lr=1.25e-05, gnorm=0.808, train_wall=51, wall=6807
2020-12-19 01:08:21 | INFO | train_inner | epoch 029:    312 / 421 symm_kl=0.535, self_kl=0, self_cv=14.664, loss=4.586, nll_loss=1.113, ppl=2.16, wps=27049.9, ups=1.94, wpb=13916.7, bsz=507.4, num_updates=12100, lr=1.25e-05, gnorm=0.797, train_wall=51, wall=6859
2020-12-19 01:09:13 | INFO | train_inner | epoch 029:    412 / 421 symm_kl=0.542, self_kl=0, self_cv=14.771, loss=4.613, nll_loss=1.123, ppl=2.18, wps=26753.8, ups=1.93, wpb=13860.4, bsz=482.7, num_updates=12200, lr=1.25e-05, gnorm=0.808, train_wall=52, wall=6910
2020-12-19 01:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:09:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:09:34 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.233 | nll_loss 3.806 | ppl 13.99 | bleu 22.69 | wps 6509 | wpb 10324.2 | bsz 375 | num_updates 12209 | best_bleu 22.86
2020-12-19 01:09:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:09:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:09:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 29 @ 12209 updates, score 22.69) (writing took 3.1052529718726873 seconds)
2020-12-19 01:09:37 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-12-19 01:09:37 | INFO | train | epoch 029 | symm_kl 0.539 | self_kl 0 | self_cv 14.738 | loss 4.6 | nll_loss 1.117 | ppl 2.17 | wps 24653.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 12209 | lr 1.25e-05 | gnorm 0.802 | train_wall 216 | wall 6934
2020-12-19 01:09:37 | INFO | fairseq.trainer | begin training epoch 30
2020-12-19 01:09:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:09:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:10:26 | INFO | train_inner | epoch 030:     91 / 421 symm_kl=0.533, self_kl=0, self_cv=14.72, loss=4.583, nll_loss=1.108, ppl=2.16, wps=19146.4, ups=1.37, wpb=14010.2, bsz=498.8, num_updates=12300, lr=1.25e-05, gnorm=0.791, train_wall=51, wall=6984
2020-12-19 01:11:18 | INFO | train_inner | epoch 030:    191 / 421 symm_kl=0.536, self_kl=0, self_cv=14.715, loss=4.591, nll_loss=1.115, ppl=2.17, wps=27018.7, ups=1.94, wpb=13933.2, bsz=483.3, num_updates=12400, lr=1.25e-05, gnorm=0.797, train_wall=51, wall=7035
2020-12-19 01:12:09 | INFO | train_inner | epoch 030:    291 / 421 symm_kl=0.541, self_kl=0, self_cv=14.749, loss=4.609, nll_loss=1.121, ppl=2.18, wps=27098.9, ups=1.94, wpb=13950.6, bsz=497.5, num_updates=12500, lr=1.25e-05, gnorm=0.804, train_wall=51, wall=7087
2020-12-19 01:13:01 | INFO | train_inner | epoch 030:    391 / 421 symm_kl=0.535, self_kl=0, self_cv=14.748, loss=4.595, nll_loss=1.117, ppl=2.17, wps=27271.5, ups=1.94, wpb=14044.2, bsz=493.8, num_updates=12600, lr=1.25e-05, gnorm=0.795, train_wall=51, wall=7138
2020-12-19 01:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:13:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:13:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:13:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:13:32 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.232 | nll_loss 3.805 | ppl 13.98 | bleu 22.74 | wps 6112.4 | wpb 10324.2 | bsz 375 | num_updates 12630 | best_bleu 22.86
2020-12-19 01:13:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:13:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:13:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 30 @ 12630 updates, score 22.74) (writing took 2.65439679287374 seconds)
2020-12-19 01:13:35 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-12-19 01:13:35 | INFO | train | epoch 030 | symm_kl 0.537 | self_kl 0 | self_cv 14.73 | loss 4.596 | nll_loss 1.116 | ppl 2.17 | wps 24674.1 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 12630 | lr 1.25e-05 | gnorm 0.798 | train_wall 216 | wall 7172
2020-12-19 01:13:35 | INFO | fairseq.trainer | begin training epoch 31
2020-12-19 01:13:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:14:14 | INFO | train_inner | epoch 031:     70 / 421 symm_kl=0.542, self_kl=0, self_cv=14.738, loss=4.613, nll_loss=1.125, ppl=2.18, wps=19026.6, ups=1.37, wpb=13873.1, bsz=481.6, num_updates=12700, lr=1.25e-05, gnorm=0.81, train_wall=51, wall=7211
2020-12-19 01:15:05 | INFO | train_inner | epoch 031:    170 / 421 symm_kl=0.53, self_kl=0, self_cv=14.666, loss=4.575, nll_loss=1.109, ppl=2.16, wps=27370.5, ups=1.95, wpb=14050.2, bsz=507.7, num_updates=12800, lr=1.25e-05, gnorm=0.786, train_wall=51, wall=7262
2020-12-19 01:15:56 | INFO | train_inner | epoch 031:    270 / 421 symm_kl=0.54, self_kl=0, self_cv=14.791, loss=4.61, nll_loss=1.121, ppl=2.17, wps=27110.8, ups=1.95, wpb=13924.8, bsz=465.5, num_updates=12900, lr=1.25e-05, gnorm=0.807, train_wall=51, wall=7314
2020-12-19 01:16:48 | INFO | train_inner | epoch 031:    370 / 421 symm_kl=0.532, self_kl=0, self_cv=14.684, loss=4.58, nll_loss=1.11, ppl=2.16, wps=27275.7, ups=1.95, wpb=14000.3, bsz=501.4, num_updates=13000, lr=1.25e-05, gnorm=0.788, train_wall=51, wall=7365
2020-12-19 01:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:17:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:17:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:17:31 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.229 | nll_loss 3.803 | ppl 13.96 | bleu 22.83 | wps 5675.9 | wpb 10324.2 | bsz 375 | num_updates 13051 | best_bleu 22.86
2020-12-19 01:17:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:17:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:17:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 31 @ 13051 updates, score 22.83) (writing took 3.0296606197953224 seconds)
2020-12-19 01:17:34 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-12-19 01:17:34 | INFO | train | epoch 031 | symm_kl 0.535 | self_kl 0 | self_cv 14.722 | loss 4.593 | nll_loss 1.116 | ppl 2.17 | wps 24608.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 13051 | lr 1.25e-05 | gnorm 0.796 | train_wall 215 | wall 7411
2020-12-19 01:17:34 | INFO | fairseq.trainer | begin training epoch 32
2020-12-19 01:17:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:17:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:18:02 | INFO | train_inner | epoch 032:     49 / 421 symm_kl=0.535, self_kl=0, self_cv=14.771, loss=4.601, nll_loss=1.122, ppl=2.18, wps=18532.9, ups=1.35, wpb=13736.1, bsz=497.8, num_updates=13100, lr=1.25e-05, gnorm=0.803, train_wall=51, wall=7439
2020-12-19 01:18:53 | INFO | train_inner | epoch 032:    149 / 421 symm_kl=0.53, self_kl=0, self_cv=14.726, loss=4.581, nll_loss=1.11, ppl=2.16, wps=27702.9, ups=1.95, wpb=14205.9, bsz=491.4, num_updates=13200, lr=1.25e-05, gnorm=0.781, train_wall=51, wall=7491
2020-12-19 01:19:44 | INFO | train_inner | epoch 032:    249 / 421 symm_kl=0.531, self_kl=0, self_cv=14.709, loss=4.579, nll_loss=1.109, ppl=2.16, wps=27477.7, ups=1.95, wpb=14086.9, bsz=488.9, num_updates=13300, lr=1.25e-05, gnorm=0.789, train_wall=51, wall=7542
2020-12-19 01:20:36 | INFO | train_inner | epoch 032:    349 / 421 symm_kl=0.54, self_kl=0, self_cv=14.724, loss=4.603, nll_loss=1.12, ppl=2.17, wps=26887.9, ups=1.94, wpb=13848.6, bsz=472.5, num_updates=13400, lr=1.25e-05, gnorm=0.81, train_wall=51, wall=7593
2020-12-19 01:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:21:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:21:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:21:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:21:29 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.229 | nll_loss 3.801 | ppl 13.94 | bleu 22.71 | wps 6230.8 | wpb 10324.2 | bsz 375 | num_updates 13472 | best_bleu 22.86
2020-12-19 01:21:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 32 @ 13472 updates, score 22.71) (writing took 3.05741011723876 seconds)
2020-12-19 01:21:32 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-12-19 01:21:32 | INFO | train | epoch 032 | symm_kl 0.533 | self_kl 0 | self_cv 14.72 | loss 4.589 | nll_loss 1.115 | ppl 2.17 | wps 24727.8 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 13472 | lr 1.25e-05 | gnorm 0.795 | train_wall 215 | wall 7649
2020-12-19 01:21:32 | INFO | fairseq.trainer | begin training epoch 33
2020-12-19 01:21:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:21:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:21:49 | INFO | train_inner | epoch 033:     28 / 421 symm_kl=0.53, self_kl=0, self_cv=14.699, loss=4.586, nll_loss=1.117, ppl=2.17, wps=18949.9, ups=1.36, wpb=13913.9, bsz=525.4, num_updates=13500, lr=1.25e-05, gnorm=0.796, train_wall=51, wall=7667
2020-12-19 01:22:41 | INFO | train_inner | epoch 033:    128 / 421 symm_kl=0.526, self_kl=0, self_cv=14.702, loss=4.573, nll_loss=1.11, ppl=2.16, wps=27282.4, ups=1.95, wpb=14000, bsz=500, num_updates=13600, lr=1.25e-05, gnorm=0.782, train_wall=51, wall=7718
2020-12-19 01:23:32 | INFO | train_inner | epoch 033:    228 / 421 symm_kl=0.531, self_kl=0, self_cv=14.713, loss=4.584, nll_loss=1.113, ppl=2.16, wps=27228.2, ups=1.94, wpb=14017.7, bsz=502.2, num_updates=13700, lr=1.25e-05, gnorm=0.789, train_wall=51, wall=7770
2020-12-19 01:24:23 | INFO | train_inner | epoch 033:    328 / 421 symm_kl=0.538, self_kl=0, self_cv=14.744, loss=4.602, nll_loss=1.12, ppl=2.17, wps=27205, ups=1.95, wpb=13934, bsz=474.8, num_updates=13800, lr=1.25e-05, gnorm=0.802, train_wall=51, wall=7821
2020-12-19 01:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:25:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:25:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:25:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:25:26 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.227 | nll_loss 3.798 | ppl 13.91 | bleu 22.71 | wps 6695.5 | wpb 10324.2 | bsz 375 | num_updates 13893 | best_bleu 22.86
2020-12-19 01:25:26 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:25:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 33 @ 13893 updates, score 22.71) (writing took 3.1833939626812935 seconds)
2020-12-19 01:25:29 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-12-19 01:25:29 | INFO | train | epoch 033 | symm_kl 0.532 | self_kl 0 | self_cv 14.715 | loss 4.586 | nll_loss 1.114 | ppl 2.16 | wps 24763 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 13893 | lr 1.25e-05 | gnorm 0.793 | train_wall 215 | wall 7887
2020-12-19 01:25:29 | INFO | fairseq.trainer | begin training epoch 34
2020-12-19 01:25:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:25:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:25:36 | INFO | train_inner | epoch 034:      7 / 421 symm_kl=0.531, self_kl=0, self_cv=14.686, loss=4.583, nll_loss=1.114, ppl=2.16, wps=19117.2, ups=1.37, wpb=13912, bsz=487.7, num_updates=13900, lr=1.25e-05, gnorm=0.801, train_wall=51, wall=7894
2020-12-19 01:26:27 | INFO | train_inner | epoch 034:    107 / 421 symm_kl=0.533, self_kl=0, self_cv=14.717, loss=4.591, nll_loss=1.117, ppl=2.17, wps=27384.9, ups=1.96, wpb=13986, bsz=504.2, num_updates=14000, lr=1.25e-05, gnorm=0.791, train_wall=51, wall=7945
2020-12-19 01:27:18 | INFO | train_inner | epoch 034:    207 / 421 symm_kl=0.531, self_kl=0, self_cv=14.723, loss=4.59, nll_loss=1.119, ppl=2.17, wps=27317.4, ups=1.95, wpb=13983.3, bsz=494.8, num_updates=14100, lr=1.25e-05, gnorm=0.789, train_wall=51, wall=7996
2020-12-19 01:28:10 | INFO | train_inner | epoch 034:    307 / 421 symm_kl=0.524, self_kl=0, self_cv=14.649, loss=4.565, nll_loss=1.108, ppl=2.15, wps=27021.2, ups=1.94, wpb=13929, bsz=504.4, num_updates=14200, lr=1.25e-05, gnorm=0.787, train_wall=51, wall=8047
2020-12-19 01:29:01 | INFO | train_inner | epoch 034:    407 / 421 symm_kl=0.529, self_kl=0, self_cv=14.688, loss=4.579, nll_loss=1.112, ppl=2.16, wps=27149.1, ups=1.94, wpb=13997.4, bsz=476.1, num_updates=14300, lr=1.25e-05, gnorm=0.787, train_wall=51, wall=8099
2020-12-19 01:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:29:25 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.225 | nll_loss 3.796 | ppl 13.89 | bleu 22.71 | wps 5919.2 | wpb 10324.2 | bsz 375 | num_updates 14314 | best_bleu 22.86
2020-12-19 01:29:25 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:29:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:29:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 34 @ 14314 updates, score 22.71) (writing took 3.274738708510995 seconds)
2020-12-19 01:29:28 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-12-19 01:29:28 | INFO | train | epoch 034 | symm_kl 0.53 | self_kl 0 | self_cv 14.7 | loss 4.582 | nll_loss 1.114 | ppl 2.16 | wps 24601.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 14314 | lr 1.25e-05 | gnorm 0.79 | train_wall 215 | wall 8126
2020-12-19 01:29:28 | INFO | fairseq.trainer | begin training epoch 35
2020-12-19 01:29:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:29:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:30:16 | INFO | train_inner | epoch 035:     86 / 421 symm_kl=0.524, self_kl=0, self_cv=14.732, loss=4.57, nll_loss=1.107, ppl=2.15, wps=18839.3, ups=1.35, wpb=13962.1, bsz=477.3, num_updates=14400, lr=1.25e-05, gnorm=0.787, train_wall=51, wall=8173
2020-12-19 01:31:07 | INFO | train_inner | epoch 035:    186 / 421 symm_kl=0.524, self_kl=0, self_cv=14.643, loss=4.56, nll_loss=1.103, ppl=2.15, wps=27118.5, ups=1.94, wpb=13963.9, bsz=507.5, num_updates=14500, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=8224
2020-12-19 01:31:59 | INFO | train_inner | epoch 035:    286 / 421 symm_kl=0.531, self_kl=0, self_cv=14.772, loss=4.593, nll_loss=1.119, ppl=2.17, wps=27341.9, ups=1.94, wpb=14103.9, bsz=479.2, num_updates=14600, lr=1.25e-05, gnorm=0.786, train_wall=51, wall=8276
2020-12-19 01:32:50 | INFO | train_inner | epoch 035:    386 / 421 symm_kl=0.531, self_kl=0, self_cv=14.661, loss=4.586, nll_loss=1.118, ppl=2.17, wps=26893.7, ups=1.93, wpb=13917.1, bsz=499.5, num_updates=14700, lr=1.25e-05, gnorm=0.79, train_wall=52, wall=8328
2020-12-19 01:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:33:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:33:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:33:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:33:24 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.225 | nll_loss 3.796 | ppl 13.89 | bleu 22.71 | wps 6409.3 | wpb 10324.2 | bsz 375 | num_updates 14735 | best_bleu 22.86
2020-12-19 01:33:24 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:33:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:33:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 35 @ 14735 updates, score 22.71) (writing took 3.371643988415599 seconds)
2020-12-19 01:33:27 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-12-19 01:33:27 | INFO | train | epoch 035 | symm_kl 0.528 | self_kl 0 | self_cv 14.699 | loss 4.579 | nll_loss 1.113 | ppl 2.16 | wps 24614.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 14735 | lr 1.25e-05 | gnorm 0.787 | train_wall 216 | wall 8365
2020-12-19 01:33:27 | INFO | fairseq.trainer | begin training epoch 36
2020-12-19 01:33:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:33:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:34:03 | INFO | train_inner | epoch 036:     65 / 421 symm_kl=0.529, self_kl=0, self_cv=14.708, loss=4.584, nll_loss=1.117, ppl=2.17, wps=18849.2, ups=1.37, wpb=13745.1, bsz=484.9, num_updates=14800, lr=1.25e-05, gnorm=0.799, train_wall=50, wall=8401
2020-12-19 01:34:55 | INFO | train_inner | epoch 036:    165 / 421 symm_kl=0.532, self_kl=0, self_cv=14.755, loss=4.596, nll_loss=1.12, ppl=2.17, wps=27057.5, ups=1.94, wpb=13932.1, bsz=482.5, num_updates=14900, lr=1.25e-05, gnorm=0.797, train_wall=51, wall=8452
2020-12-19 01:35:46 | INFO | train_inner | epoch 036:    265 / 421 symm_kl=0.523, self_kl=0, self_cv=14.697, loss=4.566, nll_loss=1.107, ppl=2.15, wps=27480.9, ups=1.95, wpb=14089.7, bsz=509.1, num_updates=15000, lr=1.25e-05, gnorm=0.781, train_wall=51, wall=8504
2020-12-19 01:36:38 | INFO | train_inner | epoch 036:    365 / 421 symm_kl=0.519, self_kl=0, self_cv=14.622, loss=4.552, nll_loss=1.105, ppl=2.15, wps=27679.9, ups=1.94, wpb=14257.4, bsz=501.1, num_updates=15100, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=8555
2020-12-19 01:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:37:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:37:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:37:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:37:23 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.228 | nll_loss 3.801 | ppl 13.94 | bleu 22.65 | wps 6125.3 | wpb 10324.2 | bsz 375 | num_updates 15156 | best_bleu 22.86
2020-12-19 01:37:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:37:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 36 @ 15156 updates, score 22.65) (writing took 3.2498743776232004 seconds)
2020-12-19 01:37:26 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-12-19 01:37:26 | INFO | train | epoch 036 | symm_kl 0.527 | self_kl 0 | self_cv 14.692 | loss 4.576 | nll_loss 1.112 | ppl 2.16 | wps 24664.9 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 15156 | lr 1.25e-05 | gnorm 0.789 | train_wall 215 | wall 8603
2020-12-19 01:37:26 | INFO | fairseq.trainer | begin training epoch 37
2020-12-19 01:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:37:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:37:51 | INFO | train_inner | epoch 037:     44 / 421 symm_kl=0.532, self_kl=0, self_cv=14.71, loss=4.594, nll_loss=1.122, ppl=2.18, wps=18716.7, ups=1.36, wpb=13760.8, bsz=468.6, num_updates=15200, lr=1.25e-05, gnorm=0.801, train_wall=51, wall=8629
2020-12-19 01:38:42 | INFO | train_inner | epoch 037:    144 / 421 symm_kl=0.529, self_kl=0, self_cv=14.702, loss=4.584, nll_loss=1.118, ppl=2.17, wps=27003, ups=1.95, wpb=13844.6, bsz=487.3, num_updates=15300, lr=1.25e-05, gnorm=0.795, train_wall=51, wall=8680
2020-12-19 01:39:34 | INFO | train_inner | epoch 037:    244 / 421 symm_kl=0.52, self_kl=0, self_cv=14.658, loss=4.557, nll_loss=1.106, ppl=2.15, wps=27305.3, ups=1.95, wpb=14021.7, bsz=500.2, num_updates=15400, lr=1.25e-05, gnorm=0.775, train_wall=51, wall=8731
2020-12-19 01:40:25 | INFO | train_inner | epoch 037:    344 / 421 symm_kl=0.523, self_kl=0, self_cv=14.679, loss=4.568, nll_loss=1.111, ppl=2.16, wps=27513.2, ups=1.95, wpb=14112, bsz=500.6, num_updates=15500, lr=1.25e-05, gnorm=0.775, train_wall=51, wall=8782
2020-12-19 01:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:41:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:41:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:41:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:41:20 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.223 | nll_loss 3.795 | ppl 13.89 | bleu 22.75 | wps 6584 | wpb 10324.2 | bsz 375 | num_updates 15577 | best_bleu 22.86
2020-12-19 01:41:20 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:41:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 37 @ 15577 updates, score 22.75) (writing took 3.250481240451336 seconds)
2020-12-19 01:41:23 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-12-19 01:41:23 | INFO | train | epoch 037 | symm_kl 0.525 | self_kl 0 | self_cv 14.674 | loss 4.571 | nll_loss 1.112 | ppl 2.16 | wps 24785.6 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 15577 | lr 1.25e-05 | gnorm 0.785 | train_wall 215 | wall 8841
2020-12-19 01:41:23 | INFO | fairseq.trainer | begin training epoch 38
2020-12-19 01:41:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:41:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:41:38 | INFO | train_inner | epoch 038:     23 / 421 symm_kl=0.527, self_kl=0, self_cv=14.656, loss=4.579, nll_loss=1.118, ppl=2.17, wps=18890.2, ups=1.37, wpb=13763.3, bsz=486, num_updates=15600, lr=1.25e-05, gnorm=0.802, train_wall=51, wall=8855
2020-12-19 01:42:29 | INFO | train_inner | epoch 038:    123 / 421 symm_kl=0.522, self_kl=0, self_cv=14.657, loss=4.561, nll_loss=1.106, ppl=2.15, wps=27179.7, ups=1.96, wpb=13863.9, bsz=510.3, num_updates=15700, lr=1.25e-05, gnorm=0.786, train_wall=51, wall=8906
2020-12-19 01:43:20 | INFO | train_inner | epoch 038:    223 / 421 symm_kl=0.522, self_kl=0, self_cv=14.631, loss=4.564, nll_loss=1.112, ppl=2.16, wps=27484.7, ups=1.95, wpb=14077.8, bsz=498.1, num_updates=15800, lr=1.25e-05, gnorm=0.779, train_wall=51, wall=8958
2020-12-19 01:44:12 | INFO | train_inner | epoch 038:    323 / 421 symm_kl=0.527, self_kl=0, self_cv=14.676, loss=4.582, nll_loss=1.12, ppl=2.17, wps=27364, ups=1.94, wpb=14103.4, bsz=481.4, num_updates=15900, lr=1.25e-05, gnorm=0.779, train_wall=51, wall=9009
2020-12-19 01:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:45:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:45:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:45:18 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.227 | nll_loss 3.798 | ppl 13.91 | bleu 22.74 | wps 6471.9 | wpb 10324.2 | bsz 375 | num_updates 15998 | best_bleu 22.86
2020-12-19 01:45:18 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:45:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 38 @ 15998 updates, score 22.74) (writing took 3.2630646396428347 seconds)
2020-12-19 01:45:21 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-12-19 01:45:21 | INFO | train | epoch 038 | symm_kl 0.523 | self_kl 0 | self_cv 14.673 | loss 4.569 | nll_loss 1.112 | ppl 2.16 | wps 24717.1 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 15998 | lr 1.25e-05 | gnorm 0.785 | train_wall 215 | wall 9078
2020-12-19 01:45:21 | INFO | fairseq.trainer | begin training epoch 39
2020-12-19 01:45:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:45:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:45:25 | INFO | train_inner | epoch 039:      2 / 421 symm_kl=0.519, self_kl=0, self_cv=14.691, loss=4.558, nll_loss=1.105, ppl=2.15, wps=18904, ups=1.36, wpb=13913.6, bsz=491.7, num_updates=16000, lr=1.25e-05, gnorm=0.788, train_wall=51, wall=9083
2020-12-19 01:46:16 | INFO | train_inner | epoch 039:    102 / 421 symm_kl=0.523, self_kl=0, self_cv=14.654, loss=4.568, nll_loss=1.113, ppl=2.16, wps=27448.6, ups=1.96, wpb=13976.1, bsz=494.8, num_updates=16100, lr=1.25e-05, gnorm=0.78, train_wall=51, wall=9134
2020-12-19 01:47:08 | INFO | train_inner | epoch 039:    202 / 421 symm_kl=0.515, self_kl=0, self_cv=14.642, loss=4.54, nll_loss=1.096, ppl=2.14, wps=27273.6, ups=1.94, wpb=14067.4, bsz=497.4, num_updates=16200, lr=1.25e-05, gnorm=0.773, train_wall=51, wall=9185
2020-12-19 01:47:59 | INFO | train_inner | epoch 039:    302 / 421 symm_kl=0.525, self_kl=0, self_cv=14.71, loss=4.581, nll_loss=1.12, ppl=2.17, wps=27318.3, ups=1.94, wpb=14046.5, bsz=496.7, num_updates=16300, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=9237
2020-12-19 01:48:50 | INFO | train_inner | epoch 039:    402 / 421 symm_kl=0.523, self_kl=0, self_cv=14.683, loss=4.571, nll_loss=1.115, ppl=2.17, wps=27151.9, ups=1.96, wpb=13881.8, bsz=485.9, num_updates=16400, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=9288
2020-12-19 01:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:49:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:49:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:49:17 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.224 | nll_loss 3.797 | ppl 13.9 | bleu 22.73 | wps 5905.4 | wpb 10324.2 | bsz 375 | num_updates 16419 | best_bleu 22.86
2020-12-19 01:49:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:49:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:49:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 39 @ 16419 updates, score 22.73) (writing took 3.3012000247836113 seconds)
2020-12-19 01:49:20 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-12-19 01:49:20 | INFO | train | epoch 039 | symm_kl 0.522 | self_kl 0 | self_cv 14.67 | loss 4.566 | nll_loss 1.112 | ppl 2.16 | wps 24602.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 16419 | lr 1.25e-05 | gnorm 0.782 | train_wall 215 | wall 9318
2020-12-19 01:49:20 | INFO | fairseq.trainer | begin training epoch 40
2020-12-19 01:49:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:49:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:50:04 | INFO | train_inner | epoch 040:     81 / 421 symm_kl=0.529, self_kl=0, self_cv=14.775, loss=4.59, nll_loss=1.119, ppl=2.17, wps=18583.4, ups=1.35, wpb=13775.3, bsz=458.8, num_updates=16500, lr=1.25e-05, gnorm=0.8, train_wall=51, wall=9362
2020-12-19 01:50:56 | INFO | train_inner | epoch 040:    181 / 421 symm_kl=0.516, self_kl=0, self_cv=14.597, loss=4.548, nll_loss=1.106, ppl=2.15, wps=27211.8, ups=1.95, wpb=13989.1, bsz=509.5, num_updates=16600, lr=1.25e-05, gnorm=0.781, train_wall=51, wall=9413
2020-12-19 01:51:47 | INFO | train_inner | epoch 040:    281 / 421 symm_kl=0.517, self_kl=0, self_cv=14.666, loss=4.551, nll_loss=1.103, ppl=2.15, wps=27480.8, ups=1.95, wpb=14114.3, bsz=492.2, num_updates=16700, lr=1.25e-05, gnorm=0.777, train_wall=51, wall=9465
2020-12-19 01:52:39 | INFO | train_inner | epoch 040:    381 / 421 symm_kl=0.523, self_kl=0, self_cv=14.66, loss=4.574, nll_loss=1.121, ppl=2.17, wps=27284.5, ups=1.95, wpb=14010.3, bsz=512.3, num_updates=16800, lr=1.25e-05, gnorm=0.782, train_wall=51, wall=9516
2020-12-19 01:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:53:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:53:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:53:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:53:16 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.22 | nll_loss 3.793 | ppl 13.87 | bleu 22.89 | wps 5944.2 | wpb 10324.2 | bsz 375 | num_updates 16840 | best_bleu 22.89
2020-12-19 01:53:16 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:53:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 40 @ 16840 updates, score 22.89) (writing took 5.1729934848845005 seconds)
2020-12-19 01:53:21 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-12-19 01:53:21 | INFO | train | epoch 040 | symm_kl 0.52 | self_kl 0 | self_cv 14.673 | loss 4.563 | nll_loss 1.111 | ppl 2.16 | wps 24422.2 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 16840 | lr 1.25e-05 | gnorm 0.783 | train_wall 215 | wall 9558
2020-12-19 01:53:21 | INFO | fairseq.trainer | begin training epoch 41
2020-12-19 01:53:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:53:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:53:54 | INFO | train_inner | epoch 041:     60 / 421 symm_kl=0.516, self_kl=0, self_cv=14.639, loss=4.553, nll_loss=1.108, ppl=2.16, wps=18265.6, ups=1.32, wpb=13852.1, bsz=485.2, num_updates=16900, lr=1.25e-05, gnorm=0.779, train_wall=51, wall=9592
2020-12-19 01:54:46 | INFO | train_inner | epoch 041:    160 / 421 symm_kl=0.518, self_kl=0, self_cv=14.684, loss=4.558, nll_loss=1.107, ppl=2.15, wps=27271, ups=1.94, wpb=14070.9, bsz=484.6, num_updates=17000, lr=1.25e-05, gnorm=0.777, train_wall=51, wall=9643
2020-12-19 01:55:37 | INFO | train_inner | epoch 041:    260 / 421 symm_kl=0.513, self_kl=0, self_cv=14.529, loss=4.539, nll_loss=1.106, ppl=2.15, wps=27132.5, ups=1.95, wpb=13910.3, bsz=522.1, num_updates=17100, lr=1.25e-05, gnorm=0.773, train_wall=51, wall=9695
2020-12-19 01:56:29 | INFO | train_inner | epoch 041:    360 / 421 symm_kl=0.522, self_kl=0, self_cv=14.71, loss=4.575, nll_loss=1.117, ppl=2.17, wps=27276.5, ups=1.95, wpb=13988.5, bsz=486.2, num_updates=17200, lr=1.25e-05, gnorm=0.785, train_wall=51, wall=9746
2020-12-19 01:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 01:57:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 01:57:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 01:57:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 01:57:17 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.222 | nll_loss 3.793 | ppl 13.86 | bleu 22.78 | wps 5679.1 | wpb 10324.2 | bsz 375 | num_updates 17261 | best_bleu 22.89
2020-12-19 01:57:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 01:57:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 41 @ 17261 updates, score 22.78) (writing took 3.203216576948762 seconds)
2020-12-19 01:57:20 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2020-12-19 01:57:20 | INFO | train | epoch 041 | symm_kl 0.519 | self_kl 0 | self_cv 14.659 | loss 4.56 | nll_loss 1.111 | ppl 2.16 | wps 24552.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 17261 | lr 1.25e-05 | gnorm 0.78 | train_wall 215 | wall 9798
2020-12-19 01:57:20 | INFO | fairseq.trainer | begin training epoch 42
2020-12-19 01:57:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 01:57:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 01:57:43 | INFO | train_inner | epoch 042:     39 / 421 symm_kl=0.519, self_kl=0, self_cv=14.706, loss=4.563, nll_loss=1.109, ppl=2.16, wps=18723.1, ups=1.34, wpb=13992.9, bsz=466.6, num_updates=17300, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=9821
2020-12-19 01:58:35 | INFO | train_inner | epoch 042:    139 / 421 symm_kl=0.518, self_kl=0, self_cv=14.685, loss=4.562, nll_loss=1.11, ppl=2.16, wps=27021.1, ups=1.95, wpb=13864.2, bsz=490.1, num_updates=17400, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=9872
2020-12-19 01:59:26 | INFO | train_inner | epoch 042:    239 / 421 symm_kl=0.516, self_kl=0, self_cv=14.602, loss=4.548, nll_loss=1.106, ppl=2.15, wps=27214.4, ups=1.94, wpb=14054, bsz=497.4, num_updates=17500, lr=1.25e-05, gnorm=0.776, train_wall=51, wall=9924
2020-12-19 02:00:17 | INFO | train_inner | epoch 042:    339 / 421 symm_kl=0.516, self_kl=0, self_cv=14.652, loss=4.553, nll_loss=1.107, ppl=2.15, wps=27414.1, ups=1.95, wpb=14062.4, bsz=506.2, num_updates=17600, lr=1.25e-05, gnorm=0.776, train_wall=51, wall=9975
2020-12-19 02:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:01:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:01:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:01:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:01:15 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.221 | nll_loss 3.794 | ppl 13.87 | bleu 22.67 | wps 6409.9 | wpb 10324.2 | bsz 375 | num_updates 17682 | best_bleu 22.89
2020-12-19 02:01:15 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:01:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 42 @ 17682 updates, score 22.67) (writing took 3.2173953652381897 seconds)
2020-12-19 02:01:19 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2020-12-19 02:01:19 | INFO | train | epoch 042 | symm_kl 0.517 | self_kl 0 | self_cv 14.651 | loss 4.557 | nll_loss 1.11 | ppl 2.16 | wps 24702.5 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 17682 | lr 1.25e-05 | gnorm 0.782 | train_wall 215 | wall 10036
2020-12-19 02:01:19 | INFO | fairseq.trainer | begin training epoch 43
2020-12-19 02:01:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:01:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:01:31 | INFO | train_inner | epoch 043:     18 / 421 symm_kl=0.518, self_kl=0, self_cv=14.664, loss=4.565, nll_loss=1.116, ppl=2.17, wps=18822.9, ups=1.36, wpb=13796.6, bsz=485.9, num_updates=17700, lr=1.25e-05, gnorm=0.791, train_wall=51, wall=10048
2020-12-19 02:02:22 | INFO | train_inner | epoch 043:    118 / 421 symm_kl=0.516, self_kl=0, self_cv=14.657, loss=4.555, nll_loss=1.11, ppl=2.16, wps=27263.4, ups=1.95, wpb=13998.6, bsz=490.6, num_updates=17800, lr=1.25e-05, gnorm=0.773, train_wall=51, wall=10100
2020-12-19 02:03:14 | INFO | train_inner | epoch 043:    218 / 421 symm_kl=0.519, self_kl=0, self_cv=14.663, loss=4.56, nll_loss=1.11, ppl=2.16, wps=27033.3, ups=1.94, wpb=13921.6, bsz=480.3, num_updates=17900, lr=1.25e-05, gnorm=0.786, train_wall=51, wall=10151
2020-12-19 02:04:05 | INFO | train_inner | epoch 043:    318 / 421 symm_kl=0.515, self_kl=0, self_cv=14.635, loss=4.554, nll_loss=1.111, ppl=2.16, wps=27238.8, ups=1.94, wpb=14013.3, bsz=509.1, num_updates=18000, lr=1.25e-05, gnorm=0.776, train_wall=51, wall=10203
2020-12-19 02:04:56 | INFO | train_inner | epoch 043:    418 / 421 symm_kl=0.515, self_kl=0, self_cv=14.62, loss=4.553, nll_loss=1.112, ppl=2.16, wps=27467.5, ups=1.95, wpb=14072.7, bsz=493.7, num_updates=18100, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=10254
2020-12-19 02:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:05:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:05:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:05:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:05:15 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.219 | nll_loss 3.79 | ppl 13.83 | bleu 22.85 | wps 5893.4 | wpb 10324.2 | bsz 375 | num_updates 18103 | best_bleu 22.89
2020-12-19 02:05:15 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:05:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:05:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:05:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:05:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:05:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 43 @ 18103 updates, score 22.85) (writing took 3.2244441360235214 seconds)
2020-12-19 02:05:18 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2020-12-19 02:05:18 | INFO | train | epoch 043 | symm_kl 0.515 | self_kl 0 | self_cv 14.641 | loss 4.554 | nll_loss 1.11 | ppl 2.16 | wps 24577.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 18103 | lr 1.25e-05 | gnorm 0.781 | train_wall 215 | wall 10275
2020-12-19 02:05:18 | INFO | fairseq.trainer | begin training epoch 44
2020-12-19 02:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:05:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:06:10 | INFO | train_inner | epoch 044:     97 / 421 symm_kl=0.513, self_kl=0, self_cv=14.675, loss=4.545, nll_loss=1.102, ppl=2.15, wps=18696.5, ups=1.35, wpb=13866.6, bsz=492.2, num_updates=18200, lr=1.25e-05, gnorm=0.793, train_wall=51, wall=10328
2020-12-19 02:07:02 | INFO | train_inner | epoch 044:    197 / 421 symm_kl=0.508, self_kl=0, self_cv=14.628, loss=4.526, nll_loss=1.092, ppl=2.13, wps=27232.5, ups=1.94, wpb=14058.6, bsz=492.3, num_updates=18300, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=10380
2020-12-19 02:07:53 | INFO | train_inner | epoch 044:    297 / 421 symm_kl=0.513, self_kl=0, self_cv=14.564, loss=4.55, nll_loss=1.115, ppl=2.17, wps=27136, ups=1.95, wpb=13940.4, bsz=512, num_updates=18400, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=10431
2020-12-19 02:08:45 | INFO | train_inner | epoch 044:    397 / 421 symm_kl=0.522, self_kl=0, self_cv=14.755, loss=4.582, nll_loss=1.121, ppl=2.18, wps=27394.5, ups=1.95, wpb=14035.6, bsz=473.9, num_updates=18500, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=10482
2020-12-19 02:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:08:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:08:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:08:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:08:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:08:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:09:13 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.219 | nll_loss 3.792 | ppl 13.85 | bleu 22.78 | wps 6123.3 | wpb 10324.2 | bsz 375 | num_updates 18524 | best_bleu 22.89
2020-12-19 02:09:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:09:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:09:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:09:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:09:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 44 @ 18524 updates, score 22.78) (writing took 3.286923123523593 seconds)
2020-12-19 02:09:17 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2020-12-19 02:09:17 | INFO | train | epoch 044 | symm_kl 0.515 | self_kl 0 | self_cv 14.649 | loss 4.552 | nll_loss 1.109 | ppl 2.16 | wps 24613.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 18524 | lr 1.25e-05 | gnorm 0.776 | train_wall 215 | wall 10514
2020-12-19 02:09:17 | INFO | fairseq.trainer | begin training epoch 45
2020-12-19 02:09:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:09:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:09:59 | INFO | train_inner | epoch 045:     76 / 421 symm_kl=0.513, self_kl=0, self_cv=14.598, loss=4.551, nll_loss=1.115, ppl=2.17, wps=18654, ups=1.35, wpb=13771.3, bsz=483, num_updates=18600, lr=1.25e-05, gnorm=0.781, train_wall=51, wall=10556
2020-12-19 02:10:50 | INFO | train_inner | epoch 045:    176 / 421 symm_kl=0.515, self_kl=0, self_cv=14.614, loss=4.551, nll_loss=1.11, ppl=2.16, wps=27278.9, ups=1.95, wpb=13992.1, bsz=510.8, num_updates=18700, lr=1.25e-05, gnorm=0.777, train_wall=51, wall=10607
2020-12-19 02:11:41 | INFO | train_inner | epoch 045:    276 / 421 symm_kl=0.52, self_kl=0, self_cv=14.692, loss=4.569, nll_loss=1.116, ppl=2.17, wps=27270.4, ups=1.95, wpb=13974.4, bsz=476, num_updates=18800, lr=1.25e-05, gnorm=0.782, train_wall=51, wall=10659
2020-12-19 02:12:33 | INFO | train_inner | epoch 045:    376 / 421 symm_kl=0.509, self_kl=0, self_cv=14.626, loss=4.534, nll_loss=1.101, ppl=2.14, wps=27403.9, ups=1.94, wpb=14092, bsz=499.6, num_updates=18900, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=10710
2020-12-19 02:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:12:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:12:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:12:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:12:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:12:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:12:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:12:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:12:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:13:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:13:12 | INFO | valid | epoch 045 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.219 | nll_loss 3.791 | ppl 13.85 | bleu 22.8 | wps 5862.4 | wpb 10324.2 | bsz 375 | num_updates 18945 | best_bleu 22.89
2020-12-19 02:13:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:13:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:13:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:13:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:13:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:13:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 45 @ 18945 updates, score 22.8) (writing took 3.27263368293643 seconds)
2020-12-19 02:13:16 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2020-12-19 02:13:16 | INFO | train | epoch 045 | symm_kl 0.513 | self_kl 0 | self_cv 14.638 | loss 4.549 | nll_loss 1.108 | ppl 2.16 | wps 24608.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 18945 | lr 1.25e-05 | gnorm 0.776 | train_wall 215 | wall 10753
2020-12-19 02:13:16 | INFO | fairseq.trainer | begin training epoch 46
2020-12-19 02:13:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:13:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:13:47 | INFO | train_inner | epoch 046:     55 / 421 symm_kl=0.511, self_kl=0, self_cv=14.575, loss=4.535, nll_loss=1.102, ppl=2.15, wps=18799.7, ups=1.35, wpb=13951.3, bsz=487.3, num_updates=19000, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=10784
2020-12-19 02:14:39 | INFO | train_inner | epoch 046:    155 / 421 symm_kl=0.514, self_kl=0, self_cv=14.647, loss=4.556, nll_loss=1.115, ppl=2.17, wps=26771.2, ups=1.93, wpb=13867.7, bsz=496.7, num_updates=19100, lr=1.25e-05, gnorm=0.783, train_wall=52, wall=10836
2020-12-19 02:15:30 | INFO | train_inner | epoch 046:    255 / 421 symm_kl=0.513, self_kl=0, self_cv=14.68, loss=4.551, nll_loss=1.107, ppl=2.15, wps=27262.8, ups=1.93, wpb=14102.5, bsz=494.7, num_updates=19200, lr=1.25e-05, gnorm=0.77, train_wall=52, wall=10888
2020-12-19 02:16:21 | INFO | train_inner | epoch 046:    355 / 421 symm_kl=0.512, self_kl=0, self_cv=14.596, loss=4.544, nll_loss=1.11, ppl=2.16, wps=27375.2, ups=1.96, wpb=13996.6, bsz=487.2, num_updates=19300, lr=1.25e-05, gnorm=0.778, train_wall=51, wall=10939
2020-12-19 02:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:16:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:16:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:16:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:16:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:16:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:16:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:16:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:16:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:17:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:17:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:17:12 | INFO | valid | epoch 046 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.216 | nll_loss 3.789 | ppl 13.82 | bleu 22.84 | wps 5785.4 | wpb 10324.2 | bsz 375 | num_updates 19366 | best_bleu 22.89
2020-12-19 02:17:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:17:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:17:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:17:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:17:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:17:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:17:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:17:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 46 @ 19366 updates, score 22.84) (writing took 3.2634564824402332 seconds)
2020-12-19 02:17:15 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2020-12-19 02:17:15 | INFO | train | epoch 046 | symm_kl 0.512 | self_kl 0 | self_cv 14.62 | loss 4.547 | nll_loss 1.109 | ppl 2.16 | wps 24544.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 19366 | lr 1.25e-05 | gnorm 0.777 | train_wall 215 | wall 10993
2020-12-19 02:17:15 | INFO | fairseq.trainer | begin training epoch 47
2020-12-19 02:17:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:17:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:17:36 | INFO | train_inner | epoch 047:     34 / 421 symm_kl=0.508, self_kl=0, self_cv=14.571, loss=4.536, nll_loss=1.108, ppl=2.16, wps=18784, ups=1.35, wpb=13956.4, bsz=499.5, num_updates=19400, lr=1.25e-05, gnorm=0.772, train_wall=51, wall=11013
2020-12-19 02:18:27 | INFO | train_inner | epoch 047:    134 / 421 symm_kl=0.52, self_kl=0, self_cv=14.693, loss=4.571, nll_loss=1.118, ppl=2.17, wps=27112.3, ups=1.94, wpb=13959.6, bsz=462.2, num_updates=19500, lr=1.25e-05, gnorm=0.784, train_wall=51, wall=11065
2020-12-19 02:19:18 | INFO | train_inner | epoch 047:    234 / 421 symm_kl=0.507, self_kl=0, self_cv=14.628, loss=4.539, nll_loss=1.107, ppl=2.15, wps=27356.6, ups=1.95, wpb=13996.9, bsz=506.4, num_updates=19600, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=11116
2020-12-19 02:20:10 | INFO | train_inner | epoch 047:    334 / 421 symm_kl=0.507, self_kl=0, self_cv=14.521, loss=4.528, nll_loss=1.106, ppl=2.15, wps=27143.7, ups=1.94, wpb=13997.8, bsz=500.8, num_updates=19700, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=11167
2020-12-19 02:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:20:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:20:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:20:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:20:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:20:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:20:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:20:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:20:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:20:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:20:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:20:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:20:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:21:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:21:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:21:10 | INFO | valid | epoch 047 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.215 | nll_loss 3.787 | ppl 13.8 | bleu 22.86 | wps 6341.2 | wpb 10324.2 | bsz 375 | num_updates 19787 | best_bleu 22.89
2020-12-19 02:21:10 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:21:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 47 @ 19787 updates, score 22.86) (writing took 3.2522228471934795 seconds)
2020-12-19 02:21:14 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2020-12-19 02:21:14 | INFO | train | epoch 047 | symm_kl 0.51 | self_kl 0 | self_cv 14.612 | loss 4.543 | nll_loss 1.109 | ppl 2.16 | wps 24685.5 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 19787 | lr 1.25e-05 | gnorm 0.774 | train_wall 215 | wall 11231
2020-12-19 02:21:14 | INFO | fairseq.trainer | begin training epoch 48
2020-12-19 02:21:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:21:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:21:23 | INFO | train_inner | epoch 048:     13 / 421 symm_kl=0.509, self_kl=0, self_cv=14.62, loss=4.539, nll_loss=1.106, ppl=2.15, wps=18876.4, ups=1.36, wpb=13865.8, bsz=501.2, num_updates=19800, lr=1.25e-05, gnorm=0.786, train_wall=51, wall=11241
2020-12-19 02:22:14 | INFO | train_inner | epoch 048:    113 / 421 symm_kl=0.515, self_kl=0, self_cv=14.669, loss=4.555, nll_loss=1.11, ppl=2.16, wps=27345.4, ups=1.96, wpb=13942.5, bsz=492.8, num_updates=19900, lr=1.25e-05, gnorm=0.779, train_wall=51, wall=11292
2020-12-19 02:23:06 | INFO | train_inner | epoch 048:    213 / 421 symm_kl=0.51, self_kl=0, self_cv=14.583, loss=4.544, nll_loss=1.112, ppl=2.16, wps=27304.9, ups=1.95, wpb=13986.9, bsz=473.4, num_updates=20000, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=11343
2020-12-19 02:23:57 | INFO | train_inner | epoch 048:    313 / 421 symm_kl=0.51, self_kl=0, self_cv=14.605, loss=4.542, nll_loss=1.109, ppl=2.16, wps=27263.9, ups=1.95, wpb=13999.2, bsz=503.7, num_updates=20100, lr=1.25e-05, gnorm=0.773, train_wall=51, wall=11394
2020-12-19 02:24:49 | INFO | train_inner | epoch 048:    413 / 421 symm_kl=0.507, self_kl=0, self_cv=14.661, loss=4.536, nll_loss=1.101, ppl=2.15, wps=27010.8, ups=1.93, wpb=13966.9, bsz=498.5, num_updates=20200, lr=1.25e-05, gnorm=0.771, train_wall=52, wall=11446
2020-12-19 02:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:24:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:24:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:24:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:24:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:24:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:24:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:24:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:25:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:25:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:25:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:25:08 | INFO | valid | epoch 048 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.216 | nll_loss 3.79 | ppl 13.83 | bleu 22.9 | wps 6508.3 | wpb 10324.2 | bsz 375 | num_updates 20208 | best_bleu 22.9
2020-12-19 02:25:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:25:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:25:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:25:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:25:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:25:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:25:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:25:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 48 @ 20208 updates, score 22.9) (writing took 5.279579238966107 seconds)
2020-12-19 02:25:14 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2020-12-19 02:25:14 | INFO | train | epoch 048 | symm_kl 0.51 | self_kl 0 | self_cv 14.623 | loss 4.542 | nll_loss 1.107 | ppl 2.15 | wps 24506.6 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 20208 | lr 1.25e-05 | gnorm 0.773 | train_wall 215 | wall 11471
2020-12-19 02:25:14 | INFO | fairseq.trainer | begin training epoch 49
2020-12-19 02:25:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:25:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:26:04 | INFO | train_inner | epoch 049:     92 / 421 symm_kl=0.506, self_kl=0, self_cv=14.617, loss=4.53, nll_loss=1.1, ppl=2.14, wps=18580.9, ups=1.33, wpb=13934.4, bsz=503, num_updates=20300, lr=1.25e-05, gnorm=0.768, train_wall=51, wall=11521
2020-12-19 02:26:55 | INFO | train_inner | epoch 049:    192 / 421 symm_kl=0.518, self_kl=0, self_cv=14.68, loss=4.571, nll_loss=1.123, ppl=2.18, wps=27034.4, ups=1.95, wpb=13889.8, bsz=475.2, num_updates=20400, lr=1.25e-05, gnorm=0.785, train_wall=51, wall=11572
2020-12-19 02:27:46 | INFO | train_inner | epoch 049:    292 / 421 symm_kl=0.505, self_kl=0, self_cv=14.564, loss=4.527, nll_loss=1.104, ppl=2.15, wps=27096.6, ups=1.95, wpb=13923.3, bsz=497, num_updates=20500, lr=1.25e-05, gnorm=0.772, train_wall=51, wall=11624
2020-12-19 02:28:38 | INFO | train_inner | epoch 049:    392 / 421 symm_kl=0.506, self_kl=0, self_cv=14.574, loss=4.53, nll_loss=1.105, ppl=2.15, wps=27600.8, ups=1.95, wpb=14132.9, bsz=483.7, num_updates=20600, lr=1.25e-05, gnorm=0.763, train_wall=51, wall=11675
2020-12-19 02:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:28:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:28:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:28:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:28:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:28:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:28:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:28:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:28:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:28:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:28:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:28:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:28:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:29:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:29:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:29:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:29:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:29:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:29:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:29:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:29:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:29:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:29:09 | INFO | valid | epoch 049 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.213 | nll_loss 3.785 | ppl 13.78 | bleu 22.81 | wps 6115 | wpb 10324.2 | bsz 375 | num_updates 20629 | best_bleu 22.9
2020-12-19 02:29:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:29:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:29:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:29:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:29:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 49 @ 20629 updates, score 22.81) (writing took 3.0967883802950382 seconds)
2020-12-19 02:29:12 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2020-12-19 02:29:12 | INFO | train | epoch 049 | symm_kl 0.508 | self_kl 0 | self_cv 14.606 | loss 4.539 | nll_loss 1.108 | ppl 2.16 | wps 24647.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 20629 | lr 1.25e-05 | gnorm 0.772 | train_wall 215 | wall 11710
2020-12-19 02:29:12 | INFO | fairseq.trainer | begin training epoch 50
2020-12-19 02:29:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:29:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:29:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:29:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:29:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:29:52 | INFO | train_inner | epoch 050:     71 / 421 symm_kl=0.507, self_kl=0, self_cv=14.601, loss=4.534, nll_loss=1.106, ppl=2.15, wps=18900.1, ups=1.35, wpb=13974.8, bsz=500.3, num_updates=20700, lr=1.25e-05, gnorm=0.774, train_wall=51, wall=11749
2020-12-19 02:30:43 | INFO | train_inner | epoch 050:    171 / 421 symm_kl=0.51, self_kl=0, self_cv=14.615, loss=4.541, nll_loss=1.106, ppl=2.15, wps=27024.6, ups=1.95, wpb=13849.1, bsz=471, num_updates=20800, lr=1.25e-05, gnorm=0.782, train_wall=51, wall=11800
2020-12-19 02:31:34 | INFO | train_inner | epoch 050:    271 / 421 symm_kl=0.5, self_kl=0, self_cv=14.557, loss=4.513, nll_loss=1.097, ppl=2.14, wps=27447, ups=1.94, wpb=14131.2, bsz=510.4, num_updates=20900, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=11852
2020-12-19 02:32:25 | INFO | train_inner | epoch 050:    371 / 421 symm_kl=0.508, self_kl=0, self_cv=14.554, loss=4.539, nll_loss=1.112, ppl=2.16, wps=27343.1, ups=1.95, wpb=13993.5, bsz=510.5, num_updates=21000, lr=1.25e-05, gnorm=0.772, train_wall=51, wall=11903
2020-12-19 02:32:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:32:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:32:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:32:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:32:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:32:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:32:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:32:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:32:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:32:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:33:07 | INFO | valid | epoch 050 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.215 | nll_loss 3.788 | ppl 13.82 | bleu 22.79 | wps 6198.9 | wpb 10324.2 | bsz 375 | num_updates 21050 | best_bleu 22.9
2020-12-19 02:33:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:33:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:33:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:33:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:33:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:33:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:33:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:33:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 50 @ 21050 updates, score 22.79) (writing took 3.0928062982857227 seconds)
2020-12-19 02:33:10 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2020-12-19 02:33:10 | INFO | train | epoch 050 | symm_kl 0.508 | self_kl 0 | self_cv 14.599 | loss 4.537 | nll_loss 1.107 | ppl 2.15 | wps 24692 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 21050 | lr 1.25e-05 | gnorm 0.773 | train_wall 215 | wall 11948
2020-12-19 02:33:10 | INFO | fairseq.trainer | begin training epoch 51
2020-12-19 02:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:33:39 | INFO | train_inner | epoch 051:     50 / 421 symm_kl=0.516, self_kl=0, self_cv=14.704, loss=4.571, nll_loss=1.123, ppl=2.18, wps=18808.7, ups=1.36, wpb=13798.6, bsz=464.4, num_updates=21100, lr=1.25e-05, gnorm=0.791, train_wall=51, wall=11976
2020-12-19 02:34:30 | INFO | train_inner | epoch 051:    150 / 421 symm_kl=0.505, self_kl=0, self_cv=14.591, loss=4.533, nll_loss=1.108, ppl=2.16, wps=27444.1, ups=1.95, wpb=14049.9, bsz=505.3, num_updates=21200, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=12027
2020-12-19 02:35:22 | INFO | train_inner | epoch 051:    250 / 421 symm_kl=0.508, self_kl=0, self_cv=14.605, loss=4.54, nll_loss=1.11, ppl=2.16, wps=27043, ups=1.94, wpb=13949.7, bsz=501, num_updates=21300, lr=1.25e-05, gnorm=0.77, train_wall=51, wall=12079
2020-12-19 02:36:13 | INFO | train_inner | epoch 051:    350 / 421 symm_kl=0.504, self_kl=0, self_cv=14.607, loss=4.526, nll_loss=1.1, ppl=2.14, wps=27231.8, ups=1.95, wpb=13994.4, bsz=484.5, num_updates=21400, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=12130
2020-12-19 02:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:36:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:36:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:36:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:36:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:36:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:36:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:36:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:36:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:36:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:36:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:36:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:36:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:37:07 | INFO | valid | epoch 051 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.212 | nll_loss 3.784 | ppl 13.77 | bleu 22.9 | wps 5536.4 | wpb 10324.2 | bsz 375 | num_updates 21471 | best_bleu 22.9
2020-12-19 02:37:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:37:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:37:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:37:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:37:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:37:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:37:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:37:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 51 @ 21471 updates, score 22.9) (writing took 5.254419991746545 seconds)
2020-12-19 02:37:12 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2020-12-19 02:37:12 | INFO | train | epoch 051 | symm_kl 0.506 | self_kl 0 | self_cv 14.602 | loss 4.535 | nll_loss 1.107 | ppl 2.15 | wps 24300.6 | ups 1.74 | wpb 13969.5 | bsz 492.6 | num_updates 21471 | lr 1.25e-05 | gnorm 0.771 | train_wall 215 | wall 12190
2020-12-19 02:37:12 | INFO | fairseq.trainer | begin training epoch 52
2020-12-19 02:37:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:37:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:37:30 | INFO | train_inner | epoch 052:     29 / 421 symm_kl=0.501, self_kl=0, self_cv=14.584, loss=4.519, nll_loss=1.099, ppl=2.14, wps=18131.4, ups=1.29, wpb=14005.4, bsz=491.4, num_updates=21500, lr=1.25e-05, gnorm=0.772, train_wall=51, wall=12208
2020-12-19 02:38:21 | INFO | train_inner | epoch 052:    129 / 421 symm_kl=0.506, self_kl=0, self_cv=14.609, loss=4.534, nll_loss=1.106, ppl=2.15, wps=27380.8, ups=1.95, wpb=14011.3, bsz=500.1, num_updates=21600, lr=1.25e-05, gnorm=0.763, train_wall=51, wall=12259
2020-12-19 02:39:12 | INFO | train_inner | epoch 052:    229 / 421 symm_kl=0.516, self_kl=0, self_cv=14.644, loss=4.567, nll_loss=1.125, ppl=2.18, wps=27244.9, ups=1.96, wpb=13925.4, bsz=462.5, num_updates=21700, lr=1.25e-05, gnorm=0.779, train_wall=51, wall=12310
2020-12-19 02:40:04 | INFO | train_inner | epoch 052:    329 / 421 symm_kl=0.502, self_kl=0, self_cv=14.588, loss=4.52, nll_loss=1.099, ppl=2.14, wps=27122.8, ups=1.95, wpb=13906.2, bsz=492.3, num_updates=21800, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=12361
2020-12-19 02:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:40:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:40:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:40:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:40:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:40:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:40:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:40:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:40:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:41:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:41:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:41:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:41:09 | INFO | valid | epoch 052 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.214 | nll_loss 3.786 | ppl 13.8 | bleu 22.77 | wps 5587.2 | wpb 10324.2 | bsz 375 | num_updates 21892 | best_bleu 22.9
2020-12-19 02:41:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:41:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:41:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:41:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 52 @ 21892 updates, score 22.77) (writing took 3.216156754642725 seconds)
2020-12-19 02:41:12 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2020-12-19 02:41:12 | INFO | train | epoch 052 | symm_kl 0.505 | self_kl 0 | self_cv 14.598 | loss 4.532 | nll_loss 1.106 | ppl 2.15 | wps 24565 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 21892 | lr 1.25e-05 | gnorm 0.77 | train_wall 215 | wall 12429
2020-12-19 02:41:12 | INFO | fairseq.trainer | begin training epoch 53
2020-12-19 02:41:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:41:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:41:19 | INFO | train_inner | epoch 053:      8 / 421 symm_kl=0.495, self_kl=0, self_cv=14.492, loss=4.499, nll_loss=1.095, ppl=2.14, wps=18593.4, ups=1.33, wpb=13998.2, bsz=519.4, num_updates=21900, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=12437
2020-12-19 02:42:10 | INFO | train_inner | epoch 053:    108 / 421 symm_kl=0.508, self_kl=0, self_cv=14.61, loss=4.541, nll_loss=1.111, ppl=2.16, wps=27581.4, ups=1.96, wpb=14041.4, bsz=485.9, num_updates=22000, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=12487
2020-12-19 02:43:01 | INFO | train_inner | epoch 053:    208 / 421 symm_kl=0.503, self_kl=0, self_cv=14.589, loss=4.524, nll_loss=1.102, ppl=2.15, wps=27077.6, ups=1.95, wpb=13904.8, bsz=492.6, num_updates=22100, lr=1.25e-05, gnorm=0.77, train_wall=51, wall=12539
2020-12-19 02:43:53 | INFO | train_inner | epoch 053:    308 / 421 symm_kl=0.499, self_kl=0, self_cv=14.58, loss=4.513, nll_loss=1.097, ppl=2.14, wps=27142.6, ups=1.93, wpb=14051.7, bsz=498.5, num_updates=22200, lr=1.25e-05, gnorm=0.763, train_wall=52, wall=12591
2020-12-19 02:44:45 | INFO | train_inner | epoch 053:    408 / 421 symm_kl=0.509, self_kl=0, self_cv=14.584, loss=4.545, nll_loss=1.116, ppl=2.17, wps=26905.4, ups=1.93, wpb=13918.4, bsz=491.2, num_updates=22300, lr=1.25e-05, gnorm=0.774, train_wall=52, wall=12642
2020-12-19 02:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:44:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:44:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:44:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:44:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:44:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:44:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:44:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:44:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:45:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:45:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:45:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:45:08 | INFO | valid | epoch 053 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.216 | nll_loss 3.79 | ppl 13.83 | bleu 22.77 | wps 6014.4 | wpb 10324.2 | bsz 375 | num_updates 22313 | best_bleu 22.9
2020-12-19 02:45:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:45:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:45:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:45:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:45:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 53 @ 22313 updates, score 22.77) (writing took 3.1489021442830563 seconds)
2020-12-19 02:45:11 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2020-12-19 02:45:11 | INFO | train | epoch 053 | symm_kl 0.504 | self_kl 0 | self_cv 14.58 | loss 4.529 | nll_loss 1.106 | ppl 2.15 | wps 24573.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 22313 | lr 1.25e-05 | gnorm 0.769 | train_wall 216 | wall 12669
2020-12-19 02:45:11 | INFO | fairseq.trainer | begin training epoch 54
2020-12-19 02:45:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:45:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:45:59 | INFO | train_inner | epoch 054:     87 / 421 symm_kl=0.504, self_kl=0, self_cv=14.651, loss=4.532, nll_loss=1.105, ppl=2.15, wps=18940.5, ups=1.35, wpb=13991.3, bsz=490.6, num_updates=22400, lr=1.25e-05, gnorm=0.776, train_wall=51, wall=12716
2020-12-19 02:46:50 | INFO | train_inner | epoch 054:    187 / 421 symm_kl=0.503, self_kl=0, self_cv=14.611, loss=4.535, nll_loss=1.111, ppl=2.16, wps=27210.4, ups=1.94, wpb=13999.8, bsz=486.5, num_updates=22500, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=12768
2020-12-19 02:47:42 | INFO | train_inner | epoch 054:    287 / 421 symm_kl=0.499, self_kl=0, self_cv=14.555, loss=4.516, nll_loss=1.101, ppl=2.14, wps=27167.4, ups=1.93, wpb=14070.5, bsz=509, num_updates=22600, lr=1.25e-05, gnorm=0.759, train_wall=52, wall=12819
2020-12-19 02:48:33 | INFO | train_inner | epoch 054:    387 / 421 symm_kl=0.507, self_kl=0, self_cv=14.611, loss=4.538, nll_loss=1.109, ppl=2.16, wps=27160.3, ups=1.96, wpb=13862.2, bsz=486.7, num_updates=22700, lr=1.25e-05, gnorm=0.778, train_wall=51, wall=12870
2020-12-19 02:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:48:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:48:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:48:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:48:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:48:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:48:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:48:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:48:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:48:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:48:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:48:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:48:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:49:07 | INFO | valid | epoch 054 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.215 | nll_loss 3.787 | ppl 13.8 | bleu 22.82 | wps 5832.6 | wpb 10324.2 | bsz 375 | num_updates 22734 | best_bleu 22.9
2020-12-19 02:49:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:49:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:49:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:49:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:49:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:49:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:49:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:49:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 54 @ 22734 updates, score 22.82) (writing took 3.1857817247509956 seconds)
2020-12-19 02:49:11 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2020-12-19 02:49:11 | INFO | train | epoch 054 | symm_kl 0.503 | self_kl 0 | self_cv 14.598 | loss 4.528 | nll_loss 1.105 | ppl 2.15 | wps 24555.2 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 22734 | lr 1.25e-05 | gnorm 0.77 | train_wall 216 | wall 12908
2020-12-19 02:49:11 | INFO | fairseq.trainer | begin training epoch 55
2020-12-19 02:49:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:49:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:49:47 | INFO | train_inner | epoch 055:     66 / 421 symm_kl=0.506, self_kl=0, self_cv=14.58, loss=4.539, nll_loss=1.113, ppl=2.16, wps=18602.9, ups=1.34, wpb=13841.5, bsz=488.1, num_updates=22800, lr=1.25e-05, gnorm=0.776, train_wall=51, wall=12945
2020-12-19 02:50:39 | INFO | train_inner | epoch 055:    166 / 421 symm_kl=0.496, self_kl=0, self_cv=14.469, loss=4.503, nll_loss=1.099, ppl=2.14, wps=27139.7, ups=1.93, wpb=14052.4, bsz=517.9, num_updates=22900, lr=1.25e-05, gnorm=0.758, train_wall=52, wall=12997
2020-12-19 02:51:31 | INFO | train_inner | epoch 055:    266 / 421 symm_kl=0.504, self_kl=0, self_cv=14.654, loss=4.531, nll_loss=1.102, ppl=2.15, wps=27110.3, ups=1.93, wpb=14060.1, bsz=471.7, num_updates=23000, lr=1.25e-05, gnorm=0.769, train_wall=52, wall=13048
2020-12-19 02:52:22 | INFO | train_inner | epoch 055:    366 / 421 symm_kl=0.502, self_kl=0, self_cv=14.553, loss=4.525, nll_loss=1.108, ppl=2.16, wps=27082.1, ups=1.95, wpb=13892.3, bsz=496.7, num_updates=23100, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=13100
2020-12-19 02:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:52:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:52:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:52:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:52:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:53:07 | INFO | valid | epoch 055 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.213 | nll_loss 3.785 | ppl 13.79 | bleu 22.78 | wps 6389.1 | wpb 10324.2 | bsz 375 | num_updates 23155 | best_bleu 22.9
2020-12-19 02:53:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:53:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:53:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:53:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:53:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:53:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 55 @ 23155 updates, score 22.78) (writing took 3.208127776160836 seconds)
2020-12-19 02:53:10 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2020-12-19 02:53:10 | INFO | train | epoch 055 | symm_kl 0.502 | self_kl 0 | self_cv 14.58 | loss 4.526 | nll_loss 1.106 | ppl 2.15 | wps 24597.9 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 23155 | lr 1.25e-05 | gnorm 0.769 | train_wall 216 | wall 13147
2020-12-19 02:53:10 | INFO | fairseq.trainer | begin training epoch 56
2020-12-19 02:53:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:53:36 | INFO | train_inner | epoch 056:     45 / 421 symm_kl=0.507, self_kl=0, self_cv=14.677, loss=4.544, nll_loss=1.11, ppl=2.16, wps=18806.7, ups=1.36, wpb=13788.6, bsz=481.8, num_updates=23200, lr=1.25e-05, gnorm=0.788, train_wall=51, wall=13173
2020-12-19 02:54:27 | INFO | train_inner | epoch 056:    145 / 421 symm_kl=0.492, self_kl=0, self_cv=14.499, loss=4.497, nll_loss=1.096, ppl=2.14, wps=27579.1, ups=1.94, wpb=14199.1, bsz=519.6, num_updates=23300, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=13225
2020-12-19 02:55:18 | INFO | train_inner | epoch 056:    245 / 421 symm_kl=0.501, self_kl=0, self_cv=14.622, loss=4.527, nll_loss=1.104, ppl=2.15, wps=27216.5, ups=1.95, wpb=13964, bsz=488.3, num_updates=23400, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=13276
2020-12-19 02:56:10 | INFO | train_inner | epoch 056:    345 / 421 symm_kl=0.505, self_kl=0, self_cv=14.591, loss=4.529, nll_loss=1.104, ppl=2.15, wps=26707.4, ups=1.93, wpb=13808, bsz=486.3, num_updates=23500, lr=1.25e-05, gnorm=0.777, train_wall=52, wall=13328
2020-12-19 02:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 02:56:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:56:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:56:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:56:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:56:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:56:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:56:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:56:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:56:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:56:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 02:56:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 02:56:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 02:57:05 | INFO | valid | epoch 056 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.212 | nll_loss 3.783 | ppl 13.76 | bleu 22.78 | wps 6504.5 | wpb 10324.2 | bsz 375 | num_updates 23576 | best_bleu 22.9
2020-12-19 02:57:05 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 02:57:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:57:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:57:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:57:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:57:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:57:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:57:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 56 @ 23576 updates, score 22.78) (writing took 3.171591216698289 seconds)
2020-12-19 02:57:08 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2020-12-19 02:57:08 | INFO | train | epoch 056 | symm_kl 0.501 | self_kl 0 | self_cv 14.583 | loss 4.524 | nll_loss 1.105 | ppl 2.15 | wps 24703.9 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 23576 | lr 1.25e-05 | gnorm 0.766 | train_wall 215 | wall 13385
2020-12-19 02:57:08 | INFO | fairseq.trainer | begin training epoch 57
2020-12-19 02:57:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 02:57:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 02:57:23 | INFO | train_inner | epoch 057:     24 / 421 symm_kl=0.501, self_kl=0, self_cv=14.549, loss=4.529, nll_loss=1.112, ppl=2.16, wps=19156.7, ups=1.37, wpb=13962, bsz=488.1, num_updates=23600, lr=1.25e-05, gnorm=0.768, train_wall=51, wall=13400
2020-12-19 02:58:14 | INFO | train_inner | epoch 057:    124 / 421 symm_kl=0.499, self_kl=0, self_cv=14.571, loss=4.523, nll_loss=1.107, ppl=2.15, wps=27246.1, ups=1.95, wpb=13953.8, bsz=500.8, num_updates=23700, lr=1.25e-05, gnorm=0.759, train_wall=51, wall=13452
2020-12-19 02:59:06 | INFO | train_inner | epoch 057:    224 / 421 symm_kl=0.502, self_kl=0, self_cv=14.575, loss=4.521, nll_loss=1.1, ppl=2.14, wps=27137.7, ups=1.95, wpb=13941.2, bsz=473.1, num_updates=23800, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=13503
2020-12-19 02:59:57 | INFO | train_inner | epoch 057:    324 / 421 symm_kl=0.497, self_kl=0, self_cv=14.552, loss=4.512, nll_loss=1.1, ppl=2.14, wps=27219.8, ups=1.94, wpb=14044.8, bsz=504.2, num_updates=23900, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=13555
2020-12-19 03:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:00:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:00:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:00:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:00:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:00:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:00:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:00:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:00:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:00:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:00:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:00:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:00:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:01:03 | INFO | valid | epoch 057 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.21 | nll_loss 3.783 | ppl 13.77 | bleu 22.87 | wps 6612 | wpb 10324.2 | bsz 375 | num_updates 23997 | best_bleu 22.9
2020-12-19 03:01:03 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:01:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:01:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:01:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:01:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:01:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:01:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:01:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 57 @ 23997 updates, score 22.87) (writing took 3.2239469811320305 seconds)
2020-12-19 03:01:06 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2020-12-19 03:01:06 | INFO | train | epoch 057 | symm_kl 0.5 | self_kl 0 | self_cv 14.579 | loss 4.522 | nll_loss 1.104 | ppl 2.15 | wps 24717.5 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 23997 | lr 1.25e-05 | gnorm 0.765 | train_wall 216 | wall 13623
2020-12-19 03:01:06 | INFO | fairseq.trainer | begin training epoch 58
2020-12-19 03:01:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:01:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:01:11 | INFO | train_inner | epoch 058:      3 / 421 symm_kl=0.5, self_kl=0, self_cv=14.606, loss=4.524, nll_loss=1.104, ppl=2.15, wps=19046.5, ups=1.36, wpb=13965.8, bsz=483.9, num_updates=24000, lr=1.25e-05, gnorm=0.769, train_wall=51, wall=13628
2020-12-19 03:02:01 | INFO | train_inner | epoch 058:    103 / 421 symm_kl=0.492, self_kl=0, self_cv=14.567, loss=4.501, nll_loss=1.095, ppl=2.14, wps=27716.9, ups=1.96, wpb=14125.7, bsz=513.5, num_updates=24100, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=13679
2020-12-19 03:02:53 | INFO | train_inner | epoch 058:    203 / 421 symm_kl=0.508, self_kl=0, self_cv=14.647, loss=4.549, nll_loss=1.117, ppl=2.17, wps=26993.4, ups=1.94, wpb=13886.5, bsz=477.5, num_updates=24200, lr=1.25e-05, gnorm=0.778, train_wall=51, wall=13730
2020-12-19 03:03:44 | INFO | train_inner | epoch 058:    303 / 421 symm_kl=0.5, self_kl=0, self_cv=14.587, loss=4.524, nll_loss=1.105, ppl=2.15, wps=27206.9, ups=1.95, wpb=13979.3, bsz=488.4, num_updates=24300, lr=1.25e-05, gnorm=0.763, train_wall=51, wall=13782
2020-12-19 03:04:36 | INFO | train_inner | epoch 058:    403 / 421 symm_kl=0.498, self_kl=0, self_cv=14.522, loss=4.515, nll_loss=1.104, ppl=2.15, wps=27125, ups=1.95, wpb=13927.2, bsz=482.3, num_updates=24400, lr=1.25e-05, gnorm=0.763, train_wall=51, wall=13833
2020-12-19 03:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:04:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:04:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:04:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:04:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:04:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:04:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:04:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:04:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:04:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:04:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:04:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:04:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:05:01 | INFO | valid | epoch 058 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.782 | ppl 13.76 | bleu 22.85 | wps 6276.8 | wpb 10324.2 | bsz 375 | num_updates 24418 | best_bleu 22.9
2020-12-19 03:05:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:05:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:05:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:05:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:05:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:05:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:05:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:05:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 58 @ 24418 updates, score 22.85) (writing took 3.1958350837230682 seconds)
2020-12-19 03:05:04 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2020-12-19 03:05:04 | INFO | train | epoch 058 | symm_kl 0.499 | self_kl 0 | self_cv 14.572 | loss 4.519 | nll_loss 1.104 | ppl 2.15 | wps 24672.3 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 24418 | lr 1.25e-05 | gnorm 0.764 | train_wall 215 | wall 13862
2020-12-19 03:05:04 | INFO | fairseq.trainer | begin training epoch 59
2020-12-19 03:05:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:05:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:05:49 | INFO | train_inner | epoch 059:     82 / 421 symm_kl=0.499, self_kl=0, self_cv=14.566, loss=4.521, nll_loss=1.105, ppl=2.15, wps=19041.8, ups=1.36, wpb=13975.5, bsz=496.1, num_updates=24500, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=13907
2020-12-19 03:06:40 | INFO | train_inner | epoch 059:    182 / 421 symm_kl=0.497, self_kl=0, self_cv=14.595, loss=4.514, nll_loss=1.1, ppl=2.14, wps=27110.8, ups=1.95, wpb=13932.4, bsz=486.6, num_updates=24600, lr=1.25e-05, gnorm=0.762, train_wall=51, wall=13958
2020-12-19 03:07:32 | INFO | train_inner | epoch 059:    282 / 421 symm_kl=0.502, self_kl=0, self_cv=14.614, loss=4.531, nll_loss=1.108, ppl=2.16, wps=27080.4, ups=1.95, wpb=13891, bsz=476.6, num_updates=24700, lr=1.25e-05, gnorm=0.772, train_wall=51, wall=14009
2020-12-19 03:08:23 | INFO | train_inner | epoch 059:    382 / 421 symm_kl=0.491, self_kl=0, self_cv=14.49, loss=4.496, nll_loss=1.098, ppl=2.14, wps=27367.7, ups=1.93, wpb=14152.9, bsz=520.6, num_updates=24800, lr=1.25e-05, gnorm=0.749, train_wall=52, wall=14061
2020-12-19 03:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:08:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:08:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:08:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:08:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:08:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:08:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:08:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:08:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:08:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:08:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:08:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:08:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:09:01 | INFO | valid | epoch 059 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.781 | ppl 13.75 | bleu 22.9 | wps 5764.7 | wpb 10324.2 | bsz 375 | num_updates 24839 | best_bleu 22.9
2020-12-19 03:09:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:09:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:09:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:09:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:09:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:09:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:09:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:09:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 59 @ 24839 updates, score 22.9) (writing took 5.257817953824997 seconds)
2020-12-19 03:09:06 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2020-12-19 03:09:06 | INFO | train | epoch 059 | symm_kl 0.498 | self_kl 0 | self_cv 14.573 | loss 4.519 | nll_loss 1.104 | ppl 2.15 | wps 24325.9 | ups 1.74 | wpb 13969.5 | bsz 492.6 | num_updates 24839 | lr 1.25e-05 | gnorm 0.764 | train_wall 216 | wall 14103
2020-12-19 03:09:06 | INFO | fairseq.trainer | begin training epoch 60
2020-12-19 03:09:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:09:40 | INFO | train_inner | epoch 060:     61 / 421 symm_kl=0.499, self_kl=0, self_cv=14.609, loss=4.525, nll_loss=1.107, ppl=2.15, wps=18212.1, ups=1.31, wpb=13915, bsz=494.5, num_updates=24900, lr=1.25e-05, gnorm=0.763, train_wall=51, wall=14137
2020-12-19 03:10:31 | INFO | train_inner | epoch 060:    161 / 421 symm_kl=0.498, self_kl=0, self_cv=14.555, loss=4.517, nll_loss=1.103, ppl=2.15, wps=27238, ups=1.95, wpb=13949.2, bsz=495.3, num_updates=25000, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=14189
2020-12-19 03:11:23 | INFO | train_inner | epoch 060:    261 / 421 symm_kl=0.499, self_kl=0, self_cv=14.573, loss=4.52, nll_loss=1.103, ppl=2.15, wps=27126.9, ups=1.94, wpb=13980, bsz=487, num_updates=25100, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=14240
2020-12-19 03:12:14 | INFO | train_inner | epoch 060:    361 / 421 symm_kl=0.495, self_kl=0, self_cv=14.537, loss=4.511, nll_loss=1.104, ppl=2.15, wps=27379.5, ups=1.96, wpb=14002.2, bsz=497.2, num_updates=25200, lr=1.25e-05, gnorm=0.758, train_wall=51, wall=14291
2020-12-19 03:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:12:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:12:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:12:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:12:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:12:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:12:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:12:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:12:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:13:01 | INFO | valid | epoch 060 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.782 | ppl 13.76 | bleu 22.78 | wps 5980.7 | wpb 10324.2 | bsz 375 | num_updates 25260 | best_bleu 22.9
2020-12-19 03:13:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:13:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:13:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:13:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:13:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:13:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:13:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:13:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 60 @ 25260 updates, score 22.78) (writing took 3.2006705328822136 seconds)
2020-12-19 03:13:05 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2020-12-19 03:13:05 | INFO | train | epoch 060 | symm_kl 0.497 | self_kl 0 | self_cv 14.566 | loss 4.515 | nll_loss 1.103 | ppl 2.15 | wps 24645.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 25260 | lr 1.25e-05 | gnorm 0.766 | train_wall 215 | wall 14342
2020-12-19 03:13:05 | INFO | fairseq.trainer | begin training epoch 61
2020-12-19 03:13:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:13:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:13:28 | INFO | train_inner | epoch 061:     40 / 421 symm_kl=0.494, self_kl=0, self_cv=14.56, loss=4.508, nll_loss=1.101, ppl=2.14, wps=18852.1, ups=1.35, wpb=13960.9, bsz=497.4, num_updates=25300, lr=1.25e-05, gnorm=0.774, train_wall=51, wall=14365
2020-12-19 03:14:19 | INFO | train_inner | epoch 061:    140 / 421 symm_kl=0.498, self_kl=0, self_cv=14.575, loss=4.518, nll_loss=1.104, ppl=2.15, wps=26965.9, ups=1.94, wpb=13876.7, bsz=488.5, num_updates=25400, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=14417
2020-12-19 03:15:11 | INFO | train_inner | epoch 061:    240 / 421 symm_kl=0.499, self_kl=0, self_cv=14.629, loss=4.526, nll_loss=1.106, ppl=2.15, wps=27070.4, ups=1.94, wpb=13922.9, bsz=496.8, num_updates=25500, lr=1.25e-05, gnorm=0.768, train_wall=51, wall=14468
2020-12-19 03:16:02 | INFO | train_inner | epoch 061:    340 / 421 symm_kl=0.496, self_kl=0, self_cv=14.515, loss=4.505, nll_loss=1.098, ppl=2.14, wps=27542.2, ups=1.94, wpb=14164, bsz=486.6, num_updates=25600, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=14520
2020-12-19 03:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:16:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:16:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:16:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:16:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:16:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:16:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:16:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:16:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:16:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:16:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:16:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:17:02 | INFO | valid | epoch 061 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.21 | nll_loss 3.784 | ppl 13.78 | bleu 22.84 | wps 5176.2 | wpb 10324.2 | bsz 375 | num_updates 25681 | best_bleu 22.9
2020-12-19 03:17:02 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:17:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:17:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:17:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:17:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:17:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:17:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:17:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 61 @ 25681 updates, score 22.84) (writing took 3.1984879039227962 seconds)
2020-12-19 03:17:06 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2020-12-19 03:17:06 | INFO | train | epoch 061 | symm_kl 0.497 | self_kl 0 | self_cv 14.565 | loss 4.515 | nll_loss 1.103 | ppl 2.15 | wps 24397.2 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 25681 | lr 1.25e-05 | gnorm 0.764 | train_wall 216 | wall 14583
2020-12-19 03:17:06 | INFO | fairseq.trainer | begin training epoch 62
2020-12-19 03:17:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:17:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:17:18 | INFO | train_inner | epoch 062:     19 / 421 symm_kl=0.496, self_kl=0, self_cv=14.512, loss=4.514, nll_loss=1.107, ppl=2.15, wps=18136.8, ups=1.31, wpb=13835, bsz=493.3, num_updates=25700, lr=1.25e-05, gnorm=0.769, train_wall=51, wall=14596
2020-12-19 03:18:09 | INFO | train_inner | epoch 062:    119 / 421 symm_kl=0.498, self_kl=0, self_cv=14.578, loss=4.513, nll_loss=1.098, ppl=2.14, wps=27440.2, ups=1.96, wpb=13986.2, bsz=487.6, num_updates=25800, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=14647
2020-12-19 03:19:01 | INFO | train_inner | epoch 062:    219 / 421 symm_kl=0.495, self_kl=0, self_cv=14.557, loss=4.515, nll_loss=1.106, ppl=2.15, wps=27433, ups=1.95, wpb=14050.9, bsz=497.9, num_updates=25900, lr=1.25e-05, gnorm=0.754, train_wall=51, wall=14698
2020-12-19 03:19:52 | INFO | train_inner | epoch 062:    319 / 421 symm_kl=0.493, self_kl=0, self_cv=14.549, loss=4.506, nll_loss=1.101, ppl=2.15, wps=27220.4, ups=1.95, wpb=13962.5, bsz=495.5, num_updates=26000, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=14749
2020-12-19 03:20:43 | INFO | train_inner | epoch 062:    419 / 421 symm_kl=0.497, self_kl=0, self_cv=14.556, loss=4.518, nll_loss=1.107, ppl=2.15, wps=27261.7, ups=1.95, wpb=13977.3, bsz=489.4, num_updates=26100, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=14801
2020-12-19 03:20:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:20:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:20:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:20:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:20:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:20:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:20:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:21:00 | INFO | valid | epoch 062 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.213 | nll_loss 3.784 | ppl 13.78 | bleu 22.89 | wps 6461.4 | wpb 10324.2 | bsz 375 | num_updates 26102 | best_bleu 22.9
2020-12-19 03:21:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:21:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:21:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:21:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:21:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 62 @ 26102 updates, score 22.89) (writing took 3.1910841185599566 seconds)
2020-12-19 03:21:03 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2020-12-19 03:21:03 | INFO | train | epoch 062 | symm_kl 0.495 | self_kl 0 | self_cv 14.547 | loss 4.512 | nll_loss 1.103 | ppl 2.15 | wps 24769.1 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 26102 | lr 1.25e-05 | gnorm 0.763 | train_wall 215 | wall 14820
2020-12-19 03:21:03 | INFO | fairseq.trainer | begin training epoch 63
2020-12-19 03:21:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:21:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:21:56 | INFO | train_inner | epoch 063:     98 / 421 symm_kl=0.493, self_kl=0, self_cv=14.566, loss=4.502, nll_loss=1.094, ppl=2.13, wps=19314.5, ups=1.37, wpb=14090.7, bsz=472.6, num_updates=26200, lr=1.25e-05, gnorm=0.767, train_wall=51, wall=14874
2020-12-19 03:22:48 | INFO | train_inner | epoch 063:    198 / 421 symm_kl=0.497, self_kl=0, self_cv=14.573, loss=4.519, nll_loss=1.106, ppl=2.15, wps=27032.9, ups=1.95, wpb=13897.7, bsz=494.5, num_updates=26300, lr=1.25e-05, gnorm=0.762, train_wall=51, wall=14925
2020-12-19 03:23:39 | INFO | train_inner | epoch 063:    298 / 421 symm_kl=0.492, self_kl=0, self_cv=14.548, loss=4.504, nll_loss=1.101, ppl=2.15, wps=27022.5, ups=1.94, wpb=13936.7, bsz=513.1, num_updates=26400, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=14977
2020-12-19 03:24:31 | INFO | train_inner | epoch 063:    398 / 421 symm_kl=0.497, self_kl=0, self_cv=14.553, loss=4.521, nll_loss=1.11, ppl=2.16, wps=27052.2, ups=1.94, wpb=13957.4, bsz=498.3, num_updates=26500, lr=1.25e-05, gnorm=0.761, train_wall=51, wall=15028
2020-12-19 03:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:24:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:24:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:24:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:24:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:24:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:24:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:24:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:24:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:24:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:24:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:24:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:25:00 | INFO | valid | epoch 063 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.781 | ppl 13.75 | bleu 22.87 | wps 5332.5 | wpb 10324.2 | bsz 375 | num_updates 26523 | best_bleu 22.9
2020-12-19 03:25:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:25:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:25:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:25:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:25:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:25:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:25:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:25:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 63 @ 26523 updates, score 22.87) (writing took 3.233800606802106 seconds)
2020-12-19 03:25:04 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2020-12-19 03:25:04 | INFO | train | epoch 063 | symm_kl 0.495 | self_kl 0 | self_cv 14.557 | loss 4.511 | nll_loss 1.102 | ppl 2.15 | wps 24439.3 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 26523 | lr 1.25e-05 | gnorm 0.761 | train_wall 215 | wall 15061
2020-12-19 03:25:04 | INFO | fairseq.trainer | begin training epoch 64
2020-12-19 03:25:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:25:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:25:46 | INFO | train_inner | epoch 064:     77 / 421 symm_kl=0.492, self_kl=0, self_cv=14.56, loss=4.498, nll_loss=1.092, ppl=2.13, wps=18520.7, ups=1.33, wpb=13916.8, bsz=482.8, num_updates=26600, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=15103
2020-12-19 03:26:37 | INFO | train_inner | epoch 064:    177 / 421 symm_kl=0.493, self_kl=0, self_cv=14.52, loss=4.509, nll_loss=1.106, ppl=2.15, wps=27342.4, ups=1.96, wpb=13975.7, bsz=487.3, num_updates=26700, lr=1.25e-05, gnorm=0.761, train_wall=51, wall=15154
2020-12-19 03:27:28 | INFO | train_inner | epoch 064:    277 / 421 symm_kl=0.493, self_kl=0, self_cv=14.557, loss=4.508, nll_loss=1.102, ppl=2.15, wps=27450.6, ups=1.94, wpb=14128.6, bsz=497.4, num_updates=26800, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=15206
2020-12-19 03:28:20 | INFO | train_inner | epoch 064:    377 / 421 symm_kl=0.497, self_kl=0, self_cv=14.557, loss=4.519, nll_loss=1.108, ppl=2.16, wps=27007.5, ups=1.95, wpb=13883.7, bsz=493.9, num_updates=26900, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=15257
2020-12-19 03:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:28:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:28:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:28:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:28:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:28:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:28:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:28:58 | INFO | valid | epoch 064 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.207 | nll_loss 3.778 | ppl 13.72 | bleu 22.99 | wps 6474 | wpb 10324.2 | bsz 375 | num_updates 26944 | best_bleu 22.99
2020-12-19 03:28:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:28:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:28:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:29:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:29:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:29:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:29:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_best.pt (epoch 64 @ 26944 updates, score 22.99) (writing took 5.2521691881120205 seconds)
2020-12-19 03:29:04 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2020-12-19 03:29:04 | INFO | train | epoch 064 | symm_kl 0.493 | self_kl 0 | self_cv 14.553 | loss 4.509 | nll_loss 1.102 | ppl 2.15 | wps 24521.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 26944 | lr 1.25e-05 | gnorm 0.761 | train_wall 215 | wall 15301
2020-12-19 03:29:04 | INFO | fairseq.trainer | begin training epoch 65
2020-12-19 03:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:29:35 | INFO | train_inner | epoch 065:     56 / 421 symm_kl=0.493, self_kl=0, self_cv=14.552, loss=4.508, nll_loss=1.102, ppl=2.15, wps=18379, ups=1.33, wpb=13770.9, bsz=483.4, num_updates=27000, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=15332
2020-12-19 03:30:26 | INFO | train_inner | epoch 065:    156 / 421 symm_kl=0.492, self_kl=0, self_cv=14.526, loss=4.503, nll_loss=1.1, ppl=2.14, wps=27427, ups=1.95, wpb=14040.4, bsz=480.6, num_updates=27100, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=15383
2020-12-19 03:31:17 | INFO | train_inner | epoch 065:    256 / 421 symm_kl=0.493, self_kl=0, self_cv=14.527, loss=4.507, nll_loss=1.104, ppl=2.15, wps=27063.8, ups=1.94, wpb=13927, bsz=516.4, num_updates=27200, lr=1.25e-05, gnorm=0.759, train_wall=51, wall=15435
2020-12-19 03:32:09 | INFO | train_inner | epoch 065:    356 / 421 symm_kl=0.493, self_kl=0, self_cv=14.575, loss=4.51, nll_loss=1.103, ppl=2.15, wps=27365, ups=1.95, wpb=14052, bsz=486.2, num_updates=27300, lr=1.25e-05, gnorm=0.754, train_wall=51, wall=15486
2020-12-19 03:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:32:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:32:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:32:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:32:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:32:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:32:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:32:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:32:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:32:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:32:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:32:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:32:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:33:00 | INFO | valid | epoch 065 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.782 | ppl 13.76 | bleu 22.78 | wps 5426.7 | wpb 10324.2 | bsz 375 | num_updates 27365 | best_bleu 22.99
2020-12-19 03:33:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:33:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 65 @ 27365 updates, score 22.78) (writing took 3.2093179561197758 seconds)
2020-12-19 03:33:04 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2020-12-19 03:33:04 | INFO | train | epoch 065 | symm_kl 0.493 | self_kl 0 | self_cv 14.548 | loss 4.507 | nll_loss 1.103 | ppl 2.15 | wps 24489.5 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 27365 | lr 1.25e-05 | gnorm 0.758 | train_wall 215 | wall 15541
2020-12-19 03:33:04 | INFO | fairseq.trainer | begin training epoch 66
2020-12-19 03:33:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:33:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:33:24 | INFO | train_inner | epoch 066:     35 / 421 symm_kl=0.493, self_kl=0, self_cv=14.56, loss=4.511, nll_loss=1.106, ppl=2.15, wps=18374.6, ups=1.32, wpb=13884.4, bsz=501.7, num_updates=27400, lr=1.25e-05, gnorm=0.769, train_wall=51, wall=15562
2020-12-19 03:34:16 | INFO | train_inner | epoch 066:    135 / 421 symm_kl=0.488, self_kl=0, self_cv=14.508, loss=4.486, nll_loss=1.089, ppl=2.13, wps=27252.8, ups=1.94, wpb=14031.2, bsz=494.3, num_updates=27500, lr=1.25e-05, gnorm=0.75, train_wall=51, wall=15613
2020-12-19 03:35:07 | INFO | train_inner | epoch 066:    235 / 421 symm_kl=0.489, self_kl=0, self_cv=14.491, loss=4.492, nll_loss=1.094, ppl=2.14, wps=27137.8, ups=1.94, wpb=14005.9, bsz=498.6, num_updates=27600, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=15665
2020-12-19 03:35:59 | INFO | train_inner | epoch 066:    335 / 421 symm_kl=0.492, self_kl=0, self_cv=14.614, loss=4.512, nll_loss=1.103, ppl=2.15, wps=27478.5, ups=1.95, wpb=14104.2, bsz=488.2, num_updates=27700, lr=1.25e-05, gnorm=0.755, train_wall=51, wall=15716
2020-12-19 03:36:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:36:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:36:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:36:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:36:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:36:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:36:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:36:59 | INFO | valid | epoch 066 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.21 | nll_loss 3.782 | ppl 13.76 | bleu 22.72 | wps 6063.4 | wpb 10324.2 | bsz 375 | num_updates 27786 | best_bleu 22.99
2020-12-19 03:36:59 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:37:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:37:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:37:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:37:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:37:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:37:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:37:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 66 @ 27786 updates, score 22.72) (writing took 3.2447495479136705 seconds)
2020-12-19 03:37:02 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2020-12-19 03:37:02 | INFO | train | epoch 066 | symm_kl 0.492 | self_kl 0 | self_cv 14.542 | loss 4.504 | nll_loss 1.101 | ppl 2.15 | wps 24633.9 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 27786 | lr 1.25e-05 | gnorm 0.759 | train_wall 215 | wall 15780
2020-12-19 03:37:02 | INFO | fairseq.trainer | begin training epoch 67
2020-12-19 03:37:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:37:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:37:13 | INFO | train_inner | epoch 067:     14 / 421 symm_kl=0.493, self_kl=0, self_cv=14.516, loss=4.51, nll_loss=1.109, ppl=2.16, wps=18737.3, ups=1.35, wpb=13844.4, bsz=484.9, num_updates=27800, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=15790
2020-12-19 03:38:04 | INFO | train_inner | epoch 067:    114 / 421 symm_kl=0.5, self_kl=0, self_cv=14.634, loss=4.535, nll_loss=1.113, ppl=2.16, wps=27391.9, ups=1.96, wpb=13962.4, bsz=482.9, num_updates=27900, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=15841
2020-12-19 03:38:55 | INFO | train_inner | epoch 067:    214 / 421 symm_kl=0.489, self_kl=0, self_cv=14.557, loss=4.501, nll_loss=1.1, ppl=2.14, wps=27164.6, ups=1.93, wpb=14065.6, bsz=497.8, num_updates=28000, lr=1.25e-05, gnorm=0.756, train_wall=52, wall=15893
2020-12-19 03:39:47 | INFO | train_inner | epoch 067:    314 / 421 symm_kl=0.487, self_kl=0, self_cv=14.473, loss=4.485, nll_loss=1.093, ppl=2.13, wps=27036.2, ups=1.93, wpb=14011.8, bsz=495.5, num_updates=28100, lr=1.25e-05, gnorm=0.756, train_wall=52, wall=15945
2020-12-19 03:40:39 | INFO | train_inner | epoch 067:    414 / 421 symm_kl=0.491, self_kl=0, self_cv=14.528, loss=4.503, nll_loss=1.103, ppl=2.15, wps=26797.8, ups=1.94, wpb=13845.2, bsz=495.4, num_updates=28200, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=15996
2020-12-19 03:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:40:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:40:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:40:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:40:59 | INFO | valid | epoch 067 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.208 | nll_loss 3.781 | ppl 13.75 | bleu 22.7 | wps 6164.6 | wpb 10324.2 | bsz 375 | num_updates 28207 | best_bleu 22.99
2020-12-19 03:40:59 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:41:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:41:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:41:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:41:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:41:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:41:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:41:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 67 @ 28207 updates, score 22.7) (writing took 3.2584644109010696 seconds)
2020-12-19 03:41:02 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2020-12-19 03:41:02 | INFO | train | epoch 067 | symm_kl 0.491 | self_kl 0 | self_cv 14.539 | loss 4.503 | nll_loss 1.101 | ppl 2.15 | wps 24547.8 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 28207 | lr 1.25e-05 | gnorm 0.759 | train_wall 216 | wall 16019
2020-12-19 03:41:02 | INFO | fairseq.trainer | begin training epoch 68
2020-12-19 03:41:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:41:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:41:53 | INFO | train_inner | epoch 068:     93 / 421 symm_kl=0.485, self_kl=0, self_cv=14.542, loss=4.486, nll_loss=1.09, ppl=2.13, wps=18812.3, ups=1.35, wpb=13895.4, bsz=502.8, num_updates=28300, lr=1.25e-05, gnorm=0.754, train_wall=51, wall=16070
2020-12-19 03:42:45 | INFO | train_inner | epoch 068:    193 / 421 symm_kl=0.49, self_kl=0, self_cv=14.544, loss=4.5, nll_loss=1.098, ppl=2.14, wps=26918.5, ups=1.93, wpb=13941.5, bsz=498.7, num_updates=28400, lr=1.25e-05, gnorm=0.76, train_wall=52, wall=16122
2020-12-19 03:43:37 | INFO | train_inner | epoch 068:    293 / 421 symm_kl=0.493, self_kl=0, self_cv=14.556, loss=4.51, nll_loss=1.105, ppl=2.15, wps=27020.5, ups=1.92, wpb=14061.8, bsz=483.7, num_updates=28500, lr=1.25e-05, gnorm=0.757, train_wall=52, wall=16174
2020-12-19 03:44:28 | INFO | train_inner | epoch 068:    393 / 421 symm_kl=0.492, self_kl=0, self_cv=14.546, loss=4.509, nll_loss=1.106, ppl=2.15, wps=27298.7, ups=1.95, wpb=14016.9, bsz=485.7, num_updates=28600, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=16225
2020-12-19 03:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:44:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:44:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:44:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:44:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:44:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:44:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:44:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:44:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:45:00 | INFO | valid | epoch 068 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.212 | nll_loss 3.784 | ppl 13.78 | bleu 22.8 | wps 5561.1 | wpb 10324.2 | bsz 375 | num_updates 28628 | best_bleu 22.99
2020-12-19 03:45:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:45:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:45:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:45:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:45:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:45:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:45:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:45:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 68 @ 28628 updates, score 22.8) (writing took 3.2322822716087103 seconds)
2020-12-19 03:45:03 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2020-12-19 03:45:03 | INFO | train | epoch 068 | symm_kl 0.49 | self_kl 0 | self_cv 14.549 | loss 4.503 | nll_loss 1.101 | ppl 2.14 | wps 24394.4 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 28628 | lr 1.25e-05 | gnorm 0.759 | train_wall 216 | wall 16261
2020-12-19 03:45:03 | INFO | fairseq.trainer | begin training epoch 69
2020-12-19 03:45:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:45:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:45:43 | INFO | train_inner | epoch 069:     72 / 421 symm_kl=0.492, self_kl=0, self_cv=14.519, loss=4.505, nll_loss=1.104, ppl=2.15, wps=18488.4, ups=1.33, wpb=13856.8, bsz=488.3, num_updates=28700, lr=1.25e-05, gnorm=0.766, train_wall=51, wall=16300
2020-12-19 03:46:34 | INFO | train_inner | epoch 069:    172 / 421 symm_kl=0.489, self_kl=0, self_cv=14.546, loss=4.499, nll_loss=1.1, ppl=2.14, wps=27335.4, ups=1.95, wpb=13998.6, bsz=496.1, num_updates=28800, lr=1.25e-05, gnorm=0.755, train_wall=51, wall=16352
2020-12-19 03:47:26 | INFO | train_inner | epoch 069:    272 / 421 symm_kl=0.486, self_kl=0, self_cv=14.494, loss=4.489, nll_loss=1.096, ppl=2.14, wps=27543.1, ups=1.94, wpb=14161.2, bsz=500.7, num_updates=28900, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=16403
2020-12-19 03:48:17 | INFO | train_inner | epoch 069:    372 / 421 symm_kl=0.491, self_kl=0, self_cv=14.529, loss=4.506, nll_loss=1.106, ppl=2.15, wps=27022, ups=1.95, wpb=13844.5, bsz=482.7, num_updates=29000, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=16454
2020-12-19 03:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:48:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:48:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:48:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:48:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:48:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:48:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:48:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:48:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:48:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:48:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:48:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:48:59 | INFO | valid | epoch 069 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.207 | nll_loss 3.779 | ppl 13.73 | bleu 22.79 | wps 5785.9 | wpb 10324.2 | bsz 375 | num_updates 29049 | best_bleu 22.99
2020-12-19 03:48:59 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:49:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:49:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:49:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:49:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:49:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:49:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:49:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 69 @ 29049 updates, score 22.79) (writing took 3.276270007714629 seconds)
2020-12-19 03:49:02 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2020-12-19 03:49:02 | INFO | train | epoch 069 | symm_kl 0.49 | self_kl 0 | self_cv 14.525 | loss 4.5 | nll_loss 1.102 | ppl 2.15 | wps 24575.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 29049 | lr 1.25e-05 | gnorm 0.759 | train_wall 215 | wall 16500
2020-12-19 03:49:02 | INFO | fairseq.trainer | begin training epoch 70
2020-12-19 03:49:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:49:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:49:31 | INFO | train_inner | epoch 070:     51 / 421 symm_kl=0.485, self_kl=0, self_cv=14.476, loss=4.483, nll_loss=1.092, ppl=2.13, wps=18677.3, ups=1.34, wpb=13940.7, bsz=497.4, num_updates=29100, lr=1.25e-05, gnorm=0.758, train_wall=51, wall=16529
2020-12-19 03:50:23 | INFO | train_inner | epoch 070:    151 / 421 symm_kl=0.488, self_kl=0, self_cv=14.545, loss=4.496, nll_loss=1.098, ppl=2.14, wps=27402.8, ups=1.95, wpb=14040.9, bsz=491.7, num_updates=29200, lr=1.25e-05, gnorm=0.755, train_wall=51, wall=16580
2020-12-19 03:51:14 | INFO | train_inner | epoch 070:    251 / 421 symm_kl=0.494, self_kl=0, self_cv=14.563, loss=4.519, nll_loss=1.114, ppl=2.16, wps=27198.4, ups=1.95, wpb=13968.4, bsz=492.8, num_updates=29300, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=16631
2020-12-19 03:52:06 | INFO | train_inner | epoch 070:    351 / 421 symm_kl=0.483, self_kl=0, self_cv=14.551, loss=4.483, nll_loss=1.09, ppl=2.13, wps=27147.9, ups=1.94, wpb=14021.5, bsz=494.1, num_updates=29400, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=16683
2020-12-19 03:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:52:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:52:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:52:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:52:58 | INFO | valid | epoch 070 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.208 | nll_loss 3.781 | ppl 13.75 | bleu 22.74 | wps 5961.8 | wpb 10324.2 | bsz 375 | num_updates 29470 | best_bleu 22.99
2020-12-19 03:52:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:53:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:53:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:53:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:53:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 70 @ 29470 updates, score 22.74) (writing took 3.2490855287760496 seconds)
2020-12-19 03:53:02 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2020-12-19 03:53:02 | INFO | train | epoch 070 | symm_kl 0.488 | self_kl 0 | self_cv 14.534 | loss 4.498 | nll_loss 1.1 | ppl 2.14 | wps 24576.8 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 29470 | lr 1.25e-05 | gnorm 0.756 | train_wall 215 | wall 16739
2020-12-19 03:53:02 | INFO | fairseq.trainer | begin training epoch 71
2020-12-19 03:53:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:53:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:53:20 | INFO | train_inner | epoch 071:     30 / 421 symm_kl=0.496, self_kl=0, self_cv=14.561, loss=4.523, nll_loss=1.114, ppl=2.16, wps=18566.8, ups=1.35, wpb=13792.5, bsz=475.6, num_updates=29500, lr=1.25e-05, gnorm=0.771, train_wall=51, wall=16757
2020-12-19 03:54:11 | INFO | train_inner | epoch 071:    130 / 421 symm_kl=0.488, self_kl=0, self_cv=14.501, loss=4.496, nll_loss=1.101, ppl=2.15, wps=27583.5, ups=1.96, wpb=14042.9, bsz=493.1, num_updates=29600, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=16808
2020-12-19 03:55:02 | INFO | train_inner | epoch 071:    230 / 421 symm_kl=0.488, self_kl=0, self_cv=14.543, loss=4.502, nll_loss=1.104, ppl=2.15, wps=27191.8, ups=1.95, wpb=13948, bsz=496.8, num_updates=29700, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=16860
2020-12-19 03:55:53 | INFO | train_inner | epoch 071:    330 / 421 symm_kl=0.489, self_kl=0, self_cv=14.572, loss=4.503, nll_loss=1.102, ppl=2.15, wps=27431.9, ups=1.95, wpb=14070.8, bsz=493.8, num_updates=29800, lr=1.25e-05, gnorm=0.753, train_wall=51, wall=16911
2020-12-19 03:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 03:56:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 03:56:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 03:56:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 03:56:55 | INFO | valid | epoch 071 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.21 | nll_loss 3.783 | ppl 13.77 | bleu 22.75 | wps 6731.2 | wpb 10324.2 | bsz 375 | num_updates 29891 | best_bleu 22.99
2020-12-19 03:56:55 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 03:56:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:56:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:56:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 71 @ 29891 updates, score 22.75) (writing took 3.224146416410804 seconds)
2020-12-19 03:56:58 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2020-12-19 03:56:58 | INFO | train | epoch 071 | symm_kl 0.488 | self_kl 0 | self_cv 14.53 | loss 4.497 | nll_loss 1.1 | ppl 2.14 | wps 24838.8 | ups 1.78 | wpb 13969.5 | bsz 492.6 | num_updates 29891 | lr 1.25e-05 | gnorm 0.755 | train_wall 215 | wall 16976
2020-12-19 03:56:58 | INFO | fairseq.trainer | begin training epoch 72
2020-12-19 03:56:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 03:57:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 03:57:06 | INFO | train_inner | epoch 072:      9 / 421 symm_kl=0.486, self_kl=0, self_cv=14.495, loss=4.482, nll_loss=1.09, ppl=2.13, wps=19011.1, ups=1.38, wpb=13812, bsz=497.7, num_updates=29900, lr=1.25e-05, gnorm=0.761, train_wall=51, wall=16984
2020-12-19 03:57:57 | INFO | train_inner | epoch 072:    109 / 421 symm_kl=0.49, self_kl=0, self_cv=14.595, loss=4.506, nll_loss=1.101, ppl=2.15, wps=27316.7, ups=1.97, wpb=13899.2, bsz=500.5, num_updates=30000, lr=1.25e-05, gnorm=0.755, train_wall=51, wall=17034
2020-12-19 03:58:48 | INFO | train_inner | epoch 072:    209 / 421 symm_kl=0.494, self_kl=0, self_cv=14.61, loss=4.521, nll_loss=1.112, ppl=2.16, wps=27358.2, ups=1.95, wpb=14056.5, bsz=479, num_updates=30100, lr=1.25e-05, gnorm=0.758, train_wall=51, wall=17086
2020-12-19 03:59:40 | INFO | train_inner | epoch 072:    309 / 421 symm_kl=0.479, self_kl=0, self_cv=14.426, loss=4.46, nll_loss=1.083, ppl=2.12, wps=27456.1, ups=1.95, wpb=14090.8, bsz=503.7, num_updates=30200, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=17137
2020-12-19 04:00:31 | INFO | train_inner | epoch 072:    409 / 421 symm_kl=0.486, self_kl=0, self_cv=14.526, loss=4.491, nll_loss=1.097, ppl=2.14, wps=27316.1, ups=1.96, wpb=13971.2, bsz=488.9, num_updates=30300, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=17188
2020-12-19 04:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:00:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:00:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:00:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:00:52 | INFO | valid | epoch 072 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.208 | nll_loss 3.78 | ppl 13.73 | bleu 22.84 | wps 6656.4 | wpb 10324.2 | bsz 375 | num_updates 30312 | best_bleu 22.99
2020-12-19 04:00:52 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:00:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 72 @ 30312 updates, score 22.84) (writing took 3.213510077446699 seconds)
2020-12-19 04:00:56 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2020-12-19 04:00:56 | INFO | train | epoch 072 | symm_kl 0.487 | self_kl 0 | self_cv 14.539 | loss 4.496 | nll_loss 1.099 | ppl 2.14 | wps 24805.8 | ups 1.78 | wpb 13969.5 | bsz 492.6 | num_updates 30312 | lr 1.25e-05 | gnorm 0.757 | train_wall 215 | wall 17213
2020-12-19 04:00:56 | INFO | fairseq.trainer | begin training epoch 73
2020-12-19 04:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:00:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:00:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:01:43 | INFO | train_inner | epoch 073:     88 / 421 symm_kl=0.49, self_kl=0, self_cv=14.593, loss=4.506, nll_loss=1.102, ppl=2.15, wps=19031.3, ups=1.38, wpb=13804.3, bsz=486.8, num_updates=30400, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=17261
2020-12-19 04:02:34 | INFO | train_inner | epoch 073:    188 / 421 symm_kl=0.488, self_kl=0, self_cv=14.552, loss=4.498, nll_loss=1.1, ppl=2.14, wps=27173.5, ups=1.96, wpb=13883.7, bsz=482.3, num_updates=30500, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=17312
2020-12-19 04:03:26 | INFO | train_inner | epoch 073:    288 / 421 symm_kl=0.477, self_kl=0, self_cv=14.38, loss=4.454, nll_loss=1.083, ppl=2.12, wps=27334.6, ups=1.94, wpb=14107.1, bsz=514.2, num_updates=30600, lr=1.25e-05, gnorm=0.738, train_wall=51, wall=17363
2020-12-19 04:04:18 | INFO | train_inner | epoch 073:    388 / 421 symm_kl=0.489, self_kl=0, self_cv=14.54, loss=4.505, nll_loss=1.108, ppl=2.16, wps=27199.7, ups=1.94, wpb=14021.4, bsz=489.6, num_updates=30700, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=17415
2020-12-19 04:04:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:04:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:04:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:04:50 | INFO | valid | epoch 073 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.783 | ppl 13.76 | bleu 22.77 | wps 6627.4 | wpb 10324.2 | bsz 375 | num_updates 30733 | best_bleu 22.99
2020-12-19 04:04:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:04:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:04:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 73 @ 30733 updates, score 22.77) (writing took 3.240170508623123 seconds)
2020-12-19 04:04:53 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2020-12-19 04:04:53 | INFO | train | epoch 073 | symm_kl 0.486 | self_kl 0 | self_cv 14.522 | loss 4.493 | nll_loss 1.099 | ppl 2.14 | wps 24755.4 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 30733 | lr 1.25e-05 | gnorm 0.753 | train_wall 215 | wall 17451
2020-12-19 04:04:53 | INFO | fairseq.trainer | begin training epoch 74
2020-12-19 04:04:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:04:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:05:30 | INFO | train_inner | epoch 074:     67 / 421 symm_kl=0.488, self_kl=0, self_cv=14.543, loss=4.503, nll_loss=1.105, ppl=2.15, wps=19194.1, ups=1.38, wpb=13947.4, bsz=487, num_updates=30800, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=17488
2020-12-19 04:06:22 | INFO | train_inner | epoch 074:    167 / 421 symm_kl=0.481, self_kl=0, self_cv=14.527, loss=4.477, nll_loss=1.09, ppl=2.13, wps=27347.5, ups=1.94, wpb=14112, bsz=503.8, num_updates=30900, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=17539
2020-12-19 04:07:13 | INFO | train_inner | epoch 074:    267 / 421 symm_kl=0.491, self_kl=0, self_cv=14.584, loss=4.514, nll_loss=1.109, ppl=2.16, wps=27200.9, ups=1.95, wpb=13972.7, bsz=481.2, num_updates=31000, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=17591
2020-12-19 04:08:05 | INFO | train_inner | epoch 074:    367 / 421 symm_kl=0.487, self_kl=0, self_cv=14.525, loss=4.498, nll_loss=1.103, ppl=2.15, wps=26922, ups=1.94, wpb=13875.6, bsz=488.2, num_updates=31100, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=17642
2020-12-19 04:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:08:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:08:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:08:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:08:48 | INFO | valid | epoch 074 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.209 | nll_loss 3.781 | ppl 13.74 | bleu 22.75 | wps 6658.7 | wpb 10324.2 | bsz 375 | num_updates 31154 | best_bleu 22.99
2020-12-19 04:08:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:08:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 74 @ 31154 updates, score 22.75) (writing took 3.224950782954693 seconds)
2020-12-19 04:08:51 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2020-12-19 04:08:51 | INFO | train | epoch 074 | symm_kl 0.486 | self_kl 0 | self_cv 14.532 | loss 4.493 | nll_loss 1.099 | ppl 2.14 | wps 24723 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 31154 | lr 1.25e-05 | gnorm 0.755 | train_wall 215 | wall 17688
2020-12-19 04:08:51 | INFO | fairseq.trainer | begin training epoch 75
2020-12-19 04:08:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:08:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:09:17 | INFO | train_inner | epoch 075:     46 / 421 symm_kl=0.48, self_kl=0, self_cv=14.49, loss=4.474, nll_loss=1.09, ppl=2.13, wps=19099.9, ups=1.38, wpb=13850.8, bsz=498.8, num_updates=31200, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=17715
2020-12-19 04:10:09 | INFO | train_inner | epoch 075:    146 / 421 symm_kl=0.481, self_kl=0, self_cv=14.488, loss=4.474, nll_loss=1.088, ppl=2.13, wps=27405, ups=1.94, wpb=14149.4, bsz=504.3, num_updates=31300, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=17766
2020-12-19 04:11:00 | INFO | train_inner | epoch 075:    246 / 421 symm_kl=0.491, self_kl=0, self_cv=14.533, loss=4.507, nll_loss=1.106, ppl=2.15, wps=27310.3, ups=1.95, wpb=13988.6, bsz=487.1, num_updates=31400, lr=1.25e-05, gnorm=0.759, train_wall=51, wall=17818
2020-12-19 04:11:52 | INFO | train_inner | epoch 075:    346 / 421 symm_kl=0.486, self_kl=0, self_cv=14.564, loss=4.497, nll_loss=1.101, ppl=2.14, wps=26846.1, ups=1.94, wpb=13842.7, bsz=481.1, num_updates=31500, lr=1.25e-05, gnorm=0.76, train_wall=51, wall=17869
2020-12-19 04:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:12:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:12:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:12:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:12:48 | INFO | valid | epoch 075 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.208 | nll_loss 3.782 | ppl 13.75 | bleu 22.76 | wps 5744.5 | wpb 10324.2 | bsz 375 | num_updates 31575 | best_bleu 22.99
2020-12-19 04:12:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:12:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:12:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 75 @ 31575 updates, score 22.76) (writing took 3.226566068828106 seconds)
2020-12-19 04:12:51 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2020-12-19 04:12:51 | INFO | train | epoch 075 | symm_kl 0.485 | self_kl 0 | self_cv 14.518 | loss 4.49 | nll_loss 1.098 | ppl 2.14 | wps 24519.7 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 31575 | lr 1.25e-05 | gnorm 0.755 | train_wall 216 | wall 17928
2020-12-19 04:12:51 | INFO | fairseq.trainer | begin training epoch 76
2020-12-19 04:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:12:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:13:07 | INFO | train_inner | epoch 076:     25 / 421 symm_kl=0.481, self_kl=0, self_cv=14.415, loss=4.478, nll_loss=1.1, ppl=2.14, wps=18546.3, ups=1.33, wpb=13898.5, bsz=505.8, num_updates=31600, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=17944
2020-12-19 04:13:58 | INFO | train_inner | epoch 076:    125 / 421 symm_kl=0.483, self_kl=0, self_cv=14.514, loss=4.488, nll_loss=1.099, ppl=2.14, wps=27530.6, ups=1.95, wpb=14096.4, bsz=515.1, num_updates=31700, lr=1.25e-05, gnorm=0.744, train_wall=51, wall=17995
2020-12-19 04:14:49 | INFO | train_inner | epoch 076:    225 / 421 symm_kl=0.484, self_kl=0, self_cv=14.486, loss=4.482, nll_loss=1.093, ppl=2.13, wps=27214.5, ups=1.95, wpb=13973.1, bsz=492.4, num_updates=31800, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=18047
2020-12-19 04:15:41 | INFO | train_inner | epoch 076:    325 / 421 symm_kl=0.49, self_kl=0, self_cv=14.585, loss=4.506, nll_loss=1.102, ppl=2.15, wps=27095.9, ups=1.94, wpb=13963, bsz=461.8, num_updates=31900, lr=1.25e-05, gnorm=0.762, train_wall=51, wall=18098
2020-12-19 04:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:16:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:16:46 | INFO | valid | epoch 076 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.206 | nll_loss 3.779 | ppl 13.73 | bleu 22.71 | wps 6224.9 | wpb 10324.2 | bsz 375 | num_updates 31996 | best_bleu 22.99
2020-12-19 04:16:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:16:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 76 @ 31996 updates, score 22.71) (writing took 3.215445438399911 seconds)
2020-12-19 04:16:49 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2020-12-19 04:16:49 | INFO | train | epoch 076 | symm_kl 0.484 | self_kl 0 | self_cv 14.513 | loss 4.489 | nll_loss 1.099 | ppl 2.14 | wps 24646.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 31996 | lr 1.25e-05 | gnorm 0.752 | train_wall 215 | wall 18167
2020-12-19 04:16:49 | INFO | fairseq.trainer | begin training epoch 77
2020-12-19 04:16:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:16:55 | INFO | train_inner | epoch 077:      4 / 421 symm_kl=0.486, self_kl=0, self_cv=14.55, loss=4.5, nll_loss=1.106, ppl=2.15, wps=18744.1, ups=1.35, wpb=13844.7, bsz=485, num_updates=32000, lr=1.25e-05, gnorm=0.761, train_wall=51, wall=18172
2020-12-19 04:17:46 | INFO | train_inner | epoch 077:    104 / 421 symm_kl=0.48, self_kl=0, self_cv=14.497, loss=4.473, nll_loss=1.09, ppl=2.13, wps=27448.7, ups=1.96, wpb=13985.2, bsz=500.6, num_updates=32100, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=18223
2020-12-19 04:18:37 | INFO | train_inner | epoch 077:    204 / 421 symm_kl=0.482, self_kl=0, self_cv=14.487, loss=4.479, nll_loss=1.093, ppl=2.13, wps=27329.3, ups=1.95, wpb=14043.8, bsz=486.1, num_updates=32200, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=18274
2020-12-19 04:19:29 | INFO | train_inner | epoch 077:    304 / 421 symm_kl=0.49, self_kl=0, self_cv=14.601, loss=4.509, nll_loss=1.105, ppl=2.15, wps=26948.1, ups=1.94, wpb=13904.1, bsz=480.2, num_updates=32300, lr=1.25e-05, gnorm=0.759, train_wall=51, wall=18326
2020-12-19 04:20:20 | INFO | train_inner | epoch 077:    404 / 421 symm_kl=0.484, self_kl=0, self_cv=14.489, loss=4.493, nll_loss=1.106, ppl=2.15, wps=27055.9, ups=1.93, wpb=14050.1, bsz=507.9, num_updates=32400, lr=1.25e-05, gnorm=0.747, train_wall=52, wall=18378
2020-12-19 04:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:20:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:20:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:20:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:20:45 | INFO | valid | epoch 077 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.204 | nll_loss 3.778 | ppl 13.71 | bleu 22.81 | wps 6127.4 | wpb 10324.2 | bsz 375 | num_updates 32417 | best_bleu 22.99
2020-12-19 04:20:45 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:20:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:20:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 77 @ 32417 updates, score 22.81) (writing took 3.286782581359148 seconds)
2020-12-19 04:20:49 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2020-12-19 04:20:49 | INFO | train | epoch 077 | symm_kl 0.484 | self_kl 0 | self_cv 14.521 | loss 4.488 | nll_loss 1.098 | ppl 2.14 | wps 24586.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 32417 | lr 1.25e-05 | gnorm 0.753 | train_wall 216 | wall 18406
2020-12-19 04:20:49 | INFO | fairseq.trainer | begin training epoch 78
2020-12-19 04:20:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:20:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:21:34 | INFO | train_inner | epoch 078:     83 / 421 symm_kl=0.486, self_kl=0, self_cv=14.49, loss=4.492, nll_loss=1.102, ppl=2.15, wps=18769.9, ups=1.36, wpb=13787.4, bsz=490.6, num_updates=32500, lr=1.25e-05, gnorm=0.764, train_wall=51, wall=18451
2020-12-19 04:22:25 | INFO | train_inner | epoch 078:    183 / 421 symm_kl=0.485, self_kl=0, self_cv=14.56, loss=4.493, nll_loss=1.098, ppl=2.14, wps=27537.8, ups=1.95, wpb=14097.3, bsz=477.3, num_updates=32600, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=18503
2020-12-19 04:23:17 | INFO | train_inner | epoch 078:    283 / 421 symm_kl=0.478, self_kl=0, self_cv=14.506, loss=4.467, nll_loss=1.085, ppl=2.12, wps=27134.7, ups=1.94, wpb=13992.1, bsz=506.1, num_updates=32700, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=18554
2020-12-19 04:24:08 | INFO | train_inner | epoch 078:    383 / 421 symm_kl=0.482, self_kl=0, self_cv=14.471, loss=4.49, nll_loss=1.106, ppl=2.15, wps=27312.8, ups=1.95, wpb=14019.5, bsz=506.6, num_updates=32800, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=18605
2020-12-19 04:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:24:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:24:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:24:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:24:44 | INFO | valid | epoch 078 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.206 | nll_loss 3.778 | ppl 13.72 | bleu 22.85 | wps 6120.3 | wpb 10324.2 | bsz 375 | num_updates 32838 | best_bleu 22.99
2020-12-19 04:24:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:24:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 78 @ 32838 updates, score 22.85) (writing took 3.288529070094228 seconds)
2020-12-19 04:24:47 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2020-12-19 04:24:47 | INFO | train | epoch 078 | symm_kl 0.483 | self_kl 0 | self_cv 14.509 | loss 4.487 | nll_loss 1.098 | ppl 2.14 | wps 24667.8 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 32838 | lr 1.25e-05 | gnorm 0.752 | train_wall 215 | wall 18645
2020-12-19 04:24:47 | INFO | fairseq.trainer | begin training epoch 79
2020-12-19 04:24:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:24:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:25:21 | INFO | train_inner | epoch 079:     62 / 421 symm_kl=0.487, self_kl=0, self_cv=14.56, loss=4.497, nll_loss=1.1, ppl=2.14, wps=18780.1, ups=1.36, wpb=13781.3, bsz=469.8, num_updates=32900, lr=1.25e-05, gnorm=0.765, train_wall=50, wall=18679
2020-12-19 04:26:13 | INFO | train_inner | epoch 079:    162 / 421 symm_kl=0.481, self_kl=0, self_cv=14.525, loss=4.482, nll_loss=1.095, ppl=2.14, wps=27275.5, ups=1.94, wpb=14053.4, bsz=495.8, num_updates=33000, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=18730
2020-12-19 04:27:04 | INFO | train_inner | epoch 079:    262 / 421 symm_kl=0.48, self_kl=0, self_cv=14.479, loss=4.476, nll_loss=1.094, ppl=2.13, wps=27447.8, ups=1.96, wpb=14036.6, bsz=502, num_updates=33100, lr=1.25e-05, gnorm=0.75, train_wall=51, wall=18781
2020-12-19 04:27:56 | INFO | train_inner | epoch 079:    362 / 421 symm_kl=0.485, self_kl=0, self_cv=14.507, loss=4.492, nll_loss=1.101, ppl=2.15, wps=26923, ups=1.93, wpb=13914.4, bsz=489, num_updates=33200, lr=1.25e-05, gnorm=0.754, train_wall=52, wall=18833
2020-12-19 04:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:28:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:28:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:28:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:28:41 | INFO | valid | epoch 079 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.777 | ppl 13.71 | bleu 22.78 | wps 6567.7 | wpb 10324.2 | bsz 375 | num_updates 33259 | best_bleu 22.99
2020-12-19 04:28:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:28:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:28:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 79 @ 33259 updates, score 22.78) (writing took 3.242663575336337 seconds)
2020-12-19 04:28:45 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2020-12-19 04:28:45 | INFO | train | epoch 079 | symm_kl 0.483 | self_kl 0 | self_cv 14.509 | loss 4.485 | nll_loss 1.098 | ppl 2.14 | wps 24759.7 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 33259 | lr 1.25e-05 | gnorm 0.754 | train_wall 215 | wall 18882
2020-12-19 04:28:45 | INFO | fairseq.trainer | begin training epoch 80
2020-12-19 04:28:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:28:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:29:08 | INFO | train_inner | epoch 080:     41 / 421 symm_kl=0.481, self_kl=0, self_cv=14.494, loss=4.481, nll_loss=1.096, ppl=2.14, wps=19129.5, ups=1.38, wpb=13895.2, bsz=496.2, num_updates=33300, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=18906
2020-12-19 04:30:00 | INFO | train_inner | epoch 080:    141 / 421 symm_kl=0.482, self_kl=0, self_cv=14.513, loss=4.481, nll_loss=1.094, ppl=2.13, wps=27170, ups=1.94, wpb=14015.3, bsz=502.4, num_updates=33400, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=18957
2020-12-19 04:30:51 | INFO | train_inner | epoch 080:    241 / 421 symm_kl=0.482, self_kl=0, self_cv=14.497, loss=4.487, nll_loss=1.101, ppl=2.15, wps=27489, ups=1.95, wpb=14112, bsz=494.1, num_updates=33500, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=19009
2020-12-19 04:31:43 | INFO | train_inner | epoch 080:    341 / 421 symm_kl=0.481, self_kl=0, self_cv=14.514, loss=4.484, nll_loss=1.097, ppl=2.14, wps=27011.5, ups=1.94, wpb=13952.8, bsz=476.2, num_updates=33600, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=19060
2020-12-19 04:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:32:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:32:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:32:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:32:40 | INFO | valid | epoch 080 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.202 | nll_loss 3.776 | ppl 13.7 | bleu 22.93 | wps 6063.5 | wpb 10324.2 | bsz 375 | num_updates 33680 | best_bleu 22.99
2020-12-19 04:32:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:32:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 80 @ 33680 updates, score 22.93) (writing took 3.2512246388942003 seconds)
2020-12-19 04:32:44 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2020-12-19 04:32:44 | INFO | train | epoch 080 | symm_kl 0.481 | self_kl 0 | self_cv 14.51 | loss 4.483 | nll_loss 1.097 | ppl 2.14 | wps 24604.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 33680 | lr 1.25e-05 | gnorm 0.751 | train_wall 215 | wall 19121
2020-12-19 04:32:44 | INFO | fairseq.trainer | begin training epoch 81
2020-12-19 04:32:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:32:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:32:57 | INFO | train_inner | epoch 081:     20 / 421 symm_kl=0.482, self_kl=0, self_cv=14.518, loss=4.486, nll_loss=1.098, ppl=2.14, wps=18736.5, ups=1.35, wpb=13861.8, bsz=491.9, num_updates=33700, lr=1.25e-05, gnorm=0.759, train_wall=51, wall=19134
2020-12-19 04:33:48 | INFO | train_inner | epoch 081:    120 / 421 symm_kl=0.479, self_kl=0, self_cv=14.532, loss=4.476, nll_loss=1.09, ppl=2.13, wps=27400.9, ups=1.96, wpb=13969.8, bsz=502, num_updates=33800, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=19185
2020-12-19 04:34:40 | INFO | train_inner | epoch 081:    220 / 421 symm_kl=0.483, self_kl=0, self_cv=14.519, loss=4.489, nll_loss=1.1, ppl=2.14, wps=26851.2, ups=1.93, wpb=13903.9, bsz=499.9, num_updates=33900, lr=1.25e-05, gnorm=0.752, train_wall=52, wall=19237
2020-12-19 04:35:31 | INFO | train_inner | epoch 081:    320 / 421 symm_kl=0.48, self_kl=0, self_cv=14.482, loss=4.478, nll_loss=1.096, ppl=2.14, wps=27463, ups=1.94, wpb=14120.4, bsz=487, num_updates=34000, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=19289
2020-12-19 04:36:23 | INFO | train_inner | epoch 081:    420 / 421 symm_kl=0.482, self_kl=0, self_cv=14.509, loss=4.484, nll_loss=1.097, ppl=2.14, wps=26848.4, ups=1.92, wpb=13969.7, bsz=489.8, num_updates=34100, lr=1.25e-05, gnorm=0.752, train_wall=52, wall=19341
2020-12-19 04:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:36:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:36:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:36:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:36:40 | INFO | valid | epoch 081 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.206 | nll_loss 3.778 | ppl 13.72 | bleu 22.77 | wps 6278.9 | wpb 10324.2 | bsz 375 | num_updates 34101 | best_bleu 22.99
2020-12-19 04:36:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:36:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:36:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 81 @ 34101 updates, score 22.77) (writing took 3.2595448885113 seconds)
2020-12-19 04:36:43 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2020-12-19 04:36:43 | INFO | train | epoch 081 | symm_kl 0.481 | self_kl 0 | self_cv 14.512 | loss 4.483 | nll_loss 1.096 | ppl 2.14 | wps 24570.4 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 34101 | lr 1.25e-05 | gnorm 0.751 | train_wall 216 | wall 19360
2020-12-19 04:36:43 | INFO | fairseq.trainer | begin training epoch 82
2020-12-19 04:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:36:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:37:36 | INFO | train_inner | epoch 082:     99 / 421 symm_kl=0.485, self_kl=0, self_cv=14.577, loss=4.496, nll_loss=1.1, ppl=2.14, wps=18996.1, ups=1.36, wpb=13925.6, bsz=481.2, num_updates=34200, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=19414
2020-12-19 04:38:28 | INFO | train_inner | epoch 082:    199 / 421 symm_kl=0.482, self_kl=0, self_cv=14.462, loss=4.479, nll_loss=1.095, ppl=2.14, wps=27163.7, ups=1.94, wpb=13999.5, bsz=488, num_updates=34300, lr=1.25e-05, gnorm=0.753, train_wall=51, wall=19465
2020-12-19 04:39:19 | INFO | train_inner | epoch 082:    299 / 421 symm_kl=0.48, self_kl=0, self_cv=14.505, loss=4.481, nll_loss=1.098, ppl=2.14, wps=27185.8, ups=1.95, wpb=13976.5, bsz=488.2, num_updates=34400, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=19517
2020-12-19 04:40:11 | INFO | train_inner | epoch 082:    399 / 421 symm_kl=0.475, self_kl=0, self_cv=14.475, loss=4.469, nll_loss=1.093, ppl=2.13, wps=27177.1, ups=1.95, wpb=13959.8, bsz=515.1, num_updates=34500, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=19568
2020-12-19 04:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:40:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:40:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:40:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:40:39 | INFO | valid | epoch 082 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.205 | nll_loss 3.778 | ppl 13.71 | bleu 22.71 | wps 5865.5 | wpb 10324.2 | bsz 375 | num_updates 34522 | best_bleu 22.99
2020-12-19 04:40:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:40:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:40:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 82 @ 34522 updates, score 22.71) (writing took 3.262238284572959 seconds)
2020-12-19 04:40:42 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2020-12-19 04:40:42 | INFO | train | epoch 082 | symm_kl 0.48 | self_kl 0 | self_cv 14.503 | loss 4.48 | nll_loss 1.096 | ppl 2.14 | wps 24606.1 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 34522 | lr 1.25e-05 | gnorm 0.75 | train_wall 215 | wall 19599
2020-12-19 04:40:42 | INFO | fairseq.trainer | begin training epoch 83
2020-12-19 04:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:41:25 | INFO | train_inner | epoch 083:     78 / 421 symm_kl=0.483, self_kl=0, self_cv=14.492, loss=4.489, nll_loss=1.103, ppl=2.15, wps=18769.4, ups=1.35, wpb=13862, bsz=480.6, num_updates=34600, lr=1.25e-05, gnorm=0.756, train_wall=50, wall=19642
2020-12-19 04:42:16 | INFO | train_inner | epoch 083:    178 / 421 symm_kl=0.481, self_kl=0, self_cv=14.473, loss=4.482, nll_loss=1.099, ppl=2.14, wps=27107.8, ups=1.95, wpb=13916.6, bsz=488.6, num_updates=34700, lr=1.25e-05, gnorm=0.75, train_wall=51, wall=19693
2020-12-19 04:43:08 | INFO | train_inner | epoch 083:    278 / 421 symm_kl=0.481, self_kl=0, self_cv=14.513, loss=4.483, nll_loss=1.097, ppl=2.14, wps=27086, ups=1.94, wpb=13982, bsz=495, num_updates=34800, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=19745
2020-12-19 04:43:59 | INFO | train_inner | epoch 083:    378 / 421 symm_kl=0.477, self_kl=0, self_cv=14.461, loss=4.468, nll_loss=1.092, ppl=2.13, wps=27135.9, ups=1.93, wpb=14049.8, bsz=508, num_updates=34900, lr=1.25e-05, gnorm=0.747, train_wall=52, wall=19797
2020-12-19 04:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:44:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:44:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:44:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:44:39 | INFO | valid | epoch 083 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.204 | nll_loss 3.777 | ppl 13.71 | bleu 22.78 | wps 5797.6 | wpb 10324.2 | bsz 375 | num_updates 34943 | best_bleu 22.99
2020-12-19 04:44:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:44:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:44:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 83 @ 34943 updates, score 22.78) (writing took 3.2617232128977776 seconds)
2020-12-19 04:44:42 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2020-12-19 04:44:42 | INFO | train | epoch 083 | symm_kl 0.48 | self_kl 0 | self_cv 14.49 | loss 4.479 | nll_loss 1.096 | ppl 2.14 | wps 24532.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 34943 | lr 1.25e-05 | gnorm 0.75 | train_wall 216 | wall 19839
2020-12-19 04:44:42 | INFO | fairseq.trainer | begin training epoch 84
2020-12-19 04:44:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:44:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:45:14 | INFO | train_inner | epoch 084:     57 / 421 symm_kl=0.478, self_kl=0, self_cv=14.547, loss=4.475, nll_loss=1.09, ppl=2.13, wps=18767.8, ups=1.34, wpb=13975, bsz=481.6, num_updates=35000, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=19871
2020-12-19 04:46:05 | INFO | train_inner | epoch 084:    157 / 421 symm_kl=0.48, self_kl=0, self_cv=14.48, loss=4.478, nll_loss=1.097, ppl=2.14, wps=26970.4, ups=1.94, wpb=13918.9, bsz=487.9, num_updates=35100, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=19923
2020-12-19 04:46:57 | INFO | train_inner | epoch 084:    257 / 421 symm_kl=0.478, self_kl=0, self_cv=14.522, loss=4.476, nll_loss=1.093, ppl=2.13, wps=27100.9, ups=1.94, wpb=13950.9, bsz=496.1, num_updates=35200, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=19974
2020-12-19 04:47:49 | INFO | train_inner | epoch 084:    357 / 421 symm_kl=0.48, self_kl=0, self_cv=14.498, loss=4.482, nll_loss=1.099, ppl=2.14, wps=27179.9, ups=1.93, wpb=14065.2, bsz=497.5, num_updates=35300, lr=1.25e-05, gnorm=0.749, train_wall=52, wall=20026
2020-12-19 04:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:48:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:48:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:48:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:48:39 | INFO | valid | epoch 084 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.208 | nll_loss 3.783 | ppl 13.77 | bleu 22.73 | wps 5874.5 | wpb 10324.2 | bsz 375 | num_updates 35364 | best_bleu 22.99
2020-12-19 04:48:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:48:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:48:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 84 @ 35364 updates, score 22.73) (writing took 3.2395757362246513 seconds)
2020-12-19 04:48:42 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2020-12-19 04:48:42 | INFO | train | epoch 084 | symm_kl 0.479 | self_kl 0 | self_cv 14.498 | loss 4.477 | nll_loss 1.095 | ppl 2.14 | wps 24488.2 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 35364 | lr 1.25e-05 | gnorm 0.75 | train_wall 216 | wall 20079
2020-12-19 04:48:42 | INFO | fairseq.trainer | begin training epoch 85
2020-12-19 04:48:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:48:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:49:03 | INFO | train_inner | epoch 085:     36 / 421 symm_kl=0.47, self_kl=0, self_cv=14.388, loss=4.443, nll_loss=1.08, ppl=2.11, wps=18714, ups=1.34, wpb=13976.4, bsz=506.2, num_updates=35400, lr=1.25e-05, gnorm=0.744, train_wall=51, wall=20101
2020-12-19 04:49:54 | INFO | train_inner | epoch 085:    136 / 421 symm_kl=0.475, self_kl=0, self_cv=14.506, loss=4.466, nll_loss=1.088, ppl=2.13, wps=27341.1, ups=1.96, wpb=13980.4, bsz=498.1, num_updates=35500, lr=1.25e-05, gnorm=0.743, train_wall=51, wall=20152
2020-12-19 04:50:46 | INFO | train_inner | epoch 085:    236 / 421 symm_kl=0.477, self_kl=0, self_cv=14.45, loss=4.471, nll_loss=1.095, ppl=2.14, wps=27246.9, ups=1.93, wpb=14089.2, bsz=493.7, num_updates=35600, lr=1.25e-05, gnorm=0.747, train_wall=52, wall=20204
2020-12-19 04:51:37 | INFO | train_inner | epoch 085:    336 / 421 symm_kl=0.482, self_kl=0, self_cv=14.504, loss=4.49, nll_loss=1.105, ppl=2.15, wps=27153, ups=1.95, wpb=13923.5, bsz=483.7, num_updates=35700, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=20255
2020-12-19 04:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:52:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:52:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:52:36 | INFO | valid | epoch 085 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.777 | ppl 13.71 | bleu 22.91 | wps 6839.7 | wpb 10324.2 | bsz 375 | num_updates 35785 | best_bleu 22.99
2020-12-19 04:52:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:52:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 85 @ 35785 updates, score 22.91) (writing took 3.2404582910239697 seconds)
2020-12-19 04:52:39 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2020-12-19 04:52:39 | INFO | train | epoch 085 | symm_kl 0.479 | self_kl 0 | self_cv 14.499 | loss 4.477 | nll_loss 1.096 | ppl 2.14 | wps 24776.2 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 35785 | lr 1.25e-05 | gnorm 0.75 | train_wall 215 | wall 20317
2020-12-19 04:52:39 | INFO | fairseq.trainer | begin training epoch 86
2020-12-19 04:52:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:52:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:52:50 | INFO | train_inner | epoch 086:     15 / 421 symm_kl=0.487, self_kl=0, self_cv=14.605, loss=4.505, nll_loss=1.106, ppl=2.15, wps=19105.2, ups=1.38, wpb=13875.6, bsz=480.7, num_updates=35800, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=20328
2020-12-19 04:53:41 | INFO | train_inner | epoch 086:    115 / 421 symm_kl=0.475, self_kl=0, self_cv=14.501, loss=4.462, nll_loss=1.085, ppl=2.12, wps=27327, ups=1.95, wpb=13984.8, bsz=487.7, num_updates=35900, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=20379
2020-12-19 04:54:33 | INFO | train_inner | epoch 086:    215 / 421 symm_kl=0.477, self_kl=0, self_cv=14.5, loss=4.472, nll_loss=1.092, ppl=2.13, wps=27007.8, ups=1.94, wpb=13938.5, bsz=498.3, num_updates=36000, lr=1.25e-05, gnorm=0.744, train_wall=51, wall=20430
2020-12-19 04:55:24 | INFO | train_inner | epoch 086:    315 / 421 symm_kl=0.484, self_kl=0, self_cv=14.525, loss=4.497, nll_loss=1.108, ppl=2.16, wps=27156.4, ups=1.94, wpb=14000.8, bsz=477.6, num_updates=36100, lr=1.25e-05, gnorm=0.753, train_wall=51, wall=20482
2020-12-19 04:56:16 | INFO | train_inner | epoch 086:    415 / 421 symm_kl=0.475, self_kl=0, self_cv=14.511, loss=4.47, nll_loss=1.092, ppl=2.13, wps=27177.4, ups=1.94, wpb=14012.9, bsz=511.5, num_updates=36200, lr=1.25e-05, gnorm=0.741, train_wall=51, wall=20533
2020-12-19 04:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 04:56:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 04:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 04:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 04:56:35 | INFO | valid | epoch 086 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.204 | nll_loss 3.776 | ppl 13.7 | bleu 22.78 | wps 6286.1 | wpb 10324.2 | bsz 375 | num_updates 36206 | best_bleu 22.99
2020-12-19 04:56:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 04:56:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:56:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 86 @ 36206 updates, score 22.78) (writing took 3.223501617088914 seconds)
2020-12-19 04:56:38 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2020-12-19 04:56:38 | INFO | train | epoch 086 | symm_kl 0.478 | self_kl 0 | self_cv 14.505 | loss 4.475 | nll_loss 1.094 | ppl 2.14 | wps 24611.6 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 36206 | lr 1.25e-05 | gnorm 0.75 | train_wall 216 | wall 20556
2020-12-19 04:56:38 | INFO | fairseq.trainer | begin training epoch 87
2020-12-19 04:56:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 04:56:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 04:57:29 | INFO | train_inner | epoch 087:     94 / 421 symm_kl=0.477, self_kl=0, self_cv=14.468, loss=4.468, nll_loss=1.09, ppl=2.13, wps=18782.5, ups=1.36, wpb=13761.8, bsz=487.9, num_updates=36300, lr=1.25e-05, gnorm=0.765, train_wall=51, wall=20607
2020-12-19 04:58:21 | INFO | train_inner | epoch 087:    194 / 421 symm_kl=0.477, self_kl=0, self_cv=14.517, loss=4.468, nll_loss=1.088, ppl=2.13, wps=27162.7, ups=1.94, wpb=14010.6, bsz=480, num_updates=36400, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=20658
2020-12-19 04:59:13 | INFO | train_inner | epoch 087:    294 / 421 symm_kl=0.477, self_kl=0, self_cv=14.497, loss=4.473, nll_loss=1.094, ppl=2.13, wps=27238.1, ups=1.93, wpb=14131.5, bsz=494.4, num_updates=36500, lr=1.25e-05, gnorm=0.744, train_wall=52, wall=20710
2020-12-19 05:00:04 | INFO | train_inner | epoch 087:    394 / 421 symm_kl=0.479, self_kl=0, self_cv=14.525, loss=4.487, nll_loss=1.104, ppl=2.15, wps=26982, ups=1.94, wpb=13941.3, bsz=509.6, num_updates=36600, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=20762
2020-12-19 05:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:00:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:00:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:00:35 | INFO | valid | epoch 087 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.775 | ppl 13.69 | bleu 22.65 | wps 5826.6 | wpb 10324.2 | bsz 375 | num_updates 36627 | best_bleu 22.99
2020-12-19 05:00:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:00:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 87 @ 36627 updates, score 22.65) (writing took 3.270714119076729 seconds)
2020-12-19 05:00:39 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2020-12-19 05:00:39 | INFO | train | epoch 087 | symm_kl 0.477 | self_kl 0 | self_cv 14.507 | loss 4.474 | nll_loss 1.094 | ppl 2.13 | wps 24478.2 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 36627 | lr 1.25e-05 | gnorm 0.749 | train_wall 216 | wall 20796
2020-12-19 05:00:39 | INFO | fairseq.trainer | begin training epoch 88
2020-12-19 05:00:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:00:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:01:19 | INFO | train_inner | epoch 088:     73 / 421 symm_kl=0.477, self_kl=0, self_cv=14.545, loss=4.48, nll_loss=1.097, ppl=2.14, wps=18707.1, ups=1.34, wpb=13922, bsz=483, num_updates=36700, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=20836
2020-12-19 05:02:10 | INFO | train_inner | epoch 088:    173 / 421 symm_kl=0.473, self_kl=0, self_cv=14.457, loss=4.455, nll_loss=1.083, ppl=2.12, wps=26817.5, ups=1.94, wpb=13837.3, bsz=483.8, num_updates=36800, lr=1.25e-05, gnorm=0.742, train_wall=51, wall=20888
2020-12-19 05:03:02 | INFO | train_inner | epoch 088:    273 / 421 symm_kl=0.479, self_kl=0, self_cv=14.477, loss=4.482, nll_loss=1.103, ppl=2.15, wps=27240.9, ups=1.93, wpb=14095, bsz=506.8, num_updates=36900, lr=1.25e-05, gnorm=0.746, train_wall=52, wall=20940
2020-12-19 05:03:54 | INFO | train_inner | epoch 088:    373 / 421 symm_kl=0.48, self_kl=0, self_cv=14.531, loss=4.483, nll_loss=1.098, ppl=2.14, wps=27125.9, ups=1.94, wpb=13973.8, bsz=490.4, num_updates=37000, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=20991
2020-12-19 05:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:04:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:04:34 | INFO | valid | epoch 088 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.2 | nll_loss 3.774 | ppl 13.68 | bleu 22.65 | wps 6223.4 | wpb 10324.2 | bsz 375 | num_updates 37048 | best_bleu 22.99
2020-12-19 05:04:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:04:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 88 @ 37048 updates, score 22.65) (writing took 3.244030997157097 seconds)
2020-12-19 05:04:38 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2020-12-19 05:04:38 | INFO | train | epoch 088 | symm_kl 0.476 | self_kl 0 | self_cv 14.491 | loss 4.473 | nll_loss 1.095 | ppl 2.14 | wps 24597.8 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 37048 | lr 1.25e-05 | gnorm 0.746 | train_wall 216 | wall 21035
2020-12-19 05:04:38 | INFO | fairseq.trainer | begin training epoch 89
2020-12-19 05:04:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:04:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:05:07 | INFO | train_inner | epoch 089:     52 / 421 symm_kl=0.471, self_kl=0, self_cv=14.43, loss=4.455, nll_loss=1.089, ppl=2.13, wps=19020, ups=1.36, wpb=13986.3, bsz=500.3, num_updates=37100, lr=1.25e-05, gnorm=0.741, train_wall=51, wall=21065
2020-12-19 05:05:59 | INFO | train_inner | epoch 089:    152 / 421 symm_kl=0.472, self_kl=0, self_cv=14.498, loss=4.458, nll_loss=1.083, ppl=2.12, wps=26998.2, ups=1.94, wpb=13927.9, bsz=491.8, num_updates=37200, lr=1.25e-05, gnorm=0.742, train_wall=51, wall=21116
2020-12-19 05:06:50 | INFO | train_inner | epoch 089:    252 / 421 symm_kl=0.48, self_kl=0, self_cv=14.52, loss=4.489, nll_loss=1.104, ppl=2.15, wps=27189.4, ups=1.94, wpb=13999.4, bsz=495.4, num_updates=37300, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=21168
2020-12-19 05:07:42 | INFO | train_inner | epoch 089:    352 / 421 symm_kl=0.48, self_kl=0, self_cv=14.55, loss=4.483, nll_loss=1.096, ppl=2.14, wps=27255.8, ups=1.93, wpb=14106.2, bsz=471, num_updates=37400, lr=1.25e-05, gnorm=0.747, train_wall=52, wall=21219
2020-12-19 05:08:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:08:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:08:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:08:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:08:36 | INFO | valid | epoch 089 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.776 | ppl 13.7 | bleu 22.79 | wps 5177.6 | wpb 10324.2 | bsz 375 | num_updates 37469 | best_bleu 22.99
2020-12-19 05:08:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:08:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 89 @ 37469 updates, score 22.79) (writing took 3.1225073039531708 seconds)
2020-12-19 05:08:39 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2020-12-19 05:08:39 | INFO | train | epoch 089 | symm_kl 0.476 | self_kl 0 | self_cv 14.487 | loss 4.471 | nll_loss 1.094 | ppl 2.13 | wps 24358 | ups 1.74 | wpb 13969.5 | bsz 492.6 | num_updates 37469 | lr 1.25e-05 | gnorm 0.746 | train_wall 216 | wall 21277
2020-12-19 05:08:39 | INFO | fairseq.trainer | begin training epoch 90
2020-12-19 05:08:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:08:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:08:58 | INFO | train_inner | epoch 090:     31 / 421 symm_kl=0.475, self_kl=0, self_cv=14.42, loss=4.464, nll_loss=1.093, ppl=2.13, wps=18247.5, ups=1.32, wpb=13829.1, bsz=499.7, num_updates=37500, lr=1.25e-05, gnorm=0.756, train_wall=51, wall=21295
2020-12-19 05:09:49 | INFO | train_inner | epoch 090:    131 / 421 symm_kl=0.476, self_kl=0, self_cv=14.549, loss=4.472, nll_loss=1.089, ppl=2.13, wps=27218, ups=1.95, wpb=13971.9, bsz=468, num_updates=37600, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=21347
2020-12-19 05:10:41 | INFO | train_inner | epoch 090:    231 / 421 symm_kl=0.473, self_kl=0, self_cv=14.458, loss=4.463, nll_loss=1.092, ppl=2.13, wps=27165.9, ups=1.93, wpb=14079.9, bsz=510.4, num_updates=37700, lr=1.25e-05, gnorm=0.739, train_wall=52, wall=21398
2020-12-19 05:11:32 | INFO | train_inner | epoch 090:    331 / 421 symm_kl=0.48, self_kl=0, self_cv=14.506, loss=4.483, nll_loss=1.1, ppl=2.14, wps=26770.9, ups=1.94, wpb=13773.4, bsz=492.6, num_updates=37800, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=21450
2020-12-19 05:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:12:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:12:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:12:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:12:35 | INFO | valid | epoch 090 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.777 | ppl 13.71 | bleu 22.77 | wps 6140.8 | wpb 10324.2 | bsz 375 | num_updates 37890 | best_bleu 22.99
2020-12-19 05:12:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:12:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 90 @ 37890 updates, score 22.77) (writing took 3.095382895320654 seconds)
2020-12-19 05:12:38 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2020-12-19 05:12:38 | INFO | train | epoch 090 | symm_kl 0.476 | self_kl 0 | self_cv 14.491 | loss 4.47 | nll_loss 1.093 | ppl 2.13 | wps 24575.4 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 37890 | lr 1.25e-05 | gnorm 0.746 | train_wall 216 | wall 21516
2020-12-19 05:12:38 | INFO | fairseq.trainer | begin training epoch 91
2020-12-19 05:12:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:12:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:12:47 | INFO | train_inner | epoch 091:     10 / 421 symm_kl=0.472, self_kl=0, self_cv=14.439, loss=4.461, nll_loss=1.093, ppl=2.13, wps=18922.5, ups=1.35, wpb=14051.5, bsz=501.5, num_updates=37900, lr=1.25e-05, gnorm=0.739, train_wall=52, wall=21524
2020-12-19 05:13:38 | INFO | train_inner | epoch 091:    110 / 421 symm_kl=0.475, self_kl=0, self_cv=14.474, loss=4.469, nll_loss=1.094, ppl=2.14, wps=27315.8, ups=1.96, wpb=13964.4, bsz=498.9, num_updates=38000, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=21575
2020-12-19 05:14:29 | INFO | train_inner | epoch 091:    210 / 421 symm_kl=0.478, self_kl=0, self_cv=14.474, loss=4.48, nll_loss=1.101, ppl=2.15, wps=27127.8, ups=1.95, wpb=13883.8, bsz=503.3, num_updates=38100, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=21626
2020-12-19 05:15:21 | INFO | train_inner | epoch 091:    310 / 421 symm_kl=0.473, self_kl=0, self_cv=14.534, loss=4.461, nll_loss=1.083, ppl=2.12, wps=27266.1, ups=1.93, wpb=14130.5, bsz=481.8, num_updates=38200, lr=1.25e-05, gnorm=0.742, train_wall=52, wall=21678
2020-12-19 05:16:12 | INFO | train_inner | epoch 091:    410 / 421 symm_kl=0.475, self_kl=0, self_cv=14.455, loss=4.469, nll_loss=1.096, ppl=2.14, wps=27086.9, ups=1.94, wpb=13954.4, bsz=488, num_updates=38300, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=21730
2020-12-19 05:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:16:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:16:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:16:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:16:34 | INFO | valid | epoch 091 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.204 | nll_loss 3.778 | ppl 13.72 | bleu 22.83 | wps 6232.7 | wpb 10324.2 | bsz 375 | num_updates 38311 | best_bleu 22.99
2020-12-19 05:16:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:16:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 91 @ 38311 updates, score 22.83) (writing took 3.1393900010734797 seconds)
2020-12-19 05:16:37 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2020-12-19 05:16:37 | INFO | train | epoch 091 | symm_kl 0.475 | self_kl 0 | self_cv 14.485 | loss 4.47 | nll_loss 1.094 | ppl 2.13 | wps 24628.4 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 38311 | lr 1.25e-05 | gnorm 0.746 | train_wall 216 | wall 21755
2020-12-19 05:16:37 | INFO | fairseq.trainer | begin training epoch 92
2020-12-19 05:16:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:16:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:17:26 | INFO | train_inner | epoch 092:     89 / 421 symm_kl=0.475, self_kl=0, self_cv=14.502, loss=4.468, nll_loss=1.091, ppl=2.13, wps=18857.7, ups=1.36, wpb=13872.5, bsz=487.1, num_updates=38400, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=21803
2020-12-19 05:18:17 | INFO | train_inner | epoch 092:    189 / 421 symm_kl=0.477, self_kl=0, self_cv=14.537, loss=4.48, nll_loss=1.099, ppl=2.14, wps=27114.3, ups=1.94, wpb=13956.8, bsz=481.9, num_updates=38500, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=21855
2020-12-19 05:19:09 | INFO | train_inner | epoch 092:    289 / 421 symm_kl=0.474, self_kl=0, self_cv=14.508, loss=4.468, nll_loss=1.093, ppl=2.13, wps=27251.8, ups=1.94, wpb=14079.7, bsz=508.1, num_updates=38600, lr=1.25e-05, gnorm=0.743, train_wall=51, wall=21907
2020-12-19 05:20:00 | INFO | train_inner | epoch 092:    389 / 421 symm_kl=0.473, self_kl=0, self_cv=14.413, loss=4.462, nll_loss=1.094, ppl=2.13, wps=27071.7, ups=1.94, wpb=13919.4, bsz=495.5, num_updates=38700, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=21958
2020-12-19 05:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:20:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:20:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:20:33 | INFO | valid | epoch 092 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.205 | nll_loss 3.778 | ppl 13.72 | bleu 22.7 | wps 6194.7 | wpb 10324.2 | bsz 375 | num_updates 38732 | best_bleu 22.99
2020-12-19 05:20:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:20:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 92 @ 38732 updates, score 22.7) (writing took 3.1098275762051344 seconds)
2020-12-19 05:20:36 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2020-12-19 05:20:36 | INFO | train | epoch 092 | symm_kl 0.474 | self_kl 0 | self_cv 14.485 | loss 4.468 | nll_loss 1.093 | ppl 2.13 | wps 24591.6 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 38732 | lr 1.25e-05 | gnorm 0.748 | train_wall 216 | wall 21994
2020-12-19 05:20:36 | INFO | fairseq.trainer | begin training epoch 93
2020-12-19 05:20:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:20:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:20:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:21:14 | INFO | train_inner | epoch 093:     68 / 421 symm_kl=0.471, self_kl=0, self_cv=14.417, loss=4.45, nll_loss=1.084, ppl=2.12, wps=18869.3, ups=1.35, wpb=13931.8, bsz=499.8, num_updates=38800, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=22032
2020-12-19 05:22:06 | INFO | train_inner | epoch 093:    168 / 421 symm_kl=0.474, self_kl=0, self_cv=14.486, loss=4.463, nll_loss=1.089, ppl=2.13, wps=26858.7, ups=1.93, wpb=13886.1, bsz=487.4, num_updates=38900, lr=1.25e-05, gnorm=0.749, train_wall=52, wall=22083
2020-12-19 05:22:58 | INFO | train_inner | epoch 093:    268 / 421 symm_kl=0.48, self_kl=0, self_cv=14.543, loss=4.487, nll_loss=1.1, ppl=2.14, wps=26885.6, ups=1.94, wpb=13850.6, bsz=485.8, num_updates=39000, lr=1.25e-05, gnorm=0.757, train_wall=51, wall=22135
2020-12-19 05:23:49 | INFO | train_inner | epoch 093:    368 / 421 symm_kl=0.473, self_kl=0, self_cv=14.536, loss=4.467, nll_loss=1.09, ppl=2.13, wps=27738.8, ups=1.95, wpb=14222.5, bsz=489.6, num_updates=39100, lr=1.25e-05, gnorm=0.74, train_wall=51, wall=22186
2020-12-19 05:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:24:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:24:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:24:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:24:32 | INFO | valid | epoch 093 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.777 | ppl 13.71 | bleu 22.79 | wps 6184.2 | wpb 10324.2 | bsz 375 | num_updates 39153 | best_bleu 22.99
2020-12-19 05:24:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:24:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:24:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 93 @ 39153 updates, score 22.79) (writing took 3.16416197642684 seconds)
2020-12-19 05:24:35 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2020-12-19 05:24:35 | INFO | train | epoch 093 | symm_kl 0.474 | self_kl 0 | self_cv 14.488 | loss 4.467 | nll_loss 1.092 | ppl 2.13 | wps 24599.5 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 39153 | lr 1.25e-05 | gnorm 0.748 | train_wall 216 | wall 22233
2020-12-19 05:24:35 | INFO | fairseq.trainer | begin training epoch 94
2020-12-19 05:24:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:24:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:25:02 | INFO | train_inner | epoch 094:     47 / 421 symm_kl=0.469, self_kl=0, self_cv=14.394, loss=4.449, nll_loss=1.088, ppl=2.13, wps=19037.3, ups=1.36, wpb=13992.9, bsz=499.8, num_updates=39200, lr=1.25e-05, gnorm=0.749, train_wall=51, wall=22260
2020-12-19 05:25:54 | INFO | train_inner | epoch 094:    147 / 421 symm_kl=0.472, self_kl=0, self_cv=14.514, loss=4.463, nll_loss=1.089, ppl=2.13, wps=27291.3, ups=1.95, wpb=14008.8, bsz=483.8, num_updates=39300, lr=1.25e-05, gnorm=0.74, train_wall=51, wall=22311
2020-12-19 05:26:45 | INFO | train_inner | epoch 094:    247 / 421 symm_kl=0.475, self_kl=0, self_cv=14.501, loss=4.471, nll_loss=1.095, ppl=2.14, wps=27301.8, ups=1.94, wpb=14073.1, bsz=497.6, num_updates=39400, lr=1.25e-05, gnorm=0.742, train_wall=51, wall=22363
2020-12-19 05:27:36 | INFO | train_inner | epoch 094:    347 / 421 symm_kl=0.48, self_kl=0, self_cv=14.501, loss=4.491, nll_loss=1.11, ppl=2.16, wps=26966.9, ups=1.96, wpb=13782.1, bsz=478.6, num_updates=39500, lr=1.25e-05, gnorm=0.752, train_wall=51, wall=22414
2020-12-19 05:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:28:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:28:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:28:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:28:31 | INFO | valid | epoch 094 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.776 | ppl 13.7 | bleu 22.81 | wps 5800.8 | wpb 10324.2 | bsz 375 | num_updates 39574 | best_bleu 22.99
2020-12-19 05:28:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:28:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 94 @ 39574 updates, score 22.81) (writing took 3.1208603028208017 seconds)
2020-12-19 05:28:34 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2020-12-19 05:28:34 | INFO | train | epoch 094 | symm_kl 0.474 | self_kl 0 | self_cv 14.484 | loss 4.467 | nll_loss 1.093 | ppl 2.13 | wps 24613.7 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 39574 | lr 1.25e-05 | gnorm 0.746 | train_wall 215 | wall 22472
2020-12-19 05:28:34 | INFO | fairseq.trainer | begin training epoch 95
2020-12-19 05:28:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:28:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:28:51 | INFO | train_inner | epoch 095:     26 / 421 symm_kl=0.469, self_kl=0, self_cv=14.451, loss=4.451, nll_loss=1.085, ppl=2.12, wps=18787.2, ups=1.34, wpb=13986.8, bsz=521.4, num_updates=39600, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=22488
2020-12-19 05:29:42 | INFO | train_inner | epoch 095:    126 / 421 symm_kl=0.478, self_kl=0, self_cv=14.529, loss=4.482, nll_loss=1.098, ppl=2.14, wps=27051.3, ups=1.95, wpb=13861.6, bsz=476.5, num_updates=39700, lr=1.25e-05, gnorm=0.751, train_wall=51, wall=22539
2020-12-19 05:30:33 | INFO | train_inner | epoch 095:    226 / 421 symm_kl=0.472, self_kl=0, self_cv=14.482, loss=4.456, nll_loss=1.084, ppl=2.12, wps=27098.8, ups=1.95, wpb=13904.9, bsz=482.6, num_updates=39800, lr=1.25e-05, gnorm=0.745, train_wall=51, wall=22591
2020-12-19 05:31:25 | INFO | train_inner | epoch 095:    326 / 421 symm_kl=0.468, self_kl=0, self_cv=14.412, loss=4.451, nll_loss=1.091, ppl=2.13, wps=27594, ups=1.95, wpb=14181.4, bsz=509.4, num_updates=39900, lr=1.25e-05, gnorm=0.737, train_wall=51, wall=22642
2020-12-19 05:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:32:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:32:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:32:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:32:31 | INFO | valid | epoch 095 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.205 | nll_loss 3.78 | ppl 13.73 | bleu 22.7 | wps 5332 | wpb 10324.2 | bsz 375 | num_updates 39995 | best_bleu 22.99
2020-12-19 05:32:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:32:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 95 @ 39995 updates, score 22.7) (writing took 3.1307358760386705 seconds)
2020-12-19 05:32:34 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2020-12-19 05:32:34 | INFO | train | epoch 095 | symm_kl 0.473 | self_kl 0 | self_cv 14.48 | loss 4.465 | nll_loss 1.093 | ppl 2.13 | wps 24496.9 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 39995 | lr 1.25e-05 | gnorm 0.746 | train_wall 215 | wall 22712
2020-12-19 05:32:34 | INFO | fairseq.trainer | begin training epoch 96
2020-12-19 05:32:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:32:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:32:40 | INFO | train_inner | epoch 096:      5 / 421 symm_kl=0.475, self_kl=0, self_cv=14.512, loss=4.475, nll_loss=1.1, ppl=2.14, wps=18389.2, ups=1.32, wpb=13880.1, bsz=488.7, num_updates=40000, lr=1.25e-05, gnorm=0.753, train_wall=51, wall=22718
2020-12-19 05:33:31 | INFO | train_inner | epoch 096:    105 / 421 symm_kl=0.468, self_kl=0, self_cv=14.489, loss=4.452, nll_loss=1.084, ppl=2.12, wps=27678.5, ups=1.95, wpb=14175.6, bsz=499, num_updates=40100, lr=1.25e-05, gnorm=0.729, train_wall=51, wall=22769
2020-12-19 05:34:23 | INFO | train_inner | epoch 096:    205 / 421 symm_kl=0.474, self_kl=0, self_cv=14.469, loss=4.467, nll_loss=1.095, ppl=2.14, wps=26912.6, ups=1.95, wpb=13801.8, bsz=502.2, num_updates=40200, lr=1.25e-05, gnorm=0.75, train_wall=51, wall=22820
2020-12-19 05:35:14 | INFO | train_inner | epoch 096:    305 / 421 symm_kl=0.476, self_kl=0, self_cv=14.487, loss=4.475, nll_loss=1.098, ppl=2.14, wps=27408.2, ups=1.95, wpb=14033.4, bsz=490.9, num_updates=40300, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=22871
2020-12-19 05:36:06 | INFO | train_inner | epoch 096:    405 / 421 symm_kl=0.473, self_kl=0, self_cv=14.481, loss=4.465, nll_loss=1.092, ppl=2.13, wps=26996.1, ups=1.94, wpb=13939.7, bsz=479.9, num_updates=40400, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=22923
2020-12-19 05:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:36:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:36:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:36:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:36:31 | INFO | valid | epoch 096 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.203 | nll_loss 3.779 | ppl 13.72 | bleu 22.68 | wps 5534 | wpb 10324.2 | bsz 375 | num_updates 40416 | best_bleu 22.99
2020-12-19 05:36:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:36:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:36:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 96 @ 40416 updates, score 22.68) (writing took 3.101550493389368 seconds)
2020-12-19 05:36:34 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2020-12-19 05:36:34 | INFO | train | epoch 096 | symm_kl 0.473 | self_kl 0 | self_cv 14.478 | loss 4.464 | nll_loss 1.092 | ppl 2.13 | wps 24512.3 | ups 1.75 | wpb 13969.5 | bsz 492.6 | num_updates 40416 | lr 1.25e-05 | gnorm 0.744 | train_wall 215 | wall 22952
2020-12-19 05:36:34 | INFO | fairseq.trainer | begin training epoch 97
2020-12-19 05:36:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:36:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:37:20 | INFO | train_inner | epoch 097:     84 / 421 symm_kl=0.47, self_kl=0, self_cv=14.468, loss=4.462, nll_loss=1.096, ppl=2.14, wps=18828.3, ups=1.34, wpb=14091.7, bsz=512.2, num_updates=40500, lr=1.25e-05, gnorm=0.736, train_wall=51, wall=22998
2020-12-19 05:38:12 | INFO | train_inner | epoch 097:    184 / 421 symm_kl=0.475, self_kl=0, self_cv=14.48, loss=4.473, nll_loss=1.099, ppl=2.14, wps=26954.4, ups=1.95, wpb=13802.1, bsz=472.5, num_updates=40600, lr=1.25e-05, gnorm=0.753, train_wall=51, wall=23049
2020-12-19 05:39:03 | INFO | train_inner | epoch 097:    284 / 421 symm_kl=0.469, self_kl=0, self_cv=14.46, loss=4.454, nll_loss=1.089, ppl=2.13, wps=27228.3, ups=1.94, wpb=14048.6, bsz=500.6, num_updates=40700, lr=1.25e-05, gnorm=0.737, train_wall=51, wall=23101
2020-12-19 05:39:55 | INFO | train_inner | epoch 097:    384 / 421 symm_kl=0.471, self_kl=0, self_cv=14.418, loss=4.454, nll_loss=1.088, ppl=2.13, wps=27165.8, ups=1.94, wpb=13995.7, bsz=497.8, num_updates=40800, lr=1.25e-05, gnorm=0.744, train_wall=51, wall=23152
2020-12-19 05:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:40:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:40:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:40:30 | INFO | valid | epoch 097 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.202 | nll_loss 3.776 | ppl 13.7 | bleu 22.75 | wps 6125.9 | wpb 10324.2 | bsz 375 | num_updates 40837 | best_bleu 22.99
2020-12-19 05:40:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:40:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:40:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 97 @ 40837 updates, score 22.75) (writing took 3.115930249914527 seconds)
2020-12-19 05:40:33 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2020-12-19 05:40:33 | INFO | train | epoch 097 | symm_kl 0.472 | self_kl 0 | self_cv 14.468 | loss 4.462 | nll_loss 1.093 | ppl 2.13 | wps 24647.4 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 40837 | lr 1.25e-05 | gnorm 0.745 | train_wall 215 | wall 23190
2020-12-19 05:40:33 | INFO | fairseq.trainer | begin training epoch 98
2020-12-19 05:40:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:40:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:41:08 | INFO | train_inner | epoch 098:     63 / 421 symm_kl=0.467, self_kl=0, self_cv=14.477, loss=4.445, nll_loss=1.08, ppl=2.11, wps=18846.9, ups=1.36, wpb=13843.1, bsz=482.2, num_updates=40900, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=23226
2020-12-19 05:41:59 | INFO | train_inner | epoch 098:    163 / 421 symm_kl=0.47, self_kl=0, self_cv=14.434, loss=4.454, nll_loss=1.089, ppl=2.13, wps=27128.8, ups=1.95, wpb=13929.2, bsz=503.2, num_updates=41000, lr=1.25e-05, gnorm=0.748, train_wall=51, wall=23277
2020-12-19 05:42:51 | INFO | train_inner | epoch 098:    263 / 421 symm_kl=0.478, self_kl=0, self_cv=14.549, loss=4.489, nll_loss=1.107, ppl=2.15, wps=26896.6, ups=1.93, wpb=13939.5, bsz=483, num_updates=41100, lr=1.25e-05, gnorm=0.748, train_wall=52, wall=23329
2020-12-19 05:43:43 | INFO | train_inner | epoch 098:    363 / 421 symm_kl=0.469, self_kl=0, self_cv=14.482, loss=4.452, nll_loss=1.086, ppl=2.12, wps=27302.2, ups=1.94, wpb=14068.5, bsz=492.2, num_updates=41200, lr=1.25e-05, gnorm=0.74, train_wall=51, wall=23380
2020-12-19 05:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:44:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:44:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:44:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:44:29 | INFO | valid | epoch 098 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.202 | nll_loss 3.777 | ppl 13.71 | bleu 22.72 | wps 6177.4 | wpb 10324.2 | bsz 375 | num_updates 41258 | best_bleu 22.99
2020-12-19 05:44:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:44:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 98 @ 41258 updates, score 22.72) (writing took 3.1425926722586155 seconds)
2020-12-19 05:44:32 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2020-12-19 05:44:32 | INFO | train | epoch 098 | symm_kl 0.471 | self_kl 0 | self_cv 14.484 | loss 4.462 | nll_loss 1.092 | ppl 2.13 | wps 24586.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 41258 | lr 1.25e-05 | gnorm 0.744 | train_wall 216 | wall 23430
2020-12-19 05:44:32 | INFO | fairseq.trainer | begin training epoch 99
2020-12-19 05:44:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:44:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:44:57 | INFO | train_inner | epoch 099:     42 / 421 symm_kl=0.471, self_kl=0, self_cv=14.451, loss=4.457, nll_loss=1.09, ppl=2.13, wps=18789.1, ups=1.35, wpb=13872, bsz=489.7, num_updates=41300, lr=1.25e-05, gnorm=0.746, train_wall=51, wall=23454
2020-12-19 05:45:48 | INFO | train_inner | epoch 099:    142 / 421 symm_kl=0.471, self_kl=0, self_cv=14.511, loss=4.464, nll_loss=1.092, ppl=2.13, wps=27261.9, ups=1.95, wpb=14015.1, bsz=501.8, num_updates=41400, lr=1.25e-05, gnorm=0.742, train_wall=51, wall=23506
2020-12-19 05:46:40 | INFO | train_inner | epoch 099:    242 / 421 symm_kl=0.472, self_kl=0, self_cv=14.475, loss=4.462, nll_loss=1.092, ppl=2.13, wps=27125.7, ups=1.93, wpb=14021.7, bsz=480, num_updates=41500, lr=1.25e-05, gnorm=0.743, train_wall=52, wall=23557
2020-12-19 05:47:31 | INFO | train_inner | epoch 099:    342 / 421 symm_kl=0.476, self_kl=0, self_cv=14.518, loss=4.481, nll_loss=1.102, ppl=2.15, wps=26937.4, ups=1.94, wpb=13915.6, bsz=489.7, num_updates=41600, lr=1.25e-05, gnorm=0.747, train_wall=51, wall=23609
2020-12-19 05:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:48:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:48:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:48:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:48:27 | INFO | valid | epoch 099 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.2 | nll_loss 3.773 | ppl 13.68 | bleu 22.82 | wps 6773.7 | wpb 10324.2 | bsz 375 | num_updates 41679 | best_bleu 22.99
2020-12-19 05:48:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 99 @ 41679 updates, score 22.82) (writing took 3.120446555316448 seconds)
2020-12-19 05:48:30 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2020-12-19 05:48:30 | INFO | train | epoch 099 | symm_kl 0.47 | self_kl 0 | self_cv 14.471 | loss 4.46 | nll_loss 1.092 | ppl 2.13 | wps 24695.3 | ups 1.77 | wpb 13969.5 | bsz 492.6 | num_updates 41679 | lr 1.25e-05 | gnorm 0.743 | train_wall 216 | wall 23668
2020-12-19 05:48:30 | INFO | fairseq.trainer | begin training epoch 100
2020-12-19 05:48:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:48:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:48:44 | INFO | train_inner | epoch 100:     21 / 421 symm_kl=0.463, self_kl=0, self_cv=14.384, loss=4.434, nll_loss=1.082, ppl=2.12, wps=19230.5, ups=1.38, wpb=13985.8, bsz=496.4, num_updates=41700, lr=1.25e-05, gnorm=0.741, train_wall=51, wall=23682
2020-12-19 05:49:36 | INFO | train_inner | epoch 100:    121 / 421 symm_kl=0.463, self_kl=0, self_cv=14.448, loss=4.432, nll_loss=1.075, ppl=2.11, wps=27451.9, ups=1.94, wpb=14118.8, bsz=510.7, num_updates=41800, lr=1.25e-05, gnorm=0.728, train_wall=51, wall=23733
2020-12-19 05:50:27 | INFO | train_inner | epoch 100:    221 / 421 symm_kl=0.47, self_kl=0, self_cv=14.496, loss=4.458, nll_loss=1.089, ppl=2.13, wps=27196.4, ups=1.94, wpb=14026.1, bsz=489.2, num_updates=41900, lr=1.25e-05, gnorm=0.743, train_wall=51, wall=23785
2020-12-19 05:51:19 | INFO | train_inner | epoch 100:    321 / 421 symm_kl=0.472, self_kl=0, self_cv=14.533, loss=4.474, nll_loss=1.1, ppl=2.14, wps=27130, ups=1.94, wpb=13989.4, bsz=484.4, num_updates=42000, lr=1.25e-05, gnorm=0.744, train_wall=51, wall=23836
2020-12-19 05:52:11 | INFO | train_inner | epoch 100:    421 / 421 symm_kl=0.477, self_kl=0, self_cv=14.473, loss=4.48, nll_loss=1.103, ppl=2.15, wps=26512.7, ups=1.93, wpb=13759.9, bsz=487.8, num_updates=42100, lr=1.25e-05, gnorm=0.761, train_wall=52, wall=23888
2020-12-19 05:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-19 05:52:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:52:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:52:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:52:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-19 05:52:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:52:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:52:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:52:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-19 05:52:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-19 05:52:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-19 05:52:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-19 05:52:27 | INFO | valid | epoch 100 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.204 | nll_loss 3.776 | ppl 13.7 | bleu 22.88 | wps 6339.6 | wpb 10324.2 | bsz 375 | num_updates 42100 | best_bleu 22.99
2020-12-19 05:52:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-19 05:52:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/closer_gap/checkpoint_last.pt (epoch 100 @ 42100 updates, score 22.88) (writing took 3.2060264740139246 seconds)
2020-12-19 05:52:30 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2020-12-19 05:52:30 | INFO | train | epoch 100 | symm_kl 0.47 | self_kl 0 | self_cv 14.477 | loss 4.458 | nll_loss 1.091 | ppl 2.13 | wps 24571.3 | ups 1.76 | wpb 13969.5 | bsz 492.6 | num_updates 42100 | lr 1.25e-05 | gnorm 0.744 | train_wall 216 | wall 23907
2020-12-19 05:52:30 | INFO | fairseq_cli.train | done training in 23906.1 seconds
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 800 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
