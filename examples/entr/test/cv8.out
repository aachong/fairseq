nohup: ignoring input
save_dir=./examples/entr/bash/../checkpoints/cv
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.0000125
lrscheduler=fixed
warmup_updates=0
max_epoch=100
r3f_lambda=1.1
extr='--noised-no-grad --cv --cv-lambda -0.03'
2020-12-20 12:33:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:27 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:15560
2020-12-20 12:33:27 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:15560
2020-12-20 12:33:27 | INFO | fairseq.distributed_utils | distributed init (rank 4): tcp://localhost:15560
2020-12-20 12:33:27 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:15560
2020-12-20 12:33:27 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:15560
2020-12-20 12:33:28 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-20 12:33:28 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-20 12:33:28 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 4
2020-12-20 12:33:28 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-20 12:33:28 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-20 12:33:31 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=True, cv_lambda=-0.03, data='./examples/entr/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:15560', distributed_no_spawn=False, distributed_num_procs=5, distributed_port=-1, distributed_rank=0, distributed_world_size=5, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[1.25e-05], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=5, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.1, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/entr/bash/../checkpoints/cv', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='tr', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, weight_decay=0.0, zero_sharding='none')
2020-12-20 12:33:32 | INFO | fairseq.tasks.translation | [en] dictionary: 19784 types
2020-12-20 12:33:32 | INFO | fairseq.tasks.translation | [tr] dictionary: 19784 types
2020-12-20 12:33:32 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.en
2020-12-20 12:33:32 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.tr
2020-12-20 12:33:32 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin valid en-tr 3000 examples
2020-12-20 12:33:33 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19784, bias=False)
  )
)
2020-12-20 12:33:33 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-20 12:33:33 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2020-12-20 12:33:33 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2020-12-20 12:33:33 | INFO | fairseq_cli.train | num. model params: 54267904 (num. trained: 54267904)
2020-12-20 12:33:33 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2020-12-20 12:33:33 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2020-12-20 12:33:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-20 12:33:33 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-20 12:33:33 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-20 12:33:33 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-20 12:33:33 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-20 12:33:33 | INFO | fairseq.utils | rank   4: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-20 12:33:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 5 workers***********************
2020-12-20 12:33:33 | INFO | fairseq_cli.train | training on 5 devices (GPUs/TPUs)
2020-12-20 12:33:33 | INFO | fairseq_cli.train | max tokens per GPU = 4000 and max sentences per GPU = None
2020-12-20 12:33:33 | INFO | fairseq.checkpoint_utils | loading pretrained model from ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2020-12-20 12:33:33 | INFO | fairseq.trainer | loaded checkpoint ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt (epoch 106 @ 0 updates)
2020-12-20 12:33:33 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-20 12:33:33 | INFO | fairseq.trainer | loading train data for epoch 1
2020-12-20 12:33:33 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.en
2020-12-20 12:33:33 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.tr
2020-12-20 12:33:33 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin train en-tr 207373 examples
2020-12-20 12:33:34 | INFO | fairseq.trainer | begin training epoch 1
2020-12-20 12:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:33:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:33:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:34:30 | INFO | train_inner | epoch 001:    100 / 337 symm_kl=0.917, self_kl=0, self_cv=22.336, loss=3.163, nll_loss=0.797, ppl=1.74, wps=33843.2, ups=1.91, wpb=17767.8, bsz=618.8, num_updates=100, lr=1.25e-05, gnorm=1.517, train_wall=53, wall=58
2020-12-20 12:35:21 | INFO | train_inner | epoch 001:    200 / 337 symm_kl=0.841, self_kl=0, self_cv=23.089, loss=3.025, nll_loss=0.785, ppl=1.72, wps=33809.8, ups=1.96, wpb=17258.2, bsz=608.3, num_updates=200, lr=1.25e-05, gnorm=1.435, train_wall=51, wall=109
2020-12-20 12:36:13 | INFO | train_inner | epoch 001:    300 / 337 symm_kl=0.794, self_kl=0, self_cv=22.934, loss=2.948, nll_loss=0.777, ppl=1.71, wps=33832.9, ups=1.93, wpb=17498.6, bsz=640.5, num_updates=300, lr=1.25e-05, gnorm=1.348, train_wall=52, wall=160
2020-12-20 12:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:36:48 | INFO | valid | epoch 001 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.901 | nll_loss 4.233 | ppl 18.8 | bleu 22.14 | wps 6193.5 | wpb 11799.1 | bsz 428.6 | num_updates 337
2020-12-20 12:36:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:36:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 1 @ 337 updates, score 22.14) (writing took 2.0620795879513025 seconds)
2020-12-20 12:36:50 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-12-20 12:36:50 | INFO | train | epoch 001 | symm_kl 0.848 | self_kl 0 | self_cv 22.855 | loss 3.04 | nll_loss 0.787 | ppl 1.73 | wps 30574.4 | ups 1.75 | wpb 17451.5 | bsz 615.4 | num_updates 337 | lr 1.25e-05 | gnorm 1.437 | train_wall 175 | wall 197
2020-12-20 12:36:50 | INFO | fairseq.trainer | begin training epoch 2
2020-12-20 12:36:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:36:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:36:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:37:26 | INFO | train_inner | epoch 002:     63 / 337 symm_kl=0.802, self_kl=0, self_cv=23.282, loss=2.958, nll_loss=0.784, ppl=1.72, wps=23769.7, ups=1.37, wpb=17298.3, bsz=602.1, num_updates=400, lr=1.25e-05, gnorm=1.393, train_wall=51, wall=233
2020-12-20 12:38:18 | INFO | train_inner | epoch 002:    163 / 337 symm_kl=0.778, self_kl=0, self_cv=23.305, loss=2.912, nll_loss=0.777, ppl=1.71, wps=33577.9, ups=1.92, wpb=17489.7, bsz=612.6, num_updates=500, lr=1.25e-05, gnorm=1.327, train_wall=52, wall=285
2020-12-20 12:39:10 | INFO | train_inner | epoch 002:    263 / 337 symm_kl=0.769, self_kl=0, self_cv=23.397, loss=2.894, nll_loss=0.776, ppl=1.71, wps=33617.4, ups=1.92, wpb=17537.2, bsz=616.8, num_updates=600, lr=1.25e-05, gnorm=1.312, train_wall=52, wall=337
2020-12-20 12:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:39:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:39:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:39:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:39:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:39:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:39:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:39:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:39:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:39:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:40:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:40:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:40:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:40:05 | INFO | valid | epoch 002 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.879 | nll_loss 4.214 | ppl 18.55 | bleu 22.24 | wps 5906.2 | wpb 11799.1 | bsz 428.6 | num_updates 674 | best_bleu 22.24
2020-12-20 12:40:05 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:40:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:40:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:40:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:40:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:40:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 2 @ 674 updates, score 22.24) (writing took 4.577487923204899 seconds)
2020-12-20 12:40:10 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-12-20 12:40:10 | INFO | train | epoch 002 | symm_kl 0.776 | self_kl 0 | self_cv 23.348 | loss 2.91 | nll_loss 0.779 | ppl 1.72 | wps 29475.4 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 674 | lr 1.25e-05 | gnorm 1.332 | train_wall 175 | wall 397
2020-12-20 12:40:10 | INFO | fairseq.trainer | begin training epoch 3
2020-12-20 12:40:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:40:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:40:26 | INFO | train_inner | epoch 003:     26 / 337 symm_kl=0.768, self_kl=0, self_cv=23.394, loss=2.898, nll_loss=0.783, ppl=1.72, wps=22814.2, ups=1.31, wpb=17350.9, bsz=607, num_updates=700, lr=1.25e-05, gnorm=1.339, train_wall=52, wall=413
2020-12-20 12:41:18 | INFO | train_inner | epoch 003:    126 / 337 symm_kl=0.754, self_kl=0, self_cv=23.501, loss=2.867, nll_loss=0.777, ppl=1.71, wps=33449.3, ups=1.92, wpb=17396, bsz=627.5, num_updates=800, lr=1.25e-05, gnorm=1.289, train_wall=52, wall=465
2020-12-20 12:42:11 | INFO | train_inner | epoch 003:    226 / 337 symm_kl=0.757, self_kl=0, self_cv=23.574, loss=2.875, nll_loss=0.783, ppl=1.72, wps=33339.1, ups=1.91, wpb=17429.2, bsz=614.9, num_updates=900, lr=1.25e-05, gnorm=1.299, train_wall=52, wall=518
2020-12-20 12:43:03 | INFO | train_inner | epoch 003:    326 / 337 symm_kl=0.741, self_kl=0, self_cv=23.588, loss=2.843, nll_loss=0.776, ppl=1.71, wps=33618.2, ups=1.91, wpb=17623.9, bsz=612.5, num_updates=1000, lr=1.25e-05, gnorm=1.271, train_wall=52, wall=570
2020-12-20 12:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:43:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:43:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:43:25 | INFO | valid | epoch 003 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.861 | nll_loss 4.194 | ppl 18.31 | bleu 22.37 | wps 5957.9 | wpb 11799.1 | bsz 428.6 | num_updates 1011 | best_bleu 22.37
2020-12-20 12:43:25 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:43:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:43:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 3 @ 1011 updates, score 22.37) (writing took 4.568711204454303 seconds)
2020-12-20 12:43:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-12-20 12:43:30 | INFO | train | epoch 003 | symm_kl 0.751 | self_kl 0 | self_cv 23.519 | loss 2.862 | nll_loss 0.778 | ppl 1.71 | wps 29425.9 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 1011 | lr 1.25e-05 | gnorm 1.292 | train_wall 175 | wall 597
2020-12-20 12:43:30 | INFO | fairseq.trainer | begin training epoch 4
2020-12-20 12:43:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:43:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:44:19 | INFO | train_inner | epoch 004:     89 / 337 symm_kl=0.743, self_kl=0, self_cv=23.655, loss=2.841, nll_loss=0.775, ppl=1.71, wps=22636.6, ups=1.32, wpb=17172.7, bsz=598, num_updates=1100, lr=1.25e-05, gnorm=1.308, train_wall=52, wall=646
2020-12-20 12:45:11 | INFO | train_inner | epoch 004:    189 / 337 symm_kl=0.742, self_kl=0, self_cv=23.756, loss=2.84, nll_loss=0.779, ppl=1.72, wps=33375.2, ups=1.9, wpb=17548.2, bsz=604.2, num_updates=1200, lr=1.25e-05, gnorm=1.265, train_wall=52, wall=699
2020-12-20 12:46:04 | INFO | train_inner | epoch 004:    289 / 337 symm_kl=0.73, self_kl=0, self_cv=23.641, loss=2.825, nll_loss=0.778, ppl=1.72, wps=33524.1, ups=1.91, wpb=17592.8, bsz=630.6, num_updates=1300, lr=1.25e-05, gnorm=1.242, train_wall=52, wall=751
2020-12-20 12:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:46:45 | INFO | valid | epoch 004 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.861 | nll_loss 4.191 | ppl 18.27 | bleu 22.29 | wps 5882.6 | wpb 11799.1 | bsz 428.6 | num_updates 1348 | best_bleu 22.37
2020-12-20 12:46:45 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:46:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 4 @ 1348 updates, score 22.29) (writing took 2.768399840220809 seconds)
2020-12-20 12:46:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-12-20 12:46:48 | INFO | train | epoch 004 | symm_kl 0.735 | self_kl 0 | self_cv 23.665 | loss 2.831 | nll_loss 0.777 | ppl 1.71 | wps 29612.7 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 1348 | lr 1.25e-05 | gnorm 1.266 | train_wall 176 | wall 795
2020-12-20 12:46:48 | INFO | fairseq.trainer | begin training epoch 5
2020-12-20 12:46:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:46:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:46:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:47:18 | INFO | train_inner | epoch 005:     52 / 337 symm_kl=0.718, self_kl=0, self_cv=23.597, loss=2.798, nll_loss=0.768, ppl=1.7, wps=23521.5, ups=1.34, wpb=17495.9, bsz=615.6, num_updates=1400, lr=1.25e-05, gnorm=1.251, train_wall=52, wall=825
2020-12-20 12:48:11 | INFO | train_inner | epoch 005:    152 / 337 symm_kl=0.726, self_kl=0, self_cv=23.801, loss=2.816, nll_loss=0.782, ppl=1.72, wps=33158.3, ups=1.91, wpb=17384.8, bsz=621.3, num_updates=1500, lr=1.25e-05, gnorm=1.252, train_wall=52, wall=878
2020-12-20 12:49:03 | INFO | train_inner | epoch 005:    252 / 337 symm_kl=0.727, self_kl=0, self_cv=23.81, loss=2.817, nll_loss=0.781, ppl=1.72, wps=33108.6, ups=1.9, wpb=17463.5, bsz=620.5, num_updates=1600, lr=1.25e-05, gnorm=1.253, train_wall=53, wall=931
2020-12-20 12:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:49:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:49:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:49:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:50:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:50:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:50:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:50:03 | INFO | valid | epoch 005 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.855 | nll_loss 4.185 | ppl 18.18 | bleu 22.41 | wps 6364 | wpb 11799.1 | bsz 428.6 | num_updates 1685 | best_bleu 22.41
2020-12-20 12:50:03 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:50:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:50:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:50:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:50:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:50:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:50:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:50:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:50:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:50:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 5 @ 1685 updates, score 22.41) (writing took 4.547797333449125 seconds)
2020-12-20 12:50:08 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-12-20 12:50:08 | INFO | train | epoch 005 | symm_kl 0.723 | self_kl 0 | self_cv 23.8 | loss 2.806 | nll_loss 0.776 | ppl 1.71 | wps 29427.3 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 1685 | lr 1.25e-05 | gnorm 1.253 | train_wall 176 | wall 995
2020-12-20 12:50:08 | INFO | fairseq.trainer | begin training epoch 6
2020-12-20 12:50:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:50:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:50:19 | INFO | train_inner | epoch 006:     15 / 337 symm_kl=0.714, self_kl=0, self_cv=23.845, loss=2.784, nll_loss=0.769, ppl=1.7, wps=22988.1, ups=1.33, wpb=17345.5, bsz=608, num_updates=1700, lr=1.25e-05, gnorm=1.26, train_wall=52, wall=1006
2020-12-20 12:51:11 | INFO | train_inner | epoch 006:    115 / 337 symm_kl=0.711, self_kl=0, self_cv=23.807, loss=2.784, nll_loss=0.772, ppl=1.71, wps=33541.8, ups=1.91, wpb=17605.6, bsz=632.5, num_updates=1800, lr=1.25e-05, gnorm=1.226, train_wall=52, wall=1059
2020-12-20 12:52:04 | INFO | train_inner | epoch 006:    215 / 337 symm_kl=0.717, self_kl=0, self_cv=24.007, loss=2.789, nll_loss=0.774, ppl=1.71, wps=33232.6, ups=1.91, wpb=17434.9, bsz=607.8, num_updates=1900, lr=1.25e-05, gnorm=1.246, train_wall=52, wall=1111
2020-12-20 12:52:57 | INFO | train_inner | epoch 006:    315 / 337 symm_kl=0.705, self_kl=0, self_cv=23.909, loss=2.77, nll_loss=0.771, ppl=1.71, wps=33267.3, ups=1.9, wpb=17526.1, bsz=618.2, num_updates=2000, lr=1.25e-05, gnorm=1.222, train_wall=53, wall=1164
2020-12-20 12:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:53:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:53:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:53:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:53:24 | INFO | valid | epoch 006 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.848 | nll_loss 4.175 | ppl 18.06 | bleu 22.38 | wps 6339.1 | wpb 11799.1 | bsz 428.6 | num_updates 2022 | best_bleu 22.41
2020-12-20 12:53:24 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 6 @ 2022 updates, score 22.38) (writing took 2.770375533029437 seconds)
2020-12-20 12:53:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-12-20 12:53:26 | INFO | train | epoch 006 | symm_kl 0.712 | self_kl 0 | self_cv 23.922 | loss 2.783 | nll_loss 0.774 | ppl 1.71 | wps 29666.5 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 2022 | lr 1.25e-05 | gnorm 1.236 | train_wall 176 | wall 1193
2020-12-20 12:53:26 | INFO | fairseq.trainer | begin training epoch 7
2020-12-20 12:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:53:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:53:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:54:10 | INFO | train_inner | epoch 007:     78 / 337 symm_kl=0.713, self_kl=0, self_cv=24.063, loss=2.783, nll_loss=0.779, ppl=1.72, wps=23393.1, ups=1.36, wpb=17213, bsz=606.4, num_updates=2100, lr=1.25e-05, gnorm=1.244, train_wall=52, wall=1237
2020-12-20 12:55:02 | INFO | train_inner | epoch 007:    178 / 337 symm_kl=0.708, self_kl=0, self_cv=24.041, loss=2.774, nll_loss=0.777, ppl=1.71, wps=33172.2, ups=1.91, wpb=17343.1, bsz=609.9, num_updates=2200, lr=1.25e-05, gnorm=1.23, train_wall=52, wall=1290
2020-12-20 12:55:55 | INFO | train_inner | epoch 007:    278 / 337 symm_kl=0.703, self_kl=0, self_cv=24.111, loss=2.76, nll_loss=0.771, ppl=1.71, wps=33571.5, ups=1.91, wpb=17587.6, bsz=623.8, num_updates=2300, lr=1.25e-05, gnorm=1.222, train_wall=52, wall=1342
2020-12-20 12:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:56:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:56:42 | INFO | valid | epoch 007 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.846 | nll_loss 4.174 | ppl 18.05 | bleu 22.38 | wps 5966.9 | wpb 11799.1 | bsz 428.6 | num_updates 2359 | best_bleu 22.41
2020-12-20 12:56:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 12:56:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:56:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 7 @ 2359 updates, score 22.38) (writing took 2.6885987874120474 seconds)
2020-12-20 12:56:45 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-12-20 12:56:45 | INFO | train | epoch 007 | symm_kl 0.704 | self_kl 0 | self_cv 24.041 | loss 2.765 | nll_loss 0.772 | ppl 1.71 | wps 29635.1 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 2359 | lr 1.25e-05 | gnorm 1.225 | train_wall 176 | wall 1392
2020-12-20 12:56:45 | INFO | fairseq.trainer | begin training epoch 8
2020-12-20 12:56:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:56:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:57:09 | INFO | train_inner | epoch 008:     41 / 337 symm_kl=0.692, self_kl=0, self_cv=23.918, loss=2.745, nll_loss=0.766, ppl=1.7, wps=23679.6, ups=1.35, wpb=17594.1, bsz=617.8, num_updates=2400, lr=1.25e-05, gnorm=1.206, train_wall=52, wall=1416
2020-12-20 12:58:01 | INFO | train_inner | epoch 008:    141 / 337 symm_kl=0.704, self_kl=0, self_cv=24.162, loss=2.761, nll_loss=0.772, ppl=1.71, wps=33404.9, ups=1.91, wpb=17462.5, bsz=603.6, num_updates=2500, lr=1.25e-05, gnorm=1.223, train_wall=52, wall=1469
2020-12-20 12:58:54 | INFO | train_inner | epoch 008:    241 / 337 symm_kl=0.685, self_kl=0, self_cv=24.094, loss=2.725, nll_loss=0.763, ppl=1.7, wps=33073, ups=1.9, wpb=17412.4, bsz=635.7, num_updates=2600, lr=1.25e-05, gnorm=1.207, train_wall=52, wall=1521
2020-12-20 12:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 12:59:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:59:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:59:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:59:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:59:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 12:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 12:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 12:59:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 12:59:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 12:59:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:00:00 | INFO | valid | epoch 008 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.835 | nll_loss 4.161 | ppl 17.89 | bleu 22.5 | wps 6576.3 | wpb 11799.1 | bsz 428.6 | num_updates 2696 | best_bleu 22.5
2020-12-20 13:00:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:00:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:00:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:00:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:00:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:00:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 8 @ 2696 updates, score 22.5) (writing took 4.649894746020436 seconds)
2020-12-20 13:00:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-12-20 13:00:04 | INFO | train | epoch 008 | symm_kl 0.696 | self_kl 0 | self_cv 24.122 | loss 2.749 | nll_loss 0.772 | ppl 1.71 | wps 29457.8 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 2696 | lr 1.25e-05 | gnorm 1.215 | train_wall 176 | wall 1592
2020-12-20 13:00:04 | INFO | fairseq.trainer | begin training epoch 9
2020-12-20 13:00:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:00:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:00:10 | INFO | train_inner | epoch 009:      4 / 337 symm_kl=0.698, self_kl=0, self_cv=24.204, loss=2.757, nll_loss=0.782, ppl=1.72, wps=22936.3, ups=1.32, wpb=17360.1, bsz=607.5, num_updates=2700, lr=1.25e-05, gnorm=1.221, train_wall=53, wall=1597
2020-12-20 13:01:02 | INFO | train_inner | epoch 009:    104 / 337 symm_kl=0.698, self_kl=0, self_cv=24.268, loss=2.745, nll_loss=0.77, ppl=1.71, wps=33486.3, ups=1.91, wpb=17489.1, bsz=603.7, num_updates=2800, lr=1.25e-05, gnorm=1.21, train_wall=52, wall=1649
2020-12-20 13:01:55 | INFO | train_inner | epoch 009:    204 / 337 symm_kl=0.688, self_kl=0, self_cv=24.157, loss=2.732, nll_loss=0.769, ppl=1.7, wps=33234.7, ups=1.9, wpb=17488.7, bsz=614.5, num_updates=2900, lr=1.25e-05, gnorm=1.207, train_wall=52, wall=1702
2020-12-20 13:02:47 | INFO | train_inner | epoch 009:    304 / 337 symm_kl=0.681, self_kl=0, self_cv=24.188, loss=2.719, nll_loss=0.767, ppl=1.7, wps=33331.6, ups=1.9, wpb=17545.6, bsz=636.8, num_updates=3000, lr=1.25e-05, gnorm=1.189, train_wall=52, wall=1754
2020-12-20 13:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:03:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:03:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:03:20 | INFO | valid | epoch 009 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.83 | nll_loss 4.156 | ppl 17.83 | bleu 22.4 | wps 6107.2 | wpb 11799.1 | bsz 428.6 | num_updates 3033 | best_bleu 22.5
2020-12-20 13:03:20 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:03:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:03:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 9 @ 3033 updates, score 22.4) (writing took 2.7292888406664133 seconds)
2020-12-20 13:03:23 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-12-20 13:03:23 | INFO | train | epoch 009 | symm_kl 0.69 | self_kl 0 | self_cv 24.222 | loss 2.735 | nll_loss 0.77 | ppl 1.71 | wps 29610.1 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 3033 | lr 1.25e-05 | gnorm 1.207 | train_wall 176 | wall 1790
2020-12-20 13:03:23 | INFO | fairseq.trainer | begin training epoch 10
2020-12-20 13:03:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:03:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:04:01 | INFO | train_inner | epoch 010:     67 / 337 symm_kl=0.69, self_kl=0, self_cv=24.369, loss=2.734, nll_loss=0.776, ppl=1.71, wps=23556.3, ups=1.36, wpb=17366.7, bsz=597.6, num_updates=3100, lr=1.25e-05, gnorm=1.216, train_wall=52, wall=1828
2020-12-20 13:04:53 | INFO | train_inner | epoch 010:    167 / 337 symm_kl=0.695, self_kl=0, self_cv=24.414, loss=2.743, nll_loss=0.778, ppl=1.71, wps=33198.1, ups=1.91, wpb=17415.9, bsz=595.6, num_updates=3200, lr=1.25e-05, gnorm=1.206, train_wall=52, wall=1881
2020-12-20 13:05:46 | INFO | train_inner | epoch 010:    267 / 337 symm_kl=0.675, self_kl=0, self_cv=24.221, loss=2.704, nll_loss=0.763, ppl=1.7, wps=32995, ups=1.89, wpb=17486.4, bsz=633.3, num_updates=3300, lr=1.25e-05, gnorm=1.181, train_wall=53, wall=1934
2020-12-20 13:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:06:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:06:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:06:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:06:39 | INFO | valid | epoch 010 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.83 | nll_loss 4.157 | ppl 17.84 | bleu 22.41 | wps 6301.5 | wpb 11799.1 | bsz 428.6 | num_updates 3370 | best_bleu 22.5
2020-12-20 13:06:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:06:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 10 @ 3370 updates, score 22.41) (writing took 2.784710520878434 seconds)
2020-12-20 13:06:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-12-20 13:06:41 | INFO | train | epoch 010 | symm_kl 0.683 | self_kl 0 | self_cv 24.314 | loss 2.72 | nll_loss 0.769 | ppl 1.7 | wps 29654.8 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 3370 | lr 1.25e-05 | gnorm 1.196 | train_wall 176 | wall 1989
2020-12-20 13:06:41 | INFO | fairseq.trainer | begin training epoch 11
2020-12-20 13:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:07:00 | INFO | train_inner | epoch 011:     30 / 337 symm_kl=0.68, self_kl=0, self_cv=24.313, loss=2.713, nll_loss=0.767, ppl=1.7, wps=23591.4, ups=1.36, wpb=17342.4, bsz=611.4, num_updates=3400, lr=1.25e-05, gnorm=1.204, train_wall=52, wall=2007
2020-12-20 13:07:52 | INFO | train_inner | epoch 011:    130 / 337 symm_kl=0.676, self_kl=0, self_cv=24.325, loss=2.705, nll_loss=0.766, ppl=1.7, wps=33470.3, ups=1.91, wpb=17481.6, bsz=620.6, num_updates=3500, lr=1.25e-05, gnorm=1.179, train_wall=52, wall=2059
2020-12-20 13:08:45 | INFO | train_inner | epoch 011:    230 / 337 symm_kl=0.688, self_kl=0, self_cv=24.447, loss=2.732, nll_loss=0.78, ppl=1.72, wps=32950.1, ups=1.9, wpb=17361.9, bsz=611.7, num_updates=3600, lr=1.25e-05, gnorm=1.196, train_wall=53, wall=2112
2020-12-20 13:09:38 | INFO | train_inner | epoch 011:    330 / 337 symm_kl=0.671, self_kl=0, self_cv=24.465, loss=2.69, nll_loss=0.765, ppl=1.7, wps=33205.7, ups=1.88, wpb=17633.5, bsz=625.1, num_updates=3700, lr=1.25e-05, gnorm=1.169, train_wall=53, wall=2165
2020-12-20 13:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:09:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:09:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:09:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:09:57 | INFO | valid | epoch 011 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.829 | nll_loss 4.155 | ppl 17.81 | bleu 22.37 | wps 6358.3 | wpb 11799.1 | bsz 428.6 | num_updates 3707 | best_bleu 22.5
2020-12-20 13:09:57 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:09:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:10:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 11 @ 3707 updates, score 22.37) (writing took 2.739462312310934 seconds)
2020-12-20 13:10:00 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-12-20 13:10:00 | INFO | train | epoch 011 | symm_kl 0.678 | self_kl 0 | self_cv 24.406 | loss 2.709 | nll_loss 0.77 | ppl 1.7 | wps 29654.9 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 3707 | lr 1.25e-05 | gnorm 1.186 | train_wall 176 | wall 2187
2020-12-20 13:10:00 | INFO | fairseq.trainer | begin training epoch 12
2020-12-20 13:10:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:10:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:10:51 | INFO | train_inner | epoch 012:     93 / 337 symm_kl=0.673, self_kl=0, self_cv=24.447, loss=2.698, nll_loss=0.768, ppl=1.7, wps=23496.7, ups=1.36, wpb=17249.7, bsz=617, num_updates=3800, lr=1.25e-05, gnorm=1.195, train_wall=52, wall=2239
2020-12-20 13:11:44 | INFO | train_inner | epoch 012:    193 / 337 symm_kl=0.671, self_kl=0, self_cv=24.411, loss=2.693, nll_loss=0.765, ppl=1.7, wps=33636.1, ups=1.9, wpb=17679.5, bsz=626.5, num_updates=3900, lr=1.25e-05, gnorm=1.164, train_wall=52, wall=2291
2020-12-20 13:12:37 | INFO | train_inner | epoch 012:    293 / 337 symm_kl=0.677, self_kl=0, self_cv=24.606, loss=2.702, nll_loss=0.773, ppl=1.71, wps=33087.4, ups=1.9, wpb=17418.7, bsz=604.6, num_updates=4000, lr=1.25e-05, gnorm=1.188, train_wall=52, wall=2344
2020-12-20 13:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:13:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:13:15 | INFO | valid | epoch 012 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.827 | nll_loss 4.154 | ppl 17.81 | bleu 22.42 | wps 6530.1 | wpb 11799.1 | bsz 428.6 | num_updates 4044 | best_bleu 22.5
2020-12-20 13:13:15 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:13:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 12 @ 4044 updates, score 22.42) (writing took 2.6827009059488773 seconds)
2020-12-20 13:13:17 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-12-20 13:13:17 | INFO | train | epoch 012 | symm_kl 0.674 | self_kl 0 | self_cv 24.493 | loss 2.698 | nll_loss 0.769 | ppl 1.7 | wps 29755.1 | ups 1.71 | wpb 17451.5 | bsz 615.4 | num_updates 4044 | lr 1.25e-05 | gnorm 1.181 | train_wall 176 | wall 2384
2020-12-20 13:13:17 | INFO | fairseq.trainer | begin training epoch 13
2020-12-20 13:13:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:13:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:13:49 | INFO | train_inner | epoch 013:     56 / 337 symm_kl=0.676, self_kl=0, self_cv=24.514, loss=2.699, nll_loss=0.767, ppl=1.7, wps=23899.7, ups=1.37, wpb=17424.1, bsz=600.8, num_updates=4100, lr=1.25e-05, gnorm=1.195, train_wall=52, wall=2417
2020-12-20 13:14:42 | INFO | train_inner | epoch 013:    156 / 337 symm_kl=0.673, self_kl=0, self_cv=24.656, loss=2.694, nll_loss=0.772, ppl=1.71, wps=33118, ups=1.89, wpb=17547.2, bsz=600.1, num_updates=4200, lr=1.25e-05, gnorm=1.172, train_wall=53, wall=2470
2020-12-20 13:15:35 | INFO | train_inner | epoch 013:    256 / 337 symm_kl=0.662, self_kl=0, self_cv=24.454, loss=2.675, nll_loss=0.763, ppl=1.7, wps=33273.4, ups=1.9, wpb=17525.1, bsz=636.2, num_updates=4300, lr=1.25e-05, gnorm=1.162, train_wall=52, wall=2522
2020-12-20 13:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:16:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:16:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:16:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:16:34 | INFO | valid | epoch 013 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.827 | nll_loss 4.151 | ppl 17.77 | bleu 22.52 | wps 5936.6 | wpb 11799.1 | bsz 428.6 | num_updates 4381 | best_bleu 22.52
2020-12-20 13:16:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:16:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 13 @ 4381 updates, score 22.52) (writing took 4.643018297851086 seconds)
2020-12-20 13:16:38 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-12-20 13:16:38 | INFO | train | epoch 013 | symm_kl 0.669 | self_kl 0 | self_cv 24.568 | loss 2.686 | nll_loss 0.768 | ppl 1.7 | wps 29254.9 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 4381 | lr 1.25e-05 | gnorm 1.176 | train_wall 176 | wall 2586
2020-12-20 13:16:38 | INFO | fairseq.trainer | begin training epoch 14
2020-12-20 13:16:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:16:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:16:51 | INFO | train_inner | epoch 014:     19 / 337 symm_kl=0.666, self_kl=0, self_cv=24.617, loss=2.679, nll_loss=0.767, ppl=1.7, wps=22652.6, ups=1.31, wpb=17242.9, bsz=614.2, num_updates=4400, lr=1.25e-05, gnorm=1.185, train_wall=52, wall=2598
2020-12-20 13:17:44 | INFO | train_inner | epoch 014:    119 / 337 symm_kl=0.665, self_kl=0, self_cv=24.603, loss=2.676, nll_loss=0.764, ppl=1.7, wps=33632.9, ups=1.91, wpb=17642.2, bsz=616.2, num_updates=4500, lr=1.25e-05, gnorm=1.166, train_wall=52, wall=2651
2020-12-20 13:18:36 | INFO | train_inner | epoch 014:    219 / 337 symm_kl=0.672, self_kl=0, self_cv=24.66, loss=2.692, nll_loss=0.774, ppl=1.71, wps=33049.3, ups=1.91, wpb=17320.2, bsz=616.1, num_updates=4600, lr=1.25e-05, gnorm=1.183, train_wall=52, wall=2703
2020-12-20 13:19:29 | INFO | train_inner | epoch 014:    319 / 337 symm_kl=0.661, self_kl=0, self_cv=24.731, loss=2.666, nll_loss=0.767, ppl=1.7, wps=33101.7, ups=1.89, wpb=17502.6, bsz=610.7, num_updates=4700, lr=1.25e-05, gnorm=1.158, train_wall=53, wall=2756
2020-12-20 13:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:19:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:19:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:19:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:19:54 | INFO | valid | epoch 014 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.828 | nll_loss 4.153 | ppl 17.78 | bleu 22.49 | wps 6411.3 | wpb 11799.1 | bsz 428.6 | num_updates 4718 | best_bleu 22.52
2020-12-20 13:19:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:19:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:19:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 14 @ 4718 updates, score 22.49) (writing took 2.714371981099248 seconds)
2020-12-20 13:19:57 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-12-20 13:19:57 | INFO | train | epoch 014 | symm_kl 0.665 | self_kl 0 | self_cv 24.654 | loss 2.677 | nll_loss 0.768 | ppl 1.7 | wps 29657.9 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 4718 | lr 1.25e-05 | gnorm 1.174 | train_wall 177 | wall 2784
2020-12-20 13:19:57 | INFO | fairseq.trainer | begin training epoch 15
2020-12-20 13:19:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:19:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:20:43 | INFO | train_inner | epoch 015:     82 / 337 symm_kl=0.666, self_kl=0, self_cv=24.738, loss=2.68, nll_loss=0.774, ppl=1.71, wps=23382.6, ups=1.35, wpb=17289, bsz=621.1, num_updates=4800, lr=1.25e-05, gnorm=1.192, train_wall=52, wall=2830
2020-12-20 13:21:36 | INFO | train_inner | epoch 015:    182 / 337 symm_kl=0.656, self_kl=0, self_cv=24.737, loss=2.65, nll_loss=0.756, ppl=1.69, wps=33138.2, ups=1.89, wpb=17524.1, bsz=617.7, num_updates=4900, lr=1.25e-05, gnorm=1.175, train_wall=53, wall=2883
2020-12-20 13:22:28 | INFO | train_inner | epoch 015:    282 / 337 symm_kl=0.659, self_kl=0, self_cv=24.703, loss=2.667, nll_loss=0.769, ppl=1.7, wps=33260.4, ups=1.9, wpb=17513.8, bsz=621.4, num_updates=5000, lr=1.25e-05, gnorm=1.158, train_wall=52, wall=2936
2020-12-20 13:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:23:13 | INFO | valid | epoch 015 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.831 | nll_loss 4.154 | ppl 17.8 | bleu 22.55 | wps 6435.4 | wpb 11799.1 | bsz 428.6 | num_updates 5055 | best_bleu 22.55
2020-12-20 13:23:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:23:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 15 @ 5055 updates, score 22.55) (writing took 4.600467272102833 seconds)
2020-12-20 13:23:17 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-12-20 13:23:17 | INFO | train | epoch 015 | symm_kl 0.661 | self_kl 0 | self_cv 24.746 | loss 2.666 | nll_loss 0.766 | ppl 1.7 | wps 29326 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 5055 | lr 1.25e-05 | gnorm 1.173 | train_wall 177 | wall 2984
2020-12-20 13:23:17 | INFO | fairseq.trainer | begin training epoch 16
2020-12-20 13:23:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:23:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:23:44 | INFO | train_inner | epoch 016:     45 / 337 symm_kl=0.662, self_kl=0, self_cv=24.779, loss=2.667, nll_loss=0.766, ppl=1.7, wps=23062.1, ups=1.33, wpb=17316.9, bsz=617.4, num_updates=5100, lr=1.25e-05, gnorm=1.184, train_wall=52, wall=3011
2020-12-20 13:24:36 | INFO | train_inner | epoch 016:    145 / 337 symm_kl=0.661, self_kl=0, self_cv=24.859, loss=2.662, nll_loss=0.767, ppl=1.7, wps=33285.7, ups=1.91, wpb=17471.4, bsz=617.3, num_updates=5200, lr=1.25e-05, gnorm=1.162, train_wall=52, wall=3063
2020-12-20 13:25:29 | INFO | train_inner | epoch 016:    245 / 337 symm_kl=0.651, self_kl=0, self_cv=24.775, loss=2.644, nll_loss=0.762, ppl=1.7, wps=33302.6, ups=1.9, wpb=17510.5, bsz=627, num_updates=5300, lr=1.25e-05, gnorm=1.153, train_wall=52, wall=3116
2020-12-20 13:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:26:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:26:32 | INFO | valid | epoch 016 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.83 | nll_loss 4.153 | ppl 17.79 | bleu 22.45 | wps 6383.1 | wpb 11799.1 | bsz 428.6 | num_updates 5392 | best_bleu 22.55
2020-12-20 13:26:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:26:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 16 @ 5392 updates, score 22.45) (writing took 2.7210561484098434 seconds)
2020-12-20 13:26:35 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-12-20 13:26:35 | INFO | train | epoch 016 | symm_kl 0.658 | self_kl 0 | self_cv 24.833 | loss 2.657 | nll_loss 0.766 | ppl 1.7 | wps 29761.7 | ups 1.71 | wpb 17451.5 | bsz 615.4 | num_updates 5392 | lr 1.25e-05 | gnorm 1.168 | train_wall 176 | wall 3182
2020-12-20 13:26:35 | INFO | fairseq.trainer | begin training epoch 17
2020-12-20 13:26:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:26:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:26:42 | INFO | train_inner | epoch 017:      8 / 337 symm_kl=0.66, self_kl=0, self_cv=24.912, loss=2.661, nll_loss=0.769, ppl=1.7, wps=23714.4, ups=1.36, wpb=17427.4, bsz=593.8, num_updates=5400, lr=1.25e-05, gnorm=1.186, train_wall=52, wall=3189
2020-12-20 13:27:34 | INFO | train_inner | epoch 017:    108 / 337 symm_kl=0.649, self_kl=0, self_cv=24.763, loss=2.638, nll_loss=0.757, ppl=1.69, wps=33570.7, ups=1.91, wpb=17584.4, bsz=619.3, num_updates=5500, lr=1.25e-05, gnorm=1.146, train_wall=52, wall=3242
2020-12-20 13:28:27 | INFO | train_inner | epoch 017:    208 / 337 symm_kl=0.652, self_kl=0, self_cv=24.787, loss=2.643, nll_loss=0.758, ppl=1.69, wps=33256.3, ups=1.9, wpb=17512.4, bsz=622.6, num_updates=5600, lr=1.25e-05, gnorm=1.15, train_wall=52, wall=3294
2020-12-20 13:29:20 | INFO | train_inner | epoch 017:    308 / 337 symm_kl=0.659, self_kl=0, self_cv=25.074, loss=2.658, nll_loss=0.774, ppl=1.71, wps=32920.2, ups=1.9, wpb=17336.6, bsz=613, num_updates=5700, lr=1.25e-05, gnorm=1.166, train_wall=52, wall=3347
2020-12-20 13:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:29:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:29:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:29:50 | INFO | valid | epoch 017 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.832 | nll_loss 4.155 | ppl 17.82 | bleu 22.39 | wps 6404.4 | wpb 11799.1 | bsz 428.6 | num_updates 5729 | best_bleu 22.55
2020-12-20 13:29:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:29:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:29:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 17 @ 5729 updates, score 22.39) (writing took 2.6919529903680086 seconds)
2020-12-20 13:29:53 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-12-20 13:29:53 | INFO | train | epoch 017 | symm_kl 0.655 | self_kl 0 | self_cv 24.897 | loss 2.65 | nll_loss 0.765 | ppl 1.7 | wps 29675.3 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 5729 | lr 1.25e-05 | gnorm 1.162 | train_wall 177 | wall 3380
2020-12-20 13:29:53 | INFO | fairseq.trainer | begin training epoch 18
2020-12-20 13:29:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:29:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:30:33 | INFO | train_inner | epoch 018:     71 / 337 symm_kl=0.659, self_kl=0, self_cv=25.056, loss=2.654, nll_loss=0.769, ppl=1.7, wps=23617.7, ups=1.36, wpb=17349.4, bsz=610.1, num_updates=5800, lr=1.25e-05, gnorm=1.184, train_wall=52, wall=3420
2020-12-20 13:31:26 | INFO | train_inner | epoch 018:    171 / 337 symm_kl=0.648, self_kl=0, self_cv=24.917, loss=2.63, nll_loss=0.757, ppl=1.69, wps=33006.1, ups=1.89, wpb=17492.7, bsz=606.4, num_updates=5900, lr=1.25e-05, gnorm=1.157, train_wall=53, wall=3473
2020-12-20 13:32:19 | INFO | train_inner | epoch 018:    271 / 337 symm_kl=0.652, self_kl=0, self_cv=24.932, loss=2.645, nll_loss=0.768, ppl=1.7, wps=33198.9, ups=1.9, wpb=17479.9, bsz=625.7, num_updates=6000, lr=1.25e-05, gnorm=1.153, train_wall=52, wall=3526
2020-12-20 13:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:32:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:32:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:32:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:32:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:32:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:32:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:32:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:32:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:32:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:32:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:33:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:33:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:33:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:33:10 | INFO | valid | epoch 018 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.831 | nll_loss 4.153 | ppl 17.79 | bleu 22.42 | wps 5726.9 | wpb 11799.1 | bsz 428.6 | num_updates 6066 | best_bleu 22.55
2020-12-20 13:33:10 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:33:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 18 @ 6066 updates, score 22.42) (writing took 2.7042168360203505 seconds)
2020-12-20 13:33:13 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-12-20 13:33:13 | INFO | train | epoch 018 | symm_kl 0.652 | self_kl 0 | self_cv 24.981 | loss 2.64 | nll_loss 0.764 | ppl 1.7 | wps 29397 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 6066 | lr 1.25e-05 | gnorm 1.16 | train_wall 177 | wall 3580
2020-12-20 13:33:13 | INFO | fairseq.trainer | begin training epoch 19
2020-12-20 13:33:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:33:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:33:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:33:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:33:34 | INFO | train_inner | epoch 019:     34 / 337 symm_kl=0.654, self_kl=0, self_cv=25.115, loss=2.644, nll_loss=0.769, ppl=1.7, wps=23107, ups=1.34, wpb=17295.8, bsz=608.8, num_updates=6100, lr=1.25e-05, gnorm=1.175, train_wall=52, wall=3601
2020-12-20 13:34:26 | INFO | train_inner | epoch 019:    134 / 337 symm_kl=0.639, self_kl=0, self_cv=24.917, loss=2.617, nll_loss=0.758, ppl=1.69, wps=33713.2, ups=1.9, wpb=17704.6, bsz=629.4, num_updates=6200, lr=1.25e-05, gnorm=1.136, train_wall=52, wall=3653
2020-12-20 13:35:19 | INFO | train_inner | epoch 019:    234 / 337 symm_kl=0.656, self_kl=0, self_cv=25.203, loss=2.644, nll_loss=0.768, ppl=1.7, wps=32947.2, ups=1.89, wpb=17402.2, bsz=613.7, num_updates=6300, lr=1.25e-05, gnorm=1.167, train_wall=53, wall=3706
2020-12-20 13:36:12 | INFO | train_inner | epoch 019:    334 / 337 symm_kl=0.651, self_kl=0, self_cv=25.026, loss=2.64, nll_loss=0.767, ppl=1.7, wps=33288.6, ups=1.9, wpb=17483.4, bsz=610.5, num_updates=6400, lr=1.25e-05, gnorm=1.154, train_wall=52, wall=3759
2020-12-20 13:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:36:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:36:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:36:29 | INFO | valid | epoch 019 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.828 | nll_loss 4.151 | ppl 17.76 | bleu 22.47 | wps 6018.3 | wpb 11799.1 | bsz 428.6 | num_updates 6403 | best_bleu 22.55
2020-12-20 13:36:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:36:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:36:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 19 @ 6403 updates, score 22.47) (writing took 2.7840339597314596 seconds)
2020-12-20 13:36:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-12-20 13:36:32 | INFO | train | epoch 019 | symm_kl 0.649 | self_kl 0 | self_cv 25.065 | loss 2.634 | nll_loss 0.764 | ppl 1.7 | wps 29567.6 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 6403 | lr 1.25e-05 | gnorm 1.168 | train_wall 176 | wall 3779
2020-12-20 13:36:32 | INFO | fairseq.trainer | begin training epoch 20
2020-12-20 13:36:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:36:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:37:26 | INFO | train_inner | epoch 020:     97 / 337 symm_kl=0.647, self_kl=0, self_cv=25.076, loss=2.631, nll_loss=0.765, ppl=1.7, wps=23431.1, ups=1.35, wpb=17395.2, bsz=613.9, num_updates=6500, lr=1.25e-05, gnorm=1.191, train_wall=52, wall=3833
2020-12-20 13:38:19 | INFO | train_inner | epoch 020:    197 / 337 symm_kl=0.644, self_kl=0, self_cv=25.111, loss=2.62, nll_loss=0.759, ppl=1.69, wps=33093.8, ups=1.89, wpb=17543.5, bsz=612, num_updates=6600, lr=1.25e-05, gnorm=1.14, train_wall=53, wall=3886
2020-12-20 13:39:12 | INFO | train_inner | epoch 020:    297 / 337 symm_kl=0.647, self_kl=0, self_cv=25.151, loss=2.628, nll_loss=0.766, ppl=1.7, wps=33047.2, ups=1.9, wpb=17412.4, bsz=626.1, num_updates=6700, lr=1.25e-05, gnorm=1.145, train_wall=53, wall=3939
2020-12-20 13:39:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:39:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:39:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:39:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:39:48 | INFO | valid | epoch 020 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.832 | nll_loss 4.156 | ppl 17.83 | bleu 22.55 | wps 6327.8 | wpb 11799.1 | bsz 428.6 | num_updates 6740 | best_bleu 22.55
2020-12-20 13:39:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:39:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:39:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 20 @ 6740 updates, score 22.55) (writing took 4.5899189207702875 seconds)
2020-12-20 13:39:53 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-12-20 13:39:53 | INFO | train | epoch 020 | symm_kl 0.646 | self_kl 0 | self_cv 25.127 | loss 2.625 | nll_loss 0.763 | ppl 1.7 | wps 29296.6 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 6740 | lr 1.25e-05 | gnorm 1.149 | train_wall 177 | wall 3980
2020-12-20 13:39:53 | INFO | fairseq.trainer | begin training epoch 21
2020-12-20 13:39:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:39:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:40:27 | INFO | train_inner | epoch 021:     60 / 337 symm_kl=0.648, self_kl=0, self_cv=25.307, loss=2.625, nll_loss=0.767, ppl=1.7, wps=22747.2, ups=1.33, wpb=17117, bsz=606.3, num_updates=6800, lr=1.25e-05, gnorm=1.175, train_wall=52, wall=4014
2020-12-20 13:41:20 | INFO | train_inner | epoch 021:    160 / 337 symm_kl=0.642, self_kl=0, self_cv=25.129, loss=2.615, nll_loss=0.76, ppl=1.69, wps=33175.9, ups=1.89, wpb=17590.5, bsz=615.6, num_updates=6900, lr=1.25e-05, gnorm=1.138, train_wall=53, wall=4067
2020-12-20 13:42:13 | INFO | train_inner | epoch 021:    260 / 337 symm_kl=0.639, self_kl=0, self_cv=25.162, loss=2.609, nll_loss=0.759, ppl=1.69, wps=33292.3, ups=1.9, wpb=17551.5, bsz=621, num_updates=7000, lr=1.25e-05, gnorm=1.131, train_wall=53, wall=4120
2020-12-20 13:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:43:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:43:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:43:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:43:08 | INFO | valid | epoch 021 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.832 | nll_loss 4.154 | ppl 17.8 | bleu 22.55 | wps 6416.3 | wpb 11799.1 | bsz 428.6 | num_updates 7077 | best_bleu 22.55
2020-12-20 13:43:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:43:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 21 @ 7077 updates, score 22.55) (writing took 4.593495726585388 seconds)
2020-12-20 13:43:13 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-12-20 13:43:13 | INFO | train | epoch 021 | symm_kl 0.644 | self_kl 0 | self_cv 25.201 | loss 2.619 | nll_loss 0.763 | ppl 1.7 | wps 29360.9 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 7077 | lr 1.25e-05 | gnorm 1.145 | train_wall 177 | wall 4180
2020-12-20 13:43:13 | INFO | fairseq.trainer | begin training epoch 22
2020-12-20 13:43:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:43:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:43:28 | INFO | train_inner | epoch 022:     23 / 337 symm_kl=0.646, self_kl=0, self_cv=25.247, loss=2.626, nll_loss=0.767, ppl=1.7, wps=23161.3, ups=1.33, wpb=17465.8, bsz=612.8, num_updates=7100, lr=1.25e-05, gnorm=1.155, train_wall=52, wall=4195
2020-12-20 13:44:20 | INFO | train_inner | epoch 022:    123 / 337 symm_kl=0.632, self_kl=0, self_cv=25.181, loss=2.595, nll_loss=0.756, ppl=1.69, wps=33522.3, ups=1.91, wpb=17537.7, bsz=626.4, num_updates=7200, lr=1.25e-05, gnorm=1.124, train_wall=52, wall=4247
2020-12-20 13:45:13 | INFO | train_inner | epoch 022:    223 / 337 symm_kl=0.646, self_kl=0, self_cv=25.314, loss=2.618, nll_loss=0.763, ppl=1.7, wps=33035.9, ups=1.89, wpb=17441, bsz=605.9, num_updates=7300, lr=1.25e-05, gnorm=1.162, train_wall=53, wall=4300
2020-12-20 13:46:06 | INFO | train_inner | epoch 022:    323 / 337 symm_kl=0.644, self_kl=0, self_cv=25.356, loss=2.616, nll_loss=0.766, ppl=1.7, wps=33186.9, ups=1.9, wpb=17474.5, bsz=612.3, num_updates=7400, lr=1.25e-05, gnorm=1.156, train_wall=52, wall=4353
2020-12-20 13:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:46:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:46:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:46:29 | INFO | valid | epoch 022 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.834 | nll_loss 4.154 | ppl 17.81 | bleu 22.49 | wps 6056.7 | wpb 11799.1 | bsz 428.6 | num_updates 7414 | best_bleu 22.55
2020-12-20 13:46:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:46:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 22 @ 7414 updates, score 22.49) (writing took 2.702410476282239 seconds)
2020-12-20 13:46:32 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-12-20 13:46:32 | INFO | train | epoch 022 | symm_kl 0.641 | self_kl 0 | self_cv 25.285 | loss 2.611 | nll_loss 0.762 | ppl 1.7 | wps 29614.8 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 7414 | lr 1.25e-05 | gnorm 1.15 | train_wall 176 | wall 4379
2020-12-20 13:46:32 | INFO | fairseq.trainer | begin training epoch 23
2020-12-20 13:46:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:46:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:47:20 | INFO | train_inner | epoch 023:     86 / 337 symm_kl=0.645, self_kl=0, self_cv=25.427, loss=2.617, nll_loss=0.767, ppl=1.7, wps=23506.1, ups=1.35, wpb=17357.8, bsz=597.6, num_updates=7500, lr=1.25e-05, gnorm=1.152, train_wall=52, wall=4427
2020-12-20 13:48:13 | INFO | train_inner | epoch 023:    186 / 337 symm_kl=0.643, self_kl=0, self_cv=25.37, loss=2.614, nll_loss=0.767, ppl=1.7, wps=32846.4, ups=1.89, wpb=17419.3, bsz=601.3, num_updates=7600, lr=1.25e-05, gnorm=1.148, train_wall=53, wall=4480
2020-12-20 13:49:06 | INFO | train_inner | epoch 023:    286 / 337 symm_kl=0.631, self_kl=0, self_cv=25.346, loss=2.587, nll_loss=0.755, ppl=1.69, wps=33040.6, ups=1.89, wpb=17511, bsz=626, num_updates=7700, lr=1.25e-05, gnorm=1.135, train_wall=53, wall=4533
2020-12-20 13:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:49:48 | INFO | valid | epoch 023 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.833 | nll_loss 4.155 | ppl 17.81 | bleu 22.59 | wps 6044.4 | wpb 11799.1 | bsz 428.6 | num_updates 7751 | best_bleu 22.59
2020-12-20 13:49:48 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:49:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 23 @ 7751 updates, score 22.59) (writing took 4.728542810305953 seconds)
2020-12-20 13:49:53 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-12-20 13:49:53 | INFO | train | epoch 023 | symm_kl 0.638 | self_kl 0 | self_cv 25.358 | loss 2.603 | nll_loss 0.762 | ppl 1.7 | wps 29203.4 | ups 1.67 | wpb 17451.5 | bsz 615.4 | num_updates 7751 | lr 1.25e-05 | gnorm 1.143 | train_wall 177 | wall 4580
2020-12-20 13:49:53 | INFO | fairseq.trainer | begin training epoch 24
2020-12-20 13:49:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:49:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:50:21 | INFO | train_inner | epoch 024:     49 / 337 symm_kl=0.632, self_kl=0, self_cv=25.325, loss=2.591, nll_loss=0.757, ppl=1.69, wps=22998, ups=1.32, wpb=17456.2, bsz=636, num_updates=7800, lr=1.25e-05, gnorm=1.142, train_wall=52, wall=4609
2020-12-20 13:51:14 | INFO | train_inner | epoch 024:    149 / 337 symm_kl=0.64, self_kl=0, self_cv=25.505, loss=2.601, nll_loss=0.76, ppl=1.69, wps=32953.2, ups=1.89, wpb=17459.2, bsz=606.2, num_updates=7900, lr=1.25e-05, gnorm=1.152, train_wall=53, wall=4662
2020-12-20 13:52:07 | INFO | train_inner | epoch 024:    249 / 337 symm_kl=0.637, self_kl=0, self_cv=25.496, loss=2.597, nll_loss=0.764, ppl=1.7, wps=33018.3, ups=1.91, wpb=17294.3, bsz=611.5, num_updates=8000, lr=1.25e-05, gnorm=1.145, train_wall=52, wall=4714
2020-12-20 13:52:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:53:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:53:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:53:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:53:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:53:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:53:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:53:09 | INFO | valid | epoch 024 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.836 | nll_loss 4.157 | ppl 17.84 | bleu 22.59 | wps 5980.2 | wpb 11799.1 | bsz 428.6 | num_updates 8088 | best_bleu 22.59
2020-12-20 13:53:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:53:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:53:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:53:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:53:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:53:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:53:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 24 @ 8088 updates, score 22.59) (writing took 4.686834203079343 seconds)
2020-12-20 13:53:14 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-12-20 13:53:14 | INFO | train | epoch 024 | symm_kl 0.636 | self_kl 0 | self_cv 25.43 | loss 2.597 | nll_loss 0.761 | ppl 1.69 | wps 29240.4 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 8088 | lr 1.25e-05 | gnorm 1.147 | train_wall 177 | wall 4781
2020-12-20 13:53:14 | INFO | fairseq.trainer | begin training epoch 25
2020-12-20 13:53:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:53:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:53:23 | INFO | train_inner | epoch 025:     12 / 337 symm_kl=0.633, self_kl=0, self_cv=25.327, loss=2.595, nll_loss=0.761, ppl=1.69, wps=22850.1, ups=1.31, wpb=17508.5, bsz=621.8, num_updates=8100, lr=1.25e-05, gnorm=1.149, train_wall=53, wall=4791
2020-12-20 13:54:15 | INFO | train_inner | epoch 025:    112 / 337 symm_kl=0.637, self_kl=0, self_cv=25.528, loss=2.595, nll_loss=0.76, ppl=1.69, wps=33706.1, ups=1.92, wpb=17531.4, bsz=603, num_updates=8200, lr=1.25e-05, gnorm=1.139, train_wall=52, wall=4843
2020-12-20 13:55:08 | INFO | train_inner | epoch 025:    212 / 337 symm_kl=0.631, self_kl=0, self_cv=25.536, loss=2.583, nll_loss=0.759, ppl=1.69, wps=33381.4, ups=1.91, wpb=17481.7, bsz=622.5, num_updates=8300, lr=1.25e-05, gnorm=1.128, train_wall=52, wall=4895
2020-12-20 13:56:00 | INFO | train_inner | epoch 025:    312 / 337 symm_kl=0.632, self_kl=0, self_cv=25.446, loss=2.591, nll_loss=0.764, ppl=1.7, wps=33506.1, ups=1.91, wpb=17552.6, bsz=628.3, num_updates=8400, lr=1.25e-05, gnorm=1.131, train_wall=52, wall=4947
2020-12-20 13:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:56:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:56:29 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.828 | nll_loss 4.15 | ppl 17.75 | bleu 22.63 | wps 6451.7 | wpb 11799.1 | bsz 428.6 | num_updates 8425 | best_bleu 22.63
2020-12-20 13:56:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:56:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:56:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 25 @ 8425 updates, score 22.63) (writing took 4.656361531466246 seconds)
2020-12-20 13:56:33 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-12-20 13:56:33 | INFO | train | epoch 025 | symm_kl 0.634 | self_kl 0 | self_cv 25.5 | loss 2.591 | nll_loss 0.761 | ppl 1.69 | wps 29525.5 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 8425 | lr 1.25e-05 | gnorm 1.138 | train_wall 176 | wall 4980
2020-12-20 13:56:33 | INFO | fairseq.trainer | begin training epoch 26
2020-12-20 13:56:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:56:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:57:15 | INFO | train_inner | epoch 026:     75 / 337 symm_kl=0.628, self_kl=0, self_cv=25.435, loss=2.574, nll_loss=0.752, ppl=1.68, wps=22901.3, ups=1.33, wpb=17208.8, bsz=625.8, num_updates=8500, lr=1.25e-05, gnorm=1.145, train_wall=52, wall=5023
2020-12-20 13:58:08 | INFO | train_inner | epoch 026:    175 / 337 symm_kl=0.631, self_kl=0, self_cv=25.605, loss=2.582, nll_loss=0.761, ppl=1.69, wps=33525.7, ups=1.91, wpb=17595.9, bsz=630.3, num_updates=8600, lr=1.25e-05, gnorm=1.125, train_wall=52, wall=5075
2020-12-20 13:59:01 | INFO | train_inner | epoch 026:    275 / 337 symm_kl=0.634, self_kl=0, self_cv=25.567, loss=2.591, nll_loss=0.763, ppl=1.7, wps=33122.8, ups=1.88, wpb=17589.5, bsz=608.2, num_updates=8700, lr=1.25e-05, gnorm=1.131, train_wall=53, wall=5128
2020-12-20 13:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 13:59:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 13:59:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 13:59:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 13:59:49 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.835 | nll_loss 4.156 | ppl 17.83 | bleu 22.35 | wps 6394.8 | wpb 11799.1 | bsz 428.6 | num_updates 8762 | best_bleu 22.63
2020-12-20 13:59:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 13:59:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 13:59:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 26 @ 8762 updates, score 22.35) (writing took 2.704017799347639 seconds)
2020-12-20 13:59:52 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-12-20 13:59:52 | INFO | train | epoch 026 | symm_kl 0.632 | self_kl 0 | self_cv 25.581 | loss 2.584 | nll_loss 0.76 | ppl 1.69 | wps 29645.7 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 8762 | lr 1.25e-05 | gnorm 1.137 | train_wall 177 | wall 5179
2020-12-20 13:59:52 | INFO | fairseq.trainer | begin training epoch 27
2020-12-20 13:59:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 13:59:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:00:15 | INFO | train_inner | epoch 027:     38 / 337 symm_kl=0.637, self_kl=0, self_cv=25.707, loss=2.596, nll_loss=0.769, ppl=1.7, wps=23422.5, ups=1.36, wpb=17266.5, bsz=587.5, num_updates=8800, lr=1.25e-05, gnorm=1.158, train_wall=52, wall=5202
2020-12-20 14:01:07 | INFO | train_inner | epoch 027:    138 / 337 symm_kl=0.638, self_kl=0, self_cv=25.701, loss=2.593, nll_loss=0.764, ppl=1.7, wps=33096.7, ups=1.9, wpb=17417.7, bsz=606.4, num_updates=8900, lr=1.25e-05, gnorm=1.151, train_wall=52, wall=5255
2020-12-20 14:02:00 | INFO | train_inner | epoch 027:    238 / 337 symm_kl=0.62, self_kl=0, self_cv=25.485, loss=2.563, nll_loss=0.753, ppl=1.69, wps=33426.5, ups=1.89, wpb=17686.9, bsz=636.9, num_updates=9000, lr=1.25e-05, gnorm=1.113, train_wall=53, wall=5307
2020-12-20 14:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:02:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:02:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:02:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:02:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:02:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:03:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:03:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:03:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:03:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:03:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:03:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:03:09 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.834 | nll_loss 4.153 | ppl 17.79 | bleu 22.54 | wps 5856.6 | wpb 11799.1 | bsz 428.6 | num_updates 9099 | best_bleu 22.63
2020-12-20 14:03:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:03:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:03:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:03:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:03:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:03:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:03:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:03:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:03:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:03:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 27 @ 9099 updates, score 22.54) (writing took 2.7501052655279636 seconds)
2020-12-20 14:03:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-12-20 14:03:11 | INFO | train | epoch 027 | symm_kl 0.63 | self_kl 0 | self_cv 25.659 | loss 2.578 | nll_loss 0.76 | ppl 1.69 | wps 29433.9 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 9099 | lr 1.25e-05 | gnorm 1.138 | train_wall 177 | wall 5379
2020-12-20 14:03:11 | INFO | fairseq.trainer | begin training epoch 28
2020-12-20 14:03:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:03:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:03:15 | INFO | train_inner | epoch 028:      1 / 337 symm_kl=0.63, self_kl=0, self_cv=25.783, loss=2.574, nll_loss=0.761, ppl=1.69, wps=22931.6, ups=1.33, wpb=17178.8, bsz=604.2, num_updates=9100, lr=1.25e-05, gnorm=1.154, train_wall=53, wall=5382
2020-12-20 14:04:08 | INFO | train_inner | epoch 028:    101 / 337 symm_kl=0.628, self_kl=0, self_cv=25.722, loss=2.568, nll_loss=0.756, ppl=1.69, wps=33203.9, ups=1.91, wpb=17385.9, bsz=604.2, num_updates=9200, lr=1.25e-05, gnorm=1.14, train_wall=52, wall=5435
2020-12-20 14:05:00 | INFO | train_inner | epoch 028:    201 / 337 symm_kl=0.624, self_kl=0, self_cv=25.698, loss=2.56, nll_loss=0.752, ppl=1.68, wps=33217.4, ups=1.89, wpb=17590.2, bsz=619.7, num_updates=9300, lr=1.25e-05, gnorm=1.126, train_wall=53, wall=5488
2020-12-20 14:05:53 | INFO | train_inner | epoch 028:    301 / 337 symm_kl=0.629, self_kl=0, self_cv=25.717, loss=2.581, nll_loss=0.769, ppl=1.7, wps=33155.4, ups=1.9, wpb=17477.9, bsz=627.3, num_updates=9400, lr=1.25e-05, gnorm=1.133, train_wall=53, wall=5540
2020-12-20 14:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:06:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:06:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:06:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:06:27 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.832 | nll_loss 4.152 | ppl 17.78 | bleu 22.5 | wps 6583.8 | wpb 11799.1 | bsz 428.6 | num_updates 9436 | best_bleu 22.63
2020-12-20 14:06:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:06:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 28 @ 9436 updates, score 22.5) (writing took 2.7935823015868664 seconds)
2020-12-20 14:06:30 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-12-20 14:06:30 | INFO | train | epoch 028 | symm_kl 0.628 | self_kl 0 | self_cv 25.722 | loss 2.572 | nll_loss 0.76 | ppl 1.69 | wps 29627.3 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 9436 | lr 1.25e-05 | gnorm 1.137 | train_wall 177 | wall 5577
2020-12-20 14:06:30 | INFO | fairseq.trainer | begin training epoch 29
2020-12-20 14:06:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:06:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:06:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:07:07 | INFO | train_inner | epoch 029:     64 / 337 symm_kl=0.628, self_kl=0, self_cv=25.761, loss=2.574, nll_loss=0.763, ppl=1.7, wps=23835.5, ups=1.36, wpb=17491.2, bsz=615.4, num_updates=9500, lr=1.25e-05, gnorm=1.137, train_wall=52, wall=5614
2020-12-20 14:07:59 | INFO | train_inner | epoch 029:    164 / 337 symm_kl=0.628, self_kl=0, self_cv=25.754, loss=2.57, nll_loss=0.758, ppl=1.69, wps=33348.8, ups=1.9, wpb=17593.4, bsz=609.3, num_updates=9600, lr=1.25e-05, gnorm=1.129, train_wall=53, wall=5667
2020-12-20 14:08:52 | INFO | train_inner | epoch 029:    264 / 337 symm_kl=0.623, self_kl=0, self_cv=25.838, loss=2.558, nll_loss=0.759, ppl=1.69, wps=32812, ups=1.9, wpb=17297.3, bsz=620.8, num_updates=9700, lr=1.25e-05, gnorm=1.135, train_wall=53, wall=5719
2020-12-20 14:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:09:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:09:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:09:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:09:46 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.834 | nll_loss 4.153 | ppl 17.79 | bleu 22.63 | wps 6580.8 | wpb 11799.1 | bsz 428.6 | num_updates 9773 | best_bleu 22.63
2020-12-20 14:09:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:09:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:09:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 29 @ 9773 updates, score 22.63) (writing took 4.573801312595606 seconds)
2020-12-20 14:09:51 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-12-20 14:09:51 | INFO | train | epoch 029 | symm_kl 0.625 | self_kl 0 | self_cv 25.797 | loss 2.564 | nll_loss 0.759 | ppl 1.69 | wps 29326 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 9773 | lr 1.25e-05 | gnorm 1.133 | train_wall 177 | wall 5778
2020-12-20 14:09:51 | INFO | fairseq.trainer | begin training epoch 30
2020-12-20 14:09:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:09:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:10:08 | INFO | train_inner | epoch 030:     27 / 337 symm_kl=0.623, self_kl=0, self_cv=25.818, loss=2.559, nll_loss=0.757, ppl=1.69, wps=22943.6, ups=1.32, wpb=17342.4, bsz=622, num_updates=9800, lr=1.25e-05, gnorm=1.139, train_wall=53, wall=5795
2020-12-20 14:11:00 | INFO | train_inner | epoch 030:    127 / 337 symm_kl=0.623, self_kl=0, self_cv=25.843, loss=2.559, nll_loss=0.76, ppl=1.69, wps=33058.2, ups=1.89, wpb=17449.4, bsz=609.1, num_updates=9900, lr=1.25e-05, gnorm=1.121, train_wall=53, wall=5848
2020-12-20 14:11:53 | INFO | train_inner | epoch 030:    227 / 337 symm_kl=0.628, self_kl=0, self_cv=25.885, loss=2.565, nll_loss=0.759, ppl=1.69, wps=33127.9, ups=1.89, wpb=17489.4, bsz=617.5, num_updates=10000, lr=1.25e-05, gnorm=1.129, train_wall=53, wall=5900
2020-12-20 14:12:46 | INFO | train_inner | epoch 030:    327 / 337 symm_kl=0.625, self_kl=0, self_cv=25.866, loss=2.564, nll_loss=0.761, ppl=1.7, wps=33139.8, ups=1.89, wpb=17512.5, bsz=610, num_updates=10100, lr=1.25e-05, gnorm=1.121, train_wall=53, wall=5953
2020-12-20 14:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:12:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:12:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:12:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:12:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:12:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:12:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:12:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:12:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:12:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:12:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:13:07 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.839 | nll_loss 4.158 | ppl 17.85 | bleu 22.56 | wps 6339.5 | wpb 11799.1 | bsz 428.6 | num_updates 10110 | best_bleu 22.63
2020-12-20 14:13:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:13:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 30 @ 10110 updates, score 22.56) (writing took 2.714486677199602 seconds)
2020-12-20 14:13:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-12-20 14:13:09 | INFO | train | epoch 030 | symm_kl 0.624 | self_kl 0 | self_cv 25.857 | loss 2.561 | nll_loss 0.759 | ppl 1.69 | wps 29568 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 10110 | lr 1.25e-05 | gnorm 1.129 | train_wall 177 | wall 5977
2020-12-20 14:13:09 | INFO | fairseq.trainer | begin training epoch 31
2020-12-20 14:13:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:13:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:14:00 | INFO | train_inner | epoch 031:     90 / 337 symm_kl=0.624, self_kl=0, self_cv=25.965, loss=2.557, nll_loss=0.758, ppl=1.69, wps=23714.7, ups=1.36, wpb=17427, bsz=612.2, num_updates=10200, lr=1.25e-05, gnorm=1.143, train_wall=52, wall=6027
2020-12-20 14:14:52 | INFO | train_inner | epoch 031:    190 / 337 symm_kl=0.623, self_kl=0, self_cv=25.916, loss=2.553, nll_loss=0.755, ppl=1.69, wps=33099.8, ups=1.9, wpb=17431.8, bsz=615.1, num_updates=10300, lr=1.25e-05, gnorm=1.128, train_wall=52, wall=6079
2020-12-20 14:15:45 | INFO | train_inner | epoch 031:    290 / 337 symm_kl=0.622, self_kl=0, self_cv=25.933, loss=2.552, nll_loss=0.756, ppl=1.69, wps=33187.4, ups=1.9, wpb=17510.4, bsz=610.6, num_updates=10400, lr=1.25e-05, gnorm=1.128, train_wall=53, wall=6132
2020-12-20 14:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:16:26 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.837 | nll_loss 4.155 | ppl 17.82 | bleu 22.57 | wps 6273.5 | wpb 11799.1 | bsz 428.6 | num_updates 10447 | best_bleu 22.63
2020-12-20 14:16:26 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:16:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 31 @ 10447 updates, score 22.57) (writing took 2.7363530807197094 seconds)
2020-12-20 14:16:28 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-12-20 14:16:28 | INFO | train | epoch 031 | symm_kl 0.622 | self_kl 0 | self_cv 25.943 | loss 2.554 | nll_loss 0.758 | ppl 1.69 | wps 29575.7 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 10447 | lr 1.25e-05 | gnorm 1.13 | train_wall 177 | wall 6175
2020-12-20 14:16:28 | INFO | fairseq.trainer | begin training epoch 32
2020-12-20 14:16:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:16:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:16:59 | INFO | train_inner | epoch 032:     53 / 337 symm_kl=0.621, self_kl=0, self_cv=26.106, loss=2.549, nll_loss=0.762, ppl=1.7, wps=23322.2, ups=1.35, wpb=17255.4, bsz=617, num_updates=10500, lr=1.25e-05, gnorm=1.138, train_wall=52, wall=6206
2020-12-20 14:17:52 | INFO | train_inner | epoch 032:    153 / 337 symm_kl=0.62, self_kl=0, self_cv=25.985, loss=2.546, nll_loss=0.755, ppl=1.69, wps=33465.7, ups=1.89, wpb=17660.6, bsz=609.2, num_updates=10600, lr=1.25e-05, gnorm=1.12, train_wall=53, wall=6259
2020-12-20 14:18:45 | INFO | train_inner | epoch 032:    253 / 337 symm_kl=0.624, self_kl=0, self_cv=26.019, loss=2.553, nll_loss=0.758, ppl=1.69, wps=33039.8, ups=1.89, wpb=17446.5, bsz=595.7, num_updates=10700, lr=1.25e-05, gnorm=1.135, train_wall=53, wall=6312
2020-12-20 14:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:19:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:19:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:19:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:19:44 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.837 | nll_loss 4.156 | ppl 17.82 | bleu 22.56 | wps 6215 | wpb 11799.1 | bsz 428.6 | num_updates 10784 | best_bleu 22.63
2020-12-20 14:19:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:19:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 32 @ 10784 updates, score 22.56) (writing took 2.7661704681813717 seconds)
2020-12-20 14:19:47 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-12-20 14:19:47 | INFO | train | epoch 032 | symm_kl 0.621 | self_kl 0 | self_cv 26.013 | loss 2.548 | nll_loss 0.758 | ppl 1.69 | wps 29577.2 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 10784 | lr 1.25e-05 | gnorm 1.128 | train_wall 177 | wall 6374
2020-12-20 14:19:47 | INFO | fairseq.trainer | begin training epoch 33
2020-12-20 14:19:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:19:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:19:58 | INFO | train_inner | epoch 033:     16 / 337 symm_kl=0.618, self_kl=0, self_cv=25.96, loss=2.552, nll_loss=0.764, ppl=1.7, wps=23424.2, ups=1.35, wpb=17324.8, bsz=646.4, num_updates=10800, lr=1.25e-05, gnorm=1.13, train_wall=52, wall=6386
2020-12-20 14:20:51 | INFO | train_inner | epoch 033:    116 / 337 symm_kl=0.613, self_kl=0, self_cv=25.994, loss=2.533, nll_loss=0.751, ppl=1.68, wps=33433.5, ups=1.91, wpb=17530, bsz=632.3, num_updates=10900, lr=1.25e-05, gnorm=1.105, train_wall=52, wall=6438
2020-12-20 14:21:44 | INFO | train_inner | epoch 033:    216 / 337 symm_kl=0.618, self_kl=0, self_cv=26.103, loss=2.54, nll_loss=0.757, ppl=1.69, wps=33053.3, ups=1.89, wpb=17512.1, bsz=621.3, num_updates=11000, lr=1.25e-05, gnorm=1.114, train_wall=53, wall=6491
2020-12-20 14:22:37 | INFO | train_inner | epoch 033:    316 / 337 symm_kl=0.628, self_kl=0, self_cv=26.244, loss=2.555, nll_loss=0.762, ppl=1.7, wps=32866.7, ups=1.9, wpb=17340, bsz=594.1, num_updates=11100, lr=1.25e-05, gnorm=1.148, train_wall=53, wall=6544
2020-12-20 14:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:22:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:22:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:22:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:22:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:22:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:23:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:23:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:23:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:23:04 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.843 | nll_loss 4.161 | ppl 17.89 | bleu 22.57 | wps 5861.4 | wpb 11799.1 | bsz 428.6 | num_updates 11121 | best_bleu 22.63
2020-12-20 14:23:04 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:23:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:23:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:23:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:23:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:23:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:23:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 33 @ 11121 updates, score 22.57) (writing took 2.7504794355481863 seconds)
2020-12-20 14:23:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-12-20 14:23:07 | INFO | train | epoch 033 | symm_kl 0.619 | self_kl 0 | self_cv 26.094 | loss 2.543 | nll_loss 0.757 | ppl 1.69 | wps 29448.1 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 11121 | lr 1.25e-05 | gnorm 1.126 | train_wall 177 | wall 6574
2020-12-20 14:23:07 | INFO | fairseq.trainer | begin training epoch 34
2020-12-20 14:23:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:23:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:23:51 | INFO | train_inner | epoch 034:     79 / 337 symm_kl=0.618, self_kl=0, self_cv=26.034, loss=2.546, nll_loss=0.759, ppl=1.69, wps=23430.9, ups=1.34, wpb=17463.9, bsz=629.8, num_updates=11200, lr=1.25e-05, gnorm=1.132, train_wall=52, wall=6618
2020-12-20 14:24:44 | INFO | train_inner | epoch 034:    179 / 337 symm_kl=0.622, self_kl=0, self_cv=26.186, loss=2.547, nll_loss=0.761, ppl=1.69, wps=33176.9, ups=1.9, wpb=17467.7, bsz=612, num_updates=11300, lr=1.25e-05, gnorm=1.129, train_wall=52, wall=6671
2020-12-20 14:25:37 | INFO | train_inner | epoch 034:    279 / 337 symm_kl=0.606, self_kl=0, self_cv=25.978, loss=2.514, nll_loss=0.745, ppl=1.68, wps=33173.1, ups=1.89, wpb=17533.2, bsz=630.6, num_updates=11400, lr=1.25e-05, gnorm=1.105, train_wall=53, wall=6724
2020-12-20 14:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:26:23 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.84 | nll_loss 4.159 | ppl 17.87 | bleu 22.43 | wps 6313.5 | wpb 11799.1 | bsz 428.6 | num_updates 11458 | best_bleu 22.63
2020-12-20 14:26:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:26:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 34 @ 11458 updates, score 22.43) (writing took 2.7362328730523586 seconds)
2020-12-20 14:26:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-12-20 14:26:26 | INFO | train | epoch 034 | symm_kl 0.618 | self_kl 0 | self_cv 26.146 | loss 2.539 | nll_loss 0.757 | ppl 1.69 | wps 29567.2 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 11458 | lr 1.25e-05 | gnorm 1.125 | train_wall 177 | wall 6773
2020-12-20 14:26:26 | INFO | fairseq.trainer | begin training epoch 35
2020-12-20 14:26:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:26:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:26:51 | INFO | train_inner | epoch 035:     42 / 337 symm_kl=0.618, self_kl=0, self_cv=26.357, loss=2.531, nll_loss=0.759, ppl=1.69, wps=23385.9, ups=1.35, wpb=17319.6, bsz=586.6, num_updates=11500, lr=1.25e-05, gnorm=1.135, train_wall=53, wall=6798
2020-12-20 14:27:44 | INFO | train_inner | epoch 035:    142 / 337 symm_kl=0.615, self_kl=0, self_cv=26.111, loss=2.532, nll_loss=0.754, ppl=1.69, wps=33099.1, ups=1.89, wpb=17486, bsz=624.4, num_updates=11600, lr=1.25e-05, gnorm=1.121, train_wall=53, wall=6851
2020-12-20 14:28:36 | INFO | train_inner | epoch 035:    242 / 337 symm_kl=0.62, self_kl=0, self_cv=26.3, loss=2.539, nll_loss=0.761, ppl=1.7, wps=33367.4, ups=1.89, wpb=17610, bsz=611.8, num_updates=11700, lr=1.25e-05, gnorm=1.128, train_wall=53, wall=6904
2020-12-20 14:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:29:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:29:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:29:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:29:41 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.844 | nll_loss 4.16 | ppl 17.87 | bleu 22.54 | wps 6413 | wpb 11799.1 | bsz 428.6 | num_updates 11795 | best_bleu 22.63
2020-12-20 14:29:41 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:29:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 35 @ 11795 updates, score 22.54) (writing took 2.7352982237935066 seconds)
2020-12-20 14:29:44 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-12-20 14:29:44 | INFO | train | epoch 035 | symm_kl 0.617 | self_kl 0 | self_cv 26.245 | loss 2.533 | nll_loss 0.758 | ppl 1.69 | wps 29653.8 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 11795 | lr 1.25e-05 | gnorm 1.128 | train_wall 177 | wall 6971
2020-12-20 14:29:44 | INFO | fairseq.trainer | begin training epoch 36
2020-12-20 14:29:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:29:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:29:50 | INFO | train_inner | epoch 036:      5 / 337 symm_kl=0.621, self_kl=0, self_cv=26.338, loss=2.543, nll_loss=0.763, ppl=1.7, wps=23433.1, ups=1.36, wpb=17218.6, bsz=611.6, num_updates=11800, lr=1.25e-05, gnorm=1.147, train_wall=52, wall=6977
2020-12-20 14:30:42 | INFO | train_inner | epoch 036:    105 / 337 symm_kl=0.617, self_kl=0, self_cv=26.356, loss=2.528, nll_loss=0.754, ppl=1.69, wps=33305.8, ups=1.92, wpb=17350, bsz=597, num_updates=11900, lr=1.25e-05, gnorm=1.128, train_wall=52, wall=7029
2020-12-20 14:31:35 | INFO | train_inner | epoch 036:    205 / 337 symm_kl=0.612, self_kl=0, self_cv=26.332, loss=2.521, nll_loss=0.755, ppl=1.69, wps=33241.9, ups=1.89, wpb=17563.2, bsz=637.4, num_updates=12000, lr=1.25e-05, gnorm=1.111, train_wall=53, wall=7082
2020-12-20 14:32:28 | INFO | train_inner | epoch 036:    305 / 337 symm_kl=0.609, self_kl=0, self_cv=26.137, loss=2.519, nll_loss=0.752, ppl=1.68, wps=33414.8, ups=1.88, wpb=17749.4, bsz=624.2, num_updates=12100, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=7135
2020-12-20 14:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:32:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:32:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:32:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:32:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:32:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:33:01 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.845 | nll_loss 4.163 | ppl 17.92 | bleu 22.55 | wps 5776.3 | wpb 11799.1 | bsz 428.6 | num_updates 12132 | best_bleu 22.63
2020-12-20 14:33:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:33:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:33:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:33:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:33:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:33:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:33:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:33:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:33:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:33:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 36 @ 12132 updates, score 22.55) (writing took 2.760610507801175 seconds)
2020-12-20 14:33:04 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-12-20 14:33:04 | INFO | train | epoch 036 | symm_kl 0.615 | self_kl 0 | self_cv 26.314 | loss 2.527 | nll_loss 0.757 | ppl 1.69 | wps 29408.5 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 12132 | lr 1.25e-05 | gnorm 1.124 | train_wall 177 | wall 7171
2020-12-20 14:33:04 | INFO | fairseq.trainer | begin training epoch 37
2020-12-20 14:33:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:33:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:33:43 | INFO | train_inner | epoch 037:     68 / 337 symm_kl=0.624, self_kl=0, self_cv=26.525, loss=2.541, nll_loss=0.765, ppl=1.7, wps=22929.8, ups=1.34, wpb=17133.2, bsz=589.4, num_updates=12200, lr=1.25e-05, gnorm=1.154, train_wall=52, wall=7210
2020-12-20 14:34:35 | INFO | train_inner | epoch 037:    168 / 337 symm_kl=0.613, self_kl=0, self_cv=26.476, loss=2.516, nll_loss=0.755, ppl=1.69, wps=33172.2, ups=1.9, wpb=17485.2, bsz=607.8, num_updates=12300, lr=1.25e-05, gnorm=1.122, train_wall=53, wall=7263
2020-12-20 14:35:28 | INFO | train_inner | epoch 037:    268 / 337 symm_kl=0.612, self_kl=0, self_cv=26.322, loss=2.522, nll_loss=0.755, ppl=1.69, wps=33118.9, ups=1.88, wpb=17570.1, bsz=627.8, num_updates=12400, lr=1.25e-05, gnorm=1.107, train_wall=53, wall=7316
2020-12-20 14:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:36:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:36:21 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.843 | nll_loss 4.161 | ppl 17.89 | bleu 22.62 | wps 5590.6 | wpb 11799.1 | bsz 428.6 | num_updates 12469 | best_bleu 22.63
2020-12-20 14:36:21 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:36:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 37 @ 12469 updates, score 22.62) (writing took 2.8042353317141533 seconds)
2020-12-20 14:36:24 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-12-20 14:36:24 | INFO | train | epoch 037 | symm_kl 0.614 | self_kl 0 | self_cv 26.39 | loss 2.522 | nll_loss 0.756 | ppl 1.69 | wps 29386.5 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 12469 | lr 1.25e-05 | gnorm 1.121 | train_wall 177 | wall 7371
2020-12-20 14:36:24 | INFO | fairseq.trainer | begin training epoch 38
2020-12-20 14:36:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:36:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:36:43 | INFO | train_inner | epoch 038:     31 / 337 symm_kl=0.612, self_kl=0, self_cv=26.41, loss=2.519, nll_loss=0.757, ppl=1.69, wps=23003.6, ups=1.34, wpb=17222.7, bsz=615.8, num_updates=12500, lr=1.25e-05, gnorm=1.131, train_wall=52, wall=7390
2020-12-20 14:37:36 | INFO | train_inner | epoch 038:    131 / 337 symm_kl=0.615, self_kl=0, self_cv=26.483, loss=2.521, nll_loss=0.758, ppl=1.69, wps=33197.6, ups=1.91, wpb=17425.3, bsz=630.2, num_updates=12600, lr=1.25e-05, gnorm=1.134, train_wall=52, wall=7443
2020-12-20 14:38:28 | INFO | train_inner | epoch 038:    231 / 337 symm_kl=0.61, self_kl=0, self_cv=26.304, loss=2.517, nll_loss=0.754, ppl=1.69, wps=33519.6, ups=1.9, wpb=17675.7, bsz=614.7, num_updates=12700, lr=1.25e-05, gnorm=1.114, train_wall=53, wall=7496
2020-12-20 14:39:21 | INFO | train_inner | epoch 038:    331 / 337 symm_kl=0.614, self_kl=0, self_cv=26.521, loss=2.518, nll_loss=0.758, ppl=1.69, wps=33237.7, ups=1.9, wpb=17471.2, bsz=610.6, num_updates=12800, lr=1.25e-05, gnorm=1.112, train_wall=52, wall=7548
2020-12-20 14:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:39:40 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.846 | nll_loss 4.163 | ppl 17.91 | bleu 22.74 | wps 6328.6 | wpb 11799.1 | bsz 428.6 | num_updates 12806 | best_bleu 22.74
2020-12-20 14:39:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:39:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:39:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 38 @ 12806 updates, score 22.74) (writing took 4.607652366161346 seconds)
2020-12-20 14:39:44 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-12-20 14:39:44 | INFO | train | epoch 038 | symm_kl 0.613 | self_kl 0 | self_cv 26.458 | loss 2.517 | nll_loss 0.756 | ppl 1.69 | wps 29403.1 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 12806 | lr 1.25e-05 | gnorm 1.126 | train_wall 176 | wall 7571
2020-12-20 14:39:44 | INFO | fairseq.trainer | begin training epoch 39
2020-12-20 14:39:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:39:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:40:36 | INFO | train_inner | epoch 039:     94 / 337 symm_kl=0.608, self_kl=0, self_cv=26.329, loss=2.513, nll_loss=0.753, ppl=1.69, wps=23071.4, ups=1.33, wpb=17340.4, bsz=616.3, num_updates=12900, lr=1.25e-05, gnorm=1.129, train_wall=52, wall=7623
2020-12-20 14:41:29 | INFO | train_inner | epoch 039:    194 / 337 symm_kl=0.608, self_kl=0, self_cv=26.52, loss=2.503, nll_loss=0.75, ppl=1.68, wps=33111, ups=1.89, wpb=17559.9, bsz=624.1, num_updates=13000, lr=1.25e-05, gnorm=1.107, train_wall=53, wall=7676
2020-12-20 14:42:22 | INFO | train_inner | epoch 039:    294 / 337 symm_kl=0.613, self_kl=0, self_cv=26.673, loss=2.515, nll_loss=0.761, ppl=1.69, wps=33109.7, ups=1.89, wpb=17501, bsz=614.3, num_updates=13100, lr=1.25e-05, gnorm=1.119, train_wall=53, wall=7729
2020-12-20 14:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:43:01 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.846 | nll_loss 4.163 | ppl 17.92 | bleu 22.68 | wps 6284.1 | wpb 11799.1 | bsz 428.6 | num_updates 13143 | best_bleu 22.74
2020-12-20 14:43:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:43:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:43:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:43:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:43:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:43:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:43:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:43:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:43:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:43:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 39 @ 13143 updates, score 22.68) (writing took 2.6893120482563972 seconds)
2020-12-20 14:43:03 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-12-20 14:43:03 | INFO | train | epoch 039 | symm_kl 0.611 | self_kl 0 | self_cv 26.537 | loss 2.512 | nll_loss 0.755 | ppl 1.69 | wps 29553 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 13143 | lr 1.25e-05 | gnorm 1.121 | train_wall 177 | wall 7770
2020-12-20 14:43:03 | INFO | fairseq.trainer | begin training epoch 40
2020-12-20 14:43:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:43:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:43:36 | INFO | train_inner | epoch 040:     57 / 337 symm_kl=0.62, self_kl=0, self_cv=26.773, loss=2.519, nll_loss=0.758, ppl=1.69, wps=23288.7, ups=1.35, wpb=17236.6, bsz=576.6, num_updates=13200, lr=1.25e-05, gnorm=1.151, train_wall=52, wall=7803
2020-12-20 14:44:29 | INFO | train_inner | epoch 040:    157 / 337 symm_kl=0.606, self_kl=0, self_cv=26.478, loss=2.504, nll_loss=0.755, ppl=1.69, wps=33003.5, ups=1.89, wpb=17472.2, bsz=635.2, num_updates=13300, lr=1.25e-05, gnorm=1.115, train_wall=53, wall=7856
2020-12-20 14:45:22 | INFO | train_inner | epoch 040:    257 / 337 symm_kl=0.608, self_kl=0, self_cv=26.642, loss=2.502, nll_loss=0.754, ppl=1.69, wps=33063.9, ups=1.88, wpb=17617.3, bsz=614.7, num_updates=13400, lr=1.25e-05, gnorm=1.12, train_wall=53, wall=7910
2020-12-20 14:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:46:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:46:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:46:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:46:20 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.848 | nll_loss 4.165 | ppl 17.94 | bleu 22.73 | wps 6365.8 | wpb 11799.1 | bsz 428.6 | num_updates 13480 | best_bleu 22.74
2020-12-20 14:46:20 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:46:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 40 @ 13480 updates, score 22.73) (writing took 2.788417963311076 seconds)
2020-12-20 14:46:23 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-12-20 14:46:23 | INFO | train | epoch 040 | symm_kl 0.61 | self_kl 0 | self_cv 26.621 | loss 2.507 | nll_loss 0.755 | ppl 1.69 | wps 29459.2 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 13480 | lr 1.25e-05 | gnorm 1.129 | train_wall 178 | wall 7970
2020-12-20 14:46:23 | INFO | fairseq.trainer | begin training epoch 41
2020-12-20 14:46:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:46:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:46:36 | INFO | train_inner | epoch 041:     20 / 337 symm_kl=0.609, self_kl=0, self_cv=26.663, loss=2.505, nll_loss=0.757, ppl=1.69, wps=23446.2, ups=1.35, wpb=17354.4, bsz=626.8, num_updates=13500, lr=1.25e-05, gnorm=1.14, train_wall=53, wall=7984
2020-12-20 14:47:29 | INFO | train_inner | epoch 041:    120 / 337 symm_kl=0.607, self_kl=0, self_cv=26.732, loss=2.497, nll_loss=0.755, ppl=1.69, wps=33360.7, ups=1.91, wpb=17489.4, bsz=602.9, num_updates=13600, lr=1.25e-05, gnorm=1.111, train_wall=52, wall=8036
2020-12-20 14:48:21 | INFO | train_inner | epoch 041:    220 / 337 symm_kl=0.602, self_kl=0, self_cv=26.484, loss=2.497, nll_loss=0.753, ppl=1.69, wps=33393.1, ups=1.91, wpb=17480.3, bsz=646.3, num_updates=13700, lr=1.25e-05, gnorm=1.101, train_wall=52, wall=8088
2020-12-20 14:49:14 | INFO | train_inner | epoch 041:    320 / 337 symm_kl=0.615, self_kl=0, self_cv=26.862, loss=2.51, nll_loss=0.76, ppl=1.69, wps=33058.2, ups=1.9, wpb=17395.3, bsz=598.1, num_updates=13800, lr=1.25e-05, gnorm=1.126, train_wall=52, wall=8141
2020-12-20 14:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:49:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:49:38 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.853 | nll_loss 4.169 | ppl 17.99 | bleu 22.58 | wps 6371.3 | wpb 11799.1 | bsz 428.6 | num_updates 13817 | best_bleu 22.74
2020-12-20 14:49:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:49:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 41 @ 13817 updates, score 22.58) (writing took 2.7790552992373705 seconds)
2020-12-20 14:49:41 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2020-12-20 14:49:41 | INFO | train | epoch 041 | symm_kl 0.608 | self_kl 0 | self_cv 26.697 | loss 2.5 | nll_loss 0.755 | ppl 1.69 | wps 29692.2 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 13817 | lr 1.25e-05 | gnorm 1.115 | train_wall 176 | wall 8168
2020-12-20 14:49:41 | INFO | fairseq.trainer | begin training epoch 42
2020-12-20 14:49:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:49:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:50:27 | INFO | train_inner | epoch 042:     83 / 337 symm_kl=0.604, self_kl=0, self_cv=26.725, loss=2.489, nll_loss=0.75, ppl=1.68, wps=23574, ups=1.36, wpb=17366, bsz=596.6, num_updates=13900, lr=1.25e-05, gnorm=1.133, train_wall=52, wall=8215
2020-12-20 14:51:20 | INFO | train_inner | epoch 042:    183 / 337 symm_kl=0.608, self_kl=0, self_cv=26.756, loss=2.5, nll_loss=0.755, ppl=1.69, wps=33226.9, ups=1.9, wpb=17532, bsz=625.7, num_updates=14000, lr=1.25e-05, gnorm=1.115, train_wall=53, wall=8267
2020-12-20 14:52:13 | INFO | train_inner | epoch 042:    283 / 337 symm_kl=0.608, self_kl=0, self_cv=26.786, loss=2.495, nll_loss=0.754, ppl=1.69, wps=33320, ups=1.9, wpb=17558.7, bsz=621.2, num_updates=14100, lr=1.25e-05, gnorm=1.117, train_wall=53, wall=8320
2020-12-20 14:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:52:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:52:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:52:58 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.848 | nll_loss 4.165 | ppl 17.94 | bleu 22.58 | wps 5770.3 | wpb 11799.1 | bsz 428.6 | num_updates 14154 | best_bleu 22.74
2020-12-20 14:52:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:53:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:53:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:53:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:53:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:53:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 42 @ 14154 updates, score 22.58) (writing took 2.7399391252547503 seconds)
2020-12-20 14:53:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2020-12-20 14:53:01 | INFO | train | epoch 042 | symm_kl 0.608 | self_kl 0 | self_cv 26.77 | loss 2.497 | nll_loss 0.755 | ppl 1.69 | wps 29445 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 14154 | lr 1.25e-05 | gnorm 1.122 | train_wall 177 | wall 8368
2020-12-20 14:53:01 | INFO | fairseq.trainer | begin training epoch 43
2020-12-20 14:53:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:53:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:53:28 | INFO | train_inner | epoch 043:     46 / 337 symm_kl=0.604, self_kl=0, self_cv=26.813, loss=2.489, nll_loss=0.753, ppl=1.69, wps=23155.3, ups=1.34, wpb=17306.7, bsz=617.6, num_updates=14200, lr=1.25e-05, gnorm=1.132, train_wall=52, wall=8395
2020-12-20 14:54:20 | INFO | train_inner | epoch 043:    146 / 337 symm_kl=0.612, self_kl=0, self_cv=26.937, loss=2.499, nll_loss=0.757, ppl=1.69, wps=33071.3, ups=1.9, wpb=17366.2, bsz=595.4, num_updates=14300, lr=1.25e-05, gnorm=1.135, train_wall=52, wall=8447
2020-12-20 14:55:13 | INFO | train_inner | epoch 043:    246 / 337 symm_kl=0.608, self_kl=0, self_cv=26.927, loss=2.495, nll_loss=0.758, ppl=1.69, wps=33232.8, ups=1.89, wpb=17558.1, bsz=631.8, num_updates=14400, lr=1.25e-05, gnorm=1.118, train_wall=53, wall=8500
2020-12-20 14:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:56:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:56:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:56:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:56:17 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.853 | nll_loss 4.169 | ppl 17.99 | bleu 22.74 | wps 6005.3 | wpb 11799.1 | bsz 428.6 | num_updates 14491 | best_bleu 22.74
2020-12-20 14:56:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:56:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 43 @ 14491 updates, score 22.74) (writing took 4.632176201790571 seconds)
2020-12-20 14:56:22 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2020-12-20 14:56:22 | INFO | train | epoch 043 | symm_kl 0.607 | self_kl 0 | self_cv 26.872 | loss 2.492 | nll_loss 0.755 | ppl 1.69 | wps 29252.1 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 14491 | lr 1.25e-05 | gnorm 1.137 | train_wall 177 | wall 8569
2020-12-20 14:56:22 | INFO | fairseq.trainer | begin training epoch 44
2020-12-20 14:56:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:56:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:56:30 | INFO | train_inner | epoch 044:      9 / 337 symm_kl=0.607, self_kl=0, self_cv=26.812, loss=2.494, nll_loss=0.754, ppl=1.69, wps=22695.7, ups=1.31, wpb=17377.5, bsz=615.1, num_updates=14500, lr=1.25e-05, gnorm=1.164, train_wall=53, wall=8577
2020-12-20 14:57:22 | INFO | train_inner | epoch 044:    109 / 337 symm_kl=0.601, self_kl=0, self_cv=26.968, loss=2.472, nll_loss=0.747, ppl=1.68, wps=33550.8, ups=1.92, wpb=17505.3, bsz=615.8, num_updates=14600, lr=1.25e-05, gnorm=1.17, train_wall=52, wall=8629
2020-12-20 14:58:15 | INFO | train_inner | epoch 044:    209 / 337 symm_kl=0.596, self_kl=0, self_cv=26.764, loss=2.468, nll_loss=0.744, ppl=1.67, wps=33156.8, ups=1.89, wpb=17514.4, bsz=636.1, num_updates=14700, lr=1.25e-05, gnorm=1.113, train_wall=53, wall=8682
2020-12-20 14:59:07 | INFO | train_inner | epoch 044:    309 / 337 symm_kl=0.617, self_kl=0, self_cv=27.097, loss=2.511, nll_loss=0.767, ppl=1.7, wps=33350.9, ups=1.91, wpb=17503, bsz=601.6, num_updates=14800, lr=1.25e-05, gnorm=1.116, train_wall=52, wall=8734
2020-12-20 14:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 14:59:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 14:59:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 14:59:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 14:59:38 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.852 | nll_loss 4.168 | ppl 17.98 | bleu 22.58 | wps 5983.4 | wpb 11799.1 | bsz 428.6 | num_updates 14828 | best_bleu 22.74
2020-12-20 14:59:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 14:59:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 14:59:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 44 @ 14828 updates, score 22.58) (writing took 2.740260861814022 seconds)
2020-12-20 14:59:41 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2020-12-20 14:59:41 | INFO | train | epoch 044 | symm_kl 0.606 | self_kl 0 | self_cv 26.958 | loss 2.487 | nll_loss 0.755 | ppl 1.69 | wps 29569.1 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 14828 | lr 1.25e-05 | gnorm 1.135 | train_wall 176 | wall 8768
2020-12-20 14:59:41 | INFO | fairseq.trainer | begin training epoch 45
2020-12-20 14:59:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 14:59:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:00:22 | INFO | train_inner | epoch 045:     72 / 337 symm_kl=0.606, self_kl=0, self_cv=27.074, loss=2.488, nll_loss=0.762, ppl=1.7, wps=23146.7, ups=1.34, wpb=17252.4, bsz=610, num_updates=14900, lr=1.25e-05, gnorm=1.115, train_wall=52, wall=8809
2020-12-20 15:01:15 | INFO | train_inner | epoch 045:    172 / 337 symm_kl=0.607, self_kl=0, self_cv=27.001, loss=2.488, nll_loss=0.755, ppl=1.69, wps=32928.9, ups=1.88, wpb=17525.6, bsz=618.3, num_updates=15000, lr=1.25e-05, gnorm=1.109, train_wall=53, wall=8862
2020-12-20 15:02:08 | INFO | train_inner | epoch 045:    272 / 337 symm_kl=0.607, self_kl=0, self_cv=27.06, loss=2.483, nll_loss=0.754, ppl=1.69, wps=33143.3, ups=1.89, wpb=17499.9, bsz=617.5, num_updates=15100, lr=1.25e-05, gnorm=1.127, train_wall=53, wall=8915
2020-12-20 15:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:02:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:02:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:02:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:02:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:02:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:02:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:02:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:02:57 | INFO | valid | epoch 045 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.855 | nll_loss 4.171 | ppl 18.02 | bleu 22.73 | wps 6388.6 | wpb 11799.1 | bsz 428.6 | num_updates 15165 | best_bleu 22.74
2020-12-20 15:02:57 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:02:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:02:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:03:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:03:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:03:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:03:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:03:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 45 @ 15165 updates, score 22.73) (writing took 2.7914759404957294 seconds)
2020-12-20 15:03:00 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2020-12-20 15:03:00 | INFO | train | epoch 045 | symm_kl 0.604 | self_kl 0 | self_cv 27.045 | loss 2.48 | nll_loss 0.754 | ppl 1.69 | wps 29496.9 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 15165 | lr 1.25e-05 | gnorm 1.121 | train_wall 178 | wall 8967
2020-12-20 15:03:00 | INFO | fairseq.trainer | begin training epoch 46
2020-12-20 15:03:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:03:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:03:21 | INFO | train_inner | epoch 046:     35 / 337 symm_kl=0.601, self_kl=0, self_cv=26.981, loss=2.473, nll_loss=0.748, ppl=1.68, wps=23720.7, ups=1.36, wpb=17489.9, bsz=603.6, num_updates=15200, lr=1.25e-05, gnorm=1.138, train_wall=52, wall=8988
2020-12-20 15:04:14 | INFO | train_inner | epoch 046:    135 / 337 symm_kl=0.599, self_kl=0, self_cv=27.128, loss=2.466, nll_loss=0.752, ppl=1.68, wps=32900.8, ups=1.9, wpb=17351.6, bsz=626.7, num_updates=15300, lr=1.25e-05, gnorm=1.11, train_wall=53, wall=9041
2020-12-20 15:05:07 | INFO | train_inner | epoch 046:    235 / 337 symm_kl=0.607, self_kl=0, self_cv=27.25, loss=2.478, nll_loss=0.755, ppl=1.69, wps=33302.9, ups=1.89, wpb=17643.4, bsz=616.5, num_updates=15400, lr=1.25e-05, gnorm=1.151, train_wall=53, wall=9094
2020-12-20 15:06:00 | INFO | train_inner | epoch 046:    335 / 337 symm_kl=0.602, self_kl=0, self_cv=27.146, loss=2.475, nll_loss=0.757, ppl=1.69, wps=33169.8, ups=1.91, wpb=17410.3, bsz=612.5, num_updates=15500, lr=1.25e-05, gnorm=1.123, train_wall=52, wall=9147
2020-12-20 15:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:06:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:06:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:06:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:06:17 | INFO | valid | epoch 046 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.856 | nll_loss 4.173 | ppl 18.04 | bleu 22.64 | wps 5617.5 | wpb 11799.1 | bsz 428.6 | num_updates 15502 | best_bleu 22.74
2020-12-20 15:06:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:06:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:06:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 46 @ 15502 updates, score 22.64) (writing took 2.7354475148022175 seconds)
2020-12-20 15:06:20 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2020-12-20 15:06:20 | INFO | train | epoch 046 | symm_kl 0.603 | self_kl 0 | self_cv 27.14 | loss 2.474 | nll_loss 0.754 | ppl 1.69 | wps 29389.8 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 15502 | lr 1.25e-05 | gnorm 1.13 | train_wall 177 | wall 9167
2020-12-20 15:06:20 | INFO | fairseq.trainer | begin training epoch 47
2020-12-20 15:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:06:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:07:14 | INFO | train_inner | epoch 047:     98 / 337 symm_kl=0.608, self_kl=0, self_cv=27.167, loss=2.484, nll_loss=0.756, ppl=1.69, wps=23212.5, ups=1.33, wpb=17388.9, bsz=586.5, num_updates=15600, lr=1.25e-05, gnorm=1.131, train_wall=52, wall=9222
2020-12-20 15:08:07 | INFO | train_inner | epoch 047:    198 / 337 symm_kl=0.598, self_kl=0, self_cv=27.313, loss=2.458, nll_loss=0.752, ppl=1.68, wps=33295.7, ups=1.9, wpb=17553.7, bsz=627.4, num_updates=15700, lr=1.25e-05, gnorm=1.115, train_wall=53, wall=9274
2020-12-20 15:09:00 | INFO | train_inner | epoch 047:    298 / 337 symm_kl=0.598, self_kl=0, self_cv=27.109, loss=2.462, nll_loss=0.748, ppl=1.68, wps=33095, ups=1.9, wpb=17460.6, bsz=633.1, num_updates=15800, lr=1.25e-05, gnorm=1.112, train_wall=53, wall=9327
2020-12-20 15:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:09:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:09:36 | INFO | valid | epoch 047 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.862 | nll_loss 4.177 | ppl 18.09 | bleu 22.72 | wps 6447.7 | wpb 11799.1 | bsz 428.6 | num_updates 15839 | best_bleu 22.74
2020-12-20 15:09:36 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:09:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:09:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 47 @ 15839 updates, score 22.72) (writing took 2.7109702806919813 seconds)
2020-12-20 15:09:38 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2020-12-20 15:09:38 | INFO | train | epoch 047 | symm_kl 0.602 | self_kl 0 | self_cv 27.225 | loss 2.47 | nll_loss 0.754 | ppl 1.69 | wps 29650.4 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 15839 | lr 1.25e-05 | gnorm 1.133 | train_wall 177 | wall 9366
2020-12-20 15:09:38 | INFO | fairseq.trainer | begin training epoch 48
2020-12-20 15:09:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:09:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:10:13 | INFO | train_inner | epoch 048:     61 / 337 symm_kl=0.608, self_kl=0, self_cv=27.379, loss=2.477, nll_loss=0.757, ppl=1.69, wps=23579.9, ups=1.37, wpb=17255.4, bsz=601.3, num_updates=15900, lr=1.25e-05, gnorm=1.18, train_wall=52, wall=9400
2020-12-20 15:11:06 | INFO | train_inner | epoch 048:    161 / 337 symm_kl=0.601, self_kl=0, self_cv=27.272, loss=2.47, nll_loss=0.758, ppl=1.69, wps=33441.4, ups=1.91, wpb=17549.3, bsz=614.6, num_updates=16000, lr=1.25e-05, gnorm=1.107, train_wall=52, wall=9453
2020-12-20 15:11:59 | INFO | train_inner | epoch 048:    261 / 337 symm_kl=0.603, self_kl=0, self_cv=27.21, loss=2.47, nll_loss=0.752, ppl=1.68, wps=33000.2, ups=1.89, wpb=17488.9, bsz=622.5, num_updates=16100, lr=1.25e-05, gnorm=1.117, train_wall=53, wall=9506
2020-12-20 15:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:12:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:12:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:12:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:12:55 | INFO | valid | epoch 048 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.863 | nll_loss 4.177 | ppl 18.09 | bleu 22.67 | wps 6342 | wpb 11799.1 | bsz 428.6 | num_updates 16176 | best_bleu 22.74
2020-12-20 15:12:55 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:12:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:12:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:12:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 48 @ 16176 updates, score 22.67) (writing took 2.747007405385375 seconds)
2020-12-20 15:12:57 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2020-12-20 15:12:57 | INFO | train | epoch 048 | symm_kl 0.602 | self_kl 0 | self_cv 27.305 | loss 2.466 | nll_loss 0.753 | ppl 1.69 | wps 29574.6 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 16176 | lr 1.25e-05 | gnorm 1.114 | train_wall 177 | wall 9564
2020-12-20 15:12:57 | INFO | fairseq.trainer | begin training epoch 49
2020-12-20 15:12:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:13:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:13:13 | INFO | train_inner | epoch 049:     24 / 337 symm_kl=0.598, self_kl=0, self_cv=27.385, loss=2.453, nll_loss=0.749, ppl=1.68, wps=23387.2, ups=1.34, wpb=17402, bsz=620, num_updates=16200, lr=1.25e-05, gnorm=1.106, train_wall=53, wall=9580
2020-12-20 15:14:05 | INFO | train_inner | epoch 049:    124 / 337 symm_kl=0.604, self_kl=0, self_cv=27.566, loss=2.46, nll_loss=0.753, ppl=1.68, wps=33132.4, ups=1.9, wpb=17403.3, bsz=619.8, num_updates=16300, lr=1.25e-05, gnorm=1.128, train_wall=52, wall=9633
2020-12-20 15:14:58 | INFO | train_inner | epoch 049:    224 / 337 symm_kl=0.603, self_kl=0, self_cv=27.458, loss=2.466, nll_loss=0.757, ppl=1.69, wps=33039.2, ups=1.9, wpb=17361.8, bsz=610.6, num_updates=16400, lr=1.25e-05, gnorm=1.119, train_wall=52, wall=9685
2020-12-20 15:15:51 | INFO | train_inner | epoch 049:    324 / 337 symm_kl=0.596, self_kl=0, self_cv=27.228, loss=2.455, nll_loss=0.748, ppl=1.68, wps=33630.7, ups=1.9, wpb=17679.8, bsz=607.3, num_updates=16500, lr=1.25e-05, gnorm=1.124, train_wall=52, wall=9738
2020-12-20 15:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:16:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:16:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:16:14 | INFO | valid | epoch 049 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.858 | nll_loss 4.174 | ppl 18.05 | bleu 22.56 | wps 5877.3 | wpb 11799.1 | bsz 428.6 | num_updates 16513 | best_bleu 22.74
2020-12-20 15:16:14 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:16:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 49 @ 16513 updates, score 22.56) (writing took 2.8138940632343292 seconds)
2020-12-20 15:16:16 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2020-12-20 15:16:16 | INFO | train | epoch 049 | symm_kl 0.601 | self_kl 0 | self_cv 27.405 | loss 2.46 | nll_loss 0.753 | ppl 1.68 | wps 29533.1 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 16513 | lr 1.25e-05 | gnorm 1.127 | train_wall 176 | wall 9764
2020-12-20 15:16:16 | INFO | fairseq.trainer | begin training epoch 50
2020-12-20 15:16:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:16:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:17:05 | INFO | train_inner | epoch 050:     87 / 337 symm_kl=0.602, self_kl=0, self_cv=27.517, loss=2.456, nll_loss=0.752, ppl=1.68, wps=23336.2, ups=1.34, wpb=17365.2, bsz=605.4, num_updates=16600, lr=1.25e-05, gnorm=1.142, train_wall=52, wall=9812
2020-12-20 15:17:58 | INFO | train_inner | epoch 050:    187 / 337 symm_kl=0.599, self_kl=0, self_cv=27.471, loss=2.454, nll_loss=0.753, ppl=1.68, wps=33084.4, ups=1.89, wpb=17461.5, bsz=618.1, num_updates=16700, lr=1.25e-05, gnorm=1.11, train_wall=53, wall=9865
2020-12-20 15:18:51 | INFO | train_inner | epoch 050:    287 / 337 symm_kl=0.595, self_kl=0, self_cv=27.367, loss=2.453, nll_loss=0.752, ppl=1.68, wps=33202.7, ups=1.9, wpb=17503.6, bsz=638.7, num_updates=16800, lr=1.25e-05, gnorm=1.109, train_wall=53, wall=9918
2020-12-20 15:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:19:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:19:33 | INFO | valid | epoch 050 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.861 | nll_loss 4.175 | ppl 18.07 | bleu 22.63 | wps 5762.6 | wpb 11799.1 | bsz 428.6 | num_updates 16850 | best_bleu 22.74
2020-12-20 15:19:33 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:19:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 50 @ 16850 updates, score 22.63) (writing took 2.7431224677711725 seconds)
2020-12-20 15:19:36 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2020-12-20 15:19:36 | INFO | train | epoch 050 | symm_kl 0.6 | self_kl 0 | self_cv 27.484 | loss 2.456 | nll_loss 0.753 | ppl 1.69 | wps 29482.7 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 16850 | lr 1.25e-05 | gnorm 1.118 | train_wall 176 | wall 9963
2020-12-20 15:19:36 | INFO | fairseq.trainer | begin training epoch 51
2020-12-20 15:19:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:19:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:20:05 | INFO | train_inner | epoch 051:     50 / 337 symm_kl=0.607, self_kl=0, self_cv=27.733, loss=2.462, nll_loss=0.757, ppl=1.69, wps=23176.1, ups=1.34, wpb=17252.4, bsz=595.6, num_updates=16900, lr=1.25e-05, gnorm=1.142, train_wall=52, wall=9992
2020-12-20 15:20:58 | INFO | train_inner | epoch 051:    150 / 337 symm_kl=0.6, self_kl=0, self_cv=27.572, loss=2.457, nll_loss=0.758, ppl=1.69, wps=33325.1, ups=1.9, wpb=17530.8, bsz=628.7, num_updates=17000, lr=1.25e-05, gnorm=1.149, train_wall=52, wall=10045
2020-12-20 15:21:50 | INFO | train_inner | epoch 051:    250 / 337 symm_kl=0.6, self_kl=0, self_cv=27.653, loss=2.448, nll_loss=0.751, ppl=1.68, wps=33166.9, ups=1.9, wpb=17454.3, bsz=610.3, num_updates=17100, lr=1.25e-05, gnorm=1.122, train_wall=52, wall=10097
2020-12-20 15:22:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:22:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:22:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:22:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:22:52 | INFO | valid | epoch 051 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.867 | nll_loss 4.182 | ppl 18.15 | bleu 22.7 | wps 5922.9 | wpb 11799.1 | bsz 428.6 | num_updates 17187 | best_bleu 22.74
2020-12-20 15:22:52 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:22:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 51 @ 17187 updates, score 22.7) (writing took 2.936673864722252 seconds)
2020-12-20 15:22:55 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2020-12-20 15:22:55 | INFO | train | epoch 051 | symm_kl 0.599 | self_kl 0 | self_cv 27.588 | loss 2.45 | nll_loss 0.753 | ppl 1.68 | wps 29500.4 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 17187 | lr 1.25e-05 | gnorm 1.13 | train_wall 177 | wall 10162
2020-12-20 15:22:55 | INFO | fairseq.trainer | begin training epoch 52
2020-12-20 15:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:23:05 | INFO | train_inner | epoch 052:     13 / 337 symm_kl=0.594, self_kl=0, self_cv=27.464, loss=2.442, nll_loss=0.746, ppl=1.68, wps=23340.5, ups=1.33, wpb=17496.1, bsz=610.9, num_updates=17200, lr=1.25e-05, gnorm=1.11, train_wall=53, wall=10172
2020-12-20 15:23:58 | INFO | train_inner | epoch 052:    113 / 337 symm_kl=0.601, self_kl=0, self_cv=27.614, loss=2.455, nll_loss=0.753, ppl=1.69, wps=33391.5, ups=1.9, wpb=17541.6, bsz=619.7, num_updates=17300, lr=1.25e-05, gnorm=1.137, train_wall=52, wall=10225
2020-12-20 15:24:50 | INFO | train_inner | epoch 052:    213 / 337 symm_kl=0.598, self_kl=0, self_cv=27.723, loss=2.443, nll_loss=0.751, ppl=1.68, wps=33266.6, ups=1.9, wpb=17493, bsz=588.5, num_updates=17400, lr=1.25e-05, gnorm=1.113, train_wall=52, wall=10277
2020-12-20 15:25:43 | INFO | train_inner | epoch 052:    313 / 337 symm_kl=0.599, self_kl=0, self_cv=27.75, loss=2.448, nll_loss=0.757, ppl=1.69, wps=32858.2, ups=1.9, wpb=17333.1, bsz=638.2, num_updates=17500, lr=1.25e-05, gnorm=1.131, train_wall=53, wall=10330
2020-12-20 15:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:25:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:25:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:25:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:25:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:25:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:26:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:26:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:26:11 | INFO | valid | epoch 052 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.866 | nll_loss 4.179 | ppl 18.12 | bleu 22.76 | wps 6378.6 | wpb 11799.1 | bsz 428.6 | num_updates 17524 | best_bleu 22.76
2020-12-20 15:26:11 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:26:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:26:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:26:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:26:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:26:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 52 @ 17524 updates, score 22.76) (writing took 4.817240996286273 seconds)
2020-12-20 15:26:16 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2020-12-20 15:26:16 | INFO | train | epoch 052 | symm_kl 0.598 | self_kl 0 | self_cv 27.678 | loss 2.446 | nll_loss 0.753 | ppl 1.68 | wps 29304.7 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 17524 | lr 1.25e-05 | gnorm 1.127 | train_wall 177 | wall 10363
2020-12-20 15:26:16 | INFO | fairseq.trainer | begin training epoch 53
2020-12-20 15:26:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:26:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:26:59 | INFO | train_inner | epoch 053:     76 / 337 symm_kl=0.592, self_kl=0, self_cv=27.516, loss=2.439, nll_loss=0.748, ppl=1.68, wps=23153.6, ups=1.32, wpb=17510.9, bsz=615.6, num_updates=17600, lr=1.25e-05, gnorm=1.108, train_wall=52, wall=10406
2020-12-20 15:27:51 | INFO | train_inner | epoch 053:    176 / 337 symm_kl=0.596, self_kl=0, self_cv=27.803, loss=2.434, nll_loss=0.749, ppl=1.68, wps=33117.2, ups=1.9, wpb=17421.5, bsz=617, num_updates=17700, lr=1.25e-05, gnorm=1.133, train_wall=52, wall=10458
2020-12-20 15:28:45 | INFO | train_inner | epoch 053:    276 / 337 symm_kl=0.595, self_kl=0, self_cv=27.696, loss=2.436, nll_loss=0.749, ppl=1.68, wps=32814.3, ups=1.88, wpb=17475, bsz=625.9, num_updates=17800, lr=1.25e-05, gnorm=1.107, train_wall=53, wall=10512
2020-12-20 15:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:29:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:29:32 | INFO | valid | epoch 053 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.87 | nll_loss 4.184 | ppl 18.18 | bleu 22.61 | wps 6479.1 | wpb 11799.1 | bsz 428.6 | num_updates 17861 | best_bleu 22.76
2020-12-20 15:29:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:29:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 53 @ 17861 updates, score 22.61) (writing took 2.727716827765107 seconds)
2020-12-20 15:29:35 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2020-12-20 15:29:35 | INFO | train | epoch 053 | symm_kl 0.598 | self_kl 0 | self_cv 27.747 | loss 2.442 | nll_loss 0.752 | ppl 1.68 | wps 29567.2 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 17861 | lr 1.25e-05 | gnorm 1.133 | train_wall 177 | wall 10562
2020-12-20 15:29:35 | INFO | fairseq.trainer | begin training epoch 54
2020-12-20 15:29:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:29:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:29:58 | INFO | train_inner | epoch 054:     39 / 337 symm_kl=0.603, self_kl=0, self_cv=27.989, loss=2.447, nll_loss=0.759, ppl=1.69, wps=23523.2, ups=1.35, wpb=17362.6, bsz=603.5, num_updates=17900, lr=1.25e-05, gnorm=1.174, train_wall=53, wall=10586
2020-12-20 15:30:51 | INFO | train_inner | epoch 054:    139 / 337 symm_kl=0.597, self_kl=0, self_cv=27.794, loss=2.44, nll_loss=0.754, ppl=1.69, wps=33072.2, ups=1.88, wpb=17552.5, bsz=615.4, num_updates=18000, lr=1.25e-05, gnorm=1.114, train_wall=53, wall=10639
2020-12-20 15:31:44 | INFO | train_inner | epoch 054:    239 / 337 symm_kl=0.593, self_kl=0, self_cv=27.853, loss=2.427, nll_loss=0.749, ppl=1.68, wps=33293.3, ups=1.9, wpb=17550.7, bsz=636.8, num_updates=18100, lr=1.25e-05, gnorm=1.165, train_wall=53, wall=10691
2020-12-20 15:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:32:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:32:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:32:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:32:53 | INFO | valid | epoch 054 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.872 | nll_loss 4.186 | ppl 18.2 | bleu 22.85 | wps 5759.3 | wpb 11799.1 | bsz 428.6 | num_updates 18198 | best_bleu 22.85
2020-12-20 15:32:53 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:32:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 54 @ 18198 updates, score 22.85) (writing took 4.6379219107329845 seconds)
2020-12-20 15:32:57 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2020-12-20 15:32:57 | INFO | train | epoch 054 | symm_kl 0.597 | self_kl 0 | self_cv 27.862 | loss 2.437 | nll_loss 0.752 | ppl 1.68 | wps 29047.5 | ups 1.66 | wpb 17451.5 | bsz 615.4 | num_updates 18198 | lr 1.25e-05 | gnorm 1.142 | train_wall 178 | wall 10765
2020-12-20 15:32:57 | INFO | fairseq.trainer | begin training epoch 55
2020-12-20 15:32:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:33:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:33:01 | INFO | train_inner | epoch 055:      2 / 337 symm_kl=0.601, self_kl=0, self_cv=27.908, loss=2.442, nll_loss=0.754, ppl=1.69, wps=22255.6, ups=1.29, wpb=17217.2, bsz=595.7, num_updates=18200, lr=1.25e-05, gnorm=1.159, train_wall=53, wall=10769
2020-12-20 15:33:54 | INFO | train_inner | epoch 055:    102 / 337 symm_kl=0.598, self_kl=0, self_cv=27.884, loss=2.441, nll_loss=0.756, ppl=1.69, wps=33623.9, ups=1.91, wpb=17581.4, bsz=635.3, num_updates=18300, lr=1.25e-05, gnorm=1.137, train_wall=52, wall=10821
2020-12-20 15:34:47 | INFO | train_inner | epoch 055:    202 / 337 symm_kl=0.596, self_kl=0, self_cv=27.964, loss=2.429, nll_loss=0.75, ppl=1.68, wps=33029.1, ups=1.89, wpb=17472, bsz=605, num_updates=18400, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=10874
2020-12-20 15:35:40 | INFO | train_inner | epoch 055:    302 / 337 symm_kl=0.594, self_kl=0, self_cv=27.945, loss=2.427, nll_loss=0.75, ppl=1.68, wps=32996.8, ups=1.89, wpb=17445, bsz=613, num_updates=18500, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=10927
2020-12-20 15:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:35:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:35:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:35:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:35:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:35:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:36:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:36:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:36:13 | INFO | valid | epoch 055 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.868 | nll_loss 4.181 | ppl 18.14 | bleu 22.91 | wps 6485.6 | wpb 11799.1 | bsz 428.6 | num_updates 18535 | best_bleu 22.91
2020-12-20 15:36:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_best.pt (epoch 55 @ 18535 updates, score 22.91) (writing took 4.9908491615206 seconds)
2020-12-20 15:36:18 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2020-12-20 15:36:18 | INFO | train | epoch 055 | symm_kl 0.596 | self_kl 0 | self_cv 27.945 | loss 2.432 | nll_loss 0.752 | ppl 1.68 | wps 29285.7 | ups 1.68 | wpb 17451.5 | bsz 615.4 | num_updates 18535 | lr 1.25e-05 | gnorm 1.123 | train_wall 177 | wall 10965
2020-12-20 15:36:18 | INFO | fairseq.trainer | begin training epoch 56
2020-12-20 15:36:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:36:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:36:55 | INFO | train_inner | epoch 056:     65 / 337 symm_kl=0.598, self_kl=0, self_cv=28.179, loss=2.428, nll_loss=0.755, ppl=1.69, wps=22925.2, ups=1.32, wpb=17310.9, bsz=605.9, num_updates=18600, lr=1.25e-05, gnorm=1.129, train_wall=52, wall=11002
2020-12-20 15:37:48 | INFO | train_inner | epoch 056:    165 / 337 symm_kl=0.585, self_kl=0, self_cv=27.893, loss=2.413, nll_loss=0.748, ppl=1.68, wps=33266, ups=1.88, wpb=17660.1, bsz=654, num_updates=18700, lr=1.25e-05, gnorm=1.147, train_wall=53, wall=11055
2020-12-20 15:38:41 | INFO | train_inner | epoch 056:    265 / 337 symm_kl=0.6, self_kl=0, self_cv=28.127, loss=2.429, nll_loss=0.751, ppl=1.68, wps=32966.5, ups=1.91, wpb=17297.2, bsz=594.2, num_updates=18800, lr=1.25e-05, gnorm=1.149, train_wall=52, wall=11108
2020-12-20 15:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:39:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:39:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:39:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:39:34 | INFO | valid | epoch 056 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.876 | nll_loss 4.188 | ppl 18.22 | bleu 22.75 | wps 5944.7 | wpb 11799.1 | bsz 428.6 | num_updates 18872 | best_bleu 22.91
2020-12-20 15:39:34 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:39:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 56 @ 18872 updates, score 22.75) (writing took 2.725435111671686 seconds)
2020-12-20 15:39:37 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2020-12-20 15:39:37 | INFO | train | epoch 056 | symm_kl 0.595 | self_kl 0 | self_cv 28.039 | loss 2.426 | nll_loss 0.751 | ppl 1.68 | wps 29562 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 18872 | lr 1.25e-05 | gnorm 1.136 | train_wall 176 | wall 11164
2020-12-20 15:39:37 | INFO | fairseq.trainer | begin training epoch 57
2020-12-20 15:39:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:39:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:39:55 | INFO | train_inner | epoch 057:     28 / 337 symm_kl=0.598, self_kl=0, self_cv=27.904, loss=2.442, nll_loss=0.756, ppl=1.69, wps=23472.7, ups=1.35, wpb=17408.6, bsz=610, num_updates=18900, lr=1.25e-05, gnorm=1.119, train_wall=52, wall=11182
2020-12-20 15:40:47 | INFO | train_inner | epoch 057:    128 / 337 symm_kl=0.595, self_kl=0, self_cv=28.296, loss=2.421, nll_loss=0.757, ppl=1.69, wps=33190.5, ups=1.91, wpb=17410.3, bsz=617, num_updates=19000, lr=1.25e-05, gnorm=1.116, train_wall=52, wall=11234
2020-12-20 15:41:40 | INFO | train_inner | epoch 057:    228 / 337 symm_kl=0.596, self_kl=0, self_cv=28.015, loss=2.426, nll_loss=0.748, ppl=1.68, wps=33183.6, ups=1.9, wpb=17501.1, bsz=612.1, num_updates=19100, lr=1.25e-05, gnorm=1.112, train_wall=53, wall=11287
2020-12-20 15:42:33 | INFO | train_inner | epoch 057:    328 / 337 symm_kl=0.594, self_kl=0, self_cv=28.198, loss=2.417, nll_loss=0.749, ppl=1.68, wps=33373.8, ups=1.9, wpb=17543.3, bsz=610, num_updates=19200, lr=1.25e-05, gnorm=1.108, train_wall=52, wall=11340
2020-12-20 15:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:42:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:42:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:42:53 | INFO | valid | epoch 057 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.883 | nll_loss 4.195 | ppl 18.31 | bleu 22.74 | wps 6058.8 | wpb 11799.1 | bsz 428.6 | num_updates 19209 | best_bleu 22.91
2020-12-20 15:42:53 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:42:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 57 @ 19209 updates, score 22.74) (writing took 2.779120072722435 seconds)
2020-12-20 15:42:56 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2020-12-20 15:42:56 | INFO | train | epoch 057 | symm_kl 0.595 | self_kl 0 | self_cv 28.138 | loss 2.422 | nll_loss 0.752 | ppl 1.68 | wps 29587.1 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 19209 | lr 1.25e-05 | gnorm 1.114 | train_wall 176 | wall 11363
2020-12-20 15:42:56 | INFO | fairseq.trainer | begin training epoch 58
2020-12-20 15:42:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:42:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:43:47 | INFO | train_inner | epoch 058:     91 / 337 symm_kl=0.587, self_kl=0, self_cv=28.204, loss=2.401, nll_loss=0.745, ppl=1.68, wps=23573.3, ups=1.35, wpb=17462.8, bsz=630.7, num_updates=19300, lr=1.25e-05, gnorm=1.11, train_wall=52, wall=11414
2020-12-20 15:44:40 | INFO | train_inner | epoch 058:    191 / 337 symm_kl=0.599, self_kl=0, self_cv=28.22, loss=2.427, nll_loss=0.753, ppl=1.68, wps=32865.7, ups=1.88, wpb=17466.8, bsz=607.4, num_updates=19400, lr=1.25e-05, gnorm=1.201, train_wall=53, wall=11467
2020-12-20 15:45:32 | INFO | train_inner | epoch 058:    291 / 337 symm_kl=0.598, self_kl=0, self_cv=28.298, loss=2.424, nll_loss=0.755, ppl=1.69, wps=33224.7, ups=1.91, wpb=17398.5, bsz=603.9, num_updates=19500, lr=1.25e-05, gnorm=1.179, train_wall=52, wall=11519
2020-12-20 15:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:45:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:45:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:45:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:45:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:45:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:46:12 | INFO | valid | epoch 058 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.878 | nll_loss 4.191 | ppl 18.26 | bleu 22.79 | wps 6386.4 | wpb 11799.1 | bsz 428.6 | num_updates 19546 | best_bleu 22.91
2020-12-20 15:46:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:46:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:46:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:46:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:46:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:46:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 58 @ 19546 updates, score 22.79) (writing took 2.752467632293701 seconds)
2020-12-20 15:46:14 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2020-12-20 15:46:14 | INFO | train | epoch 058 | symm_kl 0.594 | self_kl 0 | self_cv 28.243 | loss 2.417 | nll_loss 0.751 | ppl 1.68 | wps 29632.9 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 19546 | lr 1.25e-05 | gnorm 1.158 | train_wall 177 | wall 11562
2020-12-20 15:46:14 | INFO | fairseq.trainer | begin training epoch 59
2020-12-20 15:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:46:46 | INFO | train_inner | epoch 059:     54 / 337 symm_kl=0.595, self_kl=0, self_cv=28.25, loss=2.421, nll_loss=0.755, ppl=1.69, wps=23636.1, ups=1.36, wpb=17361.2, bsz=611.6, num_updates=19600, lr=1.25e-05, gnorm=1.146, train_wall=52, wall=11593
2020-12-20 15:47:38 | INFO | train_inner | epoch 059:    154 / 337 symm_kl=0.591, self_kl=0, self_cv=28.459, loss=2.398, nll_loss=0.746, ppl=1.68, wps=32968.3, ups=1.89, wpb=17424.9, bsz=606.2, num_updates=19700, lr=1.25e-05, gnorm=1.134, train_wall=53, wall=11646
2020-12-20 15:48:31 | INFO | train_inner | epoch 059:    254 / 337 symm_kl=0.59, self_kl=0, self_cv=28.256, loss=2.407, nll_loss=0.747, ppl=1.68, wps=33223.4, ups=1.89, wpb=17542.5, bsz=615, num_updates=19800, lr=1.25e-05, gnorm=1.104, train_wall=53, wall=11698
2020-12-20 15:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:49:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:49:30 | INFO | valid | epoch 059 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.886 | nll_loss 4.198 | ppl 18.36 | bleu 22.66 | wps 6356 | wpb 11799.1 | bsz 428.6 | num_updates 19883 | best_bleu 22.91
2020-12-20 15:49:30 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 59 @ 19883 updates, score 22.66) (writing took 2.7812496162950993 seconds)
2020-12-20 15:49:33 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2020-12-20 15:49:33 | INFO | train | epoch 059 | symm_kl 0.594 | self_kl 0 | self_cv 28.326 | loss 2.413 | nll_loss 0.751 | ppl 1.68 | wps 29571.3 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 19883 | lr 1.25e-05 | gnorm 1.127 | train_wall 177 | wall 11760
2020-12-20 15:49:33 | INFO | fairseq.trainer | begin training epoch 60
2020-12-20 15:49:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:49:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:49:45 | INFO | train_inner | epoch 060:     17 / 337 symm_kl=0.597, self_kl=0, self_cv=28.281, loss=2.427, nll_loss=0.759, ppl=1.69, wps=23558.1, ups=1.35, wpb=17421.8, bsz=628.2, num_updates=19900, lr=1.25e-05, gnorm=1.131, train_wall=52, wall=11772
2020-12-20 15:50:38 | INFO | train_inner | epoch 060:    117 / 337 symm_kl=0.594, self_kl=0, self_cv=28.441, loss=2.408, nll_loss=0.751, ppl=1.68, wps=33223, ups=1.91, wpb=17430.9, bsz=616.1, num_updates=20000, lr=1.25e-05, gnorm=1.11, train_wall=52, wall=11825
2020-12-20 15:51:31 | INFO | train_inner | epoch 060:    217 / 337 symm_kl=0.595, self_kl=0, self_cv=28.403, loss=2.413, nll_loss=0.752, ppl=1.68, wps=33129.8, ups=1.89, wpb=17518.7, bsz=619.6, num_updates=20100, lr=1.25e-05, gnorm=1.116, train_wall=53, wall=11878
2020-12-20 15:52:23 | INFO | train_inner | epoch 060:    317 / 337 symm_kl=0.59, self_kl=0, self_cv=28.344, loss=2.408, nll_loss=0.752, ppl=1.68, wps=33267.4, ups=1.9, wpb=17479.3, bsz=619.3, num_updates=20200, lr=1.25e-05, gnorm=1.122, train_wall=52, wall=11930
2020-12-20 15:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:52:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:52:49 | INFO | valid | epoch 060 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.889 | nll_loss 4.201 | ppl 18.4 | bleu 22.62 | wps 6406.2 | wpb 11799.1 | bsz 428.6 | num_updates 20220 | best_bleu 22.91
2020-12-20 15:52:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:52:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:52:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 60 @ 20220 updates, score 22.62) (writing took 2.8606747053563595 seconds)
2020-12-20 15:52:52 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2020-12-20 15:52:52 | INFO | train | epoch 060 | symm_kl 0.593 | self_kl 0 | self_cv 28.418 | loss 2.409 | nll_loss 0.751 | ppl 1.68 | wps 29618.8 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 20220 | lr 1.25e-05 | gnorm 1.123 | train_wall 177 | wall 11959
2020-12-20 15:52:52 | INFO | fairseq.trainer | begin training epoch 61
2020-12-20 15:52:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:52:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:53:37 | INFO | train_inner | epoch 061:     80 / 337 symm_kl=0.589, self_kl=0, self_cv=28.663, loss=2.39, nll_loss=0.748, ppl=1.68, wps=23508.6, ups=1.36, wpb=17297.9, bsz=616.2, num_updates=20300, lr=1.25e-05, gnorm=1.154, train_wall=52, wall=12004
2020-12-20 15:54:29 | INFO | train_inner | epoch 061:    180 / 337 symm_kl=0.595, self_kl=0, self_cv=28.557, loss=2.409, nll_loss=0.754, ppl=1.69, wps=33228.9, ups=1.9, wpb=17465.7, bsz=617.4, num_updates=20400, lr=1.25e-05, gnorm=1.107, train_wall=52, wall=12056
2020-12-20 15:55:23 | INFO | train_inner | epoch 061:    280 / 337 symm_kl=0.592, self_kl=0, self_cv=28.366, loss=2.404, nll_loss=0.745, ppl=1.68, wps=33071.6, ups=1.88, wpb=17635.8, bsz=610.7, num_updates=20500, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=12110
2020-12-20 15:55:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:55:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:55:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:55:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:55:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:55:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:55:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:56:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:56:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:56:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:56:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:56:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:56:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:56:08 | INFO | valid | epoch 061 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.893 | nll_loss 4.205 | ppl 18.44 | bleu 22.6 | wps 6342 | wpb 11799.1 | bsz 428.6 | num_updates 20557 | best_bleu 22.91
2020-12-20 15:56:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:56:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 61 @ 20557 updates, score 22.6) (writing took 2.8035795278847218 seconds)
2020-12-20 15:56:11 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2020-12-20 15:56:11 | INFO | train | epoch 061 | symm_kl 0.592 | self_kl 0 | self_cv 28.544 | loss 2.402 | nll_loss 0.751 | ppl 1.68 | wps 29535.9 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 20557 | lr 1.25e-05 | gnorm 1.141 | train_wall 177 | wall 12158
2020-12-20 15:56:11 | INFO | fairseq.trainer | begin training epoch 62
2020-12-20 15:56:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:56:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:56:36 | INFO | train_inner | epoch 062:     43 / 337 symm_kl=0.594, self_kl=0, self_cv=28.564, loss=2.405, nll_loss=0.754, ppl=1.69, wps=23511.3, ups=1.36, wpb=17324.5, bsz=614.7, num_updates=20600, lr=1.25e-05, gnorm=1.211, train_wall=52, wall=12183
2020-12-20 15:57:29 | INFO | train_inner | epoch 062:    143 / 337 symm_kl=0.589, self_kl=0, self_cv=28.656, loss=2.389, nll_loss=0.746, ppl=1.68, wps=33228, ups=1.89, wpb=17555.8, bsz=623.2, num_updates=20700, lr=1.25e-05, gnorm=1.161, train_wall=53, wall=12236
2020-12-20 15:58:22 | INFO | train_inner | epoch 062:    243 / 337 symm_kl=0.592, self_kl=0, self_cv=28.663, loss=2.395, nll_loss=0.748, ppl=1.68, wps=33029.8, ups=1.89, wpb=17490.4, bsz=614.2, num_updates=20800, lr=1.25e-05, gnorm=1.181, train_wall=53, wall=12289
2020-12-20 15:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 15:59:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 15:59:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 15:59:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 15:59:27 | INFO | valid | epoch 062 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.892 | nll_loss 4.205 | ppl 18.44 | bleu 22.65 | wps 6417 | wpb 11799.1 | bsz 428.6 | num_updates 20894 | best_bleu 22.91
2020-12-20 15:59:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 15:59:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 62 @ 20894 updates, score 22.65) (writing took 2.7571316119283438 seconds)
2020-12-20 15:59:30 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2020-12-20 15:59:30 | INFO | train | epoch 062 | symm_kl 0.592 | self_kl 0 | self_cv 28.635 | loss 2.398 | nll_loss 0.75 | ppl 1.68 | wps 29604.3 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 20894 | lr 1.25e-05 | gnorm 1.154 | train_wall 177 | wall 12357
2020-12-20 15:59:30 | INFO | fairseq.trainer | begin training epoch 63
2020-12-20 15:59:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 15:59:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 15:59:36 | INFO | train_inner | epoch 063:      6 / 337 symm_kl=0.594, self_kl=0, self_cv=28.73, loss=2.398, nll_loss=0.753, ppl=1.68, wps=23395.9, ups=1.35, wpb=17287.2, bsz=605.5, num_updates=20900, lr=1.25e-05, gnorm=1.126, train_wall=53, wall=12363
2020-12-20 16:00:28 | INFO | train_inner | epoch 063:    106 / 337 symm_kl=0.59, self_kl=0, self_cv=28.654, loss=2.393, nll_loss=0.749, ppl=1.68, wps=33854.4, ups=1.91, wpb=17688.2, bsz=611.3, num_updates=21000, lr=1.25e-05, gnorm=1.152, train_wall=52, wall=12415
2020-12-20 16:01:21 | INFO | train_inner | epoch 063:    206 / 337 symm_kl=0.59, self_kl=0, self_cv=28.79, loss=2.386, nll_loss=0.748, ppl=1.68, wps=33116.5, ups=1.9, wpb=17397.4, bsz=632.3, num_updates=21100, lr=1.25e-05, gnorm=1.142, train_wall=52, wall=12468
2020-12-20 16:02:14 | INFO | train_inner | epoch 063:    306 / 337 symm_kl=0.595, self_kl=0, self_cv=28.884, loss=2.4, nll_loss=0.758, ppl=1.69, wps=32802, ups=1.89, wpb=17349.9, bsz=614.7, num_updates=21200, lr=1.25e-05, gnorm=1.112, train_wall=53, wall=12521
2020-12-20 16:02:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:02:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:02:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:02:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:02:46 | INFO | valid | epoch 063 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.891 | nll_loss 4.202 | ppl 18.41 | bleu 22.72 | wps 5962.4 | wpb 11799.1 | bsz 428.6 | num_updates 21231 | best_bleu 22.91
2020-12-20 16:02:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:02:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:02:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 63 @ 21231 updates, score 22.72) (writing took 2.762901009991765 seconds)
2020-12-20 16:02:49 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2020-12-20 16:02:49 | INFO | train | epoch 063 | symm_kl 0.591 | self_kl 0 | self_cv 28.734 | loss 2.392 | nll_loss 0.75 | ppl 1.68 | wps 29534.8 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 21231 | lr 1.25e-05 | gnorm 1.134 | train_wall 177 | wall 12556
2020-12-20 16:02:49 | INFO | fairseq.trainer | begin training epoch 64
2020-12-20 16:02:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:02:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:03:28 | INFO | train_inner | epoch 064:     69 / 337 symm_kl=0.586, self_kl=0, self_cv=28.554, loss=2.385, nll_loss=0.742, ppl=1.67, wps=23504.1, ups=1.35, wpb=17432.1, bsz=609, num_updates=21300, lr=1.25e-05, gnorm=1.115, train_wall=52, wall=12595
2020-12-20 16:04:20 | INFO | train_inner | epoch 064:    169 / 337 symm_kl=0.586, self_kl=0, self_cv=28.799, loss=2.38, nll_loss=0.749, ppl=1.68, wps=33290.4, ups=1.9, wpb=17527.5, bsz=614.9, num_updates=21400, lr=1.25e-05, gnorm=1.116, train_wall=52, wall=12648
2020-12-20 16:05:13 | INFO | train_inner | epoch 064:    269 / 337 symm_kl=0.602, self_kl=0, self_cv=28.957, loss=2.407, nll_loss=0.757, ppl=1.69, wps=32909.7, ups=1.89, wpb=17422.4, bsz=603.6, num_updates=21500, lr=1.25e-05, gnorm=1.189, train_wall=53, wall=12701
2020-12-20 16:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:05:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:05:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:05:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:05:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:05:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:05:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:05:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:05:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:05:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:05:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:05:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:05:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:05:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:05:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:06:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:06:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:06:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:06:04 | INFO | valid | epoch 064 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.898 | nll_loss 4.209 | ppl 18.49 | bleu 22.68 | wps 6443.4 | wpb 11799.1 | bsz 428.6 | num_updates 21568 | best_bleu 22.91
2020-12-20 16:06:04 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:06:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:06:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:06:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:06:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:06:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:06:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:06:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:06:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:06:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 64 @ 21568 updates, score 22.68) (writing took 2.8572873566299677 seconds)
2020-12-20 16:06:07 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2020-12-20 16:06:07 | INFO | train | epoch 064 | symm_kl 0.591 | self_kl 0 | self_cv 28.823 | loss 2.389 | nll_loss 0.75 | ppl 1.68 | wps 29620.3 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 21568 | lr 1.25e-05 | gnorm 1.169 | train_wall 177 | wall 12754
2020-12-20 16:06:07 | INFO | fairseq.trainer | begin training epoch 65
2020-12-20 16:06:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:06:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:06:27 | INFO | train_inner | epoch 065:     32 / 337 symm_kl=0.589, self_kl=0, self_cv=28.746, loss=2.391, nll_loss=0.753, ppl=1.69, wps=23640.5, ups=1.36, wpb=17361.5, bsz=618.9, num_updates=21600, lr=1.25e-05, gnorm=1.219, train_wall=52, wall=12774
2020-12-20 16:07:19 | INFO | train_inner | epoch 065:    132 / 337 symm_kl=0.596, self_kl=0, self_cv=29.089, loss=2.387, nll_loss=0.751, ppl=1.68, wps=33020.7, ups=1.9, wpb=17369.6, bsz=595.8, num_updates=21700, lr=1.25e-05, gnorm=1.132, train_wall=52, wall=12827
2020-12-20 16:08:12 | INFO | train_inner | epoch 065:    232 / 337 symm_kl=0.585, self_kl=0, self_cv=28.865, loss=2.376, nll_loss=0.748, ppl=1.68, wps=33215.6, ups=1.89, wpb=17532.8, bsz=651.1, num_updates=21800, lr=1.25e-05, gnorm=1.107, train_wall=53, wall=12879
2020-12-20 16:09:05 | INFO | train_inner | epoch 065:    332 / 337 symm_kl=0.589, self_kl=0, self_cv=29.049, loss=2.375, nll_loss=0.748, ppl=1.68, wps=32934.6, ups=1.88, wpb=17541, bsz=604.6, num_updates=21900, lr=1.25e-05, gnorm=1.17, train_wall=53, wall=12933
2020-12-20 16:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:09:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:09:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:09:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:09:23 | INFO | valid | epoch 065 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.895 | nll_loss 4.206 | ppl 18.45 | bleu 22.59 | wps 6472.4 | wpb 11799.1 | bsz 428.6 | num_updates 21905 | best_bleu 22.91
2020-12-20 16:09:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:09:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:09:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 65 @ 21905 updates, score 22.59) (writing took 2.863590719178319 seconds)
2020-12-20 16:09:26 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2020-12-20 16:09:26 | INFO | train | epoch 065 | symm_kl 0.59 | self_kl 0 | self_cv 28.952 | loss 2.383 | nll_loss 0.75 | ppl 1.68 | wps 29579.8 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 21905 | lr 1.25e-05 | gnorm 1.135 | train_wall 177 | wall 12953
2020-12-20 16:09:26 | INFO | fairseq.trainer | begin training epoch 66
2020-12-20 16:09:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:09:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:10:19 | INFO | train_inner | epoch 066:     95 / 337 symm_kl=0.588, self_kl=0, self_cv=28.966, loss=2.375, nll_loss=0.747, ppl=1.68, wps=23660.6, ups=1.36, wpb=17360.6, bsz=622.7, num_updates=22000, lr=1.25e-05, gnorm=1.136, train_wall=52, wall=13006
2020-12-20 16:11:12 | INFO | train_inner | epoch 066:    195 / 337 symm_kl=0.585, self_kl=0, self_cv=28.985, loss=2.367, nll_loss=0.743, ppl=1.67, wps=33088.9, ups=1.89, wpb=17542.9, bsz=621, num_updates=22100, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=13059
2020-12-20 16:12:05 | INFO | train_inner | epoch 066:    295 / 337 symm_kl=0.592, self_kl=0, self_cv=29.165, loss=2.38, nll_loss=0.754, ppl=1.69, wps=33127.6, ups=1.89, wpb=17487, bsz=610.7, num_updates=22200, lr=1.25e-05, gnorm=1.116, train_wall=53, wall=13112
2020-12-20 16:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:12:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:12:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:12:42 | INFO | valid | epoch 066 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.901 | nll_loss 4.212 | ppl 18.53 | bleu 22.66 | wps 6311.5 | wpb 11799.1 | bsz 428.6 | num_updates 22242 | best_bleu 22.91
2020-12-20 16:12:42 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:12:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 66 @ 22242 updates, score 22.66) (writing took 2.8859678376466036 seconds)
2020-12-20 16:12:45 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2020-12-20 16:12:45 | INFO | train | epoch 066 | symm_kl 0.589 | self_kl 0 | self_cv 29.051 | loss 2.377 | nll_loss 0.75 | ppl 1.68 | wps 29561.7 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 22242 | lr 1.25e-05 | gnorm 1.12 | train_wall 177 | wall 13152
2020-12-20 16:12:45 | INFO | fairseq.trainer | begin training epoch 67
2020-12-20 16:12:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:12:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:13:18 | INFO | train_inner | epoch 067:     58 / 337 symm_kl=0.594, self_kl=0, self_cv=29.154, loss=2.386, nll_loss=0.755, ppl=1.69, wps=23650.1, ups=1.36, wpb=17399.4, bsz=598.9, num_updates=22300, lr=1.25e-05, gnorm=1.135, train_wall=52, wall=13185
2020-12-20 16:14:11 | INFO | train_inner | epoch 067:    158 / 337 symm_kl=0.592, self_kl=0, self_cv=29.149, loss=2.383, nll_loss=0.755, ppl=1.69, wps=33232.1, ups=1.89, wpb=17551.9, bsz=625.5, num_updates=22400, lr=1.25e-05, gnorm=1.108, train_wall=53, wall=13238
2020-12-20 16:15:04 | INFO | train_inner | epoch 067:    258 / 337 symm_kl=0.587, self_kl=0, self_cv=29.19, loss=2.365, nll_loss=0.747, ppl=1.68, wps=33221.5, ups=1.9, wpb=17458.7, bsz=609.6, num_updates=22500, lr=1.25e-05, gnorm=1.15, train_wall=52, wall=13291
2020-12-20 16:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:15:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:15:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:15:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:15:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:15:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:15:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:15:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:15:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:15:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:15:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:15:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:15:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:15:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:16:01 | INFO | valid | epoch 067 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.902 | nll_loss 4.213 | ppl 18.54 | bleu 22.81 | wps 6390.9 | wpb 11799.1 | bsz 428.6 | num_updates 22579 | best_bleu 22.91
2020-12-20 16:16:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:16:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:16:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:16:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:16:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:16:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:16:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:16:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:16:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:16:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 67 @ 22579 updates, score 22.81) (writing took 2.9089026488363743 seconds)
2020-12-20 16:16:04 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2020-12-20 16:16:04 | INFO | train | epoch 067 | symm_kl 0.589 | self_kl 0 | self_cv 29.169 | loss 2.373 | nll_loss 0.75 | ppl 1.68 | wps 29628.9 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 22579 | lr 1.25e-05 | gnorm 1.129 | train_wall 177 | wall 13351
2020-12-20 16:16:04 | INFO | fairseq.trainer | begin training epoch 68
2020-12-20 16:16:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:16:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:16:18 | INFO | train_inner | epoch 068:     21 / 337 symm_kl=0.585, self_kl=0, self_cv=29.103, loss=2.366, nll_loss=0.747, ppl=1.68, wps=23342.4, ups=1.35, wpb=17285.5, bsz=619.8, num_updates=22600, lr=1.25e-05, gnorm=1.12, train_wall=52, wall=13365
2020-12-20 16:17:10 | INFO | train_inner | epoch 068:    121 / 337 symm_kl=0.585, self_kl=0, self_cv=29.176, loss=2.362, nll_loss=0.745, ppl=1.68, wps=33010.5, ups=1.9, wpb=17412.9, bsz=629.2, num_updates=22700, lr=1.25e-05, gnorm=1.102, train_wall=53, wall=13418
2020-12-20 16:18:04 | INFO | train_inner | epoch 068:    221 / 337 symm_kl=0.592, self_kl=0, self_cv=29.405, loss=2.371, nll_loss=0.754, ppl=1.69, wps=32784.8, ups=1.87, wpb=17496.8, bsz=617.8, num_updates=22800, lr=1.25e-05, gnorm=1.105, train_wall=53, wall=13471
2020-12-20 16:18:56 | INFO | train_inner | epoch 068:    321 / 337 symm_kl=0.591, self_kl=0, self_cv=29.309, loss=2.372, nll_loss=0.752, ppl=1.68, wps=33327.5, ups=1.9, wpb=17517.2, bsz=600.6, num_updates=22900, lr=1.25e-05, gnorm=1.111, train_wall=52, wall=13523
2020-12-20 16:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:19:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:19:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:19:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:19:21 | INFO | valid | epoch 068 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.907 | nll_loss 4.217 | ppl 18.6 | bleu 22.68 | wps 6104.1 | wpb 11799.1 | bsz 428.6 | num_updates 22916 | best_bleu 22.91
2020-12-20 16:19:21 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:19:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:19:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 68 @ 22916 updates, score 22.68) (writing took 2.8586607947945595 seconds)
2020-12-20 16:19:23 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2020-12-20 16:19:23 | INFO | train | epoch 068 | symm_kl 0.589 | self_kl 0 | self_cv 29.275 | loss 2.367 | nll_loss 0.75 | ppl 1.68 | wps 29431.8 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 22916 | lr 1.25e-05 | gnorm 1.11 | train_wall 177 | wall 13551
2020-12-20 16:19:23 | INFO | fairseq.trainer | begin training epoch 69
2020-12-20 16:19:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:19:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:20:11 | INFO | train_inner | epoch 069:     84 / 337 symm_kl=0.587, self_kl=0, self_cv=29.308, loss=2.363, nll_loss=0.749, ppl=1.68, wps=23301.2, ups=1.35, wpb=17295.2, bsz=615.7, num_updates=23000, lr=1.25e-05, gnorm=1.125, train_wall=52, wall=13598
2020-12-20 16:21:04 | INFO | train_inner | epoch 069:    184 / 337 symm_kl=0.583, self_kl=0, self_cv=29.246, loss=2.354, nll_loss=0.744, ppl=1.67, wps=33205.8, ups=1.88, wpb=17694.3, bsz=628.7, num_updates=23100, lr=1.25e-05, gnorm=1.09, train_wall=53, wall=13651
2020-12-20 16:21:56 | INFO | train_inner | epoch 069:    284 / 337 symm_kl=0.591, self_kl=0, self_cv=29.519, loss=2.364, nll_loss=0.753, ppl=1.68, wps=33177.9, ups=1.9, wpb=17463.4, bsz=601.9, num_updates=23200, lr=1.25e-05, gnorm=1.139, train_wall=52, wall=13704
2020-12-20 16:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:22:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:22:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:22:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:22:40 | INFO | valid | epoch 069 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.905 | nll_loss 4.214 | ppl 18.56 | bleu 22.67 | wps 6127 | wpb 11799.1 | bsz 428.6 | num_updates 23253 | best_bleu 22.91
2020-12-20 16:22:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:22:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:22:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 69 @ 23253 updates, score 22.67) (writing took 2.941940749064088 seconds)
2020-12-20 16:22:43 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2020-12-20 16:22:43 | INFO | train | epoch 069 | symm_kl 0.588 | self_kl 0 | self_cv 29.397 | loss 2.362 | nll_loss 0.75 | ppl 1.68 | wps 29456.9 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 23253 | lr 1.25e-05 | gnorm 1.122 | train_wall 177 | wall 13750
2020-12-20 16:22:43 | INFO | fairseq.trainer | begin training epoch 70
2020-12-20 16:22:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:22:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:23:10 | INFO | train_inner | epoch 070:     47 / 337 symm_kl=0.587, self_kl=0, self_cv=29.272, loss=2.364, nll_loss=0.747, ppl=1.68, wps=23357, ups=1.35, wpb=17292.8, bsz=618.9, num_updates=23300, lr=1.25e-05, gnorm=1.135, train_wall=52, wall=13778
2020-12-20 16:24:04 | INFO | train_inner | epoch 070:    147 / 337 symm_kl=0.591, self_kl=0, self_cv=29.458, loss=2.367, nll_loss=0.753, ppl=1.69, wps=33035, ups=1.89, wpb=17521.2, bsz=615.6, num_updates=23400, lr=1.25e-05, gnorm=1.11, train_wall=53, wall=13831
2020-12-20 16:24:56 | INFO | train_inner | epoch 070:    247 / 337 symm_kl=0.586, self_kl=0, self_cv=29.491, loss=2.352, nll_loss=0.745, ppl=1.68, wps=33404.7, ups=1.9, wpb=17556.9, bsz=619, num_updates=23500, lr=1.25e-05, gnorm=1.11, train_wall=52, wall=13883
2020-12-20 16:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:25:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:25:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:25:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:25:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:25:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:25:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:26:00 | INFO | valid | epoch 070 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.909 | nll_loss 4.217 | ppl 18.6 | bleu 22.73 | wps 5994.3 | wpb 11799.1 | bsz 428.6 | num_updates 23590 | best_bleu 22.91
2020-12-20 16:26:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:26:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:26:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:26:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:26:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:26:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:26:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:26:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:26:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:26:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 70 @ 23590 updates, score 22.73) (writing took 2.950072145089507 seconds)
2020-12-20 16:26:03 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2020-12-20 16:26:03 | INFO | train | epoch 070 | symm_kl 0.589 | self_kl 0 | self_cv 29.483 | loss 2.36 | nll_loss 0.749 | ppl 1.68 | wps 29424 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 23590 | lr 1.25e-05 | gnorm 1.124 | train_wall 177 | wall 13950
2020-12-20 16:26:03 | INFO | fairseq.trainer | begin training epoch 71
2020-12-20 16:26:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:26:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:26:11 | INFO | train_inner | epoch 071:     10 / 337 symm_kl=0.597, self_kl=0, self_cv=29.793, loss=2.366, nll_loss=0.758, ppl=1.69, wps=22906.9, ups=1.33, wpb=17235.4, bsz=596.3, num_updates=23600, lr=1.25e-05, gnorm=1.163, train_wall=53, wall=13959
2020-12-20 16:27:04 | INFO | train_inner | epoch 071:    110 / 337 symm_kl=0.588, self_kl=0, self_cv=29.673, loss=2.353, nll_loss=0.753, ppl=1.68, wps=33429.5, ups=1.9, wpb=17564.4, bsz=617.2, num_updates=23700, lr=1.25e-05, gnorm=1.102, train_wall=52, wall=14011
2020-12-20 16:27:57 | INFO | train_inner | epoch 071:    210 / 337 symm_kl=0.591, self_kl=0, self_cv=29.566, loss=2.363, nll_loss=0.753, ppl=1.68, wps=33179.6, ups=1.9, wpb=17476.4, bsz=616.2, num_updates=23800, lr=1.25e-05, gnorm=1.131, train_wall=53, wall=14064
2020-12-20 16:28:49 | INFO | train_inner | epoch 071:    310 / 337 symm_kl=0.585, self_kl=0, self_cv=29.588, loss=2.345, nll_loss=0.745, ppl=1.68, wps=33096.8, ups=1.9, wpb=17424.5, bsz=632.6, num_updates=23900, lr=1.25e-05, gnorm=1.177, train_wall=52, wall=14116
2020-12-20 16:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:29:19 | INFO | valid | epoch 071 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.909 | nll_loss 4.218 | ppl 18.62 | bleu 22.72 | wps 6353.7 | wpb 11799.1 | bsz 428.6 | num_updates 23927 | best_bleu 22.91
2020-12-20 16:29:19 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:29:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:29:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 71 @ 23927 updates, score 22.72) (writing took 2.860567955300212 seconds)
2020-12-20 16:29:22 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2020-12-20 16:29:22 | INFO | train | epoch 071 | symm_kl 0.588 | self_kl 0 | self_cv 29.603 | loss 2.353 | nll_loss 0.749 | ppl 1.68 | wps 29600 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 23927 | lr 1.25e-05 | gnorm 1.137 | train_wall 177 | wall 14149
2020-12-20 16:29:22 | INFO | fairseq.trainer | begin training epoch 72
2020-12-20 16:29:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:29:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:30:03 | INFO | train_inner | epoch 072:     73 / 337 symm_kl=0.59, self_kl=0, self_cv=29.833, loss=2.347, nll_loss=0.749, ppl=1.68, wps=23457.6, ups=1.36, wpb=17222.3, bsz=610.2, num_updates=24000, lr=1.25e-05, gnorm=1.145, train_wall=52, wall=14190
2020-12-20 16:30:55 | INFO | train_inner | epoch 072:    173 / 337 symm_kl=0.592, self_kl=0, self_cv=29.921, loss=2.355, nll_loss=0.757, ppl=1.69, wps=33471.2, ups=1.9, wpb=17637.4, bsz=602.8, num_updates=24100, lr=1.25e-05, gnorm=1.122, train_wall=53, wall=14242
2020-12-20 16:31:48 | INFO | train_inner | epoch 072:    273 / 337 symm_kl=0.582, self_kl=0, self_cv=29.496, loss=2.342, nll_loss=0.744, ppl=1.67, wps=32975.8, ups=1.89, wpb=17446.8, bsz=637.4, num_updates=24200, lr=1.25e-05, gnorm=1.102, train_wall=53, wall=14295
2020-12-20 16:32:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:32:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:32:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:32:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:32:37 | INFO | valid | epoch 072 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.916 | nll_loss 4.226 | ppl 18.71 | bleu 22.76 | wps 6461.7 | wpb 11799.1 | bsz 428.6 | num_updates 24264 | best_bleu 22.91
2020-12-20 16:32:37 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:32:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:32:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 72 @ 24264 updates, score 22.76) (writing took 2.9102348275482655 seconds)
2020-12-20 16:32:40 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2020-12-20 16:32:40 | INFO | train | epoch 072 | symm_kl 0.587 | self_kl 0 | self_cv 29.739 | loss 2.348 | nll_loss 0.75 | ppl 1.68 | wps 29647.7 | ups 1.7 | wpb 17451.5 | bsz 615.4 | num_updates 24264 | lr 1.25e-05 | gnorm 1.131 | train_wall 176 | wall 14347
2020-12-20 16:32:40 | INFO | fairseq.trainer | begin training epoch 73
2020-12-20 16:32:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:32:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:33:02 | INFO | train_inner | epoch 073:     36 / 337 symm_kl=0.585, self_kl=0, self_cv=29.729, loss=2.341, nll_loss=0.745, ppl=1.68, wps=23773.5, ups=1.36, wpb=17467.2, bsz=591.5, num_updates=24300, lr=1.25e-05, gnorm=1.176, train_wall=52, wall=14369
2020-12-20 16:33:54 | INFO | train_inner | epoch 073:    136 / 337 symm_kl=0.591, self_kl=0, self_cv=30.027, loss=2.343, nll_loss=0.75, ppl=1.68, wps=32758.2, ups=1.9, wpb=17264.3, bsz=611.2, num_updates=24400, lr=1.25e-05, gnorm=1.222, train_wall=53, wall=14422
2020-12-20 16:34:47 | INFO | train_inner | epoch 073:    236 / 337 symm_kl=0.579, self_kl=0, self_cv=29.48, loss=2.337, nll_loss=0.741, ppl=1.67, wps=33249.7, ups=1.89, wpb=17624.5, bsz=640.6, num_updates=24500, lr=1.25e-05, gnorm=1.281, train_wall=53, wall=14475
2020-12-20 16:35:40 | INFO | train_inner | epoch 073:    336 / 337 symm_kl=0.594, self_kl=0, self_cv=29.931, loss=2.36, nll_loss=0.76, ppl=1.69, wps=33201.8, ups=1.9, wpb=17518.5, bsz=605.6, num_updates=24600, lr=1.25e-05, gnorm=1.117, train_wall=53, wall=14527
2020-12-20 16:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:35:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:35:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:35:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:35:56 | INFO | valid | epoch 073 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.915 | nll_loss 4.224 | ppl 18.69 | bleu 22.72 | wps 6406.7 | wpb 11799.1 | bsz 428.6 | num_updates 24601 | best_bleu 22.91
2020-12-20 16:35:56 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-20 16:35:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:35:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:35:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/cv/checkpoint_last.pt (epoch 73 @ 24601 updates, score 22.72) (writing took 2.9139364920556545 seconds)
2020-12-20 16:35:59 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2020-12-20 16:35:59 | INFO | train | epoch 073 | symm_kl 0.588 | self_kl 0 | self_cv 29.831 | loss 2.346 | nll_loss 0.75 | ppl 1.68 | wps 29569.1 | ups 1.69 | wpb 17451.5 | bsz 615.4 | num_updates 24601 | lr 1.25e-05 | gnorm 1.208 | train_wall 177 | wall 14546
2020-12-20 16:35:59 | INFO | fairseq.trainer | begin training epoch 74
2020-12-20 16:36:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:36:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:36:54 | INFO | train_inner | epoch 074:     99 / 337 symm_kl=0.582, self_kl=0, self_cv=29.778, loss=2.335, nll_loss=0.746, ppl=1.68, wps=23623.1, ups=1.35, wpb=17477.8, bsz=624.5, num_updates=24700, lr=1.25e-05, gnorm=1.124, train_wall=52, wall=14601
2020-12-20 16:37:47 | INFO | train_inner | epoch 074:    199 / 337 symm_kl=0.59, self_kl=0, self_cv=29.93, loss=2.347, nll_loss=0.751, ppl=1.68, wps=33313.3, ups=1.89, wpb=17613.3, bsz=605.6, num_updates=24800, lr=1.25e-05, gnorm=1.145, train_wall=53, wall=14654
2020-12-20 16:38:40 | INFO | train_inner | epoch 074:    299 / 337 symm_kl=0.59, self_kl=0, self_cv=30.079, loss=2.34, nll_loss=0.752, ppl=1.68, wps=32830.2, ups=1.9, wpb=17264.8, bsz=612.9, num_updates=24900, lr=1.25e-05, gnorm=1.145, train_wall=52, wall=14707
2020-12-20 16:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-20 16:39:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:39:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:39:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:39:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:39:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-20 16:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-20 16:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-20 16:39:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-20 16:39:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-20 16:39:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 362, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 740 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
