nohup: ignoring input
save_dir=./examples/entr/bash/../checkpoints/noised_input
criterion=label_smoothed_cross_entropy_r3f_noised_input
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=3000
max_epoch=200
r3f_lambda=1
extr='--warmup-init-lr 1e-07'
2021-01-14 19:02:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-14 19:02:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-14 19:02:13 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f_noised_input', cross_self_attention=False, curriculum=0, cv_lambda=0.0, data='./examples/entr/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=10000, max_tokens_valid=10000, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/entr/bash/../checkpoints/noised_input', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='tr', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=3000, weight_decay=0.0, zero_sharding='none')
2021-01-14 19:02:13 | INFO | fairseq.tasks.translation | [en] dictionary: 19784 types
2021-01-14 19:02:13 | INFO | fairseq.tasks.translation | [tr] dictionary: 19784 types
2021-01-14 19:02:13 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.en
2021-01-14 19:02:13 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.tr
2021-01-14 19:02:13 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin valid en-tr 3000 examples
2021-01-14 19:02:14 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19784, bias=False)
  )
)
2021-01-14 19:02:14 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-01-14 19:02:14 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2021-01-14 19:02:14 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f_noised_input (NoisedInputCriterion)
2021-01-14 19:02:14 | INFO | fairseq_cli.train | num. model params: 54267904 (num. trained: 54267904)
2021-01-14 19:02:17 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-01-14 19:02:17 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-01-14 19:02:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-01-14 19:02:17 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-01-14 19:02:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-01-14 19:02:17 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-01-14 19:02:17 | INFO | fairseq_cli.train | max tokens per GPU = 10000 and max sentences per GPU = None
2021-01-14 19:02:18 | INFO | fairseq.optim.adam | using FusedAdam
2021-01-14 19:02:18 | INFO | fairseq.trainer | loaded checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 25 @ 16392 updates)
2021-01-14 19:02:18 | INFO | fairseq.trainer | loading train data for epoch 25
2021-01-14 19:02:18 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.en
2021-01-14 19:02:18 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.tr
2021-01-14 19:02:18 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin train en-tr 207373 examples
2021-01-14 19:02:19 | INFO | fairseq.trainer | begin training epoch 25
2021-01-14 19:02:26 | INFO | train_inner | epoch 025:      8 / 683 symm_kl=0, loss=2.633, nll_loss=0.811, ppl=1.75, wps=6843, ups=0.8, wpb=8589.1, bsz=298, num_updates=16400, lr=1.7108e-05, gnorm=0.782, train_wall=87, wall=0
2021-01-14 19:03:53 | INFO | train_inner | epoch 025:    108 / 683 symm_kl=0, loss=2.588, nll_loss=0.758, ppl=1.69, wps=9844.3, ups=1.15, wpb=8545.7, bsz=300.6, num_updates=16500, lr=1.70561e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-14 19:05:20 | INFO | train_inner | epoch 025:    208 / 683 symm_kl=0, loss=2.58, nll_loss=0.75, ppl=1.68, wps=9908.3, ups=1.16, wpb=8575, bsz=310.1, num_updates=16600, lr=1.70046e-05, gnorm=0.708, train_wall=86, wall=0
2021-01-14 19:06:46 | INFO | train_inner | epoch 025:    308 / 683 symm_kl=0, loss=2.602, nll_loss=0.774, ppl=1.71, wps=10033.4, ups=1.16, wpb=8638.3, bsz=286.4, num_updates=16700, lr=1.69536e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 19:08:12 | INFO | train_inner | epoch 025:    408 / 683 symm_kl=0, loss=2.592, nll_loss=0.763, ppl=1.7, wps=9989.2, ups=1.16, wpb=8635.8, bsz=303.5, num_updates=16800, lr=1.69031e-05, gnorm=0.709, train_wall=86, wall=0
2021-01-14 19:09:38 | INFO | train_inner | epoch 025:    508 / 683 symm_kl=0, loss=2.593, nll_loss=0.764, ppl=1.7, wps=9996.6, ups=1.17, wpb=8569.1, bsz=304, num_updates=16900, lr=1.6853e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-14 19:11:05 | INFO | train_inner | epoch 025:    608 / 683 symm_kl=0, loss=2.582, nll_loss=0.754, ppl=1.69, wps=9957.1, ups=1.15, wpb=8648.5, bsz=330.9, num_updates=17000, lr=1.68034e-05, gnorm=0.708, train_wall=87, wall=0
2021-01-14 19:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 19:12:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:12:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:12:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:12:47 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | loss 5.852 | nll_loss 4.271 | ppl 19.3 | bleu 21.9 | wps 2241.4 | wpb 6353.4 | bsz 230.8 | num_updates 17075 | best_bleu 22.02
2021-01-14 19:12:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 19:12:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 25 @ 17075 updates, score 21.9) (writing took 2.7385219894349575 seconds)
2021-01-14 19:12:50 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-01-14 19:12:50 | INFO | train | epoch 025 | symm_kl 0 | loss 2.613 | nll_loss 0.787 | ppl 1.72 | wps 9342.8 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 17075 | lr 1.67664e-05 | gnorm 0.745 | train_wall 1178 | wall 0
2021-01-14 19:12:50 | INFO | fairseq.trainer | begin training epoch 26
2021-01-14 19:13:11 | INFO | train_inner | epoch 026:     25 / 683 symm_kl=0, loss=2.594, nll_loss=0.764, ppl=1.7, wps=6852.4, ups=0.79, wpb=8662.5, bsz=284.8, num_updates=17100, lr=1.67542e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-14 19:14:37 | INFO | train_inner | epoch 026:    125 / 683 symm_kl=0, loss=2.575, nll_loss=0.747, ppl=1.68, wps=9887.1, ups=1.16, wpb=8534.9, bsz=307.1, num_updates=17200, lr=1.67054e-05, gnorm=0.714, train_wall=86, wall=0
2021-01-14 19:16:04 | INFO | train_inner | epoch 026:    225 / 683 symm_kl=0, loss=2.598, nll_loss=0.769, ppl=1.7, wps=10125.4, ups=1.15, wpb=8767.2, bsz=317.4, num_updates=17300, lr=1.6657e-05, gnorm=0.708, train_wall=86, wall=0
2021-01-14 19:17:31 | INFO | train_inner | epoch 026:    325 / 683 symm_kl=0, loss=2.591, nll_loss=0.759, ppl=1.69, wps=9872.1, ups=1.15, wpb=8553, bsz=281.4, num_updates=17400, lr=1.66091e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-14 19:18:57 | INFO | train_inner | epoch 026:    425 / 683 symm_kl=0, loss=2.581, nll_loss=0.752, ppl=1.68, wps=10057.5, ups=1.15, wpb=8710.4, bsz=300.2, num_updates=17500, lr=1.65616e-05, gnorm=0.705, train_wall=86, wall=0
2021-01-14 19:20:25 | INFO | train_inner | epoch 026:    525 / 683 symm_kl=0, loss=2.57, nll_loss=0.742, ppl=1.67, wps=10011.3, ups=1.14, wpb=8766.8, bsz=315.3, num_updates=17600, lr=1.65145e-05, gnorm=0.696, train_wall=87, wall=0
2021-01-14 19:21:51 | INFO | train_inner | epoch 026:    625 / 683 symm_kl=0, loss=2.598, nll_loss=0.769, ppl=1.7, wps=10120.2, ups=1.17, wpb=8681.1, bsz=313.1, num_updates=17700, lr=1.64677e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-14 19:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 19:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:22:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:22:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:22:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:23:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:23:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:23:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:23:15 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | loss 5.857 | nll_loss 4.275 | ppl 19.36 | bleu 21.87 | wps 2349.4 | wpb 6353.4 | bsz 230.8 | num_updates 17758 | best_bleu 22.02
2021-01-14 19:23:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 19:23:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 26 @ 17758 updates, score 21.87) (writing took 2.6490050349384546 seconds)
2021-01-14 19:23:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-01-14 19:23:18 | INFO | train | epoch 026 | symm_kl 0 | loss 2.587 | nll_loss 0.758 | ppl 1.69 | wps 9371 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 17758 | lr 1.64408e-05 | gnorm 0.718 | train_wall 588 | wall 0
2021-01-14 19:23:18 | INFO | fairseq.trainer | begin training epoch 27
2021-01-14 19:23:53 | INFO | train_inner | epoch 027:     42 / 683 symm_kl=0, loss=2.593, nll_loss=0.762, ppl=1.7, wps=6773.7, ups=0.82, wpb=8277.3, bsz=288, num_updates=17800, lr=1.64214e-05, gnorm=0.749, train_wall=84, wall=0
2021-01-14 19:25:20 | INFO | train_inner | epoch 027:    142 / 683 symm_kl=0, loss=2.573, nll_loss=0.745, ppl=1.68, wps=10089.1, ups=1.14, wpb=8831.9, bsz=330.8, num_updates=17900, lr=1.63755e-05, gnorm=0.688, train_wall=87, wall=0
2021-01-14 19:26:47 | INFO | train_inner | epoch 027:    242 / 683 symm_kl=0, loss=2.577, nll_loss=0.747, ppl=1.68, wps=9965.7, ups=1.15, wpb=8650.4, bsz=316.6, num_updates=18000, lr=1.63299e-05, gnorm=0.707, train_wall=87, wall=0
2021-01-14 19:28:13 | INFO | train_inner | epoch 027:    342 / 683 symm_kl=0, loss=2.592, nll_loss=0.763, ppl=1.7, wps=10059.2, ups=1.16, wpb=8656, bsz=302.5, num_updates=18100, lr=1.62848e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-14 19:29:39 | INFO | train_inner | epoch 027:    442 / 683 symm_kl=0, loss=2.601, nll_loss=0.771, ppl=1.71, wps=9949.3, ups=1.17, wpb=8490.1, bsz=286.1, num_updates=18200, lr=1.624e-05, gnorm=0.732, train_wall=85, wall=0
2021-01-14 19:31:06 | INFO | train_inner | epoch 027:    542 / 683 symm_kl=0, loss=2.58, nll_loss=0.751, ppl=1.68, wps=9932.5, ups=1.15, wpb=8670.9, bsz=315.9, num_updates=18300, lr=1.61955e-05, gnorm=0.703, train_wall=87, wall=0
2021-01-14 19:32:32 | INFO | train_inner | epoch 027:    642 / 683 symm_kl=0, loss=2.596, nll_loss=0.766, ppl=1.7, wps=9658.2, ups=1.16, wpb=8328.4, bsz=284.9, num_updates=18400, lr=1.61515e-05, gnorm=0.754, train_wall=86, wall=0
2021-01-14 19:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 19:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:33:44 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | loss 5.861 | nll_loss 4.28 | ppl 19.42 | bleu 21.91 | wps 2348.5 | wpb 6353.4 | bsz 230.8 | num_updates 18441 | best_bleu 22.02
2021-01-14 19:33:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 19:33:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 27 @ 18441 updates, score 21.91) (writing took 2.746024314314127 seconds)
2021-01-14 19:33:46 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-01-14 19:33:46 | INFO | train | epoch 027 | symm_kl 0 | loss 2.586 | nll_loss 0.756 | ppl 1.69 | wps 9353.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 18441 | lr 1.61335e-05 | gnorm 0.717 | train_wall 589 | wall 0
2021-01-14 19:33:46 | INFO | fairseq.trainer | begin training epoch 28
2021-01-14 19:34:38 | INFO | train_inner | epoch 028:     59 / 683 symm_kl=0, loss=2.583, nll_loss=0.753, ppl=1.69, wps=7002.7, ups=0.8, wpb=8791.5, bsz=308.3, num_updates=18500, lr=1.61077e-05, gnorm=0.699, train_wall=87, wall=0
2021-01-14 19:36:06 | INFO | train_inner | epoch 028:    159 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=9668.7, ups=1.14, wpb=8516.9, bsz=302.5, num_updates=18600, lr=1.60644e-05, gnorm=0.71, train_wall=88, wall=0
2021-01-14 19:37:32 | INFO | train_inner | epoch 028:    259 / 683 symm_kl=0, loss=2.578, nll_loss=0.749, ppl=1.68, wps=9971.1, ups=1.16, wpb=8619.8, bsz=305.5, num_updates=18700, lr=1.60214e-05, gnorm=0.717, train_wall=86, wall=0
2021-01-14 19:38:58 | INFO | train_inner | epoch 028:    359 / 683 symm_kl=0, loss=2.596, nll_loss=0.768, ppl=1.7, wps=9951.4, ups=1.16, wpb=8560.8, bsz=331.1, num_updates=18800, lr=1.59787e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 19:40:24 | INFO | train_inner | epoch 028:    459 / 683 symm_kl=0, loss=2.594, nll_loss=0.764, ppl=1.7, wps=10015.3, ups=1.17, wpb=8562.4, bsz=289.8, num_updates=18900, lr=1.59364e-05, gnorm=0.728, train_wall=85, wall=0
2021-01-14 19:41:50 | INFO | train_inner | epoch 028:    559 / 683 symm_kl=0, loss=2.585, nll_loss=0.755, ppl=1.69, wps=10108.2, ups=1.16, wpb=8743.2, bsz=291.3, num_updates=19000, lr=1.58944e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-14 19:43:17 | INFO | train_inner | epoch 028:    659 / 683 symm_kl=0, loss=2.586, nll_loss=0.757, ppl=1.69, wps=10107.8, ups=1.16, wpb=8729.6, bsz=296.4, num_updates=19100, lr=1.58527e-05, gnorm=0.712, train_wall=86, wall=0
2021-01-14 19:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 19:43:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:43:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:43:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:43:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:44:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:44:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:44:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:44:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:44:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:44:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:44:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:44:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:44:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:44:12 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | loss 5.869 | nll_loss 4.288 | ppl 19.53 | bleu 22.01 | wps 2390.2 | wpb 6353.4 | bsz 230.8 | num_updates 19124 | best_bleu 22.02
2021-01-14 19:44:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 19:44:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 28 @ 19124 updates, score 22.01) (writing took 1.7931578159332275 seconds)
2021-01-14 19:44:13 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-01-14 19:44:13 | INFO | train | epoch 028 | symm_kl 0 | loss 2.584 | nll_loss 0.754 | ppl 1.69 | wps 9377.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 19124 | lr 1.58428e-05 | gnorm 0.717 | train_wall 589 | wall 0
2021-01-14 19:44:13 | INFO | fairseq.trainer | begin training epoch 29
2021-01-14 19:45:19 | INFO | train_inner | epoch 029:     76 / 683 symm_kl=0, loss=2.588, nll_loss=0.756, ppl=1.69, wps=6935.9, ups=0.81, wpb=8527.5, bsz=299, num_updates=19200, lr=1.58114e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-14 19:46:47 | INFO | train_inner | epoch 029:    176 / 683 symm_kl=0, loss=2.574, nll_loss=0.744, ppl=1.68, wps=10148.8, ups=1.15, wpb=8844.2, bsz=299.8, num_updates=19300, lr=1.57704e-05, gnorm=0.693, train_wall=87, wall=0
2021-01-14 19:48:12 | INFO | train_inner | epoch 029:    276 / 683 symm_kl=0, loss=2.584, nll_loss=0.754, ppl=1.69, wps=10012.2, ups=1.17, wpb=8580.7, bsz=300.6, num_updates=19400, lr=1.57297e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 19:49:37 | INFO | train_inner | epoch 029:    376 / 683 symm_kl=0, loss=2.592, nll_loss=0.762, ppl=1.7, wps=9856.6, ups=1.18, wpb=8385.2, bsz=305.3, num_updates=19500, lr=1.56893e-05, gnorm=0.746, train_wall=85, wall=0
2021-01-14 19:51:02 | INFO | train_inner | epoch 029:    476 / 683 symm_kl=0, loss=2.582, nll_loss=0.753, ppl=1.68, wps=9758.4, ups=1.18, wpb=8281.9, bsz=303.8, num_updates=19600, lr=1.56492e-05, gnorm=0.739, train_wall=85, wall=0
2021-01-14 19:52:29 | INFO | train_inner | epoch 029:    576 / 683 symm_kl=0, loss=2.584, nll_loss=0.755, ppl=1.69, wps=10103.9, ups=1.16, wpb=8746.1, bsz=315.4, num_updates=19700, lr=1.56094e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-14 19:53:56 | INFO | train_inner | epoch 029:    676 / 683 symm_kl=0, loss=2.576, nll_loss=0.746, ppl=1.68, wps=9970.1, ups=1.15, wpb=8680.1, bsz=296.8, num_updates=19800, lr=1.557e-05, gnorm=0.708, train_wall=87, wall=0
2021-01-14 19:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 19:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 19:54:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 19:54:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 19:54:38 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | loss 5.865 | nll_loss 4.285 | ppl 19.5 | bleu 21.83 | wps 2338.6 | wpb 6353.4 | bsz 230.8 | num_updates 19807 | best_bleu 22.02
2021-01-14 19:54:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 19:54:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 29 @ 19807 updates, score 21.83) (writing took 2.8082126434892416 seconds)
2021-01-14 19:54:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-01-14 19:54:41 | INFO | train | epoch 029 | symm_kl 0 | loss 2.582 | nll_loss 0.752 | ppl 1.68 | wps 9378 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 19807 | lr 1.55672e-05 | gnorm 0.718 | train_wall 587 | wall 0
2021-01-14 19:54:41 | INFO | fairseq.trainer | begin training epoch 30
2021-01-14 19:56:00 | INFO | train_inner | epoch 030:     93 / 683 symm_kl=0, loss=2.577, nll_loss=0.747, ppl=1.68, wps=6796, ups=0.81, wpb=8433.8, bsz=292.5, num_updates=19900, lr=1.55308e-05, gnorm=0.726, train_wall=85, wall=0
2021-01-14 19:57:25 | INFO | train_inner | epoch 030:    193 / 683 symm_kl=0, loss=2.574, nll_loss=0.744, ppl=1.68, wps=9938, ups=1.17, wpb=8491.4, bsz=307.8, num_updates=20000, lr=1.54919e-05, gnorm=0.719, train_wall=85, wall=0
2021-01-14 19:58:53 | INFO | train_inner | epoch 030:    293 / 683 symm_kl=0, loss=2.578, nll_loss=0.749, ppl=1.68, wps=10076.6, ups=1.14, wpb=8807, bsz=299.7, num_updates=20100, lr=1.54533e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-14 20:00:19 | INFO | train_inner | epoch 030:    393 / 683 symm_kl=0, loss=2.583, nll_loss=0.752, ppl=1.68, wps=9961.3, ups=1.16, wpb=8622.4, bsz=279.3, num_updates=20200, lr=1.5415e-05, gnorm=0.723, train_wall=86, wall=0
2021-01-14 20:01:45 | INFO | train_inner | epoch 030:    493 / 683 symm_kl=0, loss=2.586, nll_loss=0.757, ppl=1.69, wps=9933.9, ups=1.17, wpb=8483.3, bsz=325, num_updates=20300, lr=1.5377e-05, gnorm=0.731, train_wall=85, wall=0
2021-01-14 20:03:12 | INFO | train_inner | epoch 030:    593 / 683 symm_kl=0, loss=2.578, nll_loss=0.75, ppl=1.68, wps=10246.1, ups=1.15, wpb=8933.9, bsz=329.3, num_updates=20400, lr=1.53393e-05, gnorm=0.689, train_wall=87, wall=0
2021-01-14 20:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:04:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:04:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:04:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:04:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:05:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:05:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:05:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:05:05 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | loss 5.866 | nll_loss 4.285 | ppl 19.5 | bleu 21.84 | wps 2319 | wpb 6353.4 | bsz 230.8 | num_updates 20490 | best_bleu 22.02
2021-01-14 20:05:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:05:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 30 @ 20490 updates, score 21.84) (writing took 3.0665810592472553 seconds)
2021-01-14 20:05:08 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-01-14 20:05:08 | INFO | train | epoch 030 | symm_kl 0 | loss 2.58 | nll_loss 0.751 | ppl 1.68 | wps 9366.3 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 20490 | lr 1.53056e-05 | gnorm 0.718 | train_wall 588 | wall 0
2021-01-14 20:05:08 | INFO | fairseq.trainer | begin training epoch 31
2021-01-14 20:05:17 | INFO | train_inner | epoch 031:     10 / 683 symm_kl=0, loss=2.587, nll_loss=0.756, ppl=1.69, wps=6808.5, ups=0.8, wpb=8483.6, bsz=289.8, num_updates=20500, lr=1.53018e-05, gnorm=0.729, train_wall=85, wall=0
2021-01-14 20:06:43 | INFO | train_inner | epoch 031:    110 / 683 symm_kl=0, loss=2.578, nll_loss=0.748, ppl=1.68, wps=9991, ups=1.16, wpb=8632.8, bsz=343.6, num_updates=20600, lr=1.52647e-05, gnorm=0.708, train_wall=86, wall=0
2021-01-14 20:08:10 | INFO | train_inner | epoch 031:    210 / 683 symm_kl=0, loss=2.581, nll_loss=0.751, ppl=1.68, wps=9943.7, ups=1.14, wpb=8692.6, bsz=301.3, num_updates=20700, lr=1.52277e-05, gnorm=0.706, train_wall=87, wall=0
2021-01-14 20:09:37 | INFO | train_inner | epoch 031:    310 / 683 symm_kl=0, loss=2.575, nll_loss=0.744, ppl=1.68, wps=9810.4, ups=1.16, wpb=8467, bsz=295.5, num_updates=20800, lr=1.51911e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-14 20:11:03 | INFO | train_inner | epoch 031:    410 / 683 symm_kl=0, loss=2.582, nll_loss=0.75, ppl=1.68, wps=10004, ups=1.15, wpb=8665.2, bsz=296.9, num_updates=20900, lr=1.51547e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 20:12:30 | INFO | train_inner | epoch 031:    510 / 683 symm_kl=0, loss=2.584, nll_loss=0.754, ppl=1.69, wps=9937.7, ups=1.16, wpb=8585.7, bsz=294.5, num_updates=21000, lr=1.51186e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-14 20:13:55 | INFO | train_inner | epoch 031:    610 / 683 symm_kl=0, loss=2.58, nll_loss=0.751, ppl=1.68, wps=10018.9, ups=1.17, wpb=8591.9, bsz=292, num_updates=21100, lr=1.50827e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-14 20:14:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:15:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:15:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:15:34 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | loss 5.874 | nll_loss 4.292 | ppl 19.59 | bleu 21.92 | wps 2366.8 | wpb 6353.4 | bsz 230.8 | num_updates 21173 | best_bleu 22.02
2021-01-14 20:15:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:15:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 31 @ 21173 updates, score 21.92) (writing took 2.7202460821717978 seconds)
2021-01-14 20:15:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-01-14 20:15:37 | INFO | train | epoch 031 | symm_kl 0 | loss 2.579 | nll_loss 0.749 | ppl 1.68 | wps 9359.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 21173 | lr 1.50567e-05 | gnorm 0.718 | train_wall 589 | wall 0
2021-01-14 20:15:37 | INFO | fairseq.trainer | begin training epoch 32
2021-01-14 20:16:00 | INFO | train_inner | epoch 032:     27 / 683 symm_kl=0, loss=2.576, nll_loss=0.747, ppl=1.68, wps=6984.4, ups=0.8, wpb=8685.6, bsz=304.5, num_updates=21200, lr=1.50471e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-14 20:17:28 | INFO | train_inner | epoch 032:    127 / 683 symm_kl=0, loss=2.573, nll_loss=0.743, ppl=1.67, wps=10126.8, ups=1.14, wpb=8898, bsz=315.2, num_updates=21300, lr=1.50117e-05, gnorm=0.697, train_wall=88, wall=0
2021-01-14 20:18:55 | INFO | train_inner | epoch 032:    227 / 683 symm_kl=0, loss=2.583, nll_loss=0.752, ppl=1.68, wps=9966.6, ups=1.15, wpb=8651.6, bsz=288.1, num_updates=21400, lr=1.49766e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-14 20:20:20 | INFO | train_inner | epoch 032:    327 / 683 symm_kl=0, loss=2.566, nll_loss=0.736, ppl=1.67, wps=9859.6, ups=1.17, wpb=8445.4, bsz=312.7, num_updates=21500, lr=1.49417e-05, gnorm=0.712, train_wall=85, wall=0
2021-01-14 20:21:45 | INFO | train_inner | epoch 032:    427 / 683 symm_kl=0, loss=2.575, nll_loss=0.745, ppl=1.68, wps=10007.4, ups=1.17, wpb=8540.3, bsz=293.5, num_updates=21600, lr=1.49071e-05, gnorm=0.723, train_wall=85, wall=0
2021-01-14 20:23:11 | INFO | train_inner | epoch 032:    527 / 683 symm_kl=0, loss=2.591, nll_loss=0.76, ppl=1.69, wps=10122.9, ups=1.17, wpb=8684.8, bsz=286.3, num_updates=21700, lr=1.48727e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-14 20:24:37 | INFO | train_inner | epoch 032:    627 / 683 symm_kl=0, loss=2.578, nll_loss=0.75, ppl=1.68, wps=9971.4, ups=1.17, wpb=8542.3, bsz=331.3, num_updates=21800, lr=1.48386e-05, gnorm=0.719, train_wall=85, wall=0
2021-01-14 20:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:25:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:25:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:25:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:25:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:26:00 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | loss 5.87 | nll_loss 4.289 | ppl 19.55 | bleu 21.94 | wps 2372 | wpb 6353.4 | bsz 230.8 | num_updates 21856 | best_bleu 22.02
2021-01-14 20:26:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:26:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 32 @ 21856 updates, score 21.94) (writing took 2.765614904463291 seconds)
2021-01-14 20:26:03 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-01-14 20:26:03 | INFO | train | epoch 032 | symm_kl 0 | loss 2.578 | nll_loss 0.748 | ppl 1.68 | wps 9393.1 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 21856 | lr 1.48196e-05 | gnorm 0.718 | train_wall 586 | wall 0
2021-01-14 20:26:03 | INFO | fairseq.trainer | begin training epoch 33
2021-01-14 20:26:41 | INFO | train_inner | epoch 033:     44 / 683 symm_kl=0, loss=2.578, nll_loss=0.748, ppl=1.68, wps=7024.5, ups=0.8, wpb=8729.9, bsz=283, num_updates=21900, lr=1.48047e-05, gnorm=0.715, train_wall=85, wall=0
2021-01-14 20:28:07 | INFO | train_inner | epoch 033:    144 / 683 symm_kl=0, loss=2.571, nll_loss=0.741, ppl=1.67, wps=9781.1, ups=1.17, wpb=8390.5, bsz=299.7, num_updates=22000, lr=1.4771e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-14 20:29:34 | INFO | train_inner | epoch 033:    244 / 683 symm_kl=0, loss=2.573, nll_loss=0.744, ppl=1.67, wps=10095.3, ups=1.15, wpb=8775.1, bsz=309.8, num_updates=22100, lr=1.47375e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-14 20:31:01 | INFO | train_inner | epoch 033:    344 / 683 symm_kl=0, loss=2.58, nll_loss=0.751, ppl=1.68, wps=10017.6, ups=1.16, wpb=8671.5, bsz=323.9, num_updates=22200, lr=1.47043e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-14 20:32:27 | INFO | train_inner | epoch 033:    444 / 683 symm_kl=0, loss=2.581, nll_loss=0.751, ppl=1.68, wps=9988.4, ups=1.16, wpb=8604.6, bsz=306.3, num_updates=22300, lr=1.46713e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-14 20:33:53 | INFO | train_inner | epoch 033:    544 / 683 symm_kl=0, loss=2.585, nll_loss=0.753, ppl=1.69, wps=9820.7, ups=1.16, wpb=8436.7, bsz=294.8, num_updates=22400, lr=1.46385e-05, gnorm=0.738, train_wall=86, wall=0
2021-01-14 20:35:18 | INFO | train_inner | epoch 033:    644 / 683 symm_kl=0, loss=2.569, nll_loss=0.74, ppl=1.67, wps=9960.7, ups=1.17, wpb=8541.4, bsz=315.2, num_updates=22500, lr=1.46059e-05, gnorm=0.71, train_wall=86, wall=0
2021-01-14 20:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:35:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:35:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:35:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:35:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:35:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:35:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:36:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:36:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:36:27 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | loss 5.868 | nll_loss 4.29 | ppl 19.56 | bleu 22.03 | wps 2387.3 | wpb 6353.4 | bsz 230.8 | num_updates 22539 | best_bleu 22.03
2021-01-14 20:36:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:36:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_best.pt (epoch 33 @ 22539 updates, score 22.03) (writing took 4.6026877127587795 seconds)
2021-01-14 20:36:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-01-14 20:36:32 | INFO | train | epoch 033 | symm_kl 0 | loss 2.577 | nll_loss 0.747 | ppl 1.68 | wps 9348.8 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 22539 | lr 1.45933e-05 | gnorm 0.718 | train_wall 588 | wall 0
2021-01-14 20:36:32 | INFO | fairseq.trainer | begin training epoch 34
2021-01-14 20:37:24 | INFO | train_inner | epoch 034:     61 / 683 symm_kl=0, loss=2.576, nll_loss=0.745, ppl=1.68, wps=6897.9, ups=0.79, wpb=8701.1, bsz=292.8, num_updates=22600, lr=1.45736e-05, gnorm=0.711, train_wall=86, wall=0
2021-01-14 20:38:51 | INFO | train_inner | epoch 034:    161 / 683 symm_kl=0, loss=2.582, nll_loss=0.752, ppl=1.68, wps=9889.1, ups=1.15, wpb=8605.7, bsz=307.3, num_updates=22700, lr=1.45414e-05, gnorm=0.723, train_wall=87, wall=0
2021-01-14 20:40:18 | INFO | train_inner | epoch 034:    261 / 683 symm_kl=0, loss=2.557, nll_loss=0.727, ppl=1.66, wps=9958.5, ups=1.15, wpb=8639.3, bsz=322.4, num_updates=22800, lr=1.45095e-05, gnorm=0.702, train_wall=87, wall=0
2021-01-14 20:41:45 | INFO | train_inner | epoch 034:    361 / 683 symm_kl=0, loss=2.585, nll_loss=0.754, ppl=1.69, wps=9823.8, ups=1.16, wpb=8496.7, bsz=285.6, num_updates=22900, lr=1.44778e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-14 20:43:11 | INFO | train_inner | epoch 034:    461 / 683 symm_kl=0, loss=2.577, nll_loss=0.747, ppl=1.68, wps=9984.3, ups=1.16, wpb=8625.2, bsz=313, num_updates=23000, lr=1.44463e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 20:44:38 | INFO | train_inner | epoch 034:    561 / 683 symm_kl=0, loss=2.575, nll_loss=0.745, ppl=1.68, wps=10014.5, ups=1.16, wpb=8665.9, bsz=289, num_updates=23100, lr=1.4415e-05, gnorm=0.714, train_wall=86, wall=0
2021-01-14 20:46:04 | INFO | train_inner | epoch 034:    661 / 683 symm_kl=0, loss=2.577, nll_loss=0.748, ppl=1.68, wps=10070.2, ups=1.16, wpb=8665.9, bsz=308.9, num_updates=23200, lr=1.43839e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 20:46:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:46:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:46:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:46:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:46:58 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | loss 5.871 | nll_loss 4.292 | ppl 19.59 | bleu 21.85 | wps 2380.6 | wpb 6353.4 | bsz 230.8 | num_updates 23222 | best_bleu 22.03
2021-01-14 20:46:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:47:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 34 @ 23222 updates, score 21.85) (writing took 2.8196675088256598 seconds)
2021-01-14 20:47:01 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-01-14 20:47:01 | INFO | train | epoch 034 | symm_kl 0 | loss 2.576 | nll_loss 0.746 | ppl 1.68 | wps 9354.1 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 23222 | lr 1.43771e-05 | gnorm 0.72 | train_wall 589 | wall 0
2021-01-14 20:47:01 | INFO | fairseq.trainer | begin training epoch 35
2021-01-14 20:48:08 | INFO | train_inner | epoch 035:     78 / 683 symm_kl=0, loss=2.574, nll_loss=0.743, ppl=1.67, wps=6933.3, ups=0.8, wpb=8630.4, bsz=308.6, num_updates=23300, lr=1.4353e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 20:49:36 | INFO | train_inner | epoch 035:    178 / 683 symm_kl=0, loss=2.56, nll_loss=0.73, ppl=1.66, wps=9996.5, ups=1.14, wpb=8753.2, bsz=308.5, num_updates=23400, lr=1.43223e-05, gnorm=0.7, train_wall=87, wall=0
2021-01-14 20:51:03 | INFO | train_inner | epoch 035:    278 / 683 symm_kl=0, loss=2.585, nll_loss=0.753, ppl=1.69, wps=10038, ups=1.14, wpb=8771.2, bsz=307.2, num_updates=23500, lr=1.42918e-05, gnorm=0.714, train_wall=87, wall=0
2021-01-14 20:52:29 | INFO | train_inner | epoch 035:    378 / 683 symm_kl=0, loss=2.571, nll_loss=0.74, ppl=1.67, wps=9817.2, ups=1.17, wpb=8406.1, bsz=330.9, num_updates=23600, lr=1.42615e-05, gnorm=0.734, train_wall=85, wall=0
2021-01-14 20:53:55 | INFO | train_inner | epoch 035:    478 / 683 symm_kl=0, loss=2.58, nll_loss=0.75, ppl=1.68, wps=9899.6, ups=1.15, wpb=8572.6, bsz=280.6, num_updates=23700, lr=1.42314e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-14 20:55:21 | INFO | train_inner | epoch 035:    578 / 683 symm_kl=0, loss=2.577, nll_loss=0.746, ppl=1.68, wps=9932.8, ups=1.17, wpb=8518.3, bsz=278.4, num_updates=23800, lr=1.42014e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 20:56:48 | INFO | train_inner | epoch 035:    678 / 683 symm_kl=0, loss=2.58, nll_loss=0.75, ppl=1.68, wps=9836.9, ups=1.16, wpb=8515, bsz=308.6, num_updates=23900, lr=1.41717e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-14 20:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 20:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:56:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:56:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:56:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 20:57:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 20:57:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 20:57:27 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | loss 5.875 | nll_loss 4.295 | ppl 19.63 | bleu 21.87 | wps 2360.9 | wpb 6353.4 | bsz 230.8 | num_updates 23905 | best_bleu 22.03
2021-01-14 20:57:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 20:57:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 35 @ 23905 updates, score 21.87) (writing took 2.761130530387163 seconds)
2021-01-14 20:57:30 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-01-14 20:57:30 | INFO | train | epoch 035 | symm_kl 0 | loss 2.575 | nll_loss 0.744 | ppl 1.67 | wps 9343.8 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 23905 | lr 1.41702e-05 | gnorm 0.72 | train_wall 590 | wall 0
2021-01-14 20:57:30 | INFO | fairseq.trainer | begin training epoch 36
2021-01-14 20:58:53 | INFO | train_inner | epoch 036:     95 / 683 symm_kl=0, loss=2.568, nll_loss=0.738, ppl=1.67, wps=7017.2, ups=0.8, wpb=8770, bsz=326.9, num_updates=24000, lr=1.41421e-05, gnorm=0.694, train_wall=87, wall=0
2021-01-14 21:00:20 | INFO | train_inner | epoch 036:    195 / 683 symm_kl=0, loss=2.572, nll_loss=0.741, ppl=1.67, wps=9926.4, ups=1.15, wpb=8636.2, bsz=297.1, num_updates=24100, lr=1.41128e-05, gnorm=0.717, train_wall=87, wall=0
2021-01-14 21:01:46 | INFO | train_inner | epoch 036:    295 / 683 symm_kl=0, loss=2.573, nll_loss=0.741, ppl=1.67, wps=10033.9, ups=1.15, wpb=8708.2, bsz=307, num_updates=24200, lr=1.40836e-05, gnorm=0.711, train_wall=87, wall=0
2021-01-14 21:03:12 | INFO | train_inner | epoch 036:    395 / 683 symm_kl=0, loss=2.572, nll_loss=0.741, ppl=1.67, wps=9818.4, ups=1.16, wpb=8437.7, bsz=290.6, num_updates=24300, lr=1.40546e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-14 21:04:39 | INFO | train_inner | epoch 036:    495 / 683 symm_kl=0, loss=2.574, nll_loss=0.744, ppl=1.67, wps=9784.8, ups=1.16, wpb=8446.2, bsz=307.4, num_updates=24400, lr=1.40257e-05, gnorm=0.728, train_wall=86, wall=0
2021-01-14 21:06:05 | INFO | train_inner | epoch 036:    595 / 683 symm_kl=0, loss=2.576, nll_loss=0.746, ppl=1.68, wps=10040.9, ups=1.15, wpb=8699.3, bsz=307.6, num_updates=24500, lr=1.39971e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 21:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:07:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:07:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:07:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:07:57 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | loss 5.878 | nll_loss 4.299 | ppl 19.68 | bleu 21.83 | wps 2343.1 | wpb 6353.4 | bsz 230.8 | num_updates 24588 | best_bleu 22.03
2021-01-14 21:07:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 21:08:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 36 @ 24588 updates, score 21.83) (writing took 2.85815772973001 seconds)
2021-01-14 21:08:00 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-01-14 21:08:00 | INFO | train | epoch 036 | symm_kl 0 | loss 2.573 | nll_loss 0.743 | ppl 1.67 | wps 9342 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 24588 | lr 1.3972e-05 | gnorm 0.719 | train_wall 590 | wall 0
2021-01-14 21:08:00 | INFO | fairseq.trainer | begin training epoch 37
2021-01-14 21:08:10 | INFO | train_inner | epoch 037:     12 / 683 symm_kl=0, loss=2.577, nll_loss=0.745, ppl=1.68, wps=6898.2, ups=0.8, wpb=8591.7, bsz=282.7, num_updates=24600, lr=1.39686e-05, gnorm=0.726, train_wall=86, wall=0
2021-01-14 21:09:38 | INFO | train_inner | epoch 037:    112 / 683 symm_kl=0, loss=2.569, nll_loss=0.738, ppl=1.67, wps=9833.9, ups=1.14, wpb=8637.5, bsz=291.7, num_updates=24700, lr=1.39403e-05, gnorm=0.716, train_wall=88, wall=0
2021-01-14 21:11:04 | INFO | train_inner | epoch 037:    212 / 683 symm_kl=0, loss=2.579, nll_loss=0.748, ppl=1.68, wps=9843.3, ups=1.17, wpb=8446.5, bsz=314.1, num_updates=24800, lr=1.39122e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-14 21:12:30 | INFO | train_inner | epoch 037:    312 / 683 symm_kl=0, loss=2.554, nll_loss=0.725, ppl=1.65, wps=10014.3, ups=1.16, wpb=8653.3, bsz=304.6, num_updates=24900, lr=1.38842e-05, gnorm=0.703, train_wall=86, wall=0
2021-01-14 21:13:56 | INFO | train_inner | epoch 037:    412 / 683 symm_kl=0, loss=2.58, nll_loss=0.749, ppl=1.68, wps=9929.3, ups=1.17, wpb=8512.9, bsz=295.3, num_updates=25000, lr=1.38564e-05, gnorm=0.728, train_wall=86, wall=0
2021-01-14 21:15:22 | INFO | train_inner | epoch 037:    512 / 683 symm_kl=0, loss=2.58, nll_loss=0.75, ppl=1.68, wps=9933.9, ups=1.15, wpb=8623.9, bsz=323.3, num_updates=25100, lr=1.38288e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-14 21:16:50 | INFO | train_inner | epoch 037:    612 / 683 symm_kl=0, loss=2.577, nll_loss=0.746, ppl=1.68, wps=10246.7, ups=1.15, wpb=8929.2, bsz=294, num_updates=25200, lr=1.38013e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-14 21:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:17:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:17:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:17:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:17:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:17:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:17:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:17:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:17:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:17:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:18:26 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | loss 5.874 | nll_loss 4.294 | ppl 19.62 | bleu 21.94 | wps 2369.4 | wpb 6353.4 | bsz 230.8 | num_updates 25271 | best_bleu 22.03
2021-01-14 21:18:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 21:18:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 37 @ 25271 updates, score 21.94) (writing took 2.897408965975046 seconds)
2021-01-14 21:18:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-01-14 21:18:29 | INFO | train | epoch 037 | symm_kl 0 | loss 2.572 | nll_loss 0.742 | ppl 1.67 | wps 9347.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 25271 | lr 1.37819e-05 | gnorm 0.719 | train_wall 590 | wall 0
2021-01-14 21:18:29 | INFO | fairseq.trainer | begin training epoch 38
2021-01-14 21:18:53 | INFO | train_inner | epoch 038:     29 / 683 symm_kl=0, loss=2.563, nll_loss=0.732, ppl=1.66, wps=6758.8, ups=0.81, wpb=8370.2, bsz=304.3, num_updates=25300, lr=1.3774e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-14 21:20:20 | INFO | train_inner | epoch 038:    129 / 683 symm_kl=0, loss=2.565, nll_loss=0.733, ppl=1.66, wps=9883.8, ups=1.15, wpb=8575.8, bsz=306.1, num_updates=25400, lr=1.37469e-05, gnorm=0.716, train_wall=87, wall=0
2021-01-14 21:21:48 | INFO | train_inner | epoch 038:    229 / 683 symm_kl=0, loss=2.556, nll_loss=0.725, ppl=1.65, wps=9947.1, ups=1.14, wpb=8712.5, bsz=302.4, num_updates=25500, lr=1.37199e-05, gnorm=0.702, train_wall=87, wall=0
2021-01-14 21:23:15 | INFO | train_inner | epoch 038:    329 / 683 symm_kl=0, loss=2.574, nll_loss=0.743, ppl=1.67, wps=9910.6, ups=1.15, wpb=8650.8, bsz=305.4, num_updates=25600, lr=1.36931e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-14 21:24:41 | INFO | train_inner | epoch 038:    429 / 683 symm_kl=0, loss=2.576, nll_loss=0.745, ppl=1.68, wps=9984.5, ups=1.16, wpb=8600.4, bsz=314.5, num_updates=25700, lr=1.36664e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-14 21:26:08 | INFO | train_inner | epoch 038:    529 / 683 symm_kl=0, loss=2.584, nll_loss=0.753, ppl=1.68, wps=9900.4, ups=1.15, wpb=8609.3, bsz=293.9, num_updates=25800, lr=1.36399e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-14 21:27:36 | INFO | train_inner | epoch 038:    629 / 683 symm_kl=0, loss=2.57, nll_loss=0.741, ppl=1.67, wps=9921.4, ups=1.14, wpb=8712.7, bsz=291.2, num_updates=25900, lr=1.36135e-05, gnorm=0.72, train_wall=88, wall=0
2021-01-14 21:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:28:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:28:57 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | loss 5.88 | nll_loss 4.302 | ppl 19.73 | bleu 21.87 | wps 2405.4 | wpb 6353.4 | bsz 230.8 | num_updates 25954 | best_bleu 22.03
2021-01-14 21:28:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 21:29:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 38 @ 25954 updates, score 21.87) (writing took 2.8042145632207394 seconds)
2021-01-14 21:29:00 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-01-14 21:29:00 | INFO | train | epoch 038 | symm_kl 0 | loss 2.571 | nll_loss 0.74 | ppl 1.67 | wps 9315.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 25954 | lr 1.35994e-05 | gnorm 0.719 | train_wall 592 | wall 0
2021-01-14 21:29:00 | INFO | fairseq.trainer | begin training epoch 39
2021-01-14 21:29:40 | INFO | train_inner | epoch 039:     46 / 683 symm_kl=0, loss=2.575, nll_loss=0.743, ppl=1.67, wps=6951.8, ups=0.81, wpb=8624.4, bsz=302, num_updates=26000, lr=1.35873e-05, gnorm=0.716, train_wall=86, wall=0
2021-01-14 21:31:07 | INFO | train_inner | epoch 039:    146 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=9677, ups=1.16, wpb=8375.8, bsz=320.2, num_updates=26100, lr=1.35613e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 21:32:34 | INFO | train_inner | epoch 039:    246 / 683 symm_kl=0, loss=2.576, nll_loss=0.746, ppl=1.68, wps=10019.8, ups=1.14, wpb=8755.6, bsz=309.2, num_updates=26200, lr=1.35354e-05, gnorm=0.712, train_wall=87, wall=0
2021-01-14 21:34:01 | INFO | train_inner | epoch 039:    346 / 683 symm_kl=0, loss=2.583, nll_loss=0.75, ppl=1.68, wps=9935.6, ups=1.15, wpb=8614.2, bsz=299, num_updates=26300, lr=1.35096e-05, gnorm=0.725, train_wall=87, wall=0
2021-01-14 21:35:28 | INFO | train_inner | epoch 039:    446 / 683 symm_kl=0, loss=2.563, nll_loss=0.734, ppl=1.66, wps=9948.8, ups=1.15, wpb=8668.3, bsz=323.4, num_updates=26400, lr=1.3484e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-14 21:36:55 | INFO | train_inner | epoch 039:    546 / 683 symm_kl=0, loss=2.576, nll_loss=0.744, ppl=1.68, wps=9837.4, ups=1.15, wpb=8576.5, bsz=294.7, num_updates=26500, lr=1.34585e-05, gnorm=0.73, train_wall=87, wall=0
2021-01-14 21:38:22 | INFO | train_inner | epoch 039:    646 / 683 symm_kl=0, loss=2.576, nll_loss=0.744, ppl=1.68, wps=9849.3, ups=1.16, wpb=8522.3, bsz=278.9, num_updates=26600, lr=1.34332e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-14 21:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:38:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:38:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:38:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:39:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:39:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:39:29 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_kl 0 | loss 5.884 | nll_loss 4.305 | ppl 19.77 | bleu 21.85 | wps 2362.2 | wpb 6353.4 | bsz 230.8 | num_updates 26637 | best_bleu 22.03
2021-01-14 21:39:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 21:39:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 39 @ 26637 updates, score 21.85) (writing took 2.8396909572184086 seconds)
2021-01-14 21:39:32 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-01-14 21:39:32 | INFO | train | epoch 039 | symm_kl 0 | loss 2.57 | nll_loss 0.74 | ppl 1.67 | wps 9305.4 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 26637 | lr 1.34239e-05 | gnorm 0.719 | train_wall 593 | wall 0
2021-01-14 21:39:32 | INFO | fairseq.trainer | begin training epoch 40
2021-01-14 21:40:27 | INFO | train_inner | epoch 040:     63 / 683 symm_kl=0, loss=2.561, nll_loss=0.729, ppl=1.66, wps=6960.9, ups=0.8, wpb=8739.8, bsz=301.8, num_updates=26700, lr=1.3408e-05, gnorm=0.708, train_wall=87, wall=0
2021-01-14 21:41:55 | INFO | train_inner | epoch 040:    163 / 683 symm_kl=0, loss=2.556, nll_loss=0.725, ppl=1.65, wps=10139.3, ups=1.13, wpb=8938.6, bsz=297, num_updates=26800, lr=1.3383e-05, gnorm=0.689, train_wall=88, wall=0
2021-01-14 21:43:21 | INFO | train_inner | epoch 040:    263 / 683 symm_kl=0, loss=2.568, nll_loss=0.737, ppl=1.67, wps=9911.9, ups=1.16, wpb=8523.3, bsz=321.2, num_updates=26900, lr=1.33581e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-14 21:44:46 | INFO | train_inner | epoch 040:    363 / 683 symm_kl=0, loss=2.573, nll_loss=0.742, ppl=1.67, wps=9833, ups=1.18, wpb=8346.8, bsz=281.7, num_updates=27000, lr=1.33333e-05, gnorm=0.737, train_wall=85, wall=0
2021-01-14 21:46:12 | INFO | train_inner | epoch 040:    463 / 683 symm_kl=0, loss=2.574, nll_loss=0.743, ppl=1.67, wps=9821.7, ups=1.16, wpb=8472.5, bsz=295.8, num_updates=27100, lr=1.33087e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-14 21:47:39 | INFO | train_inner | epoch 040:    563 / 683 symm_kl=0, loss=2.559, nll_loss=0.73, ppl=1.66, wps=10001.5, ups=1.16, wpb=8652, bsz=325.1, num_updates=27200, lr=1.32842e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-14 21:49:05 | INFO | train_inner | epoch 040:    663 / 683 symm_kl=0, loss=2.582, nll_loss=0.751, ppl=1.68, wps=9968.5, ups=1.16, wpb=8620.4, bsz=306.2, num_updates=27300, lr=1.32599e-05, gnorm=0.728, train_wall=86, wall=0
2021-01-14 21:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:49:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:49:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:49:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:49:59 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_kl 0 | loss 5.881 | nll_loss 4.303 | ppl 19.74 | bleu 21.99 | wps 2295.1 | wpb 6353.4 | bsz 230.8 | num_updates 27320 | best_bleu 22.03
2021-01-14 21:49:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 21:50:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 40 @ 27320 updates, score 21.99) (writing took 2.840567745268345 seconds)
2021-01-14 21:50:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-01-14 21:50:02 | INFO | train | epoch 040 | symm_kl 0 | loss 2.569 | nll_loss 0.738 | ppl 1.67 | wps 9337.7 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 27320 | lr 1.3255e-05 | gnorm 0.72 | train_wall 589 | wall 0
2021-01-14 21:50:02 | INFO | fairseq.trainer | begin training epoch 41
2021-01-14 21:51:11 | INFO | train_inner | epoch 041:     80 / 683 symm_kl=0, loss=2.554, nll_loss=0.725, ppl=1.65, wps=6844, ups=0.79, wpb=8625.4, bsz=319.8, num_updates=27400, lr=1.32357e-05, gnorm=0.704, train_wall=86, wall=0
2021-01-14 21:52:39 | INFO | train_inner | epoch 041:    180 / 683 symm_kl=0, loss=2.573, nll_loss=0.742, ppl=1.67, wps=10012, ups=1.14, wpb=8800.6, bsz=313, num_updates=27500, lr=1.32116e-05, gnorm=0.708, train_wall=88, wall=0
2021-01-14 21:54:05 | INFO | train_inner | epoch 041:    280 / 683 symm_kl=0, loss=2.571, nll_loss=0.739, ppl=1.67, wps=9711.9, ups=1.17, wpb=8281.6, bsz=299.2, num_updates=27600, lr=1.31876e-05, gnorm=0.743, train_wall=85, wall=0
2021-01-14 21:55:32 | INFO | train_inner | epoch 041:    380 / 683 symm_kl=0, loss=2.569, nll_loss=0.736, ppl=1.67, wps=9910.1, ups=1.14, wpb=8669.2, bsz=322.5, num_updates=27700, lr=1.31638e-05, gnorm=0.716, train_wall=87, wall=0
2021-01-14 21:56:59 | INFO | train_inner | epoch 041:    480 / 683 symm_kl=0, loss=2.573, nll_loss=0.741, ppl=1.67, wps=10030.4, ups=1.15, wpb=8692.9, bsz=285, num_updates=27800, lr=1.31401e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-14 21:58:25 | INFO | train_inner | epoch 041:    580 / 683 symm_kl=0, loss=2.577, nll_loss=0.745, ppl=1.68, wps=9962.1, ups=1.16, wpb=8577.2, bsz=279.9, num_updates=27900, lr=1.31165e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-14 21:59:52 | INFO | train_inner | epoch 041:    680 / 683 symm_kl=0, loss=2.566, nll_loss=0.736, ppl=1.67, wps=9945, ups=1.15, wpb=8641.1, bsz=308.8, num_updates=28000, lr=1.30931e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-14 21:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 21:59:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:59:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:59:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 21:59:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 21:59:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 21:59:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:00:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:00:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:00:29 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_kl 0 | loss 5.882 | nll_loss 4.305 | ppl 19.77 | bleu 21.9 | wps 2373.9 | wpb 6353.4 | bsz 230.8 | num_updates 28003 | best_bleu 22.03
2021-01-14 22:00:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:00:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 41 @ 28003 updates, score 21.9) (writing took 2.9321074802428484 seconds)
2021-01-14 22:00:32 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-01-14 22:00:32 | INFO | train | epoch 041 | symm_kl 0 | loss 2.568 | nll_loss 0.737 | ppl 1.67 | wps 9331.7 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 28003 | lr 1.30924e-05 | gnorm 0.721 | train_wall 591 | wall 0
2021-01-14 22:00:32 | INFO | fairseq.trainer | begin training epoch 42
2021-01-14 22:01:57 | INFO | train_inner | epoch 042:     97 / 683 symm_kl=0, loss=2.561, nll_loss=0.73, ppl=1.66, wps=7090.6, ups=0.8, wpb=8847.5, bsz=309.4, num_updates=28100, lr=1.30698e-05, gnorm=0.696, train_wall=87, wall=0
2021-01-14 22:03:23 | INFO | train_inner | epoch 042:    197 / 683 symm_kl=0, loss=2.56, nll_loss=0.728, ppl=1.66, wps=9998.4, ups=1.16, wpb=8637.4, bsz=290.6, num_updates=28200, lr=1.30466e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-14 22:04:49 | INFO | train_inner | epoch 042:    297 / 683 symm_kl=0, loss=2.553, nll_loss=0.722, ppl=1.65, wps=9980.8, ups=1.16, wpb=8571.6, bsz=315, num_updates=28300, lr=1.30235e-05, gnorm=0.706, train_wall=86, wall=0
2021-01-14 22:06:14 | INFO | train_inner | epoch 042:    397 / 683 symm_kl=0, loss=2.58, nll_loss=0.747, ppl=1.68, wps=9823.8, ups=1.17, wpb=8384, bsz=297.4, num_updates=28400, lr=1.30005e-05, gnorm=0.738, train_wall=85, wall=0
2021-01-14 22:07:40 | INFO | train_inner | epoch 042:    497 / 683 symm_kl=0, loss=2.581, nll_loss=0.75, ppl=1.68, wps=10084.4, ups=1.16, wpb=8708.2, bsz=300.2, num_updates=28500, lr=1.29777e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 22:09:07 | INFO | train_inner | epoch 042:    597 / 683 symm_kl=0, loss=2.572, nll_loss=0.74, ppl=1.67, wps=9869.4, ups=1.15, wpb=8549.4, bsz=305.4, num_updates=28600, lr=1.2955e-05, gnorm=0.736, train_wall=86, wall=0
2021-01-14 22:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 22:10:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:10:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:10:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:10:57 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_kl 0 | loss 5.883 | nll_loss 4.305 | ppl 19.76 | bleu 21.88 | wps 2373.4 | wpb 6353.4 | bsz 230.8 | num_updates 28686 | best_bleu 22.03
2021-01-14 22:10:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:11:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 42 @ 28686 updates, score 21.88) (writing took 2.854872325435281 seconds)
2021-01-14 22:11:00 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-01-14 22:11:00 | INFO | train | epoch 042 | symm_kl 0 | loss 2.567 | nll_loss 0.736 | ppl 1.67 | wps 9367.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 28686 | lr 1.29356e-05 | gnorm 0.72 | train_wall 588 | wall 0
2021-01-14 22:11:00 | INFO | fairseq.trainer | begin training epoch 43
2021-01-14 22:11:12 | INFO | train_inner | epoch 043:     14 / 683 symm_kl=0, loss=2.568, nll_loss=0.738, ppl=1.67, wps=6906.5, ups=0.8, wpb=8618.8, bsz=308.9, num_updates=28700, lr=1.29324e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-14 22:12:39 | INFO | train_inner | epoch 043:    114 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=9981.1, ups=1.14, wpb=8730.9, bsz=304.3, num_updates=28800, lr=1.29099e-05, gnorm=0.708, train_wall=87, wall=0
2021-01-14 22:14:06 | INFO | train_inner | epoch 043:    214 / 683 symm_kl=0, loss=2.572, nll_loss=0.741, ppl=1.67, wps=10022.7, ups=1.15, wpb=8684.1, bsz=302.2, num_updates=28900, lr=1.28876e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-14 22:15:32 | INFO | train_inner | epoch 043:    314 / 683 symm_kl=0, loss=2.579, nll_loss=0.747, ppl=1.68, wps=9953.2, ups=1.16, wpb=8562.3, bsz=301.8, num_updates=29000, lr=1.28654e-05, gnorm=0.732, train_wall=86, wall=0
2021-01-14 22:16:58 | INFO | train_inner | epoch 043:    414 / 683 symm_kl=0, loss=2.565, nll_loss=0.734, ppl=1.66, wps=9836, ups=1.16, wpb=8493.3, bsz=301.3, num_updates=29100, lr=1.28432e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-14 22:18:25 | INFO | train_inner | epoch 043:    514 / 683 symm_kl=0, loss=2.569, nll_loss=0.737, ppl=1.67, wps=9883.1, ups=1.16, wpb=8519.1, bsz=327.4, num_updates=29200, lr=1.28212e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 22:19:51 | INFO | train_inner | epoch 043:    614 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=10034, ups=1.16, wpb=8656.5, bsz=299.6, num_updates=29300, lr=1.27993e-05, gnorm=0.714, train_wall=86, wall=0
2021-01-14 22:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 22:20:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:20:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:20:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:20:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:20:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:20:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:20:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:20:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:20:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:21:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:21:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:21:26 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_kl 0 | loss 5.882 | nll_loss 4.304 | ppl 19.76 | bleu 21.83 | wps 2382.6 | wpb 6353.4 | bsz 230.8 | num_updates 29369 | best_bleu 22.03
2021-01-14 22:21:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:21:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 43 @ 29369 updates, score 21.83) (writing took 2.966639095917344 seconds)
2021-01-14 22:21:29 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-01-14 22:21:29 | INFO | train | epoch 043 | symm_kl 0 | loss 2.567 | nll_loss 0.735 | ppl 1.66 | wps 9344.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 29369 | lr 1.27843e-05 | gnorm 0.72 | train_wall 590 | wall 0
2021-01-14 22:21:29 | INFO | fairseq.trainer | begin training epoch 44
2021-01-14 22:21:56 | INFO | train_inner | epoch 044:     31 / 683 symm_kl=0, loss=2.566, nll_loss=0.735, ppl=1.66, wps=6952.2, ups=0.8, wpb=8685.2, bsz=279.8, num_updates=29400, lr=1.27775e-05, gnorm=0.717, train_wall=87, wall=0
2021-01-14 22:23:24 | INFO | train_inner | epoch 044:    131 / 683 symm_kl=0, loss=2.558, nll_loss=0.727, ppl=1.66, wps=9931.8, ups=1.13, wpb=8751.1, bsz=310.3, num_updates=29500, lr=1.27559e-05, gnorm=0.702, train_wall=88, wall=0
2021-01-14 22:24:51 | INFO | train_inner | epoch 044:    231 / 683 symm_kl=0, loss=2.575, nll_loss=0.746, ppl=1.68, wps=10217, ups=1.15, wpb=8895.5, bsz=321, num_updates=29600, lr=1.27343e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-14 22:26:16 | INFO | train_inner | epoch 044:    331 / 683 symm_kl=0, loss=2.579, nll_loss=0.745, ppl=1.68, wps=9657.3, ups=1.18, wpb=8177.1, bsz=283.6, num_updates=29700, lr=1.27128e-05, gnorm=0.756, train_wall=84, wall=0
2021-01-14 22:27:42 | INFO | train_inner | epoch 044:    431 / 683 symm_kl=0, loss=2.559, nll_loss=0.728, ppl=1.66, wps=9778.2, ups=1.16, wpb=8430.7, bsz=312.1, num_updates=29800, lr=1.26915e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-14 22:29:10 | INFO | train_inner | epoch 044:    531 / 683 symm_kl=0, loss=2.552, nll_loss=0.721, ppl=1.65, wps=9944.3, ups=1.14, wpb=8718.1, bsz=293, num_updates=29900, lr=1.26702e-05, gnorm=0.711, train_wall=87, wall=0
2021-01-14 22:30:36 | INFO | train_inner | epoch 044:    631 / 683 symm_kl=0, loss=2.572, nll_loss=0.74, ppl=1.67, wps=9924.6, ups=1.15, wpb=8606.4, bsz=309.4, num_updates=30000, lr=1.26491e-05, gnorm=0.731, train_wall=87, wall=0
2021-01-14 22:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 22:31:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:31:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:31:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:31:56 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_kl 0 | loss 5.885 | nll_loss 4.309 | ppl 19.82 | bleu 21.99 | wps 2358.1 | wpb 6353.4 | bsz 230.8 | num_updates 30052 | best_bleu 22.03
2021-01-14 22:31:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:31:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 44 @ 30052 updates, score 21.99) (writing took 2.9842472840100527 seconds)
2021-01-14 22:31:59 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-01-14 22:31:59 | INFO | train | epoch 044 | symm_kl 0 | loss 2.566 | nll_loss 0.735 | ppl 1.66 | wps 9335.2 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 30052 | lr 1.26382e-05 | gnorm 0.72 | train_wall 590 | wall 0
2021-01-14 22:31:59 | INFO | fairseq.trainer | begin training epoch 45
2021-01-14 22:32:41 | INFO | train_inner | epoch 045:     48 / 683 symm_kl=0, loss=2.561, nll_loss=0.729, ppl=1.66, wps=6952.9, ups=0.8, wpb=8675, bsz=295.2, num_updates=30100, lr=1.26281e-05, gnorm=0.716, train_wall=86, wall=0
2021-01-14 22:34:08 | INFO | train_inner | epoch 045:    148 / 683 symm_kl=0, loss=2.553, nll_loss=0.723, ppl=1.65, wps=10047, ups=1.15, wpb=8751.9, bsz=324.2, num_updates=30200, lr=1.26072e-05, gnorm=0.699, train_wall=87, wall=0
2021-01-14 22:35:34 | INFO | train_inner | epoch 045:    248 / 683 symm_kl=0, loss=2.576, nll_loss=0.745, ppl=1.68, wps=9889.7, ups=1.16, wpb=8525.1, bsz=312.6, num_updates=30300, lr=1.25863e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-14 22:37:02 | INFO | train_inner | epoch 045:    348 / 683 symm_kl=0, loss=2.574, nll_loss=0.742, ppl=1.67, wps=9923.7, ups=1.14, wpb=8671, bsz=303.6, num_updates=30400, lr=1.25656e-05, gnorm=0.724, train_wall=87, wall=0
2021-01-14 22:38:28 | INFO | train_inner | epoch 045:    448 / 683 symm_kl=0, loss=2.574, nll_loss=0.742, ppl=1.67, wps=9848, ups=1.17, wpb=8449.2, bsz=287, num_updates=30500, lr=1.2545e-05, gnorm=0.738, train_wall=86, wall=0
2021-01-14 22:39:54 | INFO | train_inner | epoch 045:    548 / 683 symm_kl=0, loss=2.561, nll_loss=0.729, ppl=1.66, wps=9948.9, ups=1.15, wpb=8653.5, bsz=312, num_updates=30600, lr=1.25245e-05, gnorm=0.715, train_wall=87, wall=0
2021-01-14 22:41:21 | INFO | train_inner | epoch 045:    648 / 683 symm_kl=0, loss=2.571, nll_loss=0.739, ppl=1.67, wps=9982.5, ups=1.16, wpb=8614.3, bsz=293.8, num_updates=30700, lr=1.25041e-05, gnorm=0.724, train_wall=86, wall=0
2021-01-14 22:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 22:41:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:41:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:41:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:41:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:41:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:41:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:41:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:41:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:41:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:42:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:42:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:42:26 | INFO | valid | epoch 045 | valid on 'valid' subset | symm_kl 0 | loss 5.886 | nll_loss 4.31 | ppl 19.84 | bleu 21.92 | wps 2397.6 | wpb 6353.4 | bsz 230.8 | num_updates 30735 | best_bleu 22.03
2021-01-14 22:42:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:42:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 45 @ 30735 updates, score 21.92) (writing took 2.96925407089293 seconds)
2021-01-14 22:42:29 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-01-14 22:42:29 | INFO | train | epoch 045 | symm_kl 0 | loss 2.565 | nll_loss 0.733 | ppl 1.66 | wps 9343.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 30735 | lr 1.24969e-05 | gnorm 0.72 | train_wall 590 | wall 0
2021-01-14 22:42:29 | INFO | fairseq.trainer | begin training epoch 46
2021-01-14 22:43:25 | INFO | train_inner | epoch 046:     65 / 683 symm_kl=0, loss=2.548, nll_loss=0.717, ppl=1.64, wps=6922.5, ups=0.8, wpb=8613.4, bsz=297.2, num_updates=30800, lr=1.24838e-05, gnorm=0.709, train_wall=86, wall=0
2021-01-14 22:44:52 | INFO | train_inner | epoch 046:    165 / 683 symm_kl=0, loss=2.568, nll_loss=0.735, ppl=1.66, wps=9713.9, ups=1.15, wpb=8432.7, bsz=300.8, num_updates=30900, lr=1.24635e-05, gnorm=0.733, train_wall=87, wall=0
2021-01-14 22:46:19 | INFO | train_inner | epoch 046:    265 / 683 symm_kl=0, loss=2.578, nll_loss=0.746, ppl=1.68, wps=10032, ups=1.15, wpb=8713.6, bsz=287.4, num_updates=31000, lr=1.24434e-05, gnorm=0.724, train_wall=87, wall=0
2021-01-14 22:47:45 | INFO | train_inner | epoch 046:    365 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=10031.8, ups=1.16, wpb=8646.7, bsz=294.9, num_updates=31100, lr=1.24234e-05, gnorm=0.718, train_wall=86, wall=0
2021-01-14 22:49:13 | INFO | train_inner | epoch 046:    465 / 683 symm_kl=0, loss=2.566, nll_loss=0.733, ppl=1.66, wps=9963, ups=1.14, wpb=8750.7, bsz=288.8, num_updates=31200, lr=1.24035e-05, gnorm=0.713, train_wall=88, wall=0
2021-01-14 22:50:39 | INFO | train_inner | epoch 046:    565 / 683 symm_kl=0, loss=2.564, nll_loss=0.733, ppl=1.66, wps=9949.4, ups=1.17, wpb=8534.7, bsz=334.1, num_updates=31300, lr=1.23836e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 22:52:06 | INFO | train_inner | epoch 046:    665 / 683 symm_kl=0, loss=2.561, nll_loss=0.73, ppl=1.66, wps=9804.1, ups=1.15, wpb=8515.6, bsz=315.2, num_updates=31400, lr=1.23639e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-14 22:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 22:52:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 22:52:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 22:52:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 22:52:56 | INFO | valid | epoch 046 | valid on 'valid' subset | symm_kl 0 | loss 5.89 | nll_loss 4.313 | ppl 19.87 | bleu 21.93 | wps 2387.1 | wpb 6353.4 | bsz 230.8 | num_updates 31418 | best_bleu 22.03
2021-01-14 22:52:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 22:52:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 46 @ 31418 updates, score 21.93) (writing took 2.9612676333636045 seconds)
2021-01-14 22:52:59 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-01-14 22:52:59 | INFO | train | epoch 046 | symm_kl 0 | loss 2.564 | nll_loss 0.732 | ppl 1.66 | wps 9331.5 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 31418 | lr 1.23604e-05 | gnorm 0.72 | train_wall 591 | wall 0
2021-01-14 22:52:59 | INFO | fairseq.trainer | begin training epoch 47
2021-01-14 22:54:10 | INFO | train_inner | epoch 047:     82 / 683 symm_kl=0, loss=2.553, nll_loss=0.722, ppl=1.65, wps=6939.1, ups=0.8, wpb=8655.8, bsz=316.6, num_updates=31500, lr=1.23443e-05, gnorm=0.709, train_wall=87, wall=0
2021-01-14 22:55:37 | INFO | train_inner | epoch 047:    182 / 683 symm_kl=0, loss=2.567, nll_loss=0.734, ppl=1.66, wps=9754.1, ups=1.15, wpb=8464.1, bsz=299.6, num_updates=31600, lr=1.23247e-05, gnorm=0.727, train_wall=87, wall=0
2021-01-14 22:57:04 | INFO | train_inner | epoch 047:    282 / 683 symm_kl=0, loss=2.551, nll_loss=0.721, ppl=1.65, wps=9793.2, ups=1.16, wpb=8476.1, bsz=298.6, num_updates=31700, lr=1.23053e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-14 22:58:29 | INFO | train_inner | epoch 047:    382 / 683 symm_kl=0, loss=2.572, nll_loss=0.738, ppl=1.67, wps=9807.4, ups=1.17, wpb=8404.1, bsz=293.2, num_updates=31800, lr=1.22859e-05, gnorm=0.74, train_wall=86, wall=0
2021-01-14 22:59:56 | INFO | train_inner | epoch 047:    482 / 683 symm_kl=0, loss=2.557, nll_loss=0.727, ppl=1.66, wps=10104, ups=1.16, wpb=8723.7, bsz=323.8, num_updates=31900, lr=1.22666e-05, gnorm=0.71, train_wall=86, wall=0
2021-01-14 23:01:23 | INFO | train_inner | epoch 047:    582 / 683 symm_kl=0, loss=2.564, nll_loss=0.733, ppl=1.66, wps=9987.8, ups=1.15, wpb=8692.1, bsz=311.9, num_updates=32000, lr=1.22474e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-14 23:02:50 | INFO | train_inner | epoch 047:    682 / 683 symm_kl=0, loss=2.574, nll_loss=0.742, ppl=1.67, wps=10207.3, ups=1.15, wpb=8874, bsz=286.8, num_updates=32100, lr=1.22284e-05, gnorm=0.716, train_wall=87, wall=0
2021-01-14 23:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:02:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:02:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:02:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:02:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:02:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:02:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:03:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:03:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:03:25 | INFO | valid | epoch 047 | valid on 'valid' subset | symm_kl 0 | loss 5.89 | nll_loss 4.312 | ppl 19.87 | bleu 21.91 | wps 2387.5 | wpb 6353.4 | bsz 230.8 | num_updates 32101 | best_bleu 22.03
2021-01-14 23:03:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:03:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 47 @ 32101 updates, score 21.91) (writing took 2.9217509515583515 seconds)
2021-01-14 23:03:28 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-01-14 23:03:28 | INFO | train | epoch 047 | symm_kl 0 | loss 2.564 | nll_loss 0.732 | ppl 1.66 | wps 9346.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 32101 | lr 1.22282e-05 | gnorm 0.722 | train_wall 590 | wall 0
2021-01-14 23:03:28 | INFO | fairseq.trainer | begin training epoch 48
2021-01-14 23:04:54 | INFO | train_inner | epoch 048:     99 / 683 symm_kl=0, loss=2.545, nll_loss=0.714, ppl=1.64, wps=7073.9, ups=0.81, wpb=8778.7, bsz=309.2, num_updates=32200, lr=1.22094e-05, gnorm=0.698, train_wall=86, wall=0
2021-01-14 23:06:20 | INFO | train_inner | epoch 048:    199 / 683 symm_kl=0, loss=2.571, nll_loss=0.738, ppl=1.67, wps=9884.3, ups=1.16, wpb=8514.3, bsz=293.8, num_updates=32300, lr=1.21904e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-14 23:07:47 | INFO | train_inner | epoch 048:    299 / 683 symm_kl=0, loss=2.569, nll_loss=0.736, ppl=1.67, wps=10058.1, ups=1.15, wpb=8738.9, bsz=282.2, num_updates=32400, lr=1.21716e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-14 23:09:14 | INFO | train_inner | epoch 048:    399 / 683 symm_kl=0, loss=2.562, nll_loss=0.728, ppl=1.66, wps=10009.9, ups=1.15, wpb=8707.1, bsz=303.7, num_updates=32500, lr=1.21529e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-14 23:10:39 | INFO | train_inner | epoch 048:    499 / 683 symm_kl=0, loss=2.574, nll_loss=0.743, ppl=1.67, wps=9757.8, ups=1.17, wpb=8312.1, bsz=310, num_updates=32600, lr=1.21342e-05, gnorm=0.751, train_wall=85, wall=0
2021-01-14 23:12:05 | INFO | train_inner | epoch 048:    599 / 683 symm_kl=0, loss=2.553, nll_loss=0.724, ppl=1.65, wps=10043.1, ups=1.16, wpb=8684.5, bsz=328.4, num_updates=32700, lr=1.21157e-05, gnorm=0.706, train_wall=86, wall=0
2021-01-14 23:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:13:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:13:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:13:53 | INFO | valid | epoch 048 | valid on 'valid' subset | symm_kl 0 | loss 5.889 | nll_loss 4.313 | ppl 19.88 | bleu 22.06 | wps 2393 | wpb 6353.4 | bsz 230.8 | num_updates 32784 | best_bleu 22.06
2021-01-14 23:13:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:13:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_best.pt (epoch 48 @ 32784 updates, score 22.06) (writing took 4.621133012697101 seconds)
2021-01-14 23:13:57 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-01-14 23:13:57 | INFO | train | epoch 048 | symm_kl 0 | loss 2.562 | nll_loss 0.73 | ppl 1.66 | wps 9351.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 32784 | lr 1.21001e-05 | gnorm 0.72 | train_wall 588 | wall 0
2021-01-14 23:13:57 | INFO | fairseq.trainer | begin training epoch 49
2021-01-14 23:14:11 | INFO | train_inner | epoch 049:     16 / 683 symm_kl=0, loss=2.559, nll_loss=0.728, ppl=1.66, wps=6843.1, ups=0.8, wpb=8594.6, bsz=302.9, num_updates=32800, lr=1.20972e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-14 23:15:39 | INFO | train_inner | epoch 049:    116 / 683 symm_kl=0, loss=2.56, nll_loss=0.728, ppl=1.66, wps=10018.7, ups=1.14, wpb=8821.5, bsz=308.7, num_updates=32900, lr=1.20788e-05, gnorm=0.706, train_wall=88, wall=0
2021-01-14 23:17:06 | INFO | train_inner | epoch 049:    216 / 683 symm_kl=0, loss=2.564, nll_loss=0.731, ppl=1.66, wps=9879.5, ups=1.15, wpb=8567.7, bsz=301.3, num_updates=33000, lr=1.20605e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-14 23:18:32 | INFO | train_inner | epoch 049:    316 / 683 symm_kl=0, loss=2.564, nll_loss=0.731, ppl=1.66, wps=9972.9, ups=1.16, wpb=8632.9, bsz=302.4, num_updates=33100, lr=1.20422e-05, gnorm=0.718, train_wall=86, wall=0
2021-01-14 23:19:59 | INFO | train_inner | epoch 049:    416 / 683 symm_kl=0, loss=2.553, nll_loss=0.722, ppl=1.65, wps=10057.1, ups=1.15, wpb=8726, bsz=284.4, num_updates=33200, lr=1.20241e-05, gnorm=0.707, train_wall=87, wall=0
2021-01-14 23:21:25 | INFO | train_inner | epoch 049:    516 / 683 symm_kl=0, loss=2.568, nll_loss=0.737, ppl=1.67, wps=9909, ups=1.16, wpb=8513.2, bsz=308, num_updates=33300, lr=1.2006e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-14 23:22:51 | INFO | train_inner | epoch 049:    616 / 683 symm_kl=0, loss=2.567, nll_loss=0.735, ppl=1.66, wps=9896.3, ups=1.16, wpb=8550.7, bsz=303.6, num_updates=33400, lr=1.1988e-05, gnorm=0.728, train_wall=86, wall=0
2021-01-14 23:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:23:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:23:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:23:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:23:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:23:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:23:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:23:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:23:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:23:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:23:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:23:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:23:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:24:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:24:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:24:24 | INFO | valid | epoch 049 | valid on 'valid' subset | symm_kl 0 | loss 5.89 | nll_loss 4.314 | ppl 19.89 | bleu 21.91 | wps 2397 | wpb 6353.4 | bsz 230.8 | num_updates 33467 | best_bleu 22.06
2021-01-14 23:24:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:24:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 49 @ 33467 updates, score 21.91) (writing took 3.023900555446744 seconds)
2021-01-14 23:24:27 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-01-14 23:24:27 | INFO | train | epoch 049 | symm_kl 0 | loss 2.562 | nll_loss 0.73 | ppl 1.66 | wps 9344.3 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 33467 | lr 1.1976e-05 | gnorm 0.72 | train_wall 590 | wall 0
2021-01-14 23:24:27 | INFO | fairseq.trainer | begin training epoch 50
2021-01-14 23:24:55 | INFO | train_inner | epoch 050:     33 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=6873.7, ups=0.81, wpb=8510.9, bsz=322.9, num_updates=33500, lr=1.19701e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 23:26:23 | INFO | train_inner | epoch 050:    133 / 683 symm_kl=0, loss=2.566, nll_loss=0.734, ppl=1.66, wps=9885.5, ups=1.15, wpb=8632.4, bsz=297.1, num_updates=33600, lr=1.19523e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-14 23:27:49 | INFO | train_inner | epoch 050:    233 / 683 symm_kl=0, loss=2.552, nll_loss=0.72, ppl=1.65, wps=10034.7, ups=1.15, wpb=8714.4, bsz=295.8, num_updates=33700, lr=1.19345e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-14 23:29:16 | INFO | train_inner | epoch 050:    333 / 683 symm_kl=0, loss=2.561, nll_loss=0.728, ppl=1.66, wps=10030, ups=1.16, wpb=8683.3, bsz=295.2, num_updates=33800, lr=1.19169e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-14 23:30:43 | INFO | train_inner | epoch 050:    433 / 683 symm_kl=0, loss=2.562, nll_loss=0.731, ppl=1.66, wps=10044.1, ups=1.15, wpb=8697.3, bsz=318.5, num_updates=33900, lr=1.18993e-05, gnorm=0.714, train_wall=86, wall=0
2021-01-14 23:32:08 | INFO | train_inner | epoch 050:    533 / 683 symm_kl=0, loss=2.563, nll_loss=0.73, ppl=1.66, wps=9633.4, ups=1.17, wpb=8254.6, bsz=290.6, num_updates=34000, lr=1.18818e-05, gnorm=0.745, train_wall=85, wall=0
2021-01-14 23:33:35 | INFO | train_inner | epoch 050:    633 / 683 symm_kl=0, loss=2.562, nll_loss=0.731, ppl=1.66, wps=9837.6, ups=1.16, wpb=8487.8, bsz=297.8, num_updates=34100, lr=1.18643e-05, gnorm=0.734, train_wall=86, wall=0
2021-01-14 23:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:34:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:34:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:34:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:34:53 | INFO | valid | epoch 050 | valid on 'valid' subset | symm_kl 0 | loss 5.896 | nll_loss 4.32 | ppl 19.97 | bleu 21.84 | wps 2345.2 | wpb 6353.4 | bsz 230.8 | num_updates 34150 | best_bleu 22.06
2021-01-14 23:34:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:34:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 50 @ 34150 updates, score 21.84) (writing took 2.9167461842298508 seconds)
2021-01-14 23:34:56 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-01-14 23:34:56 | INFO | train | epoch 050 | symm_kl 0 | loss 2.561 | nll_loss 0.729 | ppl 1.66 | wps 9339.2 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 34150 | lr 1.18556e-05 | gnorm 0.721 | train_wall 590 | wall 0
2021-01-14 23:34:56 | INFO | fairseq.trainer | begin training epoch 51
2021-01-14 23:35:39 | INFO | train_inner | epoch 051:     50 / 683 symm_kl=0, loss=2.57, nll_loss=0.738, ppl=1.67, wps=7016.4, ups=0.8, wpb=8757.5, bsz=321.7, num_updates=34200, lr=1.1847e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 23:37:05 | INFO | train_inner | epoch 051:    150 / 683 symm_kl=0, loss=2.56, nll_loss=0.726, ppl=1.65, wps=9396.3, ups=1.16, wpb=8066.4, bsz=272.2, num_updates=34300, lr=1.18297e-05, gnorm=0.763, train_wall=86, wall=0
2021-01-14 23:38:32 | INFO | train_inner | epoch 051:    250 / 683 symm_kl=0, loss=2.558, nll_loss=0.725, ppl=1.65, wps=10107.8, ups=1.16, wpb=8740.6, bsz=299.6, num_updates=34400, lr=1.18125e-05, gnorm=0.711, train_wall=86, wall=0
2021-01-14 23:39:59 | INFO | train_inner | epoch 051:    350 / 683 symm_kl=0, loss=2.55, nll_loss=0.719, ppl=1.65, wps=10032, ups=1.15, wpb=8759.8, bsz=319.4, num_updates=34500, lr=1.17954e-05, gnorm=0.701, train_wall=87, wall=0
2021-01-14 23:41:26 | INFO | train_inner | epoch 051:    450 / 683 symm_kl=0, loss=2.566, nll_loss=0.734, ppl=1.66, wps=9832, ups=1.15, wpb=8514.7, bsz=289.5, num_updates=34600, lr=1.17783e-05, gnorm=0.738, train_wall=86, wall=0
2021-01-14 23:42:52 | INFO | train_inner | epoch 051:    550 / 683 symm_kl=0, loss=2.561, nll_loss=0.731, ppl=1.66, wps=10163.2, ups=1.15, wpb=8800.9, bsz=320.7, num_updates=34700, lr=1.17613e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-14 23:44:19 | INFO | train_inner | epoch 051:    650 / 683 symm_kl=0, loss=2.568, nll_loss=0.736, ppl=1.67, wps=10004.1, ups=1.15, wpb=8727.6, bsz=304.8, num_updates=34800, lr=1.17444e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-14 23:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:45:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:45:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:45:23 | INFO | valid | epoch 051 | valid on 'valid' subset | symm_kl 0 | loss 5.896 | nll_loss 4.321 | ppl 19.98 | bleu 21.88 | wps 2390.8 | wpb 6353.4 | bsz 230.8 | num_updates 34833 | best_bleu 22.06
2021-01-14 23:45:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:45:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 51 @ 34833 updates, score 21.88) (writing took 2.9420533627271652 seconds)
2021-01-14 23:45:26 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-01-14 23:45:26 | INFO | train | epoch 051 | symm_kl 0 | loss 2.561 | nll_loss 0.729 | ppl 1.66 | wps 9337.6 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 34833 | lr 1.17388e-05 | gnorm 0.723 | train_wall 591 | wall 0
2021-01-14 23:45:26 | INFO | fairseq.trainer | begin training epoch 52
2021-01-14 23:46:24 | INFO | train_inner | epoch 052:     67 / 683 symm_kl=0, loss=2.549, nll_loss=0.716, ppl=1.64, wps=6849.2, ups=0.8, wpb=8509.5, bsz=299, num_updates=34900, lr=1.17276e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-14 23:47:51 | INFO | train_inner | epoch 052:    167 / 683 symm_kl=0, loss=2.565, nll_loss=0.732, ppl=1.66, wps=9872, ups=1.14, wpb=8632.5, bsz=278.9, num_updates=35000, lr=1.17108e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-14 23:49:19 | INFO | train_inner | epoch 052:    267 / 683 symm_kl=0, loss=2.552, nll_loss=0.719, ppl=1.65, wps=9839.2, ups=1.14, wpb=8611.1, bsz=298.9, num_updates=35100, lr=1.16941e-05, gnorm=0.721, train_wall=87, wall=0
2021-01-14 23:50:44 | INFO | train_inner | epoch 052:    367 / 683 symm_kl=0, loss=2.562, nll_loss=0.73, ppl=1.66, wps=10100, ups=1.17, wpb=8610.6, bsz=309, num_updates=35200, lr=1.16775e-05, gnorm=0.723, train_wall=85, wall=0
2021-01-14 23:52:10 | INFO | train_inner | epoch 052:    467 / 683 symm_kl=0, loss=2.559, nll_loss=0.728, ppl=1.66, wps=9950.3, ups=1.16, wpb=8594.5, bsz=310.2, num_updates=35300, lr=1.16609e-05, gnorm=0.723, train_wall=86, wall=0
2021-01-14 23:53:36 | INFO | train_inner | epoch 052:    567 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=9983, ups=1.16, wpb=8610.6, bsz=322.9, num_updates=35400, lr=1.16445e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-14 23:55:03 | INFO | train_inner | epoch 052:    667 / 683 symm_kl=0, loss=2.567, nll_loss=0.736, ppl=1.67, wps=9995, ups=1.15, wpb=8655.8, bsz=308.6, num_updates=35500, lr=1.1628e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-14 23:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-14 23:55:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-14 23:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-14 23:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-14 23:55:52 | INFO | valid | epoch 052 | valid on 'valid' subset | symm_kl 0 | loss 5.894 | nll_loss 4.317 | ppl 19.94 | bleu 21.81 | wps 2369 | wpb 6353.4 | bsz 230.8 | num_updates 35516 | best_bleu 22.06
2021-01-14 23:55:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-14 23:55:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 52 @ 35516 updates, score 21.81) (writing took 2.979992536827922 seconds)
2021-01-14 23:55:55 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-01-14 23:55:55 | INFO | train | epoch 052 | symm_kl 0 | loss 2.56 | nll_loss 0.728 | ppl 1.66 | wps 9351 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 35516 | lr 1.16254e-05 | gnorm 0.721 | train_wall 589 | wall 0
2021-01-14 23:55:55 | INFO | fairseq.trainer | begin training epoch 53
2021-01-14 23:57:07 | INFO | train_inner | epoch 053:     84 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=7053.1, ups=0.81, wpb=8755.1, bsz=304.8, num_updates=35600, lr=1.16117e-05, gnorm=0.709, train_wall=86, wall=0
2021-01-14 23:58:33 | INFO | train_inner | epoch 053:    184 / 683 symm_kl=0, loss=2.556, nll_loss=0.723, ppl=1.65, wps=9777, ups=1.17, wpb=8388.4, bsz=308.5, num_updates=35700, lr=1.15954e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-15 00:00:00 | INFO | train_inner | epoch 053:    284 / 683 symm_kl=0, loss=2.564, nll_loss=0.729, ppl=1.66, wps=9949, ups=1.16, wpb=8606.9, bsz=282.4, num_updates=35800, lr=1.15792e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-15 00:01:26 | INFO | train_inner | epoch 053:    384 / 683 symm_kl=0, loss=2.56, nll_loss=0.728, ppl=1.66, wps=9730.5, ups=1.16, wpb=8417.1, bsz=310.1, num_updates=35900, lr=1.15631e-05, gnorm=0.737, train_wall=86, wall=0
2021-01-15 00:02:53 | INFO | train_inner | epoch 053:    484 / 683 symm_kl=0, loss=2.565, nll_loss=0.732, ppl=1.66, wps=10016.4, ups=1.15, wpb=8685.5, bsz=295, num_updates=36000, lr=1.1547e-05, gnorm=0.725, train_wall=87, wall=0
2021-01-15 00:04:20 | INFO | train_inner | epoch 053:    584 / 683 symm_kl=0, loss=2.56, nll_loss=0.728, ppl=1.66, wps=10101.2, ups=1.15, wpb=8817.7, bsz=296.7, num_updates=36100, lr=1.1531e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-15 00:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:05:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:05:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:05:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:05:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:05:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:05:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:05:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:05:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:05:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:05:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:05:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:05:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:05:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:05:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:05:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:06:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:06:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:06:20 | INFO | valid | epoch 053 | valid on 'valid' subset | symm_kl 0 | loss 5.899 | nll_loss 4.322 | ppl 20 | bleu 21.82 | wps 2390.8 | wpb 6353.4 | bsz 230.8 | num_updates 36199 | best_bleu 22.06
2021-01-15 00:06:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:06:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 53 @ 36199 updates, score 21.82) (writing took 2.9615232590585947 seconds)
2021-01-15 00:06:23 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-01-15 00:06:23 | INFO | train | epoch 053 | symm_kl 0 | loss 2.559 | nll_loss 0.727 | ppl 1.65 | wps 9360.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 36199 | lr 1.15152e-05 | gnorm 0.722 | train_wall 589 | wall 0
2021-01-15 00:06:23 | INFO | fairseq.trainer | begin training epoch 54
2021-01-15 00:06:24 | INFO | train_inner | epoch 054:      1 / 683 symm_kl=0, loss=2.549, nll_loss=0.721, ppl=1.65, wps=6977.3, ups=0.8, wpb=8675.4, bsz=339.7, num_updates=36200, lr=1.15151e-05, gnorm=0.71, train_wall=86, wall=0
2021-01-15 00:07:50 | INFO | train_inner | epoch 054:    101 / 683 symm_kl=0, loss=2.549, nll_loss=0.718, ppl=1.64, wps=9771.3, ups=1.16, wpb=8412.5, bsz=314.2, num_updates=36300, lr=1.14992e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-15 00:09:16 | INFO | train_inner | epoch 054:    201 / 683 symm_kl=0, loss=2.556, nll_loss=0.723, ppl=1.65, wps=9917.4, ups=1.16, wpb=8520.1, bsz=296.3, num_updates=36400, lr=1.14834e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-15 00:10:43 | INFO | train_inner | epoch 054:    301 / 683 symm_kl=0, loss=2.562, nll_loss=0.729, ppl=1.66, wps=9859.1, ups=1.15, wpb=8560.7, bsz=298.5, num_updates=36500, lr=1.14676e-05, gnorm=0.736, train_wall=87, wall=0
2021-01-15 00:12:11 | INFO | train_inner | epoch 054:    401 / 683 symm_kl=0, loss=2.558, nll_loss=0.725, ppl=1.65, wps=9926.7, ups=1.13, wpb=8762.4, bsz=293.8, num_updates=36600, lr=1.1452e-05, gnorm=0.714, train_wall=88, wall=0
2021-01-15 00:13:38 | INFO | train_inner | epoch 054:    501 / 683 symm_kl=0, loss=2.565, nll_loss=0.733, ppl=1.66, wps=9874.4, ups=1.16, wpb=8533.1, bsz=298.7, num_updates=36700, lr=1.14364e-05, gnorm=0.732, train_wall=86, wall=0
2021-01-15 00:15:06 | INFO | train_inner | epoch 054:    601 / 683 symm_kl=0, loss=2.551, nll_loss=0.719, ppl=1.65, wps=9963.8, ups=1.14, wpb=8756.1, bsz=315.4, num_updates=36800, lr=1.14208e-05, gnorm=0.709, train_wall=88, wall=0
2021-01-15 00:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:16:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:16:52 | INFO | valid | epoch 054 | valid on 'valid' subset | symm_kl 0 | loss 5.898 | nll_loss 4.321 | ppl 19.99 | bleu 21.82 | wps 2381.4 | wpb 6353.4 | bsz 230.8 | num_updates 36882 | best_bleu 22.06
2021-01-15 00:16:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:16:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 54 @ 36882 updates, score 21.82) (writing took 2.867413004860282 seconds)
2021-01-15 00:16:55 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-01-15 00:16:55 | INFO | train | epoch 054 | symm_kl 0 | loss 2.559 | nll_loss 0.727 | ppl 1.65 | wps 9312.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 36882 | lr 1.14081e-05 | gnorm 0.723 | train_wall 592 | wall 0
2021-01-15 00:16:55 | INFO | fairseq.trainer | begin training epoch 55
2021-01-15 00:17:10 | INFO | train_inner | epoch 055:     18 / 683 symm_kl=0, loss=2.573, nll_loss=0.742, ppl=1.67, wps=7013.5, ups=0.8, wpb=8729.7, bsz=305.8, num_updates=36900, lr=1.14053e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-15 00:18:37 | INFO | train_inner | epoch 055:    118 / 683 symm_kl=0, loss=2.565, nll_loss=0.731, ppl=1.66, wps=9777.6, ups=1.15, wpb=8490, bsz=269.8, num_updates=37000, lr=1.13899e-05, gnorm=0.737, train_wall=87, wall=0
2021-01-15 00:20:04 | INFO | train_inner | epoch 055:    218 / 683 symm_kl=0, loss=2.557, nll_loss=0.724, ppl=1.65, wps=9803.6, ups=1.15, wpb=8542.2, bsz=303.3, num_updates=37100, lr=1.13745e-05, gnorm=0.723, train_wall=87, wall=0
2021-01-15 00:21:32 | INFO | train_inner | epoch 055:    318 / 683 symm_kl=0, loss=2.548, nll_loss=0.717, ppl=1.64, wps=9960, ups=1.14, wpb=8745.3, bsz=305.7, num_updates=37200, lr=1.13592e-05, gnorm=0.712, train_wall=88, wall=0
2021-01-15 00:22:59 | INFO | train_inner | epoch 055:    418 / 683 symm_kl=0, loss=2.56, nll_loss=0.729, ppl=1.66, wps=10165.8, ups=1.15, wpb=8875.3, bsz=327, num_updates=37300, lr=1.1344e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-15 00:24:25 | INFO | train_inner | epoch 055:    518 / 683 symm_kl=0, loss=2.557, nll_loss=0.726, ppl=1.65, wps=9874.2, ups=1.16, wpb=8507, bsz=297.5, num_updates=37400, lr=1.13288e-05, gnorm=0.726, train_wall=86, wall=0
2021-01-15 00:25:52 | INFO | train_inner | epoch 055:    618 / 683 symm_kl=0, loss=2.557, nll_loss=0.725, ppl=1.65, wps=9937.3, ups=1.16, wpb=8561.8, bsz=313.9, num_updates=37500, lr=1.13137e-05, gnorm=0.725, train_wall=86, wall=0
2021-01-15 00:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:26:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:26:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:26:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:26:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:26:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:26:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:26:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:26:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:26:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:27:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:27:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:27:23 | INFO | valid | epoch 055 | valid on 'valid' subset | symm_kl 0 | loss 5.897 | nll_loss 4.322 | ppl 20 | bleu 21.86 | wps 2304.4 | wpb 6353.4 | bsz 230.8 | num_updates 37565 | best_bleu 22.06
2021-01-15 00:27:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:27:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 55 @ 37565 updates, score 21.86) (writing took 2.8450739197432995 seconds)
2021-01-15 00:27:26 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-01-15 00:27:26 | INFO | train | epoch 055 | symm_kl 0 | loss 2.558 | nll_loss 0.726 | ppl 1.65 | wps 9316.1 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 37565 | lr 1.13039e-05 | gnorm 0.722 | train_wall 591 | wall 0
2021-01-15 00:27:26 | INFO | fairseq.trainer | begin training epoch 56
2021-01-15 00:27:56 | INFO | train_inner | epoch 056:     35 / 683 symm_kl=0, loss=2.556, nll_loss=0.726, ppl=1.65, wps=6962.9, ups=0.8, wpb=8673.6, bsz=328.4, num_updates=37600, lr=1.12987e-05, gnorm=0.713, train_wall=85, wall=0
2021-01-15 00:29:23 | INFO | train_inner | epoch 056:    135 / 683 symm_kl=0, loss=2.556, nll_loss=0.723, ppl=1.65, wps=9683.6, ups=1.16, wpb=8355.3, bsz=292.9, num_updates=37700, lr=1.12837e-05, gnorm=0.737, train_wall=86, wall=0
2021-01-15 00:30:49 | INFO | train_inner | epoch 056:    235 / 683 symm_kl=0, loss=2.555, nll_loss=0.723, ppl=1.65, wps=10122, ups=1.15, wpb=8796.4, bsz=313.5, num_updates=37800, lr=1.12687e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-15 00:32:17 | INFO | train_inner | epoch 056:    335 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=9963.7, ups=1.14, wpb=8737.2, bsz=307, num_updates=37900, lr=1.12538e-05, gnorm=0.714, train_wall=87, wall=0
2021-01-15 00:33:44 | INFO | train_inner | epoch 056:    435 / 683 symm_kl=0, loss=2.555, nll_loss=0.722, ppl=1.65, wps=9899.8, ups=1.15, wpb=8640, bsz=293.3, num_updates=38000, lr=1.1239e-05, gnorm=0.723, train_wall=87, wall=0
2021-01-15 00:35:11 | INFO | train_inner | epoch 056:    535 / 683 symm_kl=0, loss=2.563, nll_loss=0.731, ppl=1.66, wps=9848.8, ups=1.16, wpb=8498.4, bsz=292.6, num_updates=38100, lr=1.12243e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-15 00:36:37 | INFO | train_inner | epoch 056:    635 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=9927.7, ups=1.15, wpb=8609.8, bsz=304.1, num_updates=38200, lr=1.12096e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-15 00:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:37:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:37:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:37:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:37:54 | INFO | valid | epoch 056 | valid on 'valid' subset | symm_kl 0 | loss 5.898 | nll_loss 4.323 | ppl 20.01 | bleu 21.89 | wps 2352.4 | wpb 6353.4 | bsz 230.8 | num_updates 38248 | best_bleu 22.06
2021-01-15 00:37:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:37:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 56 @ 38248 updates, score 21.89) (writing took 2.9057175368070602 seconds)
2021-01-15 00:37:56 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-01-15 00:37:56 | INFO | train | epoch 056 | symm_kl 0 | loss 2.557 | nll_loss 0.725 | ppl 1.65 | wps 9331.7 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 38248 | lr 1.12025e-05 | gnorm 0.722 | train_wall 591 | wall 0
2021-01-15 00:37:56 | INFO | fairseq.trainer | begin training epoch 57
2021-01-15 00:38:41 | INFO | train_inner | epoch 057:     52 / 683 symm_kl=0, loss=2.572, nll_loss=0.74, ppl=1.67, wps=6974.5, ups=0.81, wpb=8620.9, bsz=319.2, num_updates=38300, lr=1.11949e-05, gnorm=0.733, train_wall=85, wall=0
2021-01-15 00:40:09 | INFO | train_inner | epoch 057:    152 / 683 symm_kl=0, loss=2.545, nll_loss=0.713, ppl=1.64, wps=10085.1, ups=1.14, wpb=8839.3, bsz=306.9, num_updates=38400, lr=1.11803e-05, gnorm=0.696, train_wall=87, wall=0
2021-01-15 00:41:36 | INFO | train_inner | epoch 057:    252 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=10001.2, ups=1.15, wpb=8694, bsz=304.1, num_updates=38500, lr=1.11658e-05, gnorm=0.714, train_wall=87, wall=0
2021-01-15 00:43:02 | INFO | train_inner | epoch 057:    352 / 683 symm_kl=0, loss=2.567, nll_loss=0.733, ppl=1.66, wps=9799.7, ups=1.16, wpb=8451, bsz=290.3, num_updates=38600, lr=1.11513e-05, gnorm=0.748, train_wall=86, wall=0
2021-01-15 00:44:28 | INFO | train_inner | epoch 057:    452 / 683 symm_kl=0, loss=2.562, nll_loss=0.729, ppl=1.66, wps=9786.5, ups=1.16, wpb=8446.7, bsz=298.6, num_updates=38700, lr=1.11369e-05, gnorm=0.738, train_wall=86, wall=0
2021-01-15 00:45:54 | INFO | train_inner | epoch 057:    552 / 683 symm_kl=0, loss=2.557, nll_loss=0.723, ppl=1.65, wps=9853.1, ups=1.16, wpb=8507.6, bsz=309.3, num_updates=38800, lr=1.11226e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-15 00:47:21 | INFO | train_inner | epoch 057:    652 / 683 symm_kl=0, loss=2.557, nll_loss=0.726, ppl=1.65, wps=9949.6, ups=1.15, wpb=8632.2, bsz=286.7, num_updates=38900, lr=1.11083e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-15 00:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:47:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:47:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:47:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:47:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:47:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:47:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:47:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:47:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:47:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:47:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:47:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:47:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:48:23 | INFO | valid | epoch 057 | valid on 'valid' subset | symm_kl 0 | loss 5.898 | nll_loss 4.324 | ppl 20.03 | bleu 21.92 | wps 2394.1 | wpb 6353.4 | bsz 230.8 | num_updates 38931 | best_bleu 22.06
2021-01-15 00:48:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:48:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 57 @ 38931 updates, score 21.92) (writing took 2.9612728860229254 seconds)
2021-01-15 00:48:26 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-01-15 00:48:26 | INFO | train | epoch 057 | symm_kl 0 | loss 2.557 | nll_loss 0.724 | ppl 1.65 | wps 9342.6 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 38931 | lr 1.11038e-05 | gnorm 0.724 | train_wall 590 | wall 0
2021-01-15 00:48:26 | INFO | fairseq.trainer | begin training epoch 58
2021-01-15 00:49:26 | INFO | train_inner | epoch 058:     69 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=6905, ups=0.8, wpb=8595.4, bsz=312, num_updates=39000, lr=1.1094e-05, gnorm=0.715, train_wall=86, wall=0
2021-01-15 00:50:51 | INFO | train_inner | epoch 058:    169 / 683 symm_kl=0, loss=2.56, nll_loss=0.727, ppl=1.65, wps=9877.5, ups=1.17, wpb=8465.8, bsz=301.8, num_updates=39100, lr=1.10798e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-15 00:52:18 | INFO | train_inner | epoch 058:    269 / 683 symm_kl=0, loss=2.548, nll_loss=0.716, ppl=1.64, wps=9928.9, ups=1.15, wpb=8597.4, bsz=315, num_updates=39200, lr=1.10657e-05, gnorm=0.713, train_wall=86, wall=0
2021-01-15 00:53:45 | INFO | train_inner | epoch 058:    369 / 683 symm_kl=0, loss=2.557, nll_loss=0.726, ppl=1.65, wps=10172.1, ups=1.15, wpb=8857.2, bsz=294.1, num_updates=39300, lr=1.10516e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-15 00:55:12 | INFO | train_inner | epoch 058:    469 / 683 symm_kl=0, loss=2.557, nll_loss=0.725, ppl=1.65, wps=9984.2, ups=1.16, wpb=8638.9, bsz=314.1, num_updates=39400, lr=1.10375e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-15 00:56:39 | INFO | train_inner | epoch 058:    569 / 683 symm_kl=0, loss=2.557, nll_loss=0.725, ppl=1.65, wps=9919.7, ups=1.15, wpb=8639.1, bsz=311, num_updates=39500, lr=1.10236e-05, gnorm=0.721, train_wall=87, wall=0
2021-01-15 00:58:05 | INFO | train_inner | epoch 058:    669 / 683 symm_kl=0, loss=2.561, nll_loss=0.727, ppl=1.66, wps=9749.1, ups=1.16, wpb=8387.9, bsz=284.7, num_updates=39600, lr=1.10096e-05, gnorm=0.742, train_wall=86, wall=0
2021-01-15 00:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 00:58:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 00:58:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 00:58:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 00:58:52 | INFO | valid | epoch 058 | valid on 'valid' subset | symm_kl 0 | loss 5.901 | nll_loss 4.325 | ppl 20.04 | bleu 22.05 | wps 2387.1 | wpb 6353.4 | bsz 230.8 | num_updates 39614 | best_bleu 22.06
2021-01-15 00:58:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 00:58:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 58 @ 39614 updates, score 22.05) (writing took 2.9325988814234734 seconds)
2021-01-15 00:58:55 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-01-15 00:58:55 | INFO | train | epoch 058 | symm_kl 0 | loss 2.556 | nll_loss 0.723 | ppl 1.65 | wps 9349.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 39614 | lr 1.10077e-05 | gnorm 0.722 | train_wall 590 | wall 0
2021-01-15 00:58:55 | INFO | fairseq.trainer | begin training epoch 59
2021-01-15 01:00:10 | INFO | train_inner | epoch 059:     86 / 683 symm_kl=0, loss=2.554, nll_loss=0.721, ppl=1.65, wps=7095, ups=0.8, wpb=8888.2, bsz=313.4, num_updates=39700, lr=1.09958e-05, gnorm=0.706, train_wall=87, wall=0
2021-01-15 01:01:37 | INFO | train_inner | epoch 059:    186 / 683 symm_kl=0, loss=2.552, nll_loss=0.717, ppl=1.64, wps=9877.5, ups=1.14, wpb=8639, bsz=284, num_updates=39800, lr=1.09819e-05, gnorm=0.723, train_wall=87, wall=0
2021-01-15 01:03:04 | INFO | train_inner | epoch 059:    286 / 683 symm_kl=0, loss=2.562, nll_loss=0.73, ppl=1.66, wps=9878.3, ups=1.16, wpb=8529.5, bsz=293.8, num_updates=39900, lr=1.09682e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-15 01:04:30 | INFO | train_inner | epoch 059:    386 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=9924.9, ups=1.17, wpb=8504.1, bsz=299, num_updates=40000, lr=1.09545e-05, gnorm=0.729, train_wall=85, wall=0
2021-01-15 01:05:56 | INFO | train_inner | epoch 059:    486 / 683 symm_kl=0, loss=2.553, nll_loss=0.72, ppl=1.65, wps=9880.3, ups=1.16, wpb=8510, bsz=293.9, num_updates=40100, lr=1.09408e-05, gnorm=0.726, train_wall=86, wall=0
2021-01-15 01:07:23 | INFO | train_inner | epoch 059:    586 / 683 symm_kl=0, loss=2.541, nll_loss=0.71, ppl=1.64, wps=9831.1, ups=1.14, wpb=8594.1, bsz=320.6, num_updates=40200, lr=1.09272e-05, gnorm=0.717, train_wall=87, wall=0
2021-01-15 01:08:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 01:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:08:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:08:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:08:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:08:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:08:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:08:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:08:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:08:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:08:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:08:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:08:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:08:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:09:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:09:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:09:22 | INFO | valid | epoch 059 | valid on 'valid' subset | symm_kl 0 | loss 5.901 | nll_loss 4.325 | ppl 20.04 | bleu 21.99 | wps 2366.8 | wpb 6353.4 | bsz 230.8 | num_updates 40297 | best_bleu 22.06
2021-01-15 01:09:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 01:09:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 59 @ 40297 updates, score 21.99) (writing took 2.939172213897109 seconds)
2021-01-15 01:09:25 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-01-15 01:09:25 | INFO | train | epoch 059 | symm_kl 0 | loss 2.555 | nll_loss 0.722 | ppl 1.65 | wps 9339.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 40297 | lr 1.0914e-05 | gnorm 0.723 | train_wall 590 | wall 0
2021-01-15 01:09:25 | INFO | fairseq.trainer | begin training epoch 60
2021-01-15 01:09:27 | INFO | train_inner | epoch 060:      3 / 683 symm_kl=0, loss=2.564, nll_loss=0.733, ppl=1.66, wps=6965.2, ups=0.81, wpb=8648.6, bsz=318.8, num_updates=40300, lr=1.09136e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-15 01:10:54 | INFO | train_inner | epoch 060:    103 / 683 symm_kl=0, loss=2.551, nll_loss=0.716, ppl=1.64, wps=9636.4, ups=1.16, wpb=8322.1, bsz=287.4, num_updates=40400, lr=1.09001e-05, gnorm=0.747, train_wall=86, wall=0
2021-01-15 01:12:19 | INFO | train_inner | epoch 060:    203 / 683 symm_kl=0, loss=2.55, nll_loss=0.717, ppl=1.64, wps=9803.3, ups=1.18, wpb=8327.2, bsz=320.1, num_updates=40500, lr=1.08866e-05, gnorm=0.734, train_wall=85, wall=0
2021-01-15 01:13:45 | INFO | train_inner | epoch 060:    303 / 683 symm_kl=0, loss=2.551, nll_loss=0.72, ppl=1.65, wps=10100.6, ups=1.15, wpb=8745.7, bsz=286.8, num_updates=40600, lr=1.08732e-05, gnorm=0.71, train_wall=86, wall=0
2021-01-15 01:15:12 | INFO | train_inner | epoch 060:    403 / 683 symm_kl=0, loss=2.551, nll_loss=0.718, ppl=1.65, wps=10002.9, ups=1.15, wpb=8677.7, bsz=289.6, num_updates=40700, lr=1.08598e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-15 01:16:39 | INFO | train_inner | epoch 060:    503 / 683 symm_kl=0, loss=2.561, nll_loss=0.728, ppl=1.66, wps=10075.9, ups=1.14, wpb=8810.7, bsz=314.6, num_updates=40800, lr=1.08465e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-15 01:18:06 | INFO | train_inner | epoch 060:    603 / 683 symm_kl=0, loss=2.561, nll_loss=0.729, ppl=1.66, wps=9945.2, ups=1.15, wpb=8627.2, bsz=307.1, num_updates=40900, lr=1.08333e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-15 01:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 01:19:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:19:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:19:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:19:50 | INFO | valid | epoch 060 | valid on 'valid' subset | symm_kl 0 | loss 5.905 | nll_loss 4.329 | ppl 20.09 | bleu 21.83 | wps 2357.6 | wpb 6353.4 | bsz 230.8 | num_updates 40980 | best_bleu 22.06
2021-01-15 01:19:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 01:19:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 60 @ 40980 updates, score 21.83) (writing took 2.943216599524021 seconds)
2021-01-15 01:19:53 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-01-15 01:19:53 | INFO | train | epoch 060 | symm_kl 0 | loss 2.554 | nll_loss 0.722 | ppl 1.65 | wps 9360.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 40980 | lr 1.08227e-05 | gnorm 0.723 | train_wall 589 | wall 0
2021-01-15 01:19:53 | INFO | fairseq.trainer | begin training epoch 61
2021-01-15 01:20:10 | INFO | train_inner | epoch 061:     20 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=7139.9, ups=0.81, wpb=8850.9, bsz=327.2, num_updates=41000, lr=1.082e-05, gnorm=0.709, train_wall=85, wall=0
2021-01-15 01:21:37 | INFO | train_inner | epoch 061:    120 / 683 symm_kl=0, loss=2.545, nll_loss=0.712, ppl=1.64, wps=10049, ups=1.14, wpb=8784.7, bsz=291.1, num_updates=41100, lr=1.08069e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-15 01:23:03 | INFO | train_inner | epoch 061:    220 / 683 symm_kl=0, loss=2.55, nll_loss=0.715, ppl=1.64, wps=9670.7, ups=1.17, wpb=8290.5, bsz=285.4, num_updates=41200, lr=1.07937e-05, gnorm=0.744, train_wall=86, wall=0
2021-01-15 01:24:31 | INFO | train_inner | epoch 061:    320 / 683 symm_kl=0, loss=2.546, nll_loss=0.715, ppl=1.64, wps=9990.8, ups=1.14, wpb=8763.5, bsz=321.2, num_updates=41300, lr=1.07807e-05, gnorm=0.702, train_wall=88, wall=0
2021-01-15 01:25:57 | INFO | train_inner | epoch 061:    420 / 683 symm_kl=0, loss=2.563, nll_loss=0.73, ppl=1.66, wps=9941.1, ups=1.16, wpb=8542.7, bsz=297.3, num_updates=41400, lr=1.07676e-05, gnorm=0.736, train_wall=86, wall=0
2021-01-15 01:27:24 | INFO | train_inner | epoch 061:    520 / 683 symm_kl=0, loss=2.546, nll_loss=0.714, ppl=1.64, wps=10015.1, ups=1.14, wpb=8775.1, bsz=316.7, num_updates=41500, lr=1.07547e-05, gnorm=0.709, train_wall=87, wall=0
2021-01-15 01:28:50 | INFO | train_inner | epoch 061:    620 / 683 symm_kl=0, loss=2.571, nll_loss=0.739, ppl=1.67, wps=10023.2, ups=1.17, wpb=8600.2, bsz=292.6, num_updates=41600, lr=1.07417e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-15 01:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 01:29:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:29:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:29:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:29:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:29:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:29:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:29:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:29:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:30:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:30:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:30:19 | INFO | valid | epoch 061 | valid on 'valid' subset | symm_kl 0 | loss 5.908 | nll_loss 4.334 | ppl 20.17 | bleu 21.94 | wps 2380.7 | wpb 6353.4 | bsz 230.8 | num_updates 41663 | best_bleu 22.06
2021-01-15 01:30:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 01:30:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 61 @ 41663 updates, score 21.94) (writing took 2.9633630327880383 seconds)
2021-01-15 01:30:22 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-01-15 01:30:22 | INFO | train | epoch 061 | symm_kl 0 | loss 2.554 | nll_loss 0.721 | ppl 1.65 | wps 9346.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 41663 | lr 1.07336e-05 | gnorm 0.723 | train_wall 590 | wall 0
2021-01-15 01:30:22 | INFO | fairseq.trainer | begin training epoch 62
2021-01-15 01:30:54 | INFO | train_inner | epoch 062:     37 / 683 symm_kl=0, loss=2.542, nll_loss=0.71, ppl=1.64, wps=6728, ups=0.81, wpb=8306.7, bsz=316.9, num_updates=41700, lr=1.07288e-05, gnorm=0.743, train_wall=85, wall=0
2021-01-15 01:32:21 | INFO | train_inner | epoch 062:    137 / 683 symm_kl=0, loss=2.547, nll_loss=0.715, ppl=1.64, wps=10017.7, ups=1.15, wpb=8728.6, bsz=304.4, num_updates=41800, lr=1.0716e-05, gnorm=0.709, train_wall=87, wall=0
2021-01-15 01:33:48 | INFO | train_inner | epoch 062:    237 / 683 symm_kl=0, loss=2.551, nll_loss=0.718, ppl=1.65, wps=10081.5, ups=1.14, wpb=8819.1, bsz=317.7, num_updates=41900, lr=1.07032e-05, gnorm=0.705, train_wall=87, wall=0
2021-01-15 01:35:16 | INFO | train_inner | epoch 062:    337 / 683 symm_kl=0, loss=2.547, nll_loss=0.715, ppl=1.64, wps=10028.8, ups=1.15, wpb=8752.5, bsz=299.4, num_updates=42000, lr=1.06904e-05, gnorm=0.706, train_wall=87, wall=0
2021-01-15 01:36:42 | INFO | train_inner | epoch 062:    437 / 683 symm_kl=0, loss=2.559, nll_loss=0.725, ppl=1.65, wps=9779, ups=1.16, wpb=8434.1, bsz=309.1, num_updates=42100, lr=1.06777e-05, gnorm=0.741, train_wall=86, wall=0
2021-01-15 01:38:09 | INFO | train_inner | epoch 062:    537 / 683 symm_kl=0, loss=2.549, nll_loss=0.716, ppl=1.64, wps=9938.1, ups=1.15, wpb=8625.2, bsz=304.2, num_updates=42200, lr=1.06651e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-15 01:39:34 | INFO | train_inner | epoch 062:    637 / 683 symm_kl=0, loss=2.569, nll_loss=0.737, ppl=1.67, wps=10074.9, ups=1.17, wpb=8594.9, bsz=308.5, num_updates=42300, lr=1.06525e-05, gnorm=0.74, train_wall=85, wall=0
2021-01-15 01:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 01:40:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:40:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:40:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:40:48 | INFO | valid | epoch 062 | valid on 'valid' subset | symm_kl 0 | loss 5.907 | nll_loss 4.333 | ppl 20.15 | bleu 21.83 | wps 2372.5 | wpb 6353.4 | bsz 230.8 | num_updates 42346 | best_bleu 22.06
2021-01-15 01:40:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 01:40:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 62 @ 42346 updates, score 21.83) (writing took 2.9229424446821213 seconds)
2021-01-15 01:40:51 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2021-01-15 01:40:51 | INFO | train | epoch 062 | symm_kl 0 | loss 2.553 | nll_loss 0.721 | ppl 1.65 | wps 9351.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 42346 | lr 1.06467e-05 | gnorm 0.724 | train_wall 589 | wall 0
2021-01-15 01:40:51 | INFO | fairseq.trainer | begin training epoch 63
2021-01-15 01:41:38 | INFO | train_inner | epoch 063:     54 / 683 symm_kl=0, loss=2.56, nll_loss=0.726, ppl=1.65, wps=6870.9, ups=0.8, wpb=8541.2, bsz=288.2, num_updates=42400, lr=1.06399e-05, gnorm=0.733, train_wall=86, wall=0
2021-01-15 01:43:05 | INFO | train_inner | epoch 063:    154 / 683 symm_kl=0, loss=2.553, nll_loss=0.719, ppl=1.65, wps=9955.3, ups=1.15, wpb=8685.1, bsz=291, num_updates=42500, lr=1.06274e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-15 01:44:33 | INFO | train_inner | epoch 063:    254 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=9828.2, ups=1.15, wpb=8552.4, bsz=304.4, num_updates=42600, lr=1.06149e-05, gnorm=0.723, train_wall=87, wall=0
2021-01-15 01:45:58 | INFO | train_inner | epoch 063:    354 / 683 symm_kl=0, loss=2.564, nll_loss=0.731, ppl=1.66, wps=9898.5, ups=1.17, wpb=8484.7, bsz=315.2, num_updates=42700, lr=1.06025e-05, gnorm=0.731, train_wall=86, wall=0
2021-01-15 01:47:25 | INFO | train_inner | epoch 063:    454 / 683 symm_kl=0, loss=2.543, nll_loss=0.709, ppl=1.63, wps=9884.5, ups=1.15, wpb=8608.7, bsz=295.1, num_updates=42800, lr=1.05901e-05, gnorm=0.715, train_wall=87, wall=0
2021-01-15 01:48:52 | INFO | train_inner | epoch 063:    554 / 683 symm_kl=0, loss=2.545, nll_loss=0.714, ppl=1.64, wps=10122.6, ups=1.15, wpb=8802.8, bsz=298.8, num_updates=42900, lr=1.05777e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-15 01:50:19 | INFO | train_inner | epoch 063:    654 / 683 symm_kl=0, loss=2.564, nll_loss=0.731, ppl=1.66, wps=9849, ups=1.15, wpb=8587.9, bsz=307, num_updates=43000, lr=1.05654e-05, gnorm=0.735, train_wall=87, wall=0
2021-01-15 01:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 01:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:50:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:50:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:50:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:50:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:50:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:50:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:50:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 01:51:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 01:51:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 01:51:18 | INFO | valid | epoch 063 | valid on 'valid' subset | symm_kl 0 | loss 5.909 | nll_loss 4.334 | ppl 20.17 | bleu 21.91 | wps 2388.5 | wpb 6353.4 | bsz 230.8 | num_updates 43029 | best_bleu 22.06
2021-01-15 01:51:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 01:51:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 63 @ 43029 updates, score 21.91) (writing took 2.934094727039337 seconds)
2021-01-15 01:51:21 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2021-01-15 01:51:21 | INFO | train | epoch 063 | symm_kl 0 | loss 2.553 | nll_loss 0.72 | ppl 1.65 | wps 9329.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 43029 | lr 1.05618e-05 | gnorm 0.723 | train_wall 591 | wall 0
2021-01-15 01:51:21 | INFO | fairseq.trainer | begin training epoch 64
2021-01-15 01:52:23 | INFO | train_inner | epoch 064:     71 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=7035.1, ups=0.81, wpb=8680.1, bsz=348.5, num_updates=43100, lr=1.05531e-05, gnorm=0.724, train_wall=85, wall=0
2021-01-15 01:53:49 | INFO | train_inner | epoch 064:    171 / 683 symm_kl=0, loss=2.554, nll_loss=0.721, ppl=1.65, wps=9715.8, ups=1.16, wpb=8410.5, bsz=320.7, num_updates=43200, lr=1.05409e-05, gnorm=0.73, train_wall=86, wall=0
2021-01-15 01:55:17 | INFO | train_inner | epoch 064:    271 / 683 symm_kl=0, loss=2.547, nll_loss=0.713, ppl=1.64, wps=9931.4, ups=1.14, wpb=8711, bsz=287.9, num_updates=43300, lr=1.05287e-05, gnorm=0.717, train_wall=88, wall=0
2021-01-15 01:56:45 | INFO | train_inner | epoch 064:    371 / 683 symm_kl=0, loss=2.55, nll_loss=0.717, ppl=1.64, wps=10020.3, ups=1.14, wpb=8779.5, bsz=298.1, num_updates=43400, lr=1.05166e-05, gnorm=0.708, train_wall=87, wall=0
2021-01-15 01:58:11 | INFO | train_inner | epoch 064:    471 / 683 symm_kl=0, loss=2.55, nll_loss=0.716, ppl=1.64, wps=9867, ups=1.16, wpb=8483, bsz=273.6, num_updates=43500, lr=1.05045e-05, gnorm=0.736, train_wall=86, wall=0
2021-01-15 01:59:36 | INFO | train_inner | epoch 064:    571 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=9856.6, ups=1.17, wpb=8438.5, bsz=298.2, num_updates=43600, lr=1.04925e-05, gnorm=0.735, train_wall=85, wall=0
2021-01-15 02:01:03 | INFO | train_inner | epoch 064:    671 / 683 symm_kl=0, loss=2.554, nll_loss=0.723, ppl=1.65, wps=10114.5, ups=1.15, wpb=8790.1, bsz=306.3, num_updates=43700, lr=1.04804e-05, gnorm=0.716, train_wall=87, wall=0
2021-01-15 02:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:01:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:01:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:01:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:01:49 | INFO | valid | epoch 064 | valid on 'valid' subset | symm_kl 0 | loss 5.908 | nll_loss 4.333 | ppl 20.16 | bleu 21.95 | wps 2365.4 | wpb 6353.4 | bsz 230.8 | num_updates 43712 | best_bleu 22.06
2021-01-15 02:01:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:01:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 64 @ 43712 updates, score 21.95) (writing took 2.9118828512728214 seconds)
2021-01-15 02:01:51 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2021-01-15 02:01:51 | INFO | train | epoch 064 | symm_kl 0 | loss 2.552 | nll_loss 0.719 | ppl 1.65 | wps 9333.8 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 43712 | lr 1.0479e-05 | gnorm 0.723 | train_wall 590 | wall 0
2021-01-15 02:01:51 | INFO | fairseq.trainer | begin training epoch 65
2021-01-15 02:03:08 | INFO | train_inner | epoch 065:     88 / 683 symm_kl=0, loss=2.544, nll_loss=0.711, ppl=1.64, wps=6840.7, ups=0.8, wpb=8528.7, bsz=317.7, num_updates=43800, lr=1.04685e-05, gnorm=0.723, train_wall=86, wall=0
2021-01-15 02:04:34 | INFO | train_inner | epoch 065:    188 / 683 symm_kl=0, loss=2.559, nll_loss=0.724, ppl=1.65, wps=9975.9, ups=1.16, wpb=8591.9, bsz=273, num_updates=43900, lr=1.04565e-05, gnorm=0.727, train_wall=86, wall=0
2021-01-15 02:05:59 | INFO | train_inner | epoch 065:    288 / 683 symm_kl=0, loss=2.558, nll_loss=0.724, ppl=1.65, wps=9848.1, ups=1.17, wpb=8395.8, bsz=307.4, num_updates=44000, lr=1.04447e-05, gnorm=0.738, train_wall=85, wall=0
2021-01-15 02:07:26 | INFO | train_inner | epoch 065:    388 / 683 symm_kl=0, loss=2.557, nll_loss=0.724, ppl=1.65, wps=10041.8, ups=1.15, wpb=8702.2, bsz=309, num_updates=44100, lr=1.04328e-05, gnorm=0.722, train_wall=86, wall=0
2021-01-15 02:08:52 | INFO | train_inner | epoch 065:    488 / 683 symm_kl=0, loss=2.546, nll_loss=0.714, ppl=1.64, wps=9944.4, ups=1.16, wpb=8592.7, bsz=303.9, num_updates=44200, lr=1.0421e-05, gnorm=0.723, train_wall=86, wall=0
2021-01-15 02:10:18 | INFO | train_inner | epoch 065:    588 / 683 symm_kl=0, loss=2.541, nll_loss=0.709, ppl=1.63, wps=9990.7, ups=1.16, wpb=8595.2, bsz=310.6, num_updates=44300, lr=1.04092e-05, gnorm=0.72, train_wall=86, wall=0
2021-01-15 02:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:11:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:12:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:12:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:12:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:12:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:12:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:12:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:12:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:12:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:12:17 | INFO | valid | epoch 065 | valid on 'valid' subset | symm_kl 0 | loss 5.905 | nll_loss 4.33 | ppl 20.11 | bleu 21.85 | wps 2363.7 | wpb 6353.4 | bsz 230.8 | num_updates 44395 | best_bleu 22.06
2021-01-15 02:12:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:12:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 65 @ 44395 updates, score 21.85) (writing took 2.944940811023116 seconds)
2021-01-15 02:12:20 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2021-01-15 02:12:20 | INFO | train | epoch 065 | symm_kl 0 | loss 2.551 | nll_loss 0.718 | ppl 1.65 | wps 9357.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 44395 | lr 1.03981e-05 | gnorm 0.724 | train_wall 589 | wall 0
2021-01-15 02:12:20 | INFO | fairseq.trainer | begin training epoch 66
2021-01-15 02:12:24 | INFO | train_inner | epoch 066:      5 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=6942, ups=0.79, wpb=8743.2, bsz=295.6, num_updates=44400, lr=1.03975e-05, gnorm=0.724, train_wall=87, wall=0
2021-01-15 02:13:51 | INFO | train_inner | epoch 066:    105 / 683 symm_kl=0, loss=2.548, nll_loss=0.716, ppl=1.64, wps=9929.1, ups=1.16, wpb=8573.3, bsz=306.7, num_updates=44500, lr=1.03858e-05, gnorm=0.718, train_wall=86, wall=0
2021-01-15 02:15:17 | INFO | train_inner | epoch 066:    205 / 683 symm_kl=0, loss=2.552, nll_loss=0.719, ppl=1.65, wps=9988.7, ups=1.15, wpb=8649.9, bsz=306.5, num_updates=44600, lr=1.03742e-05, gnorm=0.721, train_wall=86, wall=0
2021-01-15 02:16:43 | INFO | train_inner | epoch 066:    305 / 683 symm_kl=0, loss=2.55, nll_loss=0.716, ppl=1.64, wps=10057.1, ups=1.16, wpb=8662.1, bsz=300.6, num_updates=44700, lr=1.03626e-05, gnorm=0.718, train_wall=86, wall=0
2021-01-15 02:18:10 | INFO | train_inner | epoch 066:    405 / 683 symm_kl=0, loss=2.55, nll_loss=0.717, ppl=1.64, wps=9849.6, ups=1.16, wpb=8512.4, bsz=284.4, num_updates=44800, lr=1.0351e-05, gnorm=0.734, train_wall=86, wall=0
2021-01-15 02:19:37 | INFO | train_inner | epoch 066:    505 / 683 symm_kl=0, loss=2.549, nll_loss=0.717, ppl=1.64, wps=9989.4, ups=1.15, wpb=8697.8, bsz=312.6, num_updates=44900, lr=1.03395e-05, gnorm=0.717, train_wall=87, wall=0
2021-01-15 02:21:04 | INFO | train_inner | epoch 066:    605 / 683 symm_kl=0, loss=2.558, nll_loss=0.726, ppl=1.65, wps=9963, ups=1.15, wpb=8696.7, bsz=316.6, num_updates=45000, lr=1.0328e-05, gnorm=0.72, train_wall=87, wall=0
2021-01-15 02:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:22:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:22:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:22:46 | INFO | valid | epoch 066 | valid on 'valid' subset | symm_kl 0 | loss 5.913 | nll_loss 4.339 | ppl 20.23 | bleu 21.92 | wps 2380.4 | wpb 6353.4 | bsz 230.8 | num_updates 45078 | best_bleu 22.06
2021-01-15 02:22:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:22:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 66 @ 45078 updates, score 21.92) (writing took 2.9250038154423237 seconds)
2021-01-15 02:22:49 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2021-01-15 02:22:49 | INFO | train | epoch 066 | symm_kl 0 | loss 2.551 | nll_loss 0.718 | ppl 1.65 | wps 9345.2 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 45078 | lr 1.0319e-05 | gnorm 0.724 | train_wall 590 | wall 0
2021-01-15 02:22:49 | INFO | fairseq.trainer | begin training epoch 67
2021-01-15 02:23:08 | INFO | train_inner | epoch 067:     22 / 683 symm_kl=0, loss=2.549, nll_loss=0.717, ppl=1.64, wps=6864.6, ups=0.81, wpb=8489, bsz=300.6, num_updates=45100, lr=1.03165e-05, gnorm=0.738, train_wall=86, wall=0
2021-01-15 02:24:35 | INFO | train_inner | epoch 067:    122 / 683 symm_kl=0, loss=2.546, nll_loss=0.712, ppl=1.64, wps=9813.9, ups=1.15, wpb=8560.5, bsz=297.4, num_updates=45200, lr=1.03051e-05, gnorm=0.727, train_wall=87, wall=0
2021-01-15 02:26:02 | INFO | train_inner | epoch 067:    222 / 683 symm_kl=0, loss=2.551, nll_loss=0.718, ppl=1.64, wps=9964.2, ups=1.15, wpb=8680.9, bsz=295.4, num_updates=45300, lr=1.02937e-05, gnorm=0.72, train_wall=87, wall=0
2021-01-15 02:27:29 | INFO | train_inner | epoch 067:    322 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=9939.2, ups=1.15, wpb=8652.4, bsz=292.2, num_updates=45400, lr=1.02824e-05, gnorm=0.717, train_wall=87, wall=0
2021-01-15 02:28:56 | INFO | train_inner | epoch 067:    422 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=9968, ups=1.15, wpb=8670.6, bsz=326.2, num_updates=45500, lr=1.02711e-05, gnorm=0.722, train_wall=87, wall=0
2021-01-15 02:30:22 | INFO | train_inner | epoch 067:    522 / 683 symm_kl=0, loss=2.548, nll_loss=0.716, ppl=1.64, wps=9797.7, ups=1.16, wpb=8427, bsz=307.4, num_updates=45600, lr=1.02598e-05, gnorm=0.735, train_wall=86, wall=0
2021-01-15 02:31:49 | INFO | train_inner | epoch 067:    622 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=9936.5, ups=1.15, wpb=8631.8, bsz=308.2, num_updates=45700, lr=1.02486e-05, gnorm=0.724, train_wall=87, wall=0
2021-01-15 02:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:32:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:33:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:33:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:33:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:33:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:33:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:33:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:33:17 | INFO | valid | epoch 067 | valid on 'valid' subset | symm_kl 0 | loss 5.911 | nll_loss 4.337 | ppl 20.21 | bleu 21.89 | wps 2368.7 | wpb 6353.4 | bsz 230.8 | num_updates 45761 | best_bleu 22.06
2021-01-15 02:33:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:33:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 67 @ 45761 updates, score 21.89) (writing took 2.943201182410121 seconds)
2021-01-15 02:33:20 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2021-01-15 02:33:20 | INFO | train | epoch 067 | symm_kl 0 | loss 2.55 | nll_loss 0.717 | ppl 1.64 | wps 9322.5 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 45761 | lr 1.02417e-05 | gnorm 0.724 | train_wall 591 | wall 0
2021-01-15 02:33:20 | INFO | fairseq.trainer | begin training epoch 68
2021-01-15 02:33:53 | INFO | train_inner | epoch 068:     39 / 683 symm_kl=0, loss=2.554, nll_loss=0.721, ppl=1.65, wps=6930, ups=0.81, wpb=8589.4, bsz=315.6, num_updates=45800, lr=1.02374e-05, gnorm=0.726, train_wall=86, wall=0
2021-01-15 02:35:20 | INFO | train_inner | epoch 068:    139 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=9703.3, ups=1.16, wpb=8388.7, bsz=300.8, num_updates=45900, lr=1.02262e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-15 02:36:48 | INFO | train_inner | epoch 068:    239 / 683 symm_kl=0, loss=2.554, nll_loss=0.719, ppl=1.65, wps=9889.2, ups=1.14, wpb=8706.7, bsz=274.4, num_updates=46000, lr=1.02151e-05, gnorm=0.728, train_wall=88, wall=0
2021-01-15 02:38:15 | INFO | train_inner | epoch 068:    339 / 683 symm_kl=0, loss=2.538, nll_loss=0.707, ppl=1.63, wps=9896.2, ups=1.14, wpb=8700.4, bsz=327.4, num_updates=46100, lr=1.0204e-05, gnorm=0.714, train_wall=88, wall=0
2021-01-15 02:39:42 | INFO | train_inner | epoch 068:    439 / 683 symm_kl=0, loss=2.545, nll_loss=0.713, ppl=1.64, wps=9900.7, ups=1.16, wpb=8535.5, bsz=328, num_updates=46200, lr=1.01929e-05, gnorm=0.719, train_wall=86, wall=0
2021-01-15 02:41:08 | INFO | train_inner | epoch 068:    539 / 683 symm_kl=0, loss=2.557, nll_loss=0.723, ppl=1.65, wps=10111.8, ups=1.15, wpb=8774.6, bsz=273.3, num_updates=46300, lr=1.01819e-05, gnorm=0.719, train_wall=87, wall=0
2021-01-15 02:42:36 | INFO | train_inner | epoch 068:    639 / 683 symm_kl=0, loss=2.56, nll_loss=0.728, ppl=1.66, wps=10110.4, ups=1.14, wpb=8848.9, bsz=305.7, num_updates=46400, lr=1.0171e-05, gnorm=0.718, train_wall=87, wall=0
2021-01-15 02:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:43:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:43:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:43:48 | INFO | valid | epoch 068 | valid on 'valid' subset | symm_kl 0 | loss 5.911 | nll_loss 4.338 | ppl 20.22 | bleu 21.89 | wps 2408.7 | wpb 6353.4 | bsz 230.8 | num_updates 46444 | best_bleu 22.06
2021-01-15 02:43:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:43:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 68 @ 46444 updates, score 21.89) (writing took 2.838901326060295 seconds)
2021-01-15 02:43:51 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2021-01-15 02:43:51 | INFO | train | epoch 068 | symm_kl 0 | loss 2.55 | nll_loss 0.717 | ppl 1.64 | wps 9326.8 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 46444 | lr 1.01661e-05 | gnorm 0.724 | train_wall 592 | wall 0
2021-01-15 02:43:51 | INFO | fairseq.trainer | begin training epoch 69
2021-01-15 02:44:39 | INFO | train_inner | epoch 069:     56 / 683 symm_kl=0, loss=2.549, nll_loss=0.714, ppl=1.64, wps=6825.7, ups=0.81, wpb=8391.2, bsz=274.1, num_updates=46500, lr=1.016e-05, gnorm=0.748, train_wall=85, wall=0
2021-01-15 02:46:06 | INFO | train_inner | epoch 069:    156 / 683 symm_kl=0, loss=2.543, nll_loss=0.711, ppl=1.64, wps=9856.4, ups=1.15, wpb=8561.1, bsz=303.2, num_updates=46600, lr=1.01491e-05, gnorm=0.728, train_wall=87, wall=0
2021-01-15 02:47:32 | INFO | train_inner | epoch 069:    256 / 683 symm_kl=0, loss=2.554, nll_loss=0.722, ppl=1.65, wps=9852.3, ups=1.17, wpb=8450.4, bsz=316.3, num_updates=46700, lr=1.01382e-05, gnorm=0.733, train_wall=86, wall=0
2021-01-15 02:48:59 | INFO | train_inner | epoch 069:    356 / 683 symm_kl=0, loss=2.537, nll_loss=0.704, ppl=1.63, wps=10040, ups=1.15, wpb=8728.4, bsz=319.7, num_updates=46800, lr=1.01274e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-15 02:50:25 | INFO | train_inner | epoch 069:    456 / 683 symm_kl=0, loss=2.548, nll_loss=0.716, ppl=1.64, wps=10112.7, ups=1.15, wpb=8771.6, bsz=320.4, num_updates=46900, lr=1.01166e-05, gnorm=0.71, train_wall=87, wall=0
2021-01-15 02:51:52 | INFO | train_inner | epoch 069:    556 / 683 symm_kl=0, loss=2.566, nll_loss=0.732, ppl=1.66, wps=9814.1, ups=1.15, wpb=8510.7, bsz=289.6, num_updates=47000, lr=1.01058e-05, gnorm=0.745, train_wall=87, wall=0
2021-01-15 02:53:19 | INFO | train_inner | epoch 069:    656 / 683 symm_kl=0, loss=2.554, nll_loss=0.721, ppl=1.65, wps=9896.7, ups=1.15, wpb=8625.5, bsz=307.3, num_updates=47100, lr=1.00951e-05, gnorm=0.729, train_wall=87, wall=0
2021-01-15 02:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 02:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:53:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:53:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:53:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:53:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:53:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:53:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:53:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 02:54:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 02:54:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 02:54:18 | INFO | valid | epoch 069 | valid on 'valid' subset | symm_kl 0 | loss 5.911 | nll_loss 4.339 | ppl 20.24 | bleu 21.92 | wps 2372 | wpb 6353.4 | bsz 230.8 | num_updates 47127 | best_bleu 22.06
2021-01-15 02:54:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 02:54:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 69 @ 47127 updates, score 21.92) (writing took 2.8476652298122644 seconds)
2021-01-15 02:54:21 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2021-01-15 02:54:21 | INFO | train | epoch 069 | symm_kl 0 | loss 2.549 | nll_loss 0.716 | ppl 1.64 | wps 9337.7 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 47127 | lr 1.00922e-05 | gnorm 0.726 | train_wall 591 | wall 0
2021-01-15 02:54:21 | INFO | fairseq.trainer | begin training epoch 70
2021-01-15 02:55:24 | INFO | train_inner | epoch 070:     73 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=7050.4, ups=0.8, wpb=8770.5, bsz=296.2, num_updates=47200, lr=1.00844e-05, gnorm=0.717, train_wall=86, wall=0
2021-01-15 02:56:50 | INFO | train_inner | epoch 070:    173 / 683 symm_kl=0, loss=2.563, nll_loss=0.729, ppl=1.66, wps=9904, ups=1.16, wpb=8554.8, bsz=280.4, num_updates=47300, lr=1.00737e-05, gnorm=0.74, train_wall=86, wall=0
2021-01-15 02:58:17 | INFO | train_inner | epoch 070:    273 / 683 symm_kl=0, loss=2.546, nll_loss=0.713, ppl=1.64, wps=9795, ups=1.15, wpb=8484.9, bsz=318.8, num_updates=47400, lr=1.00631e-05, gnorm=0.729, train_wall=86, wall=0
2021-01-15 02:59:44 | INFO | train_inner | epoch 070:    373 / 683 symm_kl=0, loss=2.522, nll_loss=0.69, ppl=1.61, wps=9902, ups=1.15, wpb=8625.6, bsz=307, num_updates=47500, lr=1.00525e-05, gnorm=0.701, train_wall=87, wall=0
2021-01-15 03:01:11 | INFO | train_inner | epoch 070:    473 / 683 symm_kl=0, loss=2.557, nll_loss=0.724, ppl=1.65, wps=9941.4, ups=1.15, wpb=8656.2, bsz=304.2, num_updates=47600, lr=1.00419e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-15 03:02:37 | INFO | train_inner | epoch 070:    573 / 683 symm_kl=0, loss=2.556, nll_loss=0.723, ppl=1.65, wps=9849.8, ups=1.15, wpb=8529.1, bsz=305.3, num_updates=47700, lr=1.00314e-05, gnorm=0.737, train_wall=86, wall=0
2021-01-15 03:04:05 | INFO | train_inner | epoch 070:    673 / 683 symm_kl=0, loss=2.544, nll_loss=0.712, ppl=1.64, wps=10147, ups=1.15, wpb=8849.8, bsz=306.1, num_updates=47800, lr=1.00209e-05, gnorm=0.706, train_wall=87, wall=0
2021-01-15 03:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:04:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:04:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:04:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:04:48 | INFO | valid | epoch 070 | valid on 'valid' subset | symm_kl 0 | loss 5.912 | nll_loss 4.339 | ppl 20.24 | bleu 21.96 | wps 2347.6 | wpb 6353.4 | bsz 230.8 | num_updates 47810 | best_bleu 22.06
2021-01-15 03:04:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:04:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 70 @ 47810 updates, score 21.96) (writing took 2.9890299774706364 seconds)
2021-01-15 03:04:51 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2021-01-15 03:04:51 | INFO | train | epoch 070 | symm_kl 0 | loss 2.549 | nll_loss 0.716 | ppl 1.64 | wps 9328.3 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 47810 | lr 1.00199e-05 | gnorm 0.724 | train_wall 591 | wall 0
2021-01-15 03:04:51 | INFO | fairseq.trainer | begin training epoch 71
2021-01-15 03:06:09 | INFO | train_inner | epoch 071:     90 / 683 symm_kl=0, loss=2.556, nll_loss=0.721, ppl=1.65, wps=6673.4, ups=0.81, wpb=8288.9, bsz=295.3, num_updates=47900, lr=1.00104e-05, gnorm=0.753, train_wall=85, wall=0
2021-01-15 03:07:36 | INFO | train_inner | epoch 071:    190 / 683 symm_kl=0, loss=2.549, nll_loss=0.716, ppl=1.64, wps=9831.9, ups=1.14, wpb=8615.7, bsz=283.8, num_updates=48000, lr=1e-05, gnorm=0.726, train_wall=87, wall=0
2021-01-15 03:09:02 | INFO | train_inner | epoch 071:    290 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=9943.7, ups=1.16, wpb=8542.7, bsz=303.4, num_updates=48100, lr=9.9896e-06, gnorm=0.73, train_wall=86, wall=0
2021-01-15 03:10:29 | INFO | train_inner | epoch 071:    390 / 683 symm_kl=0, loss=2.555, nll_loss=0.722, ppl=1.65, wps=9943.4, ups=1.16, wpb=8593.5, bsz=311.9, num_updates=48200, lr=9.97923e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 03:11:56 | INFO | train_inner | epoch 071:    490 / 683 symm_kl=0, loss=2.528, nll_loss=0.696, ppl=1.62, wps=9967.7, ups=1.15, wpb=8667.9, bsz=308.2, num_updates=48300, lr=9.9689e-06, gnorm=0.709, train_wall=87, wall=0
2021-01-15 03:13:22 | INFO | train_inner | epoch 071:    590 / 683 symm_kl=0, loss=2.561, nll_loss=0.728, ppl=1.66, wps=9993.1, ups=1.16, wpb=8611.3, bsz=306.8, num_updates=48400, lr=9.95859e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 03:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:14:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:14:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:14:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:14:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:14:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:14:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:14:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:14:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:15:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:15:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:15:19 | INFO | valid | epoch 071 | valid on 'valid' subset | symm_kl 0 | loss 5.915 | nll_loss 4.343 | ppl 20.29 | bleu 21.83 | wps 2354.7 | wpb 6353.4 | bsz 230.8 | num_updates 48493 | best_bleu 22.06
2021-01-15 03:15:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:15:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 71 @ 48493 updates, score 21.83) (writing took 2.8702829275280237 seconds)
2021-01-15 03:15:22 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2021-01-15 03:15:22 | INFO | train | epoch 071 | symm_kl 0 | loss 2.549 | nll_loss 0.716 | ppl 1.64 | wps 9327.5 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 48493 | lr 9.94904e-06 | gnorm 0.726 | train_wall 591 | wall 0
2021-01-15 03:15:22 | INFO | fairseq.trainer | begin training epoch 72
2021-01-15 03:15:28 | INFO | train_inner | epoch 072:      7 / 683 symm_kl=0, loss=2.544, nll_loss=0.712, ppl=1.64, wps=6977.6, ups=0.8, wpb=8771.2, bsz=312.9, num_updates=48500, lr=9.94832e-06, gnorm=0.712, train_wall=87, wall=0
2021-01-15 03:16:53 | INFO | train_inner | epoch 072:    107 / 683 symm_kl=0, loss=2.543, nll_loss=0.709, ppl=1.64, wps=9843.9, ups=1.17, wpb=8443.3, bsz=295.1, num_updates=48600, lr=9.93808e-06, gnorm=0.736, train_wall=86, wall=0
2021-01-15 03:18:19 | INFO | train_inner | epoch 072:    207 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=9657.8, ups=1.16, wpb=8324.1, bsz=325.6, num_updates=48700, lr=9.92787e-06, gnorm=0.741, train_wall=86, wall=0
2021-01-15 03:19:46 | INFO | train_inner | epoch 072:    307 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=9819.5, ups=1.15, wpb=8515.3, bsz=278.3, num_updates=48800, lr=9.91769e-06, gnorm=0.732, train_wall=87, wall=0
2021-01-15 03:21:14 | INFO | train_inner | epoch 072:    407 / 683 symm_kl=0, loss=2.543, nll_loss=0.711, ppl=1.64, wps=10059.8, ups=1.14, wpb=8852.6, bsz=306.8, num_updates=48900, lr=9.90755e-06, gnorm=0.708, train_wall=88, wall=0
2021-01-15 03:22:41 | INFO | train_inner | epoch 072:    507 / 683 symm_kl=0, loss=2.548, nll_loss=0.716, ppl=1.64, wps=9959.8, ups=1.16, wpb=8599, bsz=318.8, num_updates=49000, lr=9.89743e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 03:24:08 | INFO | train_inner | epoch 072:    607 / 683 symm_kl=0, loss=2.559, nll_loss=0.725, ppl=1.65, wps=9899.4, ups=1.15, wpb=8610.8, bsz=283, num_updates=49100, lr=9.88735e-06, gnorm=0.731, train_wall=87, wall=0
2021-01-15 03:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:25:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:25:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:25:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:25:50 | INFO | valid | epoch 072 | valid on 'valid' subset | symm_kl 0 | loss 5.915 | nll_loss 4.342 | ppl 20.28 | bleu 21.84 | wps 2382 | wpb 6353.4 | bsz 230.8 | num_updates 49176 | best_bleu 22.06
2021-01-15 03:25:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:25:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 72 @ 49176 updates, score 21.84) (writing took 2.9789934512227774 seconds)
2021-01-15 03:25:53 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2021-01-15 03:25:53 | INFO | train | epoch 072 | symm_kl 0 | loss 2.548 | nll_loss 0.715 | ppl 1.64 | wps 9318.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 49176 | lr 9.87971e-06 | gnorm 0.725 | train_wall 592 | wall 0
2021-01-15 03:25:53 | INFO | fairseq.trainer | begin training epoch 73
2021-01-15 03:26:13 | INFO | train_inner | epoch 073:     24 / 683 symm_kl=0, loss=2.549, nll_loss=0.716, ppl=1.64, wps=7145.8, ups=0.8, wpb=8977, bsz=316.2, num_updates=49200, lr=9.8773e-06, gnorm=0.701, train_wall=87, wall=0
2021-01-15 03:27:41 | INFO | train_inner | epoch 073:    124 / 683 symm_kl=0, loss=2.547, nll_loss=0.715, ppl=1.64, wps=10073, ups=1.14, wpb=8823.5, bsz=313.6, num_updates=49300, lr=9.86727e-06, gnorm=0.713, train_wall=87, wall=0
2021-01-15 03:29:07 | INFO | train_inner | epoch 073:    224 / 683 symm_kl=0, loss=2.543, nll_loss=0.708, ppl=1.63, wps=9767.6, ups=1.16, wpb=8446.7, bsz=284.1, num_updates=49400, lr=9.85728e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 03:30:34 | INFO | train_inner | epoch 073:    324 / 683 symm_kl=0, loss=2.54, nll_loss=0.708, ppl=1.63, wps=9967.8, ups=1.16, wpb=8610.1, bsz=312.6, num_updates=49500, lr=9.84732e-06, gnorm=0.722, train_wall=86, wall=0
2021-01-15 03:32:01 | INFO | train_inner | epoch 073:    424 / 683 symm_kl=0, loss=2.551, nll_loss=0.717, ppl=1.64, wps=9940.2, ups=1.15, wpb=8668.3, bsz=319.6, num_updates=49600, lr=9.83739e-06, gnorm=0.728, train_wall=87, wall=0
2021-01-15 03:33:26 | INFO | train_inner | epoch 073:    524 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=9775.1, ups=1.18, wpb=8302.7, bsz=289.1, num_updates=49700, lr=9.82749e-06, gnorm=0.747, train_wall=85, wall=0
2021-01-15 03:34:53 | INFO | train_inner | epoch 073:    624 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=10056.8, ups=1.15, wpb=8739.9, bsz=307.8, num_updates=49800, lr=9.81761e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 03:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:35:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:35:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:35:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:35:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:35:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:35:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:35:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:36:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:36:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:36:19 | INFO | valid | epoch 073 | valid on 'valid' subset | symm_kl 0 | loss 5.919 | nll_loss 4.345 | ppl 20.32 | bleu 21.81 | wps 2376.9 | wpb 6353.4 | bsz 230.8 | num_updates 49859 | best_bleu 22.06
2021-01-15 03:36:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:36:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 73 @ 49859 updates, score 21.81) (writing took 3.0081681832671165 seconds)
2021-01-15 03:36:22 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2021-01-15 03:36:22 | INFO | train | epoch 073 | symm_kl 0 | loss 2.548 | nll_loss 0.714 | ppl 1.64 | wps 9349 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 49859 | lr 9.8118e-06 | gnorm 0.726 | train_wall 590 | wall 0
2021-01-15 03:36:22 | INFO | fairseq.trainer | begin training epoch 74
2021-01-15 03:36:57 | INFO | train_inner | epoch 074:     41 / 683 symm_kl=0, loss=2.545, nll_loss=0.713, ppl=1.64, wps=7049.1, ups=0.81, wpb=8748.2, bsz=323.7, num_updates=49900, lr=9.80777e-06, gnorm=0.714, train_wall=86, wall=0
2021-01-15 03:38:24 | INFO | train_inner | epoch 074:    141 / 683 symm_kl=0, loss=2.543, nll_loss=0.707, ppl=1.63, wps=9599.7, ups=1.15, wpb=8376.2, bsz=298.2, num_updates=50000, lr=9.79796e-06, gnorm=0.742, train_wall=87, wall=0
2021-01-15 03:39:52 | INFO | train_inner | epoch 074:    241 / 683 symm_kl=0, loss=2.541, nll_loss=0.706, ppl=1.63, wps=9845.7, ups=1.14, wpb=8624.2, bsz=295.4, num_updates=50100, lr=9.78818e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 03:41:19 | INFO | train_inner | epoch 074:    341 / 683 symm_kl=0, loss=2.541, nll_loss=0.708, ppl=1.63, wps=9888.3, ups=1.15, wpb=8611.1, bsz=318.8, num_updates=50200, lr=9.77842e-06, gnorm=0.72, train_wall=87, wall=0
2021-01-15 03:42:46 | INFO | train_inner | epoch 074:    441 / 683 symm_kl=0, loss=2.545, nll_loss=0.713, ppl=1.64, wps=10013.1, ups=1.14, wpb=8752.5, bsz=332.6, num_updates=50300, lr=9.7687e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 03:44:14 | INFO | train_inner | epoch 074:    541 / 683 symm_kl=0, loss=2.557, nll_loss=0.723, ppl=1.65, wps=9931.3, ups=1.14, wpb=8707.5, bsz=282.2, num_updates=50400, lr=9.759e-06, gnorm=0.728, train_wall=87, wall=0
2021-01-15 03:45:38 | INFO | train_inner | epoch 074:    641 / 683 symm_kl=0, loss=2.565, nll_loss=0.731, ppl=1.66, wps=9973.5, ups=1.18, wpb=8446.3, bsz=276, num_updates=50500, lr=9.74933e-06, gnorm=0.752, train_wall=84, wall=0
2021-01-15 03:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:46:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:46:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:46:50 | INFO | valid | epoch 074 | valid on 'valid' subset | symm_kl 0 | loss 5.916 | nll_loss 4.343 | ppl 20.29 | bleu 21.85 | wps 2355 | wpb 6353.4 | bsz 230.8 | num_updates 50542 | best_bleu 22.06
2021-01-15 03:46:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:46:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 74 @ 50542 updates, score 21.85) (writing took 2.9072185754776 seconds)
2021-01-15 03:46:53 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2021-01-15 03:46:53 | INFO | train | epoch 074 | symm_kl 0 | loss 2.547 | nll_loss 0.714 | ppl 1.64 | wps 9319.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 50542 | lr 9.74528e-06 | gnorm 0.726 | train_wall 591 | wall 0
2021-01-15 03:46:53 | INFO | fairseq.trainer | begin training epoch 75
2021-01-15 03:47:43 | INFO | train_inner | epoch 075:     58 / 683 symm_kl=0, loss=2.542, nll_loss=0.709, ppl=1.63, wps=6986.1, ups=0.8, wpb=8700.9, bsz=306.4, num_updates=50600, lr=9.7397e-06, gnorm=0.714, train_wall=86, wall=0
2021-01-15 03:49:10 | INFO | train_inner | epoch 075:    158 / 683 symm_kl=0, loss=2.539, nll_loss=0.706, ppl=1.63, wps=9744, ups=1.15, wpb=8442.1, bsz=313.5, num_updates=50700, lr=9.73009e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 03:50:36 | INFO | train_inner | epoch 075:    258 / 683 symm_kl=0, loss=2.538, nll_loss=0.706, ppl=1.63, wps=9965.7, ups=1.16, wpb=8605.3, bsz=300.8, num_updates=50800, lr=9.7205e-06, gnorm=0.723, train_wall=86, wall=0
2021-01-15 03:52:02 | INFO | train_inner | epoch 075:    358 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=10036.2, ups=1.16, wpb=8651.8, bsz=323.5, num_updates=50900, lr=9.71095e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 03:53:29 | INFO | train_inner | epoch 075:    458 / 683 symm_kl=0, loss=2.553, nll_loss=0.718, ppl=1.64, wps=9765.1, ups=1.15, wpb=8477.9, bsz=296.6, num_updates=51000, lr=9.70143e-06, gnorm=0.743, train_wall=87, wall=0
2021-01-15 03:54:55 | INFO | train_inner | epoch 075:    558 / 683 symm_kl=0, loss=2.555, nll_loss=0.72, ppl=1.65, wps=9906.9, ups=1.16, wpb=8564.4, bsz=285.4, num_updates=51100, lr=9.69193e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 03:56:24 | INFO | train_inner | epoch 075:    658 / 683 symm_kl=0, loss=2.545, nll_loss=0.712, ppl=1.64, wps=10070.3, ups=1.13, wpb=8917.3, bsz=300.2, num_updates=51200, lr=9.68246e-06, gnorm=0.711, train_wall=88, wall=0
2021-01-15 03:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 03:56:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:56:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:56:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:56:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:56:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:56:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:56:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:56:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:56:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 03:57:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 03:57:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 03:57:21 | INFO | valid | epoch 075 | valid on 'valid' subset | symm_kl 0 | loss 5.915 | nll_loss 4.341 | ppl 20.27 | bleu 21.89 | wps 2350.7 | wpb 6353.4 | bsz 230.8 | num_updates 51225 | best_bleu 22.06
2021-01-15 03:57:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 03:57:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 75 @ 51225 updates, score 21.89) (writing took 2.9510740973055363 seconds)
2021-01-15 03:57:24 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2021-01-15 03:57:24 | INFO | train | epoch 075 | symm_kl 0 | loss 2.546 | nll_loss 0.712 | ppl 1.64 | wps 9319.7 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 51225 | lr 9.6801e-06 | gnorm 0.726 | train_wall 591 | wall 0
2021-01-15 03:57:24 | INFO | fairseq.trainer | begin training epoch 76
2021-01-15 03:58:29 | INFO | train_inner | epoch 076:     75 / 683 symm_kl=0, loss=2.544, nll_loss=0.711, ppl=1.64, wps=6832.7, ups=0.8, wpb=8514.5, bsz=295.1, num_updates=51300, lr=9.67302e-06, gnorm=0.727, train_wall=86, wall=0
2021-01-15 03:59:56 | INFO | train_inner | epoch 076:    175 / 683 symm_kl=0, loss=2.547, nll_loss=0.712, ppl=1.64, wps=9845.1, ups=1.15, wpb=8567.3, bsz=301.4, num_updates=51400, lr=9.6636e-06, gnorm=0.727, train_wall=87, wall=0
2021-01-15 04:01:23 | INFO | train_inner | epoch 076:    275 / 683 symm_kl=0, loss=2.535, nll_loss=0.702, ppl=1.63, wps=9864, ups=1.15, wpb=8576.3, bsz=301, num_updates=51500, lr=9.65422e-06, gnorm=0.726, train_wall=87, wall=0
2021-01-15 04:02:49 | INFO | train_inner | epoch 076:    375 / 683 symm_kl=0, loss=2.541, nll_loss=0.708, ppl=1.63, wps=10128.6, ups=1.16, wpb=8723.5, bsz=325.5, num_updates=51600, lr=9.64486e-06, gnorm=0.716, train_wall=86, wall=0
2021-01-15 04:04:15 | INFO | train_inner | epoch 076:    475 / 683 symm_kl=0, loss=2.551, nll_loss=0.716, ppl=1.64, wps=9772.4, ups=1.15, wpb=8472.3, bsz=287.4, num_updates=51700, lr=9.63552e-06, gnorm=0.746, train_wall=86, wall=0
2021-01-15 04:05:42 | INFO | train_inner | epoch 076:    575 / 683 symm_kl=0, loss=2.552, nll_loss=0.719, ppl=1.65, wps=10079.2, ups=1.15, wpb=8728.6, bsz=303.6, num_updates=51800, lr=9.62622e-06, gnorm=0.717, train_wall=86, wall=0
2021-01-15 04:07:09 | INFO | train_inner | epoch 076:    675 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=10019.1, ups=1.15, wpb=8696, bsz=314, num_updates=51900, lr=9.61694e-06, gnorm=0.718, train_wall=87, wall=0
2021-01-15 04:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:07:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:07:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:07:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:07:51 | INFO | valid | epoch 076 | valid on 'valid' subset | symm_kl 0 | loss 5.922 | nll_loss 4.35 | ppl 20.39 | bleu 21.8 | wps 2363.6 | wpb 6353.4 | bsz 230.8 | num_updates 51908 | best_bleu 22.06
2021-01-15 04:07:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 04:07:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 76 @ 51908 updates, score 21.8) (writing took 2.9688536189496517 seconds)
2021-01-15 04:07:54 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2021-01-15 04:07:54 | INFO | train | epoch 076 | symm_kl 0 | loss 2.545 | nll_loss 0.712 | ppl 1.64 | wps 9336.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 51908 | lr 9.6162e-06 | gnorm 0.726 | train_wall 590 | wall 0
2021-01-15 04:07:54 | INFO | fairseq.trainer | begin training epoch 77
2021-01-15 04:09:13 | INFO | train_inner | epoch 077:     92 / 683 symm_kl=0, loss=2.55, nll_loss=0.715, ppl=1.64, wps=6711.3, ups=0.81, wpb=8316.3, bsz=301.5, num_updates=52000, lr=9.60769e-06, gnorm=0.751, train_wall=86, wall=0
2021-01-15 04:10:39 | INFO | train_inner | epoch 077:    192 / 683 symm_kl=0, loss=2.542, nll_loss=0.709, ppl=1.63, wps=10063.8, ups=1.15, wpb=8718.8, bsz=293.8, num_updates=52100, lr=9.59846e-06, gnorm=0.717, train_wall=86, wall=0
2021-01-15 04:12:06 | INFO | train_inner | epoch 077:    292 / 683 symm_kl=0, loss=2.541, nll_loss=0.708, ppl=1.63, wps=9999.8, ups=1.16, wpb=8614.9, bsz=295.9, num_updates=52200, lr=9.58927e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 04:13:32 | INFO | train_inner | epoch 077:    392 / 683 symm_kl=0, loss=2.548, nll_loss=0.713, ppl=1.64, wps=9899, ups=1.16, wpb=8510.4, bsz=292.8, num_updates=52300, lr=9.58009e-06, gnorm=0.73, train_wall=86, wall=0
2021-01-15 04:14:58 | INFO | train_inner | epoch 077:    492 / 683 symm_kl=0, loss=2.54, nll_loss=0.707, ppl=1.63, wps=9889.7, ups=1.16, wpb=8559.9, bsz=307.3, num_updates=52400, lr=9.57095e-06, gnorm=0.725, train_wall=86, wall=0
2021-01-15 04:16:24 | INFO | train_inner | epoch 077:    592 / 683 symm_kl=0, loss=2.563, nll_loss=0.728, ppl=1.66, wps=9931.7, ups=1.16, wpb=8580.1, bsz=295.4, num_updates=52500, lr=9.56183e-06, gnorm=0.747, train_wall=86, wall=0
2021-01-15 04:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:17:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:17:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:17:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:17:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:17:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:17:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:17:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:18:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:18:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:18:18 | INFO | valid | epoch 077 | valid on 'valid' subset | symm_kl 0 | loss 5.916 | nll_loss 4.343 | ppl 20.3 | bleu 21.87 | wps 2371.8 | wpb 6353.4 | bsz 230.8 | num_updates 52591 | best_bleu 22.06
2021-01-15 04:18:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 04:18:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 77 @ 52591 updates, score 21.87) (writing took 2.9067548625171185 seconds)
2021-01-15 04:18:21 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2021-01-15 04:18:21 | INFO | train | epoch 077 | symm_kl 0 | loss 2.545 | nll_loss 0.712 | ppl 1.64 | wps 9369.2 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 52591 | lr 9.55355e-06 | gnorm 0.726 | train_wall 588 | wall 0
2021-01-15 04:18:21 | INFO | fairseq.trainer | begin training epoch 78
2021-01-15 04:18:29 | INFO | train_inner | epoch 078:      9 / 683 symm_kl=0, loss=2.536, nll_loss=0.705, ppl=1.63, wps=7194.1, ups=0.8, wpb=8989, bsz=331.8, num_updates=52600, lr=9.55274e-06, gnorm=0.694, train_wall=87, wall=0
2021-01-15 04:19:56 | INFO | train_inner | epoch 078:    109 / 683 symm_kl=0, loss=2.552, nll_loss=0.719, ppl=1.65, wps=9760.7, ups=1.16, wpb=8405.7, bsz=302.2, num_updates=52700, lr=9.54367e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 04:21:23 | INFO | train_inner | epoch 078:    209 / 683 symm_kl=0, loss=2.542, nll_loss=0.708, ppl=1.63, wps=10112.2, ups=1.15, wpb=8809.9, bsz=301, num_updates=52800, lr=9.53463e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 04:22:49 | INFO | train_inner | epoch 078:    309 / 683 symm_kl=0, loss=2.527, nll_loss=0.694, ppl=1.62, wps=10027.9, ups=1.15, wpb=8692, bsz=320.6, num_updates=52900, lr=9.52561e-06, gnorm=0.708, train_wall=86, wall=0
2021-01-15 04:24:15 | INFO | train_inner | epoch 078:    409 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=9938, ups=1.17, wpb=8496.9, bsz=291.1, num_updates=53000, lr=9.51662e-06, gnorm=0.737, train_wall=85, wall=0
2021-01-15 04:25:40 | INFO | train_inner | epoch 078:    509 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=9859.1, ups=1.17, wpb=8405.7, bsz=296, num_updates=53100, lr=9.50765e-06, gnorm=0.739, train_wall=85, wall=0
2021-01-15 04:27:06 | INFO | train_inner | epoch 078:    609 / 683 symm_kl=0, loss=2.551, nll_loss=0.718, ppl=1.64, wps=10144, ups=1.16, wpb=8737.5, bsz=312.9, num_updates=53200, lr=9.49871e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 04:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:28:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:28:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:28:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:28:46 | INFO | valid | epoch 078 | valid on 'valid' subset | symm_kl 0 | loss 5.919 | nll_loss 4.346 | ppl 20.34 | bleu 21.88 | wps 2375.6 | wpb 6353.4 | bsz 230.8 | num_updates 53274 | best_bleu 22.06
2021-01-15 04:28:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 04:28:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 78 @ 53274 updates, score 21.88) (writing took 2.9025403913110495 seconds)
2021-01-15 04:28:49 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2021-01-15 04:28:49 | INFO | train | epoch 078 | symm_kl 0 | loss 2.545 | nll_loss 0.711 | ppl 1.64 | wps 9376.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 53274 | lr 9.49211e-06 | gnorm 0.726 | train_wall 588 | wall 0
2021-01-15 04:28:49 | INFO | fairseq.trainer | begin training epoch 79
2021-01-15 04:29:11 | INFO | train_inner | epoch 079:     26 / 683 symm_kl=0, loss=2.549, nll_loss=0.716, ppl=1.64, wps=7011.6, ups=0.8, wpb=8750.4, bsz=309.4, num_updates=53300, lr=9.4898e-06, gnorm=0.718, train_wall=86, wall=0
2021-01-15 04:30:38 | INFO | train_inner | epoch 079:    126 / 683 symm_kl=0, loss=2.554, nll_loss=0.721, ppl=1.65, wps=9923.9, ups=1.15, wpb=8659.7, bsz=298.8, num_updates=53400, lr=9.48091e-06, gnorm=0.735, train_wall=87, wall=0
2021-01-15 04:32:06 | INFO | train_inner | epoch 079:    226 / 683 symm_kl=0, loss=2.532, nll_loss=0.698, ppl=1.62, wps=9958.4, ups=1.14, wpb=8719.5, bsz=303, num_updates=53500, lr=9.47204e-06, gnorm=0.711, train_wall=87, wall=0
2021-01-15 04:33:32 | INFO | train_inner | epoch 079:    326 / 683 symm_kl=0, loss=2.551, nll_loss=0.718, ppl=1.64, wps=9987.1, ups=1.16, wpb=8621.3, bsz=307.8, num_updates=53600, lr=9.4632e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 04:34:59 | INFO | train_inner | epoch 079:    426 / 683 symm_kl=0, loss=2.529, nll_loss=0.696, ppl=1.62, wps=10039.9, ups=1.15, wpb=8714.2, bsz=305, num_updates=53700, lr=9.45439e-06, gnorm=0.711, train_wall=87, wall=0
2021-01-15 04:36:25 | INFO | train_inner | epoch 079:    526 / 683 symm_kl=0, loss=2.56, nll_loss=0.727, ppl=1.65, wps=10027.7, ups=1.16, wpb=8609.9, bsz=293.9, num_updates=53800, lr=9.4456e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 04:37:50 | INFO | train_inner | epoch 079:    626 / 683 symm_kl=0, loss=2.542, nll_loss=0.709, ppl=1.63, wps=9846.9, ups=1.17, wpb=8417.4, bsz=309, num_updates=53900, lr=9.43683e-06, gnorm=0.735, train_wall=85, wall=0
2021-01-15 04:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:38:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:38:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:38:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:38:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:39:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:39:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:39:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:39:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:39:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:39:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:39:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:39:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:39:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:39:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:39:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:39:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:39:13 | INFO | valid | epoch 079 | valid on 'valid' subset | symm_kl 0 | loss 5.92 | nll_loss 4.348 | ppl 20.37 | bleu 21.79 | wps 2375.7 | wpb 6353.4 | bsz 230.8 | num_updates 53957 | best_bleu 22.06
2021-01-15 04:39:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 04:39:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 79 @ 53957 updates, score 21.79) (writing took 2.989322604611516 seconds)
2021-01-15 04:39:16 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2021-01-15 04:39:16 | INFO | train | epoch 079 | symm_kl 0 | loss 2.545 | nll_loss 0.711 | ppl 1.64 | wps 9368.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 53957 | lr 9.43185e-06 | gnorm 0.726 | train_wall 588 | wall 0
2021-01-15 04:39:16 | INFO | fairseq.trainer | begin training epoch 80
2021-01-15 04:39:53 | INFO | train_inner | epoch 080:     43 / 683 symm_kl=0, loss=2.553, nll_loss=0.718, ppl=1.64, wps=6886.9, ups=0.82, wpb=8426, bsz=298.9, num_updates=54000, lr=9.42809e-06, gnorm=0.743, train_wall=84, wall=0
2021-01-15 04:41:20 | INFO | train_inner | epoch 080:    143 / 683 symm_kl=0, loss=2.54, nll_loss=0.706, ppl=1.63, wps=9955.3, ups=1.15, wpb=8676.6, bsz=317.5, num_updates=54100, lr=9.41937e-06, gnorm=0.719, train_wall=87, wall=0
2021-01-15 04:42:47 | INFO | train_inner | epoch 080:    243 / 683 symm_kl=0, loss=2.544, nll_loss=0.71, ppl=1.64, wps=9961, ups=1.15, wpb=8664.6, bsz=293.5, num_updates=54200, lr=9.41068e-06, gnorm=0.717, train_wall=87, wall=0
2021-01-15 04:44:14 | INFO | train_inner | epoch 080:    343 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=10088.2, ups=1.15, wpb=8797.5, bsz=309.1, num_updates=54300, lr=9.40201e-06, gnorm=0.71, train_wall=87, wall=0
2021-01-15 04:45:40 | INFO | train_inner | epoch 080:    443 / 683 symm_kl=0, loss=2.544, nll_loss=0.709, ppl=1.64, wps=10012.8, ups=1.16, wpb=8625.8, bsz=302.3, num_updates=54400, lr=9.39336e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 04:47:07 | INFO | train_inner | epoch 080:    543 / 683 symm_kl=0, loss=2.556, nll_loss=0.723, ppl=1.65, wps=10036.3, ups=1.16, wpb=8689.3, bsz=294.6, num_updates=54500, lr=9.38474e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 04:48:32 | INFO | train_inner | epoch 080:    643 / 683 symm_kl=0, loss=2.531, nll_loss=0.697, ppl=1.62, wps=9541.7, ups=1.17, wpb=8138.8, bsz=301.5, num_updates=54600, lr=9.37614e-06, gnorm=0.749, train_wall=85, wall=0
2021-01-15 04:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:49:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:49:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:49:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:49:42 | INFO | valid | epoch 080 | valid on 'valid' subset | symm_kl 0 | loss 5.92 | nll_loss 4.348 | ppl 20.36 | bleu 21.88 | wps 2357.6 | wpb 6353.4 | bsz 230.8 | num_updates 54640 | best_bleu 22.06
2021-01-15 04:49:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 04:49:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 80 @ 54640 updates, score 21.88) (writing took 2.990277549251914 seconds)
2021-01-15 04:49:45 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2021-01-15 04:49:45 | INFO | train | epoch 080 | symm_kl 0 | loss 2.544 | nll_loss 0.71 | ppl 1.64 | wps 9352.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 54640 | lr 9.37271e-06 | gnorm 0.726 | train_wall 589 | wall 0
2021-01-15 04:49:45 | INFO | fairseq.trainer | begin training epoch 81
2021-01-15 04:50:36 | INFO | train_inner | epoch 081:     60 / 683 symm_kl=0, loss=2.541, nll_loss=0.707, ppl=1.63, wps=6934.1, ups=0.81, wpb=8603.9, bsz=302.4, num_updates=54700, lr=9.36757e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 04:52:02 | INFO | train_inner | epoch 081:    160 / 683 symm_kl=0, loss=2.539, nll_loss=0.705, ppl=1.63, wps=9967.4, ups=1.16, wpb=8588.7, bsz=325.1, num_updates=54800, lr=9.35902e-06, gnorm=0.716, train_wall=86, wall=0
2021-01-15 04:53:29 | INFO | train_inner | epoch 081:    260 / 683 symm_kl=0, loss=2.522, nll_loss=0.691, ppl=1.61, wps=10145, ups=1.15, wpb=8828.9, bsz=313.5, num_updates=54900, lr=9.35049e-06, gnorm=0.697, train_wall=87, wall=0
2021-01-15 04:54:56 | INFO | train_inner | epoch 081:    360 / 683 symm_kl=0, loss=2.535, nll_loss=0.702, ppl=1.63, wps=9945, ups=1.15, wpb=8622.1, bsz=306.4, num_updates=55000, lr=9.34199e-06, gnorm=0.723, train_wall=87, wall=0
2021-01-15 04:56:22 | INFO | train_inner | epoch 081:    460 / 683 symm_kl=0, loss=2.553, nll_loss=0.72, ppl=1.65, wps=9948.8, ups=1.16, wpb=8563, bsz=284.8, num_updates=55100, lr=9.33351e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 04:57:48 | INFO | train_inner | epoch 081:    560 / 683 symm_kl=0, loss=2.557, nll_loss=0.723, ppl=1.65, wps=9864.5, ups=1.17, wpb=8467.2, bsz=280.2, num_updates=55200, lr=9.32505e-06, gnorm=0.749, train_wall=86, wall=0
2021-01-15 04:59:15 | INFO | train_inner | epoch 081:    660 / 683 symm_kl=0, loss=2.546, nll_loss=0.712, ppl=1.64, wps=10056.9, ups=1.15, wpb=8727, bsz=322.3, num_updates=55300, lr=9.31661e-06, gnorm=0.719, train_wall=87, wall=0
2021-01-15 04:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 04:59:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 04:59:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 04:59:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 04:59:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:00:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:00:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:00:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:00:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:00:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:00:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:00:09 | INFO | valid | epoch 081 | valid on 'valid' subset | symm_kl 0 | loss 5.92 | nll_loss 4.348 | ppl 20.36 | bleu 21.88 | wps 2359.7 | wpb 6353.4 | bsz 230.8 | num_updates 55323 | best_bleu 22.06
2021-01-15 05:00:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:00:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 81 @ 55323 updates, score 21.88) (writing took 3.02639140188694 seconds)
2021-01-15 05:00:12 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2021-01-15 05:00:12 | INFO | train | epoch 081 | symm_kl 0 | loss 2.544 | nll_loss 0.71 | ppl 1.64 | wps 9380.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 55323 | lr 9.31468e-06 | gnorm 0.725 | train_wall 587 | wall 0
2021-01-15 05:00:12 | INFO | fairseq.trainer | begin training epoch 82
2021-01-15 05:01:18 | INFO | train_inner | epoch 082:     77 / 683 symm_kl=0, loss=2.545, nll_loss=0.71, ppl=1.64, wps=6954.8, ups=0.81, wpb=8577.1, bsz=278.9, num_updates=55400, lr=9.3082e-06, gnorm=0.734, train_wall=85, wall=0
2021-01-15 05:02:44 | INFO | train_inner | epoch 082:    177 / 683 symm_kl=0, loss=2.528, nll_loss=0.695, ppl=1.62, wps=9983.9, ups=1.16, wpb=8592.7, bsz=314, num_updates=55500, lr=9.29981e-06, gnorm=0.719, train_wall=86, wall=0
2021-01-15 05:04:11 | INFO | train_inner | epoch 082:    277 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=9904.7, ups=1.16, wpb=8569.9, bsz=301.2, num_updates=55600, lr=9.29144e-06, gnorm=0.734, train_wall=86, wall=0
2021-01-15 05:05:37 | INFO | train_inner | epoch 082:    377 / 683 symm_kl=0, loss=2.537, nll_loss=0.703, ppl=1.63, wps=9847.5, ups=1.16, wpb=8498.8, bsz=312.2, num_updates=55700, lr=9.2831e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 05:07:03 | INFO | train_inner | epoch 082:    477 / 683 symm_kl=0, loss=2.55, nll_loss=0.718, ppl=1.64, wps=10094.5, ups=1.16, wpb=8702.9, bsz=327, num_updates=55800, lr=9.27478e-06, gnorm=0.715, train_wall=86, wall=0
2021-01-15 05:08:30 | INFO | train_inner | epoch 082:    577 / 683 symm_kl=0, loss=2.549, nll_loss=0.715, ppl=1.64, wps=10075.2, ups=1.15, wpb=8741.4, bsz=288.8, num_updates=55900, lr=9.26648e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 05:09:56 | INFO | train_inner | epoch 082:    677 / 683 symm_kl=0, loss=2.546, nll_loss=0.712, ppl=1.64, wps=10006.5, ups=1.17, wpb=8589.1, bsz=299.4, num_updates=56000, lr=9.2582e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 05:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 05:10:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:10:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:10:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:10:36 | INFO | valid | epoch 082 | valid on 'valid' subset | symm_kl 0 | loss 5.923 | nll_loss 4.352 | ppl 20.42 | bleu 21.89 | wps 2355.8 | wpb 6353.4 | bsz 230.8 | num_updates 56006 | best_bleu 22.06
2021-01-15 05:10:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:10:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 82 @ 56006 updates, score 21.89) (writing took 3.01390309818089 seconds)
2021-01-15 05:10:39 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2021-01-15 05:10:39 | INFO | train | epoch 082 | symm_kl 0 | loss 2.543 | nll_loss 0.709 | ppl 1.64 | wps 9378 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 56006 | lr 9.25771e-06 | gnorm 0.725 | train_wall 587 | wall 0
2021-01-15 05:10:39 | INFO | fairseq.trainer | begin training epoch 83
2021-01-15 05:12:00 | INFO | train_inner | epoch 083:     94 / 683 symm_kl=0, loss=2.532, nll_loss=0.697, ppl=1.62, wps=6852.1, ups=0.8, wpb=8523.6, bsz=296.1, num_updates=56100, lr=9.24995e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 05:13:27 | INFO | train_inner | epoch 083:    194 / 683 symm_kl=0, loss=2.535, nll_loss=0.702, ppl=1.63, wps=9947.4, ups=1.15, wpb=8614.2, bsz=297.8, num_updates=56200, lr=9.24171e-06, gnorm=0.718, train_wall=86, wall=0
2021-01-15 05:14:54 | INFO | train_inner | epoch 083:    294 / 683 symm_kl=0, loss=2.544, nll_loss=0.712, ppl=1.64, wps=10193.6, ups=1.14, wpb=8914, bsz=308.6, num_updates=56300, lr=9.2335e-06, gnorm=0.707, train_wall=87, wall=0
2021-01-15 05:16:21 | INFO | train_inner | epoch 083:    394 / 683 symm_kl=0, loss=2.543, nll_loss=0.708, ppl=1.63, wps=9748.1, ups=1.15, wpb=8450.8, bsz=300.9, num_updates=56400, lr=9.22531e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 05:17:47 | INFO | train_inner | epoch 083:    494 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=10058.4, ups=1.16, wpb=8634.3, bsz=325.8, num_updates=56500, lr=9.21714e-06, gnorm=0.722, train_wall=86, wall=0
2021-01-15 05:19:13 | INFO | train_inner | epoch 083:    594 / 683 symm_kl=0, loss=2.547, nll_loss=0.713, ppl=1.64, wps=10065.7, ups=1.16, wpb=8651.7, bsz=315.3, num_updates=56600, lr=9.209e-06, gnorm=0.725, train_wall=86, wall=0
2021-01-15 05:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 05:20:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:20:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:20:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:20:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:21:04 | INFO | valid | epoch 083 | valid on 'valid' subset | symm_kl 0 | loss 5.922 | nll_loss 4.351 | ppl 20.4 | bleu 21.83 | wps 2361.9 | wpb 6353.4 | bsz 230.8 | num_updates 56689 | best_bleu 22.06
2021-01-15 05:21:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:21:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 83 @ 56689 updates, score 21.83) (writing took 2.9553673584014177 seconds)
2021-01-15 05:21:07 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2021-01-15 05:21:07 | INFO | train | epoch 083 | symm_kl 0 | loss 2.543 | nll_loss 0.709 | ppl 1.63 | wps 9369.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 56689 | lr 9.20177e-06 | gnorm 0.725 | train_wall 588 | wall 0
2021-01-15 05:21:07 | INFO | fairseq.trainer | begin training epoch 84
2021-01-15 05:21:16 | INFO | train_inner | epoch 084:     11 / 683 symm_kl=0, loss=2.55, nll_loss=0.716, ppl=1.64, wps=6809.6, ups=0.81, wpb=8391.6, bsz=278.7, num_updates=56700, lr=9.20087e-06, gnorm=0.745, train_wall=85, wall=0
2021-01-15 05:22:41 | INFO | train_inner | epoch 084:    111 / 683 symm_kl=0, loss=2.546, nll_loss=0.711, ppl=1.64, wps=9848.7, ups=1.18, wpb=8341.3, bsz=299.3, num_updates=56800, lr=9.19277e-06, gnorm=0.741, train_wall=85, wall=0
2021-01-15 05:24:07 | INFO | train_inner | epoch 084:    211 / 683 symm_kl=0, loss=2.54, nll_loss=0.708, ppl=1.63, wps=10085.7, ups=1.15, wpb=8744.6, bsz=312.2, num_updates=56900, lr=9.18469e-06, gnorm=0.713, train_wall=87, wall=0
2021-01-15 05:25:32 | INFO | train_inner | epoch 084:    311 / 683 symm_kl=0, loss=2.536, nll_loss=0.7, ppl=1.62, wps=9644.7, ups=1.18, wpb=8198.9, bsz=294.3, num_updates=57000, lr=9.17663e-06, gnorm=0.75, train_wall=85, wall=0
2021-01-15 05:26:59 | INFO | train_inner | epoch 084:    411 / 683 symm_kl=0, loss=2.548, nll_loss=0.715, ppl=1.64, wps=10159.3, ups=1.15, wpb=8807, bsz=291.8, num_updates=57100, lr=9.16859e-06, gnorm=0.721, train_wall=87, wall=0
2021-01-15 05:28:26 | INFO | train_inner | epoch 084:    511 / 683 symm_kl=0, loss=2.537, nll_loss=0.705, ppl=1.63, wps=10091.4, ups=1.15, wpb=8778.5, bsz=315.4, num_updates=57200, lr=9.16057e-06, gnorm=0.709, train_wall=87, wall=0
2021-01-15 05:29:53 | INFO | train_inner | epoch 084:    611 / 683 symm_kl=0, loss=2.54, nll_loss=0.706, ppl=1.63, wps=9999.6, ups=1.15, wpb=8685.8, bsz=315, num_updates=57300, lr=9.15258e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 05:30:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 05:30:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:30:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:30:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:31:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:31:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:31:32 | INFO | valid | epoch 084 | valid on 'valid' subset | symm_kl 0 | loss 5.922 | nll_loss 4.35 | ppl 20.39 | bleu 21.83 | wps 2368.5 | wpb 6353.4 | bsz 230.8 | num_updates 57372 | best_bleu 22.06
2021-01-15 05:31:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:31:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 84 @ 57372 updates, score 21.83) (writing took 3.0228668320924044 seconds)
2021-01-15 05:31:35 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2021-01-15 05:31:35 | INFO | train | epoch 084 | symm_kl 0 | loss 2.542 | nll_loss 0.708 | ppl 1.63 | wps 9371.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 57372 | lr 9.14683e-06 | gnorm 0.725 | train_wall 588 | wall 0
2021-01-15 05:31:35 | INFO | fairseq.trainer | begin training epoch 85
2021-01-15 05:31:59 | INFO | train_inner | epoch 085:     28 / 683 symm_kl=0, loss=2.547, nll_loss=0.714, ppl=1.64, wps=7082.5, ups=0.79, wpb=8910.6, bsz=308.2, num_updates=57400, lr=9.1446e-06, gnorm=0.709, train_wall=87, wall=0
2021-01-15 05:33:26 | INFO | train_inner | epoch 085:    128 / 683 symm_kl=0, loss=2.529, nll_loss=0.697, ppl=1.62, wps=10083, ups=1.15, wpb=8775.8, bsz=322.9, num_updates=57500, lr=9.13664e-06, gnorm=0.708, train_wall=87, wall=0
2021-01-15 05:34:52 | INFO | train_inner | epoch 085:    228 / 683 symm_kl=0, loss=2.539, nll_loss=0.704, ppl=1.63, wps=9973.8, ups=1.16, wpb=8622.8, bsz=294.8, num_updates=57600, lr=9.12871e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 05:36:19 | INFO | train_inner | epoch 085:    328 / 683 symm_kl=0, loss=2.541, nll_loss=0.708, ppl=1.63, wps=10044.7, ups=1.16, wpb=8681.4, bsz=305.5, num_updates=57700, lr=9.1208e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 05:37:45 | INFO | train_inner | epoch 085:    428 / 683 symm_kl=0, loss=2.541, nll_loss=0.706, ppl=1.63, wps=9996.1, ups=1.15, wpb=8657, bsz=292.9, num_updates=57800, lr=9.1129e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 05:39:11 | INFO | train_inner | epoch 085:    528 / 683 symm_kl=0, loss=2.556, nll_loss=0.72, ppl=1.65, wps=9682.7, ups=1.16, wpb=8321, bsz=297, num_updates=57900, lr=9.10503e-06, gnorm=0.757, train_wall=86, wall=0
2021-01-15 05:40:37 | INFO | train_inner | epoch 085:    628 / 683 symm_kl=0, loss=2.535, nll_loss=0.701, ppl=1.63, wps=9727.2, ups=1.16, wpb=8389.8, bsz=301.1, num_updates=58000, lr=9.09718e-06, gnorm=0.734, train_wall=86, wall=0
2021-01-15 05:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 05:41:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:41:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:41:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:41:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:42:00 | INFO | valid | epoch 085 | valid on 'valid' subset | symm_kl 0 | loss 5.921 | nll_loss 4.349 | ppl 20.38 | bleu 21.86 | wps 2357.4 | wpb 6353.4 | bsz 230.8 | num_updates 58055 | best_bleu 22.06
2021-01-15 05:42:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:42:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 85 @ 58055 updates, score 21.86) (writing took 2.7427466809749603 seconds)
2021-01-15 05:42:03 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2021-01-15 05:42:03 | INFO | train | epoch 085 | symm_kl 0 | loss 2.541 | nll_loss 0.707 | ppl 1.63 | wps 9358.8 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 58055 | lr 9.09287e-06 | gnorm 0.726 | train_wall 589 | wall 0
2021-01-15 05:42:03 | INFO | fairseq.trainer | begin training epoch 86
2021-01-15 05:42:42 | INFO | train_inner | epoch 086:     45 / 683 symm_kl=0, loss=2.544, nll_loss=0.709, ppl=1.64, wps=7080.6, ups=0.8, wpb=8830.1, bsz=309.4, num_updates=58100, lr=9.08934e-06, gnorm=0.712, train_wall=86, wall=0
2021-01-15 05:44:08 | INFO | train_inner | epoch 086:    145 / 683 symm_kl=0, loss=2.538, nll_loss=0.705, ppl=1.63, wps=9876.2, ups=1.16, wpb=8502.4, bsz=294.5, num_updates=58200, lr=9.08153e-06, gnorm=0.732, train_wall=86, wall=0
2021-01-15 05:45:34 | INFO | train_inner | epoch 086:    245 / 683 symm_kl=0, loss=2.547, nll_loss=0.713, ppl=1.64, wps=9897.5, ups=1.16, wpb=8543.5, bsz=287, num_updates=58300, lr=9.07374e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 05:47:01 | INFO | train_inner | epoch 086:    345 / 683 symm_kl=0, loss=2.549, nll_loss=0.713, ppl=1.64, wps=9972.5, ups=1.16, wpb=8621.8, bsz=283.6, num_updates=58400, lr=9.06597e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 05:48:27 | INFO | train_inner | epoch 086:    445 / 683 symm_kl=0, loss=2.537, nll_loss=0.703, ppl=1.63, wps=10065.9, ups=1.16, wpb=8692.9, bsz=340.2, num_updates=58500, lr=9.05822e-06, gnorm=0.718, train_wall=86, wall=0
2021-01-15 05:49:54 | INFO | train_inner | epoch 086:    545 / 683 symm_kl=0, loss=2.543, nll_loss=0.709, ppl=1.63, wps=9872.7, ups=1.16, wpb=8534.9, bsz=275.2, num_updates=58600, lr=9.05048e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 05:51:20 | INFO | train_inner | epoch 086:    645 / 683 symm_kl=0, loss=2.538, nll_loss=0.705, ppl=1.63, wps=9923.3, ups=1.16, wpb=8546, bsz=341.8, num_updates=58700, lr=9.04277e-06, gnorm=0.717, train_wall=86, wall=0
2021-01-15 05:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 05:51:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:51:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:51:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:51:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:51:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:51:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 05:52:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 05:52:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 05:52:29 | INFO | valid | epoch 086 | valid on 'valid' subset | symm_kl 0 | loss 5.925 | nll_loss 4.354 | ppl 20.45 | bleu 21.93 | wps 2313.2 | wpb 6353.4 | bsz 230.8 | num_updates 58738 | best_bleu 22.06
2021-01-15 05:52:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 05:52:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 86 @ 58738 updates, score 21.93) (writing took 2.943214178085327 seconds)
2021-01-15 05:52:32 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2021-01-15 05:52:32 | INFO | train | epoch 086 | symm_kl 0 | loss 2.541 | nll_loss 0.707 | ppl 1.63 | wps 9354.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 58738 | lr 9.03985e-06 | gnorm 0.726 | train_wall 588 | wall 0
2021-01-15 05:52:32 | INFO | fairseq.trainer | begin training epoch 87
2021-01-15 05:53:25 | INFO | train_inner | epoch 087:     62 / 683 symm_kl=0, loss=2.542, nll_loss=0.709, ppl=1.63, wps=6971.5, ups=0.8, wpb=8730.6, bsz=290.9, num_updates=58800, lr=9.03508e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 05:54:53 | INFO | train_inner | epoch 087:    162 / 683 symm_kl=0, loss=2.534, nll_loss=0.7, ppl=1.62, wps=9967.2, ups=1.14, wpb=8727.3, bsz=310.2, num_updates=58900, lr=9.02741e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 05:56:20 | INFO | train_inner | epoch 087:    262 / 683 symm_kl=0, loss=2.544, nll_loss=0.711, ppl=1.64, wps=10127.4, ups=1.15, wpb=8823.2, bsz=318.4, num_updates=59000, lr=9.01975e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 05:57:47 | INFO | train_inner | epoch 087:    362 / 683 symm_kl=0, loss=2.548, nll_loss=0.714, ppl=1.64, wps=10084.5, ups=1.15, wpb=8751.4, bsz=317.1, num_updates=59100, lr=9.01212e-06, gnorm=0.719, train_wall=87, wall=0
2021-01-15 05:59:13 | INFO | train_inner | epoch 087:    462 / 683 symm_kl=0, loss=2.55, nll_loss=0.714, ppl=1.64, wps=9692.8, ups=1.16, wpb=8363.8, bsz=294.1, num_updates=59200, lr=9.0045e-06, gnorm=0.756, train_wall=86, wall=0
2021-01-15 06:00:38 | INFO | train_inner | epoch 087:    562 / 683 symm_kl=0, loss=2.533, nll_loss=0.701, ppl=1.63, wps=10075.5, ups=1.17, wpb=8605.4, bsz=310.5, num_updates=59300, lr=8.99691e-06, gnorm=0.72, train_wall=85, wall=0
2021-01-15 06:02:05 | INFO | train_inner | epoch 087:    662 / 683 symm_kl=0, loss=2.54, nll_loss=0.704, ppl=1.63, wps=9671.9, ups=1.16, wpb=8346.2, bsz=279.8, num_updates=59400, lr=8.98933e-06, gnorm=0.736, train_wall=86, wall=0
2021-01-15 06:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:02:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:02:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:02:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:02:58 | INFO | valid | epoch 087 | valid on 'valid' subset | symm_kl 0 | loss 5.926 | nll_loss 4.356 | ppl 20.48 | bleu 21.77 | wps 2383.4 | wpb 6353.4 | bsz 230.8 | num_updates 59421 | best_bleu 22.06
2021-01-15 06:02:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:03:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 87 @ 59421 updates, score 21.77) (writing took 2.927749391645193 seconds)
2021-01-15 06:03:01 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2021-01-15 06:03:01 | INFO | train | epoch 087 | symm_kl 0 | loss 2.541 | nll_loss 0.707 | ppl 1.63 | wps 9349.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 59421 | lr 8.98774e-06 | gnorm 0.727 | train_wall 590 | wall 0
2021-01-15 06:03:01 | INFO | fairseq.trainer | begin training epoch 88
2021-01-15 06:04:09 | INFO | train_inner | epoch 088:     79 / 683 symm_kl=0, loss=2.529, nll_loss=0.695, ppl=1.62, wps=6908.6, ups=0.8, wpb=8586.9, bsz=301.9, num_updates=59500, lr=8.98177e-06, gnorm=0.718, train_wall=86, wall=0
2021-01-15 06:05:37 | INFO | train_inner | epoch 088:    179 / 683 symm_kl=0, loss=2.552, nll_loss=0.716, ppl=1.64, wps=9973.9, ups=1.13, wpb=8794, bsz=282.9, num_updates=59600, lr=8.97424e-06, gnorm=0.726, train_wall=88, wall=0
2021-01-15 06:07:03 | INFO | train_inner | epoch 088:    279 / 683 symm_kl=0, loss=2.544, nll_loss=0.711, ppl=1.64, wps=10110.2, ups=1.16, wpb=8739.5, bsz=324, num_updates=59700, lr=8.96672e-06, gnorm=0.714, train_wall=86, wall=0
2021-01-15 06:08:29 | INFO | train_inner | epoch 088:    379 / 683 symm_kl=0, loss=2.533, nll_loss=0.7, ppl=1.62, wps=9925.2, ups=1.16, wpb=8538, bsz=319.8, num_updates=59800, lr=8.95922e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 06:09:56 | INFO | train_inner | epoch 088:    479 / 683 symm_kl=0, loss=2.534, nll_loss=0.7, ppl=1.62, wps=9721.7, ups=1.16, wpb=8393.3, bsz=315.4, num_updates=59900, lr=8.95173e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 06:11:22 | INFO | train_inner | epoch 088:    579 / 683 symm_kl=0, loss=2.543, nll_loss=0.709, ppl=1.63, wps=10016.9, ups=1.15, wpb=8682.4, bsz=278.8, num_updates=60000, lr=8.94427e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 06:12:49 | INFO | train_inner | epoch 088:    679 / 683 symm_kl=0, loss=2.542, nll_loss=0.707, ppl=1.63, wps=9868.5, ups=1.16, wpb=8528.1, bsz=298.4, num_updates=60100, lr=8.93683e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 06:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:12:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:12:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:12:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:12:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:12:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:12:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:13:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:13:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:13:27 | INFO | valid | epoch 088 | valid on 'valid' subset | symm_kl 0 | loss 5.929 | nll_loss 4.359 | ppl 20.52 | bleu 21.86 | wps 2379.6 | wpb 6353.4 | bsz 230.8 | num_updates 60104 | best_bleu 22.06
2021-01-15 06:13:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:13:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 88 @ 60104 updates, score 21.86) (writing took 2.9444758519530296 seconds)
2021-01-15 06:13:30 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2021-01-15 06:13:30 | INFO | train | epoch 088 | symm_kl 0 | loss 2.54 | nll_loss 0.706 | ppl 1.63 | wps 9338.6 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 60104 | lr 8.93653e-06 | gnorm 0.726 | train_wall 590 | wall 0
2021-01-15 06:13:30 | INFO | fairseq.trainer | begin training epoch 89
2021-01-15 06:14:53 | INFO | train_inner | epoch 089:     96 / 683 symm_kl=0, loss=2.535, nll_loss=0.701, ppl=1.63, wps=6910.5, ups=0.81, wpb=8571.5, bsz=303.8, num_updates=60200, lr=8.9294e-06, gnorm=0.725, train_wall=86, wall=0
2021-01-15 06:16:19 | INFO | train_inner | epoch 089:    196 / 683 symm_kl=0, loss=2.53, nll_loss=0.695, ppl=1.62, wps=9795.2, ups=1.16, wpb=8461.5, bsz=284.4, num_updates=60300, lr=8.92199e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 06:17:46 | INFO | train_inner | epoch 089:    296 / 683 symm_kl=0, loss=2.546, nll_loss=0.713, ppl=1.64, wps=10340.4, ups=1.15, wpb=9003.8, bsz=313.5, num_updates=60400, lr=8.91461e-06, gnorm=0.706, train_wall=87, wall=0
2021-01-15 06:19:14 | INFO | train_inner | epoch 089:    396 / 683 symm_kl=0, loss=2.557, nll_loss=0.722, ppl=1.65, wps=9999.3, ups=1.15, wpb=8718.9, bsz=284.9, num_updates=60500, lr=8.90724e-06, gnorm=0.735, train_wall=87, wall=0
2021-01-15 06:20:40 | INFO | train_inner | epoch 089:    496 / 683 symm_kl=0, loss=2.543, nll_loss=0.71, ppl=1.64, wps=10056.6, ups=1.16, wpb=8684.8, bsz=330.9, num_updates=60600, lr=8.89988e-06, gnorm=0.722, train_wall=86, wall=0
2021-01-15 06:22:07 | INFO | train_inner | epoch 089:    596 / 683 symm_kl=0, loss=2.528, nll_loss=0.696, ppl=1.62, wps=10077.7, ups=1.16, wpb=8722, bsz=317.9, num_updates=60700, lr=8.89255e-06, gnorm=0.708, train_wall=86, wall=0
2021-01-15 06:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:23:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:23:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:23:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:23:56 | INFO | valid | epoch 089 | valid on 'valid' subset | symm_kl 0 | loss 5.928 | nll_loss 4.358 | ppl 20.51 | bleu 21.85 | wps 2364 | wpb 6353.4 | bsz 230.8 | num_updates 60787 | best_bleu 22.06
2021-01-15 06:23:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:23:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 89 @ 60787 updates, score 21.85) (writing took 2.9801206067204475 seconds)
2021-01-15 06:23:59 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2021-01-15 06:23:59 | INFO | train | epoch 089 | symm_kl 0 | loss 2.54 | nll_loss 0.706 | ppl 1.63 | wps 9357.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 60787 | lr 8.88618e-06 | gnorm 0.727 | train_wall 589 | wall 0
2021-01-15 06:23:59 | INFO | fairseq.trainer | begin training epoch 90
2021-01-15 06:24:10 | INFO | train_inner | epoch 090:     13 / 683 symm_kl=0, loss=2.545, nll_loss=0.708, ppl=1.63, wps=6614.8, ups=0.81, wpb=8158, bsz=288.8, num_updates=60800, lr=8.88523e-06, gnorm=0.76, train_wall=85, wall=0
2021-01-15 06:25:36 | INFO | train_inner | epoch 090:    113 / 683 symm_kl=0, loss=2.541, nll_loss=0.705, ppl=1.63, wps=9795.9, ups=1.16, wpb=8451.8, bsz=318, num_updates=60900, lr=8.87794e-06, gnorm=0.741, train_wall=86, wall=0
2021-01-15 06:27:02 | INFO | train_inner | epoch 090:    213 / 683 symm_kl=0, loss=2.54, nll_loss=0.704, ppl=1.63, wps=9872.6, ups=1.16, wpb=8499.8, bsz=290.2, num_updates=61000, lr=8.87066e-06, gnorm=0.736, train_wall=86, wall=0
2021-01-15 06:28:28 | INFO | train_inner | epoch 090:    313 / 683 symm_kl=0, loss=2.53, nll_loss=0.696, ppl=1.62, wps=9907.8, ups=1.16, wpb=8547.1, bsz=306.1, num_updates=61100, lr=8.86339e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 06:29:56 | INFO | train_inner | epoch 090:    413 / 683 symm_kl=0, loss=2.537, nll_loss=0.704, ppl=1.63, wps=10094.1, ups=1.15, wpb=8793.3, bsz=296.8, num_updates=61200, lr=8.85615e-06, gnorm=0.712, train_wall=87, wall=0
2021-01-15 06:31:22 | INFO | train_inner | epoch 090:    513 / 683 symm_kl=0, loss=2.54, nll_loss=0.706, ppl=1.63, wps=9964, ups=1.16, wpb=8612.9, bsz=298.6, num_updates=61300, lr=8.84892e-06, gnorm=0.724, train_wall=86, wall=0
2021-01-15 06:32:49 | INFO | train_inner | epoch 090:    613 / 683 symm_kl=0, loss=2.54, nll_loss=0.708, ppl=1.63, wps=9944.8, ups=1.14, wpb=8689.6, bsz=304.6, num_updates=61400, lr=8.84171e-06, gnorm=0.724, train_wall=87, wall=0
2021-01-15 06:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:33:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:33:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:33:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:33:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:33:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:33:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:33:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:33:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:33:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:33:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:33:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:33:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:34:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:34:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:34:25 | INFO | valid | epoch 090 | valid on 'valid' subset | symm_kl 0 | loss 5.929 | nll_loss 4.357 | ppl 20.5 | bleu 21.82 | wps 2375.2 | wpb 6353.4 | bsz 230.8 | num_updates 61470 | best_bleu 22.06
2021-01-15 06:34:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:34:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 90 @ 61470 updates, score 21.82) (writing took 2.97131722047925 seconds)
2021-01-15 06:34:28 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2021-01-15 06:34:28 | INFO | train | epoch 090 | symm_kl 0 | loss 2.539 | nll_loss 0.705 | ppl 1.63 | wps 9353.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 61470 | lr 8.83668e-06 | gnorm 0.726 | train_wall 589 | wall 0
2021-01-15 06:34:28 | INFO | fairseq.trainer | begin training epoch 91
2021-01-15 06:34:53 | INFO | train_inner | epoch 091:     30 / 683 symm_kl=0, loss=2.543, nll_loss=0.71, ppl=1.64, wps=7035.2, ups=0.81, wpb=8719.2, bsz=311.1, num_updates=61500, lr=8.83452e-06, gnorm=0.719, train_wall=86, wall=0
2021-01-15 06:36:20 | INFO | train_inner | epoch 091:    130 / 683 symm_kl=0, loss=2.541, nll_loss=0.706, ppl=1.63, wps=9907.3, ups=1.15, wpb=8621.2, bsz=327, num_updates=61600, lr=8.82735e-06, gnorm=0.728, train_wall=87, wall=0
2021-01-15 06:37:46 | INFO | train_inner | epoch 091:    230 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=10030.6, ups=1.17, wpb=8572.8, bsz=291.8, num_updates=61700, lr=8.82019e-06, gnorm=0.735, train_wall=85, wall=0
2021-01-15 06:39:13 | INFO | train_inner | epoch 091:    330 / 683 symm_kl=0, loss=2.536, nll_loss=0.701, ppl=1.63, wps=9990.1, ups=1.15, wpb=8695.5, bsz=299.1, num_updates=61800, lr=8.81305e-06, gnorm=0.721, train_wall=87, wall=0
2021-01-15 06:40:39 | INFO | train_inner | epoch 091:    430 / 683 symm_kl=0, loss=2.54, nll_loss=0.705, ppl=1.63, wps=9862.8, ups=1.16, wpb=8512, bsz=287.1, num_updates=61900, lr=8.80593e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 06:42:05 | INFO | train_inner | epoch 091:    530 / 683 symm_kl=0, loss=2.54, nll_loss=0.707, ppl=1.63, wps=10051.2, ups=1.16, wpb=8641.5, bsz=311.2, num_updates=62000, lr=8.79883e-06, gnorm=0.727, train_wall=86, wall=0
2021-01-15 06:43:31 | INFO | train_inner | epoch 091:    630 / 683 symm_kl=0, loss=2.54, nll_loss=0.706, ppl=1.63, wps=9892.1, ups=1.16, wpb=8511.5, bsz=304.5, num_updates=62100, lr=8.79174e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 06:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:44:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:44:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:44:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:44:53 | INFO | valid | epoch 091 | valid on 'valid' subset | symm_kl 0 | loss 5.93 | nll_loss 4.36 | ppl 20.54 | bleu 21.99 | wps 2362.1 | wpb 6353.4 | bsz 230.8 | num_updates 62153 | best_bleu 22.06
2021-01-15 06:44:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:44:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 91 @ 62153 updates, score 21.99) (writing took 3.014359522610903 seconds)
2021-01-15 06:44:56 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2021-01-15 06:44:56 | INFO | train | epoch 091 | symm_kl 0 | loss 2.539 | nll_loss 0.705 | ppl 1.63 | wps 9366.3 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 62153 | lr 8.78799e-06 | gnorm 0.727 | train_wall 588 | wall 0
2021-01-15 06:44:56 | INFO | fairseq.trainer | begin training epoch 92
2021-01-15 06:45:35 | INFO | train_inner | epoch 092:     47 / 683 symm_kl=0, loss=2.53, nll_loss=0.697, ppl=1.62, wps=6832.6, ups=0.81, wpb=8471.3, bsz=309.7, num_updates=62200, lr=8.78467e-06, gnorm=0.729, train_wall=85, wall=0
2021-01-15 06:47:03 | INFO | train_inner | epoch 092:    147 / 683 symm_kl=0, loss=2.531, nll_loss=0.697, ppl=1.62, wps=10015.7, ups=1.13, wpb=8844.2, bsz=326, num_updates=62300, lr=8.77762e-06, gnorm=0.702, train_wall=88, wall=0
2021-01-15 06:48:29 | INFO | train_inner | epoch 092:    247 / 683 symm_kl=0, loss=2.545, nll_loss=0.709, ppl=1.63, wps=9832.3, ups=1.17, wpb=8438.3, bsz=286.1, num_updates=62400, lr=8.77058e-06, gnorm=0.744, train_wall=86, wall=0
2021-01-15 06:49:56 | INFO | train_inner | epoch 092:    347 / 683 symm_kl=0, loss=2.542, nll_loss=0.707, ppl=1.63, wps=10108.7, ups=1.16, wpb=8731.4, bsz=298.2, num_updates=62500, lr=8.76356e-06, gnorm=0.727, train_wall=86, wall=0
2021-01-15 06:51:22 | INFO | train_inner | epoch 092:    447 / 683 symm_kl=0, loss=2.527, nll_loss=0.693, ppl=1.62, wps=9961.7, ups=1.15, wpb=8641.2, bsz=299.8, num_updates=62600, lr=8.75656e-06, gnorm=0.72, train_wall=87, wall=0
2021-01-15 06:52:50 | INFO | train_inner | epoch 092:    547 / 683 symm_kl=0, loss=2.542, nll_loss=0.708, ppl=1.63, wps=9910.7, ups=1.14, wpb=8657.4, bsz=303.3, num_updates=62700, lr=8.74957e-06, gnorm=0.731, train_wall=87, wall=0
2021-01-15 06:54:15 | INFO | train_inner | epoch 092:    647 / 683 symm_kl=0, loss=2.539, nll_loss=0.705, ppl=1.63, wps=10002.2, ups=1.18, wpb=8511.3, bsz=300.8, num_updates=62800, lr=8.7426e-06, gnorm=0.729, train_wall=85, wall=0
2021-01-15 06:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 06:54:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:54:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:54:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:54:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:54:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:54:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:54:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:54:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:54:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:54:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:54:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:54:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 06:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 06:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 06:55:21 | INFO | valid | epoch 092 | valid on 'valid' subset | symm_kl 0 | loss 5.929 | nll_loss 4.358 | ppl 20.51 | bleu 21.82 | wps 2376.1 | wpb 6353.4 | bsz 230.8 | num_updates 62836 | best_bleu 22.06
2021-01-15 06:55:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 06:55:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 92 @ 62836 updates, score 21.82) (writing took 2.8704049810767174 seconds)
2021-01-15 06:55:24 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2021-01-15 06:55:24 | INFO | train | epoch 092 | symm_kl 0 | loss 2.538 | nll_loss 0.704 | ppl 1.63 | wps 9361 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 62836 | lr 8.7401e-06 | gnorm 0.727 | train_wall 589 | wall 0
2021-01-15 06:55:24 | INFO | fairseq.trainer | begin training epoch 93
2021-01-15 06:56:18 | INFO | train_inner | epoch 093:     64 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=6805.9, ups=0.81, wpb=8384.5, bsz=315.9, num_updates=62900, lr=8.73565e-06, gnorm=0.742, train_wall=85, wall=0
2021-01-15 06:57:46 | INFO | train_inner | epoch 093:    164 / 683 symm_kl=0, loss=2.544, nll_loss=0.711, ppl=1.64, wps=10268.6, ups=1.14, wpb=9032.1, bsz=302.2, num_updates=63000, lr=8.72872e-06, gnorm=0.705, train_wall=88, wall=0
2021-01-15 06:59:14 | INFO | train_inner | epoch 093:    264 / 683 symm_kl=0, loss=2.54, nll_loss=0.704, ppl=1.63, wps=9808.5, ups=1.14, wpb=8594.1, bsz=282.7, num_updates=63100, lr=8.7218e-06, gnorm=0.735, train_wall=87, wall=0
2021-01-15 07:00:40 | INFO | train_inner | epoch 093:    364 / 683 symm_kl=0, loss=2.529, nll_loss=0.697, ppl=1.62, wps=10133.3, ups=1.15, wpb=8794.5, bsz=322.1, num_updates=63200, lr=8.71489e-06, gnorm=0.713, train_wall=87, wall=0
2021-01-15 07:02:07 | INFO | train_inner | epoch 093:    464 / 683 symm_kl=0, loss=2.536, nll_loss=0.703, ppl=1.63, wps=10082.6, ups=1.15, wpb=8767, bsz=307.5, num_updates=63300, lr=8.70801e-06, gnorm=0.719, train_wall=87, wall=0
2021-01-15 07:03:32 | INFO | train_inner | epoch 093:    564 / 683 symm_kl=0, loss=2.542, nll_loss=0.706, ppl=1.63, wps=9666.1, ups=1.18, wpb=8189.1, bsz=311.4, num_updates=63400, lr=8.70114e-06, gnorm=0.753, train_wall=85, wall=0
2021-01-15 07:04:58 | INFO | train_inner | epoch 093:    664 / 683 symm_kl=0, loss=2.537, nll_loss=0.704, ppl=1.63, wps=9952, ups=1.16, wpb=8557.8, bsz=288.3, num_updates=63500, lr=8.69428e-06, gnorm=0.727, train_wall=86, wall=0
2021-01-15 07:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:05:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:05:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:05:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:05:50 | INFO | valid | epoch 093 | valid on 'valid' subset | symm_kl 0 | loss 5.93 | nll_loss 4.36 | ppl 20.53 | bleu 21.81 | wps 2374.4 | wpb 6353.4 | bsz 230.8 | num_updates 63519 | best_bleu 22.06
2021-01-15 07:05:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:05:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 93 @ 63519 updates, score 21.81) (writing took 2.9455361049622297 seconds)
2021-01-15 07:05:52 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2021-01-15 07:05:52 | INFO | train | epoch 093 | symm_kl 0 | loss 2.539 | nll_loss 0.704 | ppl 1.63 | wps 9355.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 63519 | lr 8.69298e-06 | gnorm 0.728 | train_wall 589 | wall 0
2021-01-15 07:05:52 | INFO | fairseq.trainer | begin training epoch 94
2021-01-15 07:07:04 | INFO | train_inner | epoch 094:     81 / 683 symm_kl=0, loss=2.536, nll_loss=0.701, ppl=1.63, wps=6988, ups=0.8, wpb=8763.3, bsz=293.8, num_updates=63600, lr=8.68744e-06, gnorm=0.713, train_wall=87, wall=0
2021-01-15 07:08:30 | INFO | train_inner | epoch 094:    181 / 683 symm_kl=0, loss=2.533, nll_loss=0.699, ppl=1.62, wps=10040.8, ups=1.16, wpb=8683, bsz=294.1, num_updates=63700, lr=8.68062e-06, gnorm=0.725, train_wall=86, wall=0
2021-01-15 07:09:56 | INFO | train_inner | epoch 094:    281 / 683 symm_kl=0, loss=2.537, nll_loss=0.704, ppl=1.63, wps=10110.9, ups=1.16, wpb=8729.5, bsz=305.6, num_updates=63800, lr=8.67382e-06, gnorm=0.716, train_wall=86, wall=0
2021-01-15 07:11:24 | INFO | train_inner | epoch 094:    381 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=10138.7, ups=1.15, wpb=8839, bsz=307.3, num_updates=63900, lr=8.66703e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 07:12:50 | INFO | train_inner | epoch 094:    481 / 683 symm_kl=0, loss=2.541, nll_loss=0.707, ppl=1.63, wps=9987.4, ups=1.15, wpb=8652.1, bsz=326.4, num_updates=64000, lr=8.66025e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 07:14:17 | INFO | train_inner | epoch 094:    581 / 683 symm_kl=0, loss=2.534, nll_loss=0.699, ppl=1.62, wps=9704.3, ups=1.15, wpb=8402.1, bsz=295.7, num_updates=64100, lr=8.6535e-06, gnorm=0.742, train_wall=86, wall=0
2021-01-15 07:15:42 | INFO | train_inner | epoch 094:    681 / 683 symm_kl=0, loss=2.542, nll_loss=0.706, ppl=1.63, wps=9676.6, ups=1.18, wpb=8208.8, bsz=301.7, num_updates=64200, lr=8.64675e-06, gnorm=0.755, train_wall=85, wall=0
2021-01-15 07:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:15:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:15:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:15:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:15:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:15:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:15:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:15:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:16:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:16:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:16:18 | INFO | valid | epoch 094 | valid on 'valid' subset | symm_kl 0 | loss 5.931 | nll_loss 4.362 | ppl 20.56 | bleu 21.87 | wps 2386.1 | wpb 6353.4 | bsz 230.8 | num_updates 64202 | best_bleu 22.06
2021-01-15 07:16:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:16:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 94 @ 64202 updates, score 21.87) (writing took 3.014034340158105 seconds)
2021-01-15 07:16:21 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2021-01-15 07:16:21 | INFO | train | epoch 094 | symm_kl 0 | loss 2.538 | nll_loss 0.704 | ppl 1.63 | wps 9351.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 64202 | lr 8.64662e-06 | gnorm 0.729 | train_wall 589 | wall 0
2021-01-15 07:16:21 | INFO | fairseq.trainer | begin training epoch 95
2021-01-15 07:17:47 | INFO | train_inner | epoch 095:     98 / 683 symm_kl=0, loss=2.531, nll_loss=0.698, ppl=1.62, wps=7145.9, ups=0.8, wpb=8956.3, bsz=307.4, num_updates=64300, lr=8.64003e-06, gnorm=0.699, train_wall=87, wall=0
2021-01-15 07:19:13 | INFO | train_inner | epoch 095:    198 / 683 symm_kl=0, loss=2.542, nll_loss=0.707, ppl=1.63, wps=9875.3, ups=1.16, wpb=8520.7, bsz=301.6, num_updates=64400, lr=8.63332e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 07:20:38 | INFO | train_inner | epoch 095:    298 / 683 symm_kl=0, loss=2.548, nll_loss=0.713, ppl=1.64, wps=9908.5, ups=1.18, wpb=8418.3, bsz=306.7, num_updates=64500, lr=8.62662e-06, gnorm=0.745, train_wall=85, wall=0
2021-01-15 07:22:04 | INFO | train_inner | epoch 095:    398 / 683 symm_kl=0, loss=2.537, nll_loss=0.701, ppl=1.63, wps=9840.5, ups=1.17, wpb=8421.6, bsz=301.8, num_updates=64600, lr=8.61994e-06, gnorm=0.732, train_wall=85, wall=0
2021-01-15 07:23:30 | INFO | train_inner | epoch 095:    498 / 683 symm_kl=0, loss=2.543, nll_loss=0.707, ppl=1.63, wps=9827.1, ups=1.16, wpb=8476.3, bsz=280.8, num_updates=64700, lr=8.61328e-06, gnorm=0.747, train_wall=86, wall=0
2021-01-15 07:24:57 | INFO | train_inner | epoch 095:    598 / 683 symm_kl=0, loss=2.532, nll_loss=0.701, ppl=1.63, wps=10137.1, ups=1.15, wpb=8810.2, bsz=329.2, num_updates=64800, lr=8.60663e-06, gnorm=0.708, train_wall=87, wall=0
2021-01-15 07:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:26:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:26:46 | INFO | valid | epoch 095 | valid on 'valid' subset | symm_kl 0 | loss 5.929 | nll_loss 4.36 | ppl 20.53 | bleu 21.97 | wps 2377.9 | wpb 6353.4 | bsz 230.8 | num_updates 64885 | best_bleu 22.06
2021-01-15 07:26:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:26:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 95 @ 64885 updates, score 21.97) (writing took 3.1069646533578634 seconds)
2021-01-15 07:26:49 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2021-01-15 07:26:49 | INFO | train | epoch 095 | symm_kl 0 | loss 2.538 | nll_loss 0.703 | ppl 1.63 | wps 9372.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 64885 | lr 8.60099e-06 | gnorm 0.727 | train_wall 588 | wall 0
2021-01-15 07:26:49 | INFO | fairseq.trainer | begin training epoch 96
2021-01-15 07:27:01 | INFO | train_inner | epoch 096:     15 / 683 symm_kl=0, loss=2.53, nll_loss=0.696, ppl=1.62, wps=6895.6, ups=0.8, wpb=8570.1, bsz=297.3, num_updates=64900, lr=8.6e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 07:28:27 | INFO | train_inner | epoch 096:    115 / 683 symm_kl=0, loss=2.538, nll_loss=0.706, ppl=1.63, wps=10114.3, ups=1.17, wpb=8674.6, bsz=337.1, num_updates=65000, lr=8.59338e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 07:29:53 | INFO | train_inner | epoch 096:    215 / 683 symm_kl=0, loss=2.554, nll_loss=0.719, ppl=1.65, wps=10147.6, ups=1.16, wpb=8740.6, bsz=295.3, num_updates=65100, lr=8.58678e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 07:31:20 | INFO | train_inner | epoch 096:    315 / 683 symm_kl=0, loss=2.517, nll_loss=0.684, ppl=1.61, wps=10142.4, ups=1.15, wpb=8838.6, bsz=328.9, num_updates=65200, lr=8.58019e-06, gnorm=0.699, train_wall=87, wall=0
2021-01-15 07:32:46 | INFO | train_inner | epoch 096:    415 / 683 symm_kl=0, loss=2.532, nll_loss=0.697, ppl=1.62, wps=9941.2, ups=1.16, wpb=8555.2, bsz=309.4, num_updates=65300, lr=8.57362e-06, gnorm=0.723, train_wall=86, wall=0
2021-01-15 07:34:12 | INFO | train_inner | epoch 096:    515 / 683 symm_kl=0, loss=2.538, nll_loss=0.703, ppl=1.63, wps=9865, ups=1.16, wpb=8492.5, bsz=280.2, num_updates=65400, lr=8.56706e-06, gnorm=0.734, train_wall=86, wall=0
2021-01-15 07:35:39 | INFO | train_inner | epoch 096:    615 / 683 symm_kl=0, loss=2.534, nll_loss=0.699, ppl=1.62, wps=9896.1, ups=1.15, wpb=8569.2, bsz=277.8, num_updates=65500, lr=8.56052e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 07:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:36:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:36:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:36:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:36:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:37:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:37:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:37:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:37:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:37:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:37:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:37:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:37:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:37:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:37:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:37:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:37:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:37:12 | INFO | valid | epoch 096 | valid on 'valid' subset | symm_kl 0 | loss 5.931 | nll_loss 4.361 | ppl 20.55 | bleu 21.99 | wps 2380.6 | wpb 6353.4 | bsz 230.8 | num_updates 65568 | best_bleu 22.06
2021-01-15 07:37:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:37:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 96 @ 65568 updates, score 21.99) (writing took 3.135553700849414 seconds)
2021-01-15 07:37:15 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2021-01-15 07:37:15 | INFO | train | epoch 096 | symm_kl 0 | loss 2.537 | nll_loss 0.703 | ppl 1.63 | wps 9385.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 65568 | lr 8.55608e-06 | gnorm 0.727 | train_wall 587 | wall 0
2021-01-15 07:37:15 | INFO | fairseq.trainer | begin training epoch 97
2021-01-15 07:37:43 | INFO | train_inner | epoch 097:     32 / 683 symm_kl=0, loss=2.549, nll_loss=0.713, ppl=1.64, wps=6903.4, ups=0.81, wpb=8550.3, bsz=292.6, num_updates=65600, lr=8.55399e-06, gnorm=0.741, train_wall=85, wall=0
2021-01-15 07:39:09 | INFO | train_inner | epoch 097:    132 / 683 symm_kl=0, loss=2.539, nll_loss=0.705, ppl=1.63, wps=9917.3, ups=1.16, wpb=8566.9, bsz=302.8, num_updates=65700, lr=8.54748e-06, gnorm=0.732, train_wall=86, wall=0
2021-01-15 07:40:36 | INFO | train_inner | epoch 097:    232 / 683 symm_kl=0, loss=2.532, nll_loss=0.697, ppl=1.62, wps=9819.8, ups=1.16, wpb=8475.9, bsz=305.9, num_updates=65800, lr=8.54098e-06, gnorm=0.734, train_wall=86, wall=0
2021-01-15 07:42:02 | INFO | train_inner | epoch 097:    332 / 683 symm_kl=0, loss=2.543, nll_loss=0.707, ppl=1.63, wps=9857.8, ups=1.16, wpb=8531.7, bsz=285, num_updates=65900, lr=8.5345e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 07:43:29 | INFO | train_inner | epoch 097:    432 / 683 symm_kl=0, loss=2.522, nll_loss=0.689, ppl=1.61, wps=10039.6, ups=1.15, wpb=8762.5, bsz=317.4, num_updates=66000, lr=8.52803e-06, gnorm=0.708, train_wall=87, wall=0
2021-01-15 07:44:56 | INFO | train_inner | epoch 097:    532 / 683 symm_kl=0, loss=2.538, nll_loss=0.705, ppl=1.63, wps=10036.1, ups=1.15, wpb=8694.1, bsz=321.1, num_updates=66100, lr=8.52158e-06, gnorm=0.725, train_wall=86, wall=0
2021-01-15 07:46:22 | INFO | train_inner | epoch 097:    632 / 683 symm_kl=0, loss=2.543, nll_loss=0.708, ppl=1.63, wps=9920.5, ups=1.16, wpb=8521.8, bsz=297, num_updates=66200, lr=8.51514e-06, gnorm=0.733, train_wall=86, wall=0
2021-01-15 07:47:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:47:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:47:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:47:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:47:41 | INFO | valid | epoch 097 | valid on 'valid' subset | symm_kl 0 | loss 5.933 | nll_loss 4.362 | ppl 20.57 | bleu 21.83 | wps 2357 | wpb 6353.4 | bsz 230.8 | num_updates 66251 | best_bleu 22.06
2021-01-15 07:47:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:47:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 97 @ 66251 updates, score 21.83) (writing took 2.9701297990977764 seconds)
2021-01-15 07:47:44 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2021-01-15 07:47:44 | INFO | train | epoch 097 | symm_kl 0 | loss 2.537 | nll_loss 0.702 | ppl 1.63 | wps 9352.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 66251 | lr 8.51186e-06 | gnorm 0.728 | train_wall 589 | wall 0
2021-01-15 07:47:44 | INFO | fairseq.trainer | begin training epoch 98
2021-01-15 07:48:26 | INFO | train_inner | epoch 098:     49 / 683 symm_kl=0, loss=2.546, nll_loss=0.712, ppl=1.64, wps=6979.2, ups=0.81, wpb=8661.1, bsz=299.1, num_updates=66300, lr=8.50871e-06, gnorm=0.732, train_wall=86, wall=0
2021-01-15 07:49:53 | INFO | train_inner | epoch 098:    149 / 683 symm_kl=0, loss=2.548, nll_loss=0.713, ppl=1.64, wps=10025.5, ups=1.15, wpb=8728.9, bsz=312.8, num_updates=66400, lr=8.5023e-06, gnorm=0.726, train_wall=87, wall=0
2021-01-15 07:51:19 | INFO | train_inner | epoch 098:    249 / 683 symm_kl=0, loss=2.531, nll_loss=0.695, ppl=1.62, wps=9559.2, ups=1.16, wpb=8217.3, bsz=285.8, num_updates=66500, lr=8.49591e-06, gnorm=0.75, train_wall=86, wall=0
2021-01-15 07:52:45 | INFO | train_inner | epoch 098:    349 / 683 symm_kl=0, loss=2.533, nll_loss=0.698, ppl=1.62, wps=9928.1, ups=1.16, wpb=8585.1, bsz=295.5, num_updates=66600, lr=8.48953e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 07:54:13 | INFO | train_inner | epoch 098:    449 / 683 symm_kl=0, loss=2.536, nll_loss=0.703, ppl=1.63, wps=10198.5, ups=1.15, wpb=8886.9, bsz=301.2, num_updates=66700, lr=8.48316e-06, gnorm=0.711, train_wall=87, wall=0
2021-01-15 07:55:40 | INFO | train_inner | epoch 098:    549 / 683 symm_kl=0, loss=2.541, nll_loss=0.707, ppl=1.63, wps=9881.9, ups=1.15, wpb=8592.1, bsz=286.1, num_updates=66800, lr=8.47681e-06, gnorm=0.734, train_wall=87, wall=0
2021-01-15 07:57:05 | INFO | train_inner | epoch 098:    649 / 683 symm_kl=0, loss=2.533, nll_loss=0.7, ppl=1.62, wps=10156, ups=1.16, wpb=8726, bsz=333.6, num_updates=66900, lr=8.47047e-06, gnorm=0.71, train_wall=86, wall=0
2021-01-15 07:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 07:57:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:57:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:57:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:57:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:58:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:58:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:58:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:58:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 07:58:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 07:58:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 07:58:09 | INFO | valid | epoch 098 | valid on 'valid' subset | symm_kl 0 | loss 5.933 | nll_loss 4.362 | ppl 20.57 | bleu 21.82 | wps 2392.5 | wpb 6353.4 | bsz 230.8 | num_updates 66934 | best_bleu 22.06
2021-01-15 07:58:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 07:58:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 98 @ 66934 updates, score 21.82) (writing took 2.9749435652047396 seconds)
2021-01-15 07:58:12 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2021-01-15 07:58:12 | INFO | train | epoch 098 | symm_kl 0 | loss 2.537 | nll_loss 0.702 | ppl 1.63 | wps 9366 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 66934 | lr 8.46832e-06 | gnorm 0.727 | train_wall 589 | wall 0
2021-01-15 07:58:12 | INFO | fairseq.trainer | begin training epoch 99
2021-01-15 07:59:09 | INFO | train_inner | epoch 099:     66 / 683 symm_kl=0, loss=2.527, nll_loss=0.693, ppl=1.62, wps=6912.1, ups=0.81, wpb=8562.6, bsz=311, num_updates=67000, lr=8.46415e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 08:00:35 | INFO | train_inner | epoch 099:    166 / 683 symm_kl=0, loss=2.548, nll_loss=0.713, ppl=1.64, wps=9924.8, ups=1.16, wpb=8544, bsz=319.4, num_updates=67100, lr=8.45784e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 08:02:03 | INFO | train_inner | epoch 099:    266 / 683 symm_kl=0, loss=2.535, nll_loss=0.699, ppl=1.62, wps=10045.6, ups=1.15, wpb=8761, bsz=265.4, num_updates=67200, lr=8.45154e-06, gnorm=0.724, train_wall=87, wall=0
2021-01-15 08:03:28 | INFO | train_inner | epoch 099:    366 / 683 symm_kl=0, loss=2.53, nll_loss=0.697, ppl=1.62, wps=9991, ups=1.17, wpb=8523, bsz=333.1, num_updates=67300, lr=8.44526e-06, gnorm=0.731, train_wall=85, wall=0
2021-01-15 08:04:55 | INFO | train_inner | epoch 099:    466 / 683 symm_kl=0, loss=2.527, nll_loss=0.694, ppl=1.62, wps=9863.7, ups=1.15, wpb=8606.9, bsz=291.7, num_updates=67400, lr=8.43899e-06, gnorm=0.724, train_wall=87, wall=0
2021-01-15 08:06:23 | INFO | train_inner | epoch 099:    566 / 683 symm_kl=0, loss=2.545, nll_loss=0.711, ppl=1.64, wps=10088.5, ups=1.15, wpb=8805.5, bsz=290.3, num_updates=67500, lr=8.43274e-06, gnorm=0.724, train_wall=87, wall=0
2021-01-15 08:07:48 | INFO | train_inner | epoch 099:    666 / 683 symm_kl=0, loss=2.529, nll_loss=0.696, ppl=1.62, wps=10024.8, ups=1.18, wpb=8527.2, bsz=329.5, num_updates=67600, lr=8.4265e-06, gnorm=0.72, train_wall=85, wall=0
2021-01-15 08:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 08:08:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:08:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:08:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:08:37 | INFO | valid | epoch 099 | valid on 'valid' subset | symm_kl 0 | loss 5.935 | nll_loss 4.366 | ppl 20.62 | bleu 21.83 | wps 2360.2 | wpb 6353.4 | bsz 230.8 | num_updates 67617 | best_bleu 22.06
2021-01-15 08:08:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 08:08:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 99 @ 67617 updates, score 21.83) (writing took 2.9949177112430334 seconds)
2021-01-15 08:08:40 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2021-01-15 08:08:40 | INFO | train | epoch 099 | symm_kl 0 | loss 2.536 | nll_loss 0.702 | ppl 1.63 | wps 9369.3 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 67617 | lr 8.42544e-06 | gnorm 0.728 | train_wall 588 | wall 0
2021-01-15 08:08:40 | INFO | fairseq.trainer | begin training epoch 100
2021-01-15 08:09:51 | INFO | train_inner | epoch 100:     83 / 683 symm_kl=0, loss=2.54, nll_loss=0.705, ppl=1.63, wps=6907.6, ups=0.81, wpb=8540, bsz=298.3, num_updates=67700, lr=8.42028e-06, gnorm=0.738, train_wall=85, wall=0
2021-01-15 08:11:18 | INFO | train_inner | epoch 100:    183 / 683 symm_kl=0, loss=2.515, nll_loss=0.684, ppl=1.61, wps=10033, ups=1.15, wpb=8718.3, bsz=347.6, num_updates=67800, lr=8.41406e-06, gnorm=0.706, train_wall=87, wall=0
2021-01-15 08:12:44 | INFO | train_inner | epoch 100:    283 / 683 symm_kl=0, loss=2.536, nll_loss=0.701, ppl=1.63, wps=10018.8, ups=1.16, wpb=8620.9, bsz=286.1, num_updates=67900, lr=8.40787e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 08:14:10 | INFO | train_inner | epoch 100:    383 / 683 symm_kl=0, loss=2.538, nll_loss=0.704, ppl=1.63, wps=9837.5, ups=1.16, wpb=8482.4, bsz=313.6, num_updates=68000, lr=8.40168e-06, gnorm=0.74, train_wall=86, wall=0
2021-01-15 08:15:37 | INFO | train_inner | epoch 100:    483 / 683 symm_kl=0, loss=2.543, nll_loss=0.707, ppl=1.63, wps=9825.2, ups=1.15, wpb=8514.2, bsz=278.4, num_updates=68100, lr=8.39551e-06, gnorm=0.742, train_wall=86, wall=0
2021-01-15 08:17:03 | INFO | train_inner | epoch 100:    583 / 683 symm_kl=0, loss=2.542, nll_loss=0.708, ppl=1.63, wps=10025.7, ups=1.16, wpb=8642.3, bsz=308.6, num_updates=68200, lr=8.38935e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 08:18:29 | INFO | train_inner | epoch 100:    683 / 683 symm_kl=0, loss=2.536, nll_loss=0.701, ppl=1.63, wps=10031.2, ups=1.16, wpb=8634.7, bsz=285.6, num_updates=68300, lr=8.38321e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 08:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 08:18:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:18:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:18:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:18:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:19:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:19:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:19:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:19:04 | INFO | valid | epoch 100 | valid on 'valid' subset | symm_kl 0 | loss 5.934 | nll_loss 4.364 | ppl 20.59 | bleu 21.86 | wps 2389.3 | wpb 6353.4 | bsz 230.8 | num_updates 68300 | best_bleu 22.06
2021-01-15 08:19:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 08:19:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 100 @ 68300 updates, score 21.86) (writing took 3.0101239923387766 seconds)
2021-01-15 08:19:07 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2021-01-15 08:19:07 | INFO | train | epoch 100 | symm_kl 0 | loss 2.535 | nll_loss 0.701 | ppl 1.63 | wps 9376.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 68300 | lr 8.38321e-06 | gnorm 0.728 | train_wall 588 | wall 0
2021-01-15 08:19:07 | INFO | fairseq.trainer | begin training epoch 101
2021-01-15 08:20:34 | INFO | train_inner | epoch 101:    100 / 683 symm_kl=0, loss=2.53, nll_loss=0.695, ppl=1.62, wps=6988, ups=0.8, wpb=8700.4, bsz=306, num_updates=68400, lr=8.37708e-06, gnorm=0.718, train_wall=86, wall=0
2021-01-15 08:22:00 | INFO | train_inner | epoch 101:    200 / 683 symm_kl=0, loss=2.532, nll_loss=0.698, ppl=1.62, wps=10083.4, ups=1.16, wpb=8714.2, bsz=306.8, num_updates=68500, lr=8.37096e-06, gnorm=0.72, train_wall=86, wall=0
2021-01-15 08:23:26 | INFO | train_inner | epoch 101:    300 / 683 symm_kl=0, loss=2.532, nll_loss=0.696, ppl=1.62, wps=9952, ups=1.16, wpb=8583.1, bsz=303.9, num_updates=68600, lr=8.36486e-06, gnorm=0.729, train_wall=86, wall=0
2021-01-15 08:24:53 | INFO | train_inner | epoch 101:    400 / 683 symm_kl=0, loss=2.539, nll_loss=0.703, ppl=1.63, wps=9832.8, ups=1.16, wpb=8482.7, bsz=299, num_updates=68700, lr=8.35877e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 08:26:17 | INFO | train_inner | epoch 101:    500 / 683 symm_kl=0, loss=2.542, nll_loss=0.709, ppl=1.63, wps=9984.1, ups=1.18, wpb=8452.5, bsz=294.2, num_updates=68800, lr=8.35269e-06, gnorm=0.741, train_wall=84, wall=0
2021-01-15 08:27:44 | INFO | train_inner | epoch 101:    600 / 683 symm_kl=0, loss=2.542, nll_loss=0.707, ppl=1.63, wps=10080.6, ups=1.16, wpb=8679.4, bsz=294.6, num_updates=68900, lr=8.34663e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 08:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 08:28:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:28:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:28:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:29:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:29:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:29:30 | INFO | valid | epoch 101 | valid on 'valid' subset | symm_kl 0 | loss 5.932 | nll_loss 4.364 | ppl 20.59 | bleu 22.03 | wps 2370 | wpb 6353.4 | bsz 230.8 | num_updates 68983 | best_bleu 22.06
2021-01-15 08:29:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 08:29:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 101 @ 68983 updates, score 22.03) (writing took 2.964984707534313 seconds)
2021-01-15 08:29:33 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2021-01-15 08:29:33 | INFO | train | epoch 101 | symm_kl 0 | loss 2.535 | nll_loss 0.7 | ppl 1.62 | wps 9392.2 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 68983 | lr 8.3416e-06 | gnorm 0.728 | train_wall 587 | wall 0
2021-01-15 08:29:33 | INFO | fairseq.trainer | begin training epoch 102
2021-01-15 08:29:48 | INFO | train_inner | epoch 102:     17 / 683 symm_kl=0, loss=2.523, nll_loss=0.691, ppl=1.61, wps=7064.5, ups=0.81, wpb=8774.1, bsz=318.6, num_updates=69000, lr=8.34058e-06, gnorm=0.708, train_wall=86, wall=0
2021-01-15 08:31:13 | INFO | train_inner | epoch 102:    117 / 683 symm_kl=0, loss=2.53, nll_loss=0.695, ppl=1.62, wps=10069.7, ups=1.17, wpb=8638.4, bsz=324.6, num_updates=69100, lr=8.33454e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 08:32:39 | INFO | train_inner | epoch 102:    217 / 683 symm_kl=0, loss=2.541, nll_loss=0.706, ppl=1.63, wps=9976.8, ups=1.16, wpb=8564.9, bsz=308.5, num_updates=69200, lr=8.32851e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 08:34:05 | INFO | train_inner | epoch 102:    317 / 683 symm_kl=0, loss=2.532, nll_loss=0.696, ppl=1.62, wps=9916.8, ups=1.17, wpb=8470.5, bsz=308.3, num_updates=69300, lr=8.3225e-06, gnorm=0.73, train_wall=85, wall=0
2021-01-15 08:35:31 | INFO | train_inner | epoch 102:    417 / 683 symm_kl=0, loss=2.547, nll_loss=0.713, ppl=1.64, wps=10041.2, ups=1.16, wpb=8667.7, bsz=298.6, num_updates=69400, lr=8.31651e-06, gnorm=0.73, train_wall=86, wall=0
2021-01-15 08:36:57 | INFO | train_inner | epoch 102:    517 / 683 symm_kl=0, loss=2.538, nll_loss=0.702, ppl=1.63, wps=9819.6, ups=1.16, wpb=8471.2, bsz=288.6, num_updates=69500, lr=8.31052e-06, gnorm=0.746, train_wall=86, wall=0
2021-01-15 08:38:24 | INFO | train_inner | epoch 102:    617 / 683 symm_kl=0, loss=2.54, nll_loss=0.705, ppl=1.63, wps=10050.2, ups=1.16, wpb=8687.2, bsz=291.8, num_updates=69600, lr=8.30455e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 08:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 08:39:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:39:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:39:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:39:56 | INFO | valid | epoch 102 | valid on 'valid' subset | symm_kl 0 | loss 5.935 | nll_loss 4.367 | ppl 20.63 | bleu 21.91 | wps 2373.4 | wpb 6353.4 | bsz 230.8 | num_updates 69666 | best_bleu 22.06
2021-01-15 08:39:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 08:39:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 102 @ 69666 updates, score 21.91) (writing took 2.9614267498254776 seconds)
2021-01-15 08:39:59 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2021-01-15 08:39:59 | INFO | train | epoch 102 | symm_kl 0 | loss 2.535 | nll_loss 0.701 | ppl 1.63 | wps 9402.3 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 69666 | lr 8.30061e-06 | gnorm 0.729 | train_wall 586 | wall 0
2021-01-15 08:39:59 | INFO | fairseq.trainer | begin training epoch 103
2021-01-15 08:40:27 | INFO | train_inner | epoch 103:     34 / 683 symm_kl=0, loss=2.523, nll_loss=0.69, ppl=1.61, wps=7004.7, ups=0.81, wpb=8662.6, bsz=328.6, num_updates=69700, lr=8.29859e-06, gnorm=0.715, train_wall=85, wall=0
2021-01-15 08:41:54 | INFO | train_inner | epoch 103:    134 / 683 symm_kl=0, loss=2.53, nll_loss=0.697, ppl=1.62, wps=10070.9, ups=1.16, wpb=8675.2, bsz=311.3, num_updates=69800, lr=8.29264e-06, gnorm=0.717, train_wall=86, wall=0
2021-01-15 08:43:20 | INFO | train_inner | epoch 103:    234 / 683 symm_kl=0, loss=2.524, nll_loss=0.689, ppl=1.61, wps=9958, ups=1.16, wpb=8571.7, bsz=311.2, num_updates=69900, lr=8.28671e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 08:44:46 | INFO | train_inner | epoch 103:    334 / 683 symm_kl=0, loss=2.533, nll_loss=0.698, ppl=1.62, wps=10134.5, ups=1.16, wpb=8733.9, bsz=292.6, num_updates=70000, lr=8.28079e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 08:46:12 | INFO | train_inner | epoch 103:    434 / 683 symm_kl=0, loss=2.54, nll_loss=0.703, ppl=1.63, wps=9866.1, ups=1.16, wpb=8492.1, bsz=280.2, num_updates=70100, lr=8.27488e-06, gnorm=0.739, train_wall=86, wall=0
2021-01-15 08:47:37 | INFO | train_inner | epoch 103:    534 / 683 symm_kl=0, loss=2.545, nll_loss=0.71, ppl=1.64, wps=10018.2, ups=1.17, wpb=8553, bsz=273.3, num_updates=70200, lr=8.26898e-06, gnorm=0.74, train_wall=85, wall=0
2021-01-15 08:49:04 | INFO | train_inner | epoch 103:    634 / 683 symm_kl=0, loss=2.533, nll_loss=0.699, ppl=1.62, wps=9972.5, ups=1.15, wpb=8657.8, bsz=327.3, num_updates=70300, lr=8.2631e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 08:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 08:49:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:49:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:49:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:49:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:49:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:49:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:49:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:49:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:49:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:49:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:49:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:49:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:49:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:49:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:49:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 08:50:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 08:50:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 08:50:22 | INFO | valid | epoch 103 | valid on 'valid' subset | symm_kl 0 | loss 5.935 | nll_loss 4.366 | ppl 20.62 | bleu 21.91 | wps 2395 | wpb 6353.4 | bsz 230.8 | num_updates 70349 | best_bleu 22.06
2021-01-15 08:50:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 08:50:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 103 @ 70349 updates, score 21.91) (writing took 3.017714060842991 seconds)
2021-01-15 08:50:25 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2021-01-15 08:50:25 | INFO | train | epoch 103 | symm_kl 0 | loss 2.534 | nll_loss 0.7 | ppl 1.62 | wps 9398.7 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 70349 | lr 8.26022e-06 | gnorm 0.728 | train_wall 586 | wall 0
2021-01-15 08:50:25 | INFO | fairseq.trainer | begin training epoch 104
2021-01-15 08:51:09 | INFO | train_inner | epoch 104:     51 / 683 symm_kl=0, loss=2.533, nll_loss=0.699, ppl=1.62, wps=6999.8, ups=0.8, wpb=8725, bsz=328.6, num_updates=70400, lr=8.25723e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 08:52:34 | INFO | train_inner | epoch 104:    151 / 683 symm_kl=0, loss=2.546, nll_loss=0.711, ppl=1.64, wps=10038, ups=1.17, wpb=8566.5, bsz=311, num_updates=70500, lr=8.25137e-06, gnorm=0.74, train_wall=85, wall=0
2021-01-15 08:54:00 | INFO | train_inner | epoch 104:    251 / 683 symm_kl=0, loss=2.527, nll_loss=0.691, ppl=1.61, wps=9946, ups=1.17, wpb=8536.1, bsz=286.6, num_updates=70600, lr=8.24552e-06, gnorm=0.73, train_wall=86, wall=0
2021-01-15 08:55:27 | INFO | train_inner | epoch 104:    351 / 683 symm_kl=0, loss=2.533, nll_loss=0.697, ppl=1.62, wps=9923.3, ups=1.15, wpb=8600.8, bsz=287, num_updates=70700, lr=8.23969e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 08:56:54 | INFO | train_inner | epoch 104:    451 / 683 symm_kl=0, loss=2.528, nll_loss=0.693, ppl=1.62, wps=10024.3, ups=1.15, wpb=8734.3, bsz=290.7, num_updates=70800, lr=8.23387e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 08:58:20 | INFO | train_inner | epoch 104:    551 / 683 symm_kl=0, loss=2.539, nll_loss=0.704, ppl=1.63, wps=9843.1, ups=1.15, wpb=8534.7, bsz=294.5, num_updates=70900, lr=8.22806e-06, gnorm=0.736, train_wall=87, wall=0
2021-01-15 08:59:47 | INFO | train_inner | epoch 104:    651 / 683 symm_kl=0, loss=2.535, nll_loss=0.702, ppl=1.63, wps=9978.1, ups=1.16, wpb=8591.3, bsz=320.6, num_updates=71000, lr=8.22226e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 09:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:00:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:00:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:00:49 | INFO | valid | epoch 104 | valid on 'valid' subset | symm_kl 0 | loss 5.934 | nll_loss 4.365 | ppl 20.61 | bleu 21.89 | wps 2373.8 | wpb 6353.4 | bsz 230.8 | num_updates 71032 | best_bleu 22.06
2021-01-15 09:00:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:00:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 104 @ 71032 updates, score 21.89) (writing took 3.0361695550382137 seconds)
2021-01-15 09:00:52 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2021-01-15 09:00:52 | INFO | train | epoch 104 | symm_kl 0 | loss 2.534 | nll_loss 0.699 | ppl 1.62 | wps 9369.9 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 71032 | lr 8.22041e-06 | gnorm 0.727 | train_wall 588 | wall 0
2021-01-15 09:00:52 | INFO | fairseq.trainer | begin training epoch 105
2021-01-15 09:01:50 | INFO | train_inner | epoch 105:     68 / 683 symm_kl=0, loss=2.529, nll_loss=0.693, ppl=1.62, wps=6778.4, ups=0.81, wpb=8378.2, bsz=316.1, num_updates=71100, lr=8.21648e-06, gnorm=0.735, train_wall=85, wall=0
2021-01-15 09:03:15 | INFO | train_inner | epoch 105:    168 / 683 symm_kl=0, loss=2.535, nll_loss=0.699, ppl=1.62, wps=9870.4, ups=1.17, wpb=8419.9, bsz=294.5, num_updates=71200, lr=8.21071e-06, gnorm=0.741, train_wall=85, wall=0
2021-01-15 09:04:42 | INFO | train_inner | epoch 105:    268 / 683 symm_kl=0, loss=2.543, nll_loss=0.71, ppl=1.64, wps=10164.2, ups=1.16, wpb=8783.3, bsz=319.8, num_updates=71300, lr=8.20495e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 09:06:09 | INFO | train_inner | epoch 105:    368 / 683 symm_kl=0, loss=2.545, nll_loss=0.71, ppl=1.64, wps=10015.4, ups=1.14, wpb=8751.7, bsz=300.1, num_updates=71400, lr=8.1992e-06, gnorm=0.733, train_wall=87, wall=0
2021-01-15 09:07:35 | INFO | train_inner | epoch 105:    468 / 683 symm_kl=0, loss=2.524, nll_loss=0.69, ppl=1.61, wps=10096.2, ups=1.17, wpb=8646.6, bsz=321, num_updates=71500, lr=8.19346e-06, gnorm=0.72, train_wall=85, wall=0
2021-01-15 09:09:02 | INFO | train_inner | epoch 105:    568 / 683 symm_kl=0, loss=2.521, nll_loss=0.687, ppl=1.61, wps=10077.9, ups=1.15, wpb=8787.1, bsz=297.8, num_updates=71600, lr=8.18774e-06, gnorm=0.706, train_wall=87, wall=0
2021-01-15 09:10:28 | INFO | train_inner | epoch 105:    668 / 683 symm_kl=0, loss=2.541, nll_loss=0.706, ppl=1.63, wps=9949.3, ups=1.17, wpb=8533.9, bsz=285.5, num_updates=71700, lr=8.18203e-06, gnorm=0.74, train_wall=86, wall=0
2021-01-15 09:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:10:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:10:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:10:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:10:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:11:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:11:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:11:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:11:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:11:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:11:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:11:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:11:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:11:16 | INFO | valid | epoch 105 | valid on 'valid' subset | symm_kl 0 | loss 5.934 | nll_loss 4.365 | ppl 20.61 | bleu 22.03 | wps 2365.9 | wpb 6353.4 | bsz 230.8 | num_updates 71715 | best_bleu 22.06
2021-01-15 09:11:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:11:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 105 @ 71715 updates, score 22.03) (writing took 2.9545286297798157 seconds)
2021-01-15 09:11:19 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2021-01-15 09:11:19 | INFO | train | epoch 105 | symm_kl 0 | loss 2.534 | nll_loss 0.699 | ppl 1.62 | wps 9383.2 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 71715 | lr 8.18117e-06 | gnorm 0.729 | train_wall 587 | wall 0
2021-01-15 09:11:19 | INFO | fairseq.trainer | begin training epoch 106
2021-01-15 09:12:32 | INFO | train_inner | epoch 106:     85 / 683 symm_kl=0, loss=2.542, nll_loss=0.706, ppl=1.63, wps=6832.4, ups=0.81, wpb=8456.3, bsz=313.6, num_updates=71800, lr=8.17633e-06, gnorm=0.744, train_wall=85, wall=0
2021-01-15 09:13:59 | INFO | train_inner | epoch 106:    185 / 683 symm_kl=0, loss=2.53, nll_loss=0.695, ppl=1.62, wps=10111.6, ups=1.14, wpb=8847.3, bsz=307.5, num_updates=71900, lr=8.17064e-06, gnorm=0.715, train_wall=87, wall=0
2021-01-15 09:15:25 | INFO | train_inner | epoch 106:    285 / 683 symm_kl=0, loss=2.533, nll_loss=0.695, ppl=1.62, wps=9667.4, ups=1.17, wpb=8287.2, bsz=270.1, num_updates=72000, lr=8.16497e-06, gnorm=0.75, train_wall=86, wall=0
2021-01-15 09:16:50 | INFO | train_inner | epoch 106:    385 / 683 symm_kl=0, loss=2.536, nll_loss=0.701, ppl=1.63, wps=9900.2, ups=1.17, wpb=8447.9, bsz=308.4, num_updates=72100, lr=8.1593e-06, gnorm=0.746, train_wall=85, wall=0
2021-01-15 09:18:17 | INFO | train_inner | epoch 106:    485 / 683 symm_kl=0, loss=2.543, nll_loss=0.71, ppl=1.64, wps=10122.5, ups=1.15, wpb=8801.9, bsz=298.2, num_updates=72200, lr=8.15365e-06, gnorm=0.719, train_wall=87, wall=0
2021-01-15 09:19:44 | INFO | train_inner | epoch 106:    585 / 683 symm_kl=0, loss=2.525, nll_loss=0.692, ppl=1.62, wps=10042.6, ups=1.16, wpb=8688.7, bsz=325.3, num_updates=72300, lr=8.14801e-06, gnorm=0.716, train_wall=86, wall=0
2021-01-15 09:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:21:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:21:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:21:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:21:44 | INFO | valid | epoch 106 | valid on 'valid' subset | symm_kl 0 | loss 5.94 | nll_loss 4.37 | ppl 20.68 | bleu 21.88 | wps 2376.1 | wpb 6353.4 | bsz 230.8 | num_updates 72398 | best_bleu 22.06
2021-01-15 09:21:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:21:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 106 @ 72398 updates, score 21.88) (writing took 2.9567320812493563 seconds)
2021-01-15 09:21:47 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2021-01-15 09:21:47 | INFO | train | epoch 106 | symm_kl 0 | loss 2.533 | nll_loss 0.699 | ppl 1.62 | wps 9366.5 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 72398 | lr 8.14249e-06 | gnorm 0.729 | train_wall 588 | wall 0
2021-01-15 09:21:47 | INFO | fairseq.trainer | begin training epoch 107
2021-01-15 09:21:49 | INFO | train_inner | epoch 107:      2 / 683 symm_kl=0, loss=2.525, nll_loss=0.692, ppl=1.62, wps=6956.8, ups=0.8, wpb=8703.5, bsz=304, num_updates=72400, lr=8.14238e-06, gnorm=0.716, train_wall=87, wall=0
2021-01-15 09:23:15 | INFO | train_inner | epoch 107:    102 / 683 symm_kl=0, loss=2.53, nll_loss=0.694, ppl=1.62, wps=9973.1, ups=1.16, wpb=8595.2, bsz=295.8, num_updates=72500, lr=8.13676e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 09:24:41 | INFO | train_inner | epoch 107:    202 / 683 symm_kl=0, loss=2.529, nll_loss=0.696, ppl=1.62, wps=10059.2, ups=1.16, wpb=8669.2, bsz=322.7, num_updates=72600, lr=8.13116e-06, gnorm=0.723, train_wall=86, wall=0
2021-01-15 09:26:07 | INFO | train_inner | epoch 107:    302 / 683 symm_kl=0, loss=2.531, nll_loss=0.694, ppl=1.62, wps=9658, ups=1.16, wpb=8311.6, bsz=300.1, num_updates=72700, lr=8.12556e-06, gnorm=0.75, train_wall=86, wall=0
2021-01-15 09:27:34 | INFO | train_inner | epoch 107:    402 / 683 symm_kl=0, loss=2.527, nll_loss=0.695, ppl=1.62, wps=9979.7, ups=1.16, wpb=8639.7, bsz=301.5, num_updates=72800, lr=8.11998e-06, gnorm=0.721, train_wall=86, wall=0
2021-01-15 09:29:00 | INFO | train_inner | epoch 107:    502 / 683 symm_kl=0, loss=2.551, nll_loss=0.716, ppl=1.64, wps=10050.2, ups=1.16, wpb=8643.7, bsz=291.7, num_updates=72900, lr=8.11441e-06, gnorm=0.743, train_wall=86, wall=0
2021-01-15 09:30:26 | INFO | train_inner | epoch 107:    602 / 683 symm_kl=0, loss=2.528, nll_loss=0.693, ppl=1.62, wps=9960.8, ups=1.16, wpb=8592, bsz=308.4, num_updates=73000, lr=8.10885e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 09:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:31:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:31:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:31:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:31:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:32:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:32:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:32:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:32:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:32:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:32:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:32:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:32:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:32:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:32:11 | INFO | valid | epoch 107 | valid on 'valid' subset | symm_kl 0 | loss 5.936 | nll_loss 4.367 | ppl 20.64 | bleu 21.91 | wps 2371.6 | wpb 6353.4 | bsz 230.8 | num_updates 73081 | best_bleu 22.06
2021-01-15 09:32:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:32:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 107 @ 73081 updates, score 21.91) (writing took 2.7768133524805307 seconds)
2021-01-15 09:32:14 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2021-01-15 09:32:14 | INFO | train | epoch 107 | symm_kl 0 | loss 2.533 | nll_loss 0.698 | ppl 1.62 | wps 9375 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 73081 | lr 8.10435e-06 | gnorm 0.729 | train_wall 588 | wall 0
2021-01-15 09:32:14 | INFO | fairseq.trainer | begin training epoch 108
2021-01-15 09:32:30 | INFO | train_inner | epoch 108:     19 / 683 symm_kl=0, loss=2.53, nll_loss=0.696, ppl=1.62, wps=7048.1, ups=0.81, wpb=8742.5, bsz=311.2, num_updates=73100, lr=8.1033e-06, gnorm=0.717, train_wall=86, wall=0
2021-01-15 09:33:56 | INFO | train_inner | epoch 108:    119 / 683 symm_kl=0, loss=2.542, nll_loss=0.705, ppl=1.63, wps=9863.4, ups=1.17, wpb=8463.1, bsz=271, num_updates=73200, lr=8.09776e-06, gnorm=0.746, train_wall=86, wall=0
2021-01-15 09:35:23 | INFO | train_inner | epoch 108:    219 / 683 symm_kl=0, loss=2.519, nll_loss=0.685, ppl=1.61, wps=9900.8, ups=1.14, wpb=8653.1, bsz=314.3, num_updates=73300, lr=8.09224e-06, gnorm=0.718, train_wall=87, wall=0
2021-01-15 09:36:50 | INFO | train_inner | epoch 108:    319 / 683 symm_kl=0, loss=2.524, nll_loss=0.691, ppl=1.61, wps=10237.7, ups=1.16, wpb=8855.9, bsz=337.2, num_updates=73400, lr=8.08672e-06, gnorm=0.703, train_wall=86, wall=0
2021-01-15 09:38:16 | INFO | train_inner | epoch 108:    419 / 683 symm_kl=0, loss=2.542, nll_loss=0.706, ppl=1.63, wps=10077.9, ups=1.16, wpb=8696.5, bsz=273.7, num_updates=73500, lr=8.08122e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 09:39:43 | INFO | train_inner | epoch 108:    519 / 683 symm_kl=0, loss=2.54, nll_loss=0.706, ppl=1.63, wps=10188.7, ups=1.15, wpb=8854.5, bsz=311.4, num_updates=73600, lr=8.07573e-06, gnorm=0.723, train_wall=87, wall=0
2021-01-15 09:41:08 | INFO | train_inner | epoch 108:    619 / 683 symm_kl=0, loss=2.533, nll_loss=0.698, ppl=1.62, wps=9777.4, ups=1.17, wpb=8338.7, bsz=322.5, num_updates=73700, lr=8.07025e-06, gnorm=0.736, train_wall=85, wall=0
2021-01-15 09:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:42:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:42:38 | INFO | valid | epoch 108 | valid on 'valid' subset | symm_kl 0 | loss 5.94 | nll_loss 4.37 | ppl 20.68 | bleu 21.77 | wps 2391.1 | wpb 6353.4 | bsz 230.8 | num_updates 73764 | best_bleu 22.06
2021-01-15 09:42:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:42:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 108 @ 73764 updates, score 21.77) (writing took 2.9003184847533703 seconds)
2021-01-15 09:42:41 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2021-01-15 09:42:41 | INFO | train | epoch 108 | symm_kl 0 | loss 2.533 | nll_loss 0.698 | ppl 1.62 | wps 9381.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 73764 | lr 8.06675e-06 | gnorm 0.73 | train_wall 588 | wall 0
2021-01-15 09:42:41 | INFO | fairseq.trainer | begin training epoch 109
2021-01-15 09:43:12 | INFO | train_inner | epoch 109:     36 / 683 symm_kl=0, loss=2.534, nll_loss=0.698, ppl=1.62, wps=6891.3, ups=0.81, wpb=8503.7, bsz=287.8, num_updates=73800, lr=8.06478e-06, gnorm=0.739, train_wall=85, wall=0
2021-01-15 09:44:38 | INFO | train_inner | epoch 109:    136 / 683 symm_kl=0, loss=2.526, nll_loss=0.691, ppl=1.61, wps=9905.5, ups=1.15, wpb=8597.8, bsz=308.7, num_updates=73900, lr=8.05932e-06, gnorm=0.725, train_wall=87, wall=0
2021-01-15 09:46:04 | INFO | train_inner | epoch 109:    236 / 683 symm_kl=0, loss=2.539, nll_loss=0.705, ppl=1.63, wps=10110.3, ups=1.16, wpb=8695.5, bsz=311, num_updates=74000, lr=8.05387e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 09:47:31 | INFO | train_inner | epoch 109:    336 / 683 symm_kl=0, loss=2.535, nll_loss=0.698, ppl=1.62, wps=10060.4, ups=1.16, wpb=8657.3, bsz=294.3, num_updates=74100, lr=8.04844e-06, gnorm=0.726, train_wall=86, wall=0
2021-01-15 09:48:56 | INFO | train_inner | epoch 109:    436 / 683 symm_kl=0, loss=2.526, nll_loss=0.691, ppl=1.61, wps=9856.8, ups=1.17, wpb=8398.5, bsz=285.9, num_updates=74200, lr=8.04301e-06, gnorm=0.741, train_wall=85, wall=0
2021-01-15 09:50:22 | INFO | train_inner | epoch 109:    536 / 683 symm_kl=0, loss=2.539, nll_loss=0.704, ppl=1.63, wps=9975.7, ups=1.16, wpb=8600.2, bsz=300.6, num_updates=74300, lr=8.0376e-06, gnorm=0.739, train_wall=86, wall=0
2021-01-15 09:51:48 | INFO | train_inner | epoch 109:    636 / 683 symm_kl=0, loss=2.533, nll_loss=0.698, ppl=1.62, wps=9856.8, ups=1.16, wpb=8481.2, bsz=312.3, num_updates=74400, lr=8.03219e-06, gnorm=0.732, train_wall=86, wall=0
2021-01-15 09:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 09:52:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:53:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 09:53:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 09:53:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 09:53:04 | INFO | valid | epoch 109 | valid on 'valid' subset | symm_kl 0 | loss 5.936 | nll_loss 4.367 | ppl 20.64 | bleu 21.85 | wps 2368.1 | wpb 6353.4 | bsz 230.8 | num_updates 74447 | best_bleu 22.06
2021-01-15 09:53:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 09:53:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 109 @ 74447 updates, score 21.85) (writing took 2.863099280744791 seconds)
2021-01-15 09:53:07 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2021-01-15 09:53:07 | INFO | train | epoch 109 | symm_kl 0 | loss 2.532 | nll_loss 0.698 | ppl 1.62 | wps 9397.4 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 74447 | lr 8.02966e-06 | gnorm 0.729 | train_wall 586 | wall 0
2021-01-15 09:53:07 | INFO | fairseq.trainer | begin training epoch 110
2021-01-15 09:53:53 | INFO | train_inner | epoch 110:     53 / 683 symm_kl=0, loss=2.526, nll_loss=0.692, ppl=1.62, wps=7045.4, ups=0.8, wpb=8790.6, bsz=307.5, num_updates=74500, lr=8.0268e-06, gnorm=0.714, train_wall=87, wall=0
2021-01-15 09:55:20 | INFO | train_inner | epoch 110:    153 / 683 symm_kl=0, loss=2.541, nll_loss=0.704, ppl=1.63, wps=9946.6, ups=1.15, wpb=8645.9, bsz=303.6, num_updates=74600, lr=8.02142e-06, gnorm=0.731, train_wall=87, wall=0
2021-01-15 09:56:46 | INFO | train_inner | epoch 110:    253 / 683 symm_kl=0, loss=2.536, nll_loss=0.7, ppl=1.62, wps=9912.2, ups=1.16, wpb=8512.6, bsz=311.1, num_updates=74700, lr=8.01605e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 09:58:12 | INFO | train_inner | epoch 110:    353 / 683 symm_kl=0, loss=2.536, nll_loss=0.7, ppl=1.63, wps=10025.7, ups=1.15, wpb=8705.4, bsz=279, num_updates=74800, lr=8.01069e-06, gnorm=0.73, train_wall=87, wall=0
2021-01-15 09:59:38 | INFO | train_inner | epoch 110:    453 / 683 symm_kl=0, loss=2.53, nll_loss=0.696, ppl=1.62, wps=9938.8, ups=1.17, wpb=8514.2, bsz=305.7, num_updates=74900, lr=8.00534e-06, gnorm=0.729, train_wall=85, wall=0
2021-01-15 10:01:05 | INFO | train_inner | epoch 110:    553 / 683 symm_kl=0, loss=2.531, nll_loss=0.697, ppl=1.62, wps=10021.7, ups=1.15, wpb=8682.1, bsz=318, num_updates=75000, lr=8e-06, gnorm=0.728, train_wall=86, wall=0
2021-01-15 10:02:31 | INFO | train_inner | epoch 110:    653 / 683 symm_kl=0, loss=2.524, nll_loss=0.691, ppl=1.61, wps=9851.1, ups=1.15, wpb=8549.2, bsz=306.2, num_updates=75100, lr=7.99467e-06, gnorm=0.728, train_wall=87, wall=0
2021-01-15 10:02:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 10:03:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:03:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:03:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:03:33 | INFO | valid | epoch 110 | valid on 'valid' subset | symm_kl 0 | loss 5.936 | nll_loss 4.368 | ppl 20.66 | bleu 21.94 | wps 2371.5 | wpb 6353.4 | bsz 230.8 | num_updates 75130 | best_bleu 22.06
2021-01-15 10:03:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 10:03:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 110 @ 75130 updates, score 21.94) (writing took 2.8950453512370586 seconds)
2021-01-15 10:03:36 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2021-01-15 10:03:36 | INFO | train | epoch 110 | symm_kl 0 | loss 2.532 | nll_loss 0.697 | ppl 1.62 | wps 9352.6 | ups 1.09 | wpb 8610.8 | bsz 303.6 | num_updates 75130 | lr 7.99308e-06 | gnorm 0.73 | train_wall 589 | wall 0
2021-01-15 10:03:36 | INFO | fairseq.trainer | begin training epoch 111
2021-01-15 10:04:36 | INFO | train_inner | epoch 111:     70 / 683 symm_kl=0, loss=2.543, nll_loss=0.708, ppl=1.63, wps=6959.1, ups=0.8, wpb=8653.6, bsz=290.4, num_updates=75200, lr=7.98935e-06, gnorm=0.735, train_wall=86, wall=0
2021-01-15 10:06:03 | INFO | train_inner | epoch 111:    170 / 683 symm_kl=0, loss=2.539, nll_loss=0.703, ppl=1.63, wps=9967, ups=1.15, wpb=8680.4, bsz=293.3, num_updates=75300, lr=7.98405e-06, gnorm=0.731, train_wall=87, wall=0
2021-01-15 10:07:28 | INFO | train_inner | epoch 111:    270 / 683 symm_kl=0, loss=2.527, nll_loss=0.692, ppl=1.62, wps=9805.2, ups=1.18, wpb=8321.1, bsz=306.5, num_updates=75400, lr=7.97875e-06, gnorm=0.74, train_wall=85, wall=0
2021-01-15 10:08:54 | INFO | train_inner | epoch 111:    370 / 683 symm_kl=0, loss=2.53, nll_loss=0.696, ppl=1.62, wps=10005.2, ups=1.17, wpb=8584.9, bsz=294.2, num_updates=75500, lr=7.97347e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 10:10:21 | INFO | train_inner | epoch 111:    470 / 683 symm_kl=0, loss=2.533, nll_loss=0.697, ppl=1.62, wps=9855.4, ups=1.15, wpb=8573.2, bsz=300.2, num_updates=75600, lr=7.96819e-06, gnorm=0.739, train_wall=87, wall=0
2021-01-15 10:11:48 | INFO | train_inner | epoch 111:    570 / 683 symm_kl=0, loss=2.515, nll_loss=0.682, ppl=1.6, wps=10106.1, ups=1.15, wpb=8786.4, bsz=333, num_updates=75700, lr=7.96293e-06, gnorm=0.695, train_wall=87, wall=0
2021-01-15 10:13:16 | INFO | train_inner | epoch 111:    670 / 683 symm_kl=0, loss=2.533, nll_loss=0.697, ppl=1.62, wps=9931.3, ups=1.13, wpb=8789.2, bsz=312.6, num_updates=75800, lr=7.95767e-06, gnorm=0.72, train_wall=88, wall=0
2021-01-15 10:13:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 10:13:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:13:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:13:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:13:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:14:03 | INFO | valid | epoch 111 | valid on 'valid' subset | symm_kl 0 | loss 5.941 | nll_loss 4.372 | ppl 20.71 | bleu 21.92 | wps 2339.3 | wpb 6353.4 | bsz 230.8 | num_updates 75813 | best_bleu 22.06
2021-01-15 10:14:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 10:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 111 @ 75813 updates, score 21.92) (writing took 2.863890388980508 seconds)
2021-01-15 10:14:06 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2021-01-15 10:14:06 | INFO | train | epoch 111 | symm_kl 0 | loss 2.531 | nll_loss 0.696 | ppl 1.62 | wps 9337.9 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 75813 | lr 7.95699e-06 | gnorm 0.729 | train_wall 590 | wall 0
2021-01-15 10:14:06 | INFO | fairseq.trainer | begin training epoch 112
2021-01-15 10:15:21 | INFO | train_inner | epoch 112:     87 / 683 symm_kl=0, loss=2.535, nll_loss=0.7, ppl=1.62, wps=6923.3, ups=0.8, wpb=8635.9, bsz=310.7, num_updates=75900, lr=7.95243e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 10:16:46 | INFO | train_inner | epoch 112:    187 / 683 symm_kl=0, loss=2.52, nll_loss=0.686, ppl=1.61, wps=9747.6, ups=1.17, wpb=8344.1, bsz=319.9, num_updates=76000, lr=7.94719e-06, gnorm=0.735, train_wall=85, wall=0
2021-01-15 10:18:13 | INFO | train_inner | epoch 112:    287 / 683 symm_kl=0, loss=2.534, nll_loss=0.696, ppl=1.62, wps=9793.7, ups=1.16, wpb=8442.1, bsz=308.4, num_updates=76100, lr=7.94197e-06, gnorm=0.742, train_wall=86, wall=0
2021-01-15 10:19:39 | INFO | train_inner | epoch 112:    387 / 683 symm_kl=0, loss=2.535, nll_loss=0.701, ppl=1.63, wps=9942.1, ups=1.15, wpb=8614.1, bsz=284.1, num_updates=76200, lr=7.93676e-06, gnorm=0.738, train_wall=86, wall=0
2021-01-15 10:21:07 | INFO | train_inner | epoch 112:    487 / 683 symm_kl=0, loss=2.531, nll_loss=0.695, ppl=1.62, wps=10148.9, ups=1.14, wpb=8880.9, bsz=294.8, num_updates=76300, lr=7.93156e-06, gnorm=0.717, train_wall=87, wall=0
2021-01-15 10:22:34 | INFO | train_inner | epoch 112:    587 / 683 symm_kl=0, loss=2.537, nll_loss=0.704, ppl=1.63, wps=10101.3, ups=1.14, wpb=8862.9, bsz=311.2, num_updates=76400, lr=7.92636e-06, gnorm=0.715, train_wall=88, wall=0
2021-01-15 10:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 10:24:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:24:32 | INFO | valid | epoch 112 | valid on 'valid' subset | symm_kl 0 | loss 5.937 | nll_loss 4.37 | ppl 20.68 | bleu 21.87 | wps 2353.7 | wpb 6353.4 | bsz 230.8 | num_updates 76496 | best_bleu 22.06
2021-01-15 10:24:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 10:24:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 112 @ 76496 updates, score 21.87) (writing took 2.822662165388465 seconds)
2021-01-15 10:24:35 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2021-01-15 10:24:35 | INFO | train | epoch 112 | symm_kl 0 | loss 2.531 | nll_loss 0.696 | ppl 1.62 | wps 9340.1 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 76496 | lr 7.92139e-06 | gnorm 0.731 | train_wall 590 | wall 0
2021-01-15 10:24:35 | INFO | fairseq.trainer | begin training epoch 113
2021-01-15 10:24:39 | INFO | train_inner | epoch 113:      4 / 683 symm_kl=0, loss=2.528, nll_loss=0.693, ppl=1.62, wps=6788.2, ups=0.81, wpb=8424.5, bsz=292.5, num_updates=76500, lr=7.92118e-06, gnorm=0.737, train_wall=86, wall=0
2021-01-15 10:26:04 | INFO | train_inner | epoch 113:    104 / 683 symm_kl=0, loss=2.532, nll_loss=0.697, ppl=1.62, wps=9796, ups=1.17, wpb=8362.9, bsz=298.5, num_updates=76600, lr=7.91601e-06, gnorm=0.744, train_wall=85, wall=0
2021-01-15 10:27:31 | INFO | train_inner | epoch 113:    204 / 683 symm_kl=0, loss=2.525, nll_loss=0.692, ppl=1.62, wps=10192.4, ups=1.15, wpb=8827.9, bsz=331.4, num_updates=76700, lr=7.91085e-06, gnorm=0.707, train_wall=86, wall=0
2021-01-15 10:28:56 | INFO | train_inner | epoch 113:    304 / 683 symm_kl=0, loss=2.527, nll_loss=0.692, ppl=1.62, wps=9710, ups=1.18, wpb=8263.6, bsz=315.3, num_updates=76800, lr=7.90569e-06, gnorm=0.749, train_wall=85, wall=0
2021-01-15 10:30:23 | INFO | train_inner | epoch 113:    404 / 683 symm_kl=0, loss=2.532, nll_loss=0.697, ppl=1.62, wps=10040, ups=1.14, wpb=8774.9, bsz=300.2, num_updates=76900, lr=7.90055e-06, gnorm=0.72, train_wall=87, wall=0
2021-01-15 10:31:51 | INFO | train_inner | epoch 113:    504 / 683 symm_kl=0, loss=2.539, nll_loss=0.703, ppl=1.63, wps=9883.6, ups=1.14, wpb=8651.4, bsz=299.5, num_updates=77000, lr=7.89542e-06, gnorm=0.732, train_wall=87, wall=0
2021-01-15 10:33:19 | INFO | train_inner | epoch 113:    604 / 683 symm_kl=0, loss=2.531, nll_loss=0.696, ppl=1.62, wps=9942.5, ups=1.14, wpb=8759.1, bsz=295.8, num_updates=77100, lr=7.8903e-06, gnorm=0.716, train_wall=88, wall=0
2021-01-15 10:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 10:34:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:34:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:34:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:34:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:35:02 | INFO | valid | epoch 113 | valid on 'valid' subset | symm_kl 0 | loss 5.94 | nll_loss 4.372 | ppl 20.71 | bleu 21.82 | wps 2397.8 | wpb 6353.4 | bsz 230.8 | num_updates 77179 | best_bleu 22.06
2021-01-15 10:35:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 10:35:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 113 @ 77179 updates, score 21.82) (writing took 2.8523171469569206 seconds)
2021-01-15 10:35:05 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2021-01-15 10:35:05 | INFO | train | epoch 113 | symm_kl 0 | loss 2.531 | nll_loss 0.696 | ppl 1.62 | wps 9339.4 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 77179 | lr 7.88626e-06 | gnorm 0.728 | train_wall 591 | wall 0
2021-01-15 10:35:05 | INFO | fairseq.trainer | begin training epoch 114
2021-01-15 10:35:23 | INFO | train_inner | epoch 114:     21 / 683 symm_kl=0, loss=2.522, nll_loss=0.686, ppl=1.61, wps=6916.1, ups=0.81, wpb=8580.5, bsz=270.6, num_updates=77200, lr=7.88519e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 10:36:49 | INFO | train_inner | epoch 114:    121 / 683 symm_kl=0, loss=2.526, nll_loss=0.691, ppl=1.61, wps=9894.3, ups=1.16, wpb=8501.2, bsz=303.8, num_updates=77300, lr=7.88008e-06, gnorm=0.735, train_wall=86, wall=0
2021-01-15 10:38:15 | INFO | train_inner | epoch 114:    221 / 683 symm_kl=0, loss=2.529, nll_loss=0.694, ppl=1.62, wps=9992.4, ups=1.16, wpb=8635.9, bsz=282.6, num_updates=77400, lr=7.87499e-06, gnorm=0.731, train_wall=86, wall=0
2021-01-15 10:39:42 | INFO | train_inner | epoch 114:    321 / 683 symm_kl=0, loss=2.523, nll_loss=0.689, ppl=1.61, wps=9998.4, ups=1.15, wpb=8686.5, bsz=312.8, num_updates=77500, lr=7.86991e-06, gnorm=0.722, train_wall=87, wall=0
2021-01-15 10:41:09 | INFO | train_inner | epoch 114:    421 / 683 symm_kl=0, loss=2.525, nll_loss=0.691, ppl=1.61, wps=10163.6, ups=1.15, wpb=8809.4, bsz=330.2, num_updates=77600, lr=7.86484e-06, gnorm=0.706, train_wall=86, wall=0
2021-01-15 10:42:36 | INFO | train_inner | epoch 114:    521 / 683 symm_kl=0, loss=2.534, nll_loss=0.698, ppl=1.62, wps=9871.2, ups=1.15, wpb=8597.8, bsz=297, num_updates=77700, lr=7.85977e-06, gnorm=0.736, train_wall=87, wall=0
2021-01-15 10:44:02 | INFO | train_inner | epoch 114:    621 / 683 symm_kl=0, loss=2.54, nll_loss=0.704, ppl=1.63, wps=9802.7, ups=1.16, wpb=8435.3, bsz=291.6, num_updates=77800, lr=7.85472e-06, gnorm=0.748, train_wall=86, wall=0
2021-01-15 10:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-15 10:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-15 10:45:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-15 10:45:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-15 10:45:32 | INFO | valid | epoch 114 | valid on 'valid' subset | symm_kl 0 | loss 5.942 | nll_loss 4.375 | ppl 20.75 | bleu 21.95 | wps 2307.3 | wpb 6353.4 | bsz 230.8 | num_updates 77862 | best_bleu 22.06
2021-01-15 10:45:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-15 10:45:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_input/checkpoint_last.pt (epoch 114 @ 77862 updates, score 21.95) (writing took 2.880551628768444 seconds)
2021-01-15 10:45:35 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2021-01-15 10:45:35 | INFO | train | epoch 114 | symm_kl 0 | loss 2.53 | nll_loss 0.695 | ppl 1.62 | wps 9335.3 | ups 1.08 | wpb 8610.8 | bsz 303.6 | num_updates 77862 | lr 7.85159e-06 | gnorm 0.73 | train_wall 590 | wall 0
2021-01-15 10:45:35 | INFO | fairseq.trainer | begin training epoch 115
2021-01-15 10:46:07 | INFO | train_inner | epoch 115:     38 / 683 symm_kl=0, loss=2.535, nll_loss=0.701, ppl=1.63, wps=6986.6, ups=0.8, wpb=8768.3, bsz=318.7, num_updates=77900, lr=7.84968e-06, gnorm=0.722, train_wall=86, wall=0
2021-01-15 10:47:35 | INFO | train_inner | epoch 115:    138 / 683 symm_kl=0, loss=2.532, nll_loss=0.699, ppl=1.62, wps=9964.7, ups=1.14, wpb=8732.5, bsz=336.9, num_updates=78000, lr=7.84465e-06, gnorm=0.723, train_wall=87, wall=0
2021-01-15 10:49:03 | INFO | train_inner | epoch 115:    238 / 683 symm_kl=0, loss=2.528, nll_loss=0.692, ppl=1.62, wps=9945.3, ups=1.13, wpb=8783, bsz=286.9, num_updates=78100, lr=7.83962e-06, gnorm=0.717, train_wall=88, wall=0
2021-01-15 10:50:29 | INFO | train_inner | epoch 115:    338 / 683 symm_kl=0, loss=2.54, nll_loss=0.702, ppl=1.63, wps=9747.6, ups=1.17, wpb=8359.5, bsz=280.4, num_updates=78200, lr=7.83461e-06, gnorm=0.751, train_wall=86, wall=0
Killed
