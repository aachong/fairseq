nohup: ignoring input
save_dir=./examples/entr/bash/../checkpoints/noised_target
还是改了那个没有梯度的dropout=0.0,相当于无dropout
criterion=label_smoothed_cross_entropy_r3f
label_smoothing=0.1
dropout=0.3
lr=0.00004
lrscheduler=inverse_sqrt
warmup_updates=3000
max_epoch=200
r3f_lambda=1
extr='--warmup-init-lr 1e-07 --noised-no-grad'
2021-01-16 15:50:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:16 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:19842
2021-01-16 15:50:16 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:19842
2021-01-16 15:50:16 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:19842
2021-01-16 15:50:17 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2021-01-16 15:50:17 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2021-01-16 15:50:17 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2021-01-16 15:50:21 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy_r3f', cross_self_attention=False, curriculum=0, cv=False, cv_lambda=0.0, data='./examples/entr/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', de_std=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:19842', distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-06, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[4e-05], lr_scheduler='inverse_sqrt', max_epoch=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', noised_eval_model=False, noised_no_grad=True, nprocs_per_node=3, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=1.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/entr/bash/../checkpoints/noised_target', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, self_training_drc=False, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='tr', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=3000, weight_decay=0.0, zero_sharding='none')
2021-01-16 15:50:21 | INFO | fairseq.tasks.translation | [en] dictionary: 19784 types
2021-01-16 15:50:21 | INFO | fairseq.tasks.translation | [tr] dictionary: 19784 types
2021-01-16 15:50:21 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.en
2021-01-16 15:50:21 | INFO | fairseq.data.data_utils | loaded 3000 examples from: ./examples/entr/bash/../data-bin/valid.en-tr.tr
2021-01-16 15:50:21 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin valid en-tr 3000 examples
2021-01-16 15:50:23 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19784, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19784, bias=False)
  )
)
2021-01-16 15:50:23 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-01-16 15:50:23 | INFO | fairseq_cli.train | model: transformer (TransformerModel)
2021-01-16 15:50:23 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy_r3f (LabelSmoothedCrossEntropyR3FCriterion)
2021-01-16 15:50:23 | INFO | fairseq_cli.train | num. model params: 54267904 (num. trained: 54267904)
2021-01-16 15:50:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-01-16 15:50:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-01-16 15:50:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-01-16 15:50:23 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-01-16 15:50:23 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-01-16 15:50:23 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2021-01-16 15:50:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2021-01-16 15:50:23 | INFO | fairseq_cli.train | training on 3 devices (GPUs/TPUs)
2021-01-16 15:50:23 | INFO | fairseq_cli.train | max tokens per GPU = 6000 and max sentences per GPU = None
2021-01-16 15:50:23 | INFO | fairseq.checkpoint_utils | loading pretrained model from ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt: optimizer, lr scheduler, meters, dataloader will be reset
2021-01-16 15:50:23 | INFO | fairseq.trainer | loaded checkpoint ./examples/entr/bash/../checkpoints/baseline/checkpoint_last.pt (epoch 106 @ 0 updates)
2021-01-16 15:50:23 | INFO | fairseq.optim.adam | using FusedAdam
2021-01-16 15:50:23 | INFO | fairseq.trainer | loading train data for epoch 1
2021-01-16 15:50:23 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.en
2021-01-16 15:50:23 | INFO | fairseq.data.data_utils | loaded 207373 examples from: ./examples/entr/bash/../data-bin/train.en-tr.tr
2021-01-16 15:50:23 | INFO | fairseq.tasks.translation | ./examples/entr/bash/../data-bin train en-tr 207373 examples
2021-01-16 15:50:24 | INFO | fairseq.trainer | begin training epoch 1
2021-01-16 15:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:50:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:50:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:51:30 | INFO | train_inner | epoch 001:    100 / 375 symm_kl=1.101, self_kl=0, self_cv=0, loss=4.252, nll_loss=0.843, ppl=1.79, wps=25500.3, ups=1.62, wpb=15737.3, bsz=531.8, num_updates=100, lr=1.43e-06, gnorm=2.001, train_wall=62, wall=67
2021-01-16 15:52:32 | INFO | train_inner | epoch 001:    200 / 375 symm_kl=0.984, self_kl=0, self_cv=0, loss=4.078, nll_loss=0.832, ppl=1.78, wps=25187.6, ups=1.61, wpb=15669, bsz=570.1, num_updates=200, lr=2.76e-06, gnorm=2.023, train_wall=62, wall=130
2021-01-16 15:53:35 | INFO | train_inner | epoch 001:    300 / 375 symm_kl=0.811, self_kl=0, self_cv=0, loss=3.831, nll_loss=0.822, ppl=1.77, wps=25244.1, ups=1.59, wpb=15841.3, bsz=567.8, num_updates=300, lr=4.09e-06, gnorm=1.782, train_wall=63, wall=192
2021-01-16 15:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 15:54:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:54:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:54:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:54:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:54:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:54:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:54:40 | INFO | valid | epoch 001 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.89 | nll_loss 4.259 | ppl 19.15 | bleu 21.97 | wps 5567.1 | wpb 11799.1 | bsz 428.6 | num_updates 375
2021-01-16 15:54:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 15:54:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 1 @ 375 updates, score 21.97) (writing took 2.350537171587348 seconds)
2021-01-16 15:54:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-01-16 15:54:42 | INFO | train | epoch 001 | symm_kl 0.932 | self_kl 0 | self_cv 0 | loss 4.007 | nll_loss 0.829 | ppl 1.78 | wps 23164.1 | ups 1.48 | wpb 15683.1 | bsz 553 | num_updates 375 | lr 5.0875e-06 | gnorm 1.859 | train_wall 233 | wall 259
2021-01-16 15:54:42 | INFO | fairseq.trainer | begin training epoch 2
2021-01-16 15:54:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:54:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:54:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:54:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:55:01 | INFO | train_inner | epoch 002:     25 / 375 symm_kl=0.787, self_kl=0, self_cv=0, loss=3.803, nll_loss=0.812, ppl=1.76, wps=17995.5, ups=1.16, wpb=15515.8, bsz=539.8, num_updates=400, lr=5.42e-06, gnorm=1.535, train_wall=62, wall=279
2021-01-16 15:56:04 | INFO | train_inner | epoch 002:    125 / 375 symm_kl=0.759, self_kl=0, self_cv=0, loss=3.758, nll_loss=0.806, ppl=1.75, wps=25147.7, ups=1.6, wpb=15724.6, bsz=551.4, num_updates=500, lr=6.75e-06, gnorm=1.463, train_wall=62, wall=341
2021-01-16 15:57:06 | INFO | train_inner | epoch 002:    225 / 375 symm_kl=0.746, self_kl=0, self_cv=0, loss=3.745, nll_loss=0.812, ppl=1.76, wps=25058.9, ups=1.59, wpb=15723.4, bsz=572.9, num_updates=600, lr=8.08e-06, gnorm=1.399, train_wall=63, wall=404
2021-01-16 15:58:09 | INFO | train_inner | epoch 002:    325 / 375 symm_kl=0.737, self_kl=0, self_cv=0, loss=3.728, nll_loss=0.806, ppl=1.75, wps=24950, ups=1.59, wpb=15716.5, bsz=554, num_updates=700, lr=9.41e-06, gnorm=1.403, train_wall=63, wall=467
2021-01-16 15:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 15:58:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:58:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:58:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:58:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:58:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:58:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:58:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:58:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 15:58:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 15:58:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 15:59:00 | INFO | valid | epoch 002 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.869 | nll_loss 4.236 | ppl 18.84 | bleu 21.97 | wps 5352.1 | wpb 11799.1 | bsz 428.6 | num_updates 750 | best_bleu 21.97
2021-01-16 15:59:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 15:59:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:59:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:59:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:59:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:59:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 2 @ 750 updates, score 21.97) (writing took 4.879291333258152 seconds)
2021-01-16 15:59:05 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-01-16 15:59:05 | INFO | train | epoch 002 | symm_kl 0.747 | self_kl 0 | self_cv 0 | loss 3.743 | nll_loss 0.808 | ppl 1.75 | wps 22388.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 750 | lr 1.0075e-05 | gnorm 1.426 | train_wall 234 | wall 522
2021-01-16 15:59:05 | INFO | fairseq.trainer | begin training epoch 3
2021-01-16 15:59:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 15:59:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 15:59:40 | INFO | train_inner | epoch 003:     50 / 375 symm_kl=0.732, self_kl=0, self_cv=0, loss=3.721, nll_loss=0.807, ppl=1.75, wps=17353.4, ups=1.11, wpb=15636, bsz=534, num_updates=800, lr=1.074e-05, gnorm=1.4, train_wall=62, wall=557
2021-01-16 16:00:42 | INFO | train_inner | epoch 003:    150 / 375 symm_kl=0.717, self_kl=0, self_cv=0, loss=3.701, nll_loss=0.81, ppl=1.75, wps=25053.2, ups=1.6, wpb=15704.8, bsz=556.1, num_updates=900, lr=1.207e-05, gnorm=1.363, train_wall=62, wall=620
2021-01-16 16:01:45 | INFO | train_inner | epoch 003:    250 / 375 symm_kl=0.701, self_kl=0, self_cv=0, loss=3.671, nll_loss=0.806, ppl=1.75, wps=24930.2, ups=1.58, wpb=15749.3, bsz=561.7, num_updates=1000, lr=1.34e-05, gnorm=1.329, train_wall=63, wall=683
2021-01-16 16:02:48 | INFO | train_inner | epoch 003:    350 / 375 symm_kl=0.707, self_kl=0, self_cv=0, loss=3.687, nll_loss=0.81, ppl=1.75, wps=24708.9, ups=1.59, wpb=15573.8, bsz=545.2, num_updates=1100, lr=1.473e-05, gnorm=1.355, train_wall=63, wall=746
2021-01-16 16:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:03:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:03:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:03:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:03:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:03:23 | INFO | valid | epoch 003 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.831 | nll_loss 4.202 | ppl 18.4 | bleu 22.09 | wps 5283 | wpb 11799.1 | bsz 428.6 | num_updates 1125 | best_bleu 22.09
2021-01-16 16:03:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:03:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:03:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:03:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 3 @ 1125 updates, score 22.09) (writing took 4.804648431017995 seconds)
2021-01-16 16:03:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-01-16 16:03:28 | INFO | train | epoch 003 | symm_kl 0.71 | self_kl 0 | self_cv 0 | loss 3.689 | nll_loss 0.809 | ppl 1.75 | wps 22337.1 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 1125 | lr 1.50625e-05 | gnorm 1.353 | train_wall 235 | wall 785
2021-01-16 16:03:28 | INFO | fairseq.trainer | begin training epoch 4
2021-01-16 16:03:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:03:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:04:19 | INFO | train_inner | epoch 004:     75 / 375 symm_kl=0.699, self_kl=0, self_cv=0, loss=3.676, nll_loss=0.813, ppl=1.76, wps=17304, ups=1.11, wpb=15618, bsz=550.9, num_updates=1200, lr=1.606e-05, gnorm=1.332, train_wall=62, wall=836
2021-01-16 16:05:22 | INFO | train_inner | epoch 004:    175 / 375 symm_kl=0.699, self_kl=0, self_cv=0, loss=3.682, nll_loss=0.818, ppl=1.76, wps=24752.2, ups=1.59, wpb=15541.5, bsz=519.8, num_updates=1300, lr=1.739e-05, gnorm=1.34, train_wall=63, wall=899
2021-01-16 16:06:25 | INFO | train_inner | epoch 004:    275 / 375 symm_kl=0.682, self_kl=0, self_cv=0, loss=3.647, nll_loss=0.809, ppl=1.75, wps=24660.7, ups=1.58, wpb=15580.9, bsz=558.5, num_updates=1400, lr=1.872e-05, gnorm=1.311, train_wall=63, wall=962
2021-01-16 16:07:28 | INFO | train_inner | epoch 004:    375 / 375 symm_kl=0.661, self_kl=0, self_cv=0, loss=3.605, nll_loss=0.799, ppl=1.74, wps=25048.5, ups=1.57, wpb=15914.6, bsz=581, num_updates=1500, lr=2.005e-05, gnorm=1.262, train_wall=63, wall=1026
2021-01-16 16:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:07:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:07:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:07:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:07:47 | INFO | valid | epoch 004 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.82 | nll_loss 4.19 | ppl 18.26 | bleu 22.16 | wps 5571.9 | wpb 11799.1 | bsz 428.6 | num_updates 1500 | best_bleu 22.16
2021-01-16 16:07:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:07:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:07:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:07:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 4 @ 1500 updates, score 22.16) (writing took 4.8233259581029415 seconds)
2021-01-16 16:07:51 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-01-16 16:07:51 | INFO | train | epoch 004 | symm_kl 0.684 | self_kl 0 | self_cv 0 | loss 3.65 | nll_loss 0.809 | ppl 1.75 | wps 22342.3 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 1500 | lr 2.005e-05 | gnorm 1.308 | train_wall 235 | wall 1049
2021-01-16 16:07:51 | INFO | fairseq.trainer | begin training epoch 5
2021-01-16 16:07:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:07:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:08:57 | INFO | train_inner | epoch 005:    100 / 375 symm_kl=0.67, self_kl=0, self_cv=0, loss=3.628, nll_loss=0.807, ppl=1.75, wps=17738.7, ups=1.13, wpb=15746.2, bsz=566.6, num_updates=1600, lr=2.138e-05, gnorm=1.27, train_wall=62, wall=1114
2021-01-16 16:10:00 | INFO | train_inner | epoch 005:    200 / 375 symm_kl=0.668, self_kl=0, self_cv=0, loss=3.628, nll_loss=0.812, ppl=1.76, wps=24771.3, ups=1.58, wpb=15632.9, bsz=527.8, num_updates=1700, lr=2.271e-05, gnorm=1.287, train_wall=63, wall=1177
2021-01-16 16:11:03 | INFO | train_inner | epoch 005:    300 / 375 symm_kl=0.658, self_kl=0, self_cv=0, loss=3.612, nll_loss=0.81, ppl=1.75, wps=25000.8, ups=1.59, wpb=15747.3, bsz=580.6, num_updates=1800, lr=2.404e-05, gnorm=1.259, train_wall=63, wall=1240
2021-01-16 16:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:11:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:11:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:11:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:11:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:11:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:11:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:12:08 | INFO | valid | epoch 005 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.796 | nll_loss 4.167 | ppl 17.96 | bleu 22.1 | wps 5823 | wpb 11799.1 | bsz 428.6 | num_updates 1875 | best_bleu 22.16
2021-01-16 16:12:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:12:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:12:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:12:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:12:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:12:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 5 @ 1875 updates, score 22.1) (writing took 3.0040681213140488 seconds)
2021-01-16 16:12:11 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-01-16 16:12:11 | INFO | train | epoch 005 | symm_kl 0.664 | self_kl 0 | self_cv 0 | loss 3.621 | nll_loss 0.811 | ppl 1.75 | wps 22609.9 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 1875 | lr 2.50375e-05 | gnorm 1.277 | train_wall 235 | wall 1309
2021-01-16 16:12:12 | INFO | fairseq.trainer | begin training epoch 6
2021-01-16 16:12:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:12:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:12:30 | INFO | train_inner | epoch 006:     25 / 375 symm_kl=0.658, self_kl=0, self_cv=0, loss=3.611, nll_loss=0.81, ppl=1.75, wps=17893.8, ups=1.15, wpb=15605.2, bsz=531.2, num_updates=1900, lr=2.537e-05, gnorm=1.293, train_wall=63, wall=1328
2021-01-16 16:13:33 | INFO | train_inner | epoch 006:    125 / 375 symm_kl=0.658, self_kl=0, self_cv=0, loss=3.62, nll_loss=0.819, ppl=1.76, wps=25031.9, ups=1.6, wpb=15647.2, bsz=553.5, num_updates=2000, lr=2.67e-05, gnorm=1.268, train_wall=62, wall=1390
2021-01-16 16:14:36 | INFO | train_inner | epoch 006:    225 / 375 symm_kl=0.646, self_kl=0, self_cv=0, loss=3.595, nll_loss=0.812, ppl=1.76, wps=24925.3, ups=1.58, wpb=15731.5, bsz=541.6, num_updates=2100, lr=2.803e-05, gnorm=1.249, train_wall=63, wall=1453
2021-01-16 16:15:39 | INFO | train_inner | epoch 006:    325 / 375 symm_kl=0.635, self_kl=0, self_cv=0, loss=3.575, nll_loss=0.808, ppl=1.75, wps=24873, ups=1.58, wpb=15703, bsz=577.4, num_updates=2200, lr=2.936e-05, gnorm=1.231, train_wall=63, wall=1516
2021-01-16 16:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:16:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:16:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:16:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:16:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:16:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:16:29 | INFO | valid | epoch 006 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.783 | nll_loss 4.156 | ppl 17.82 | bleu 22.26 | wps 5452.2 | wpb 11799.1 | bsz 428.6 | num_updates 2250 | best_bleu 22.26
2021-01-16 16:16:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:16:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:16:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 6 @ 2250 updates, score 22.26) (writing took 5.2976811286062 seconds)
2021-01-16 16:16:34 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-01-16 16:16:34 | INFO | train | epoch 006 | symm_kl 0.647 | self_kl 0 | self_cv 0 | loss 3.597 | nll_loss 0.813 | ppl 1.76 | wps 22372 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 2250 | lr 3.0025e-05 | gnorm 1.253 | train_wall 235 | wall 1572
2021-01-16 16:16:34 | INFO | fairseq.trainer | begin training epoch 7
2021-01-16 16:16:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:16:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:17:09 | INFO | train_inner | epoch 007:     50 / 375 symm_kl=0.639, self_kl=0, self_cv=0, loss=3.59, nll_loss=0.816, ppl=1.76, wps=17319, ups=1.11, wpb=15635.2, bsz=546.7, num_updates=2300, lr=3.069e-05, gnorm=1.246, train_wall=62, wall=1607
2021-01-16 16:18:12 | INFO | train_inner | epoch 007:    150 / 375 symm_kl=0.628, self_kl=0, self_cv=0, loss=3.562, nll_loss=0.805, ppl=1.75, wps=25015.9, ups=1.59, wpb=15771.3, bsz=562.1, num_updates=2400, lr=3.202e-05, gnorm=1.215, train_wall=63, wall=1670
2021-01-16 16:19:16 | INFO | train_inner | epoch 007:    250 / 375 symm_kl=0.639, self_kl=0, self_cv=0, loss=3.589, nll_loss=0.817, ppl=1.76, wps=24702.2, ups=1.57, wpb=15764.9, bsz=551.8, num_updates=2500, lr=3.335e-05, gnorm=1.235, train_wall=64, wall=1734
2021-01-16 16:20:19 | INFO | train_inner | epoch 007:    350 / 375 symm_kl=0.633, self_kl=0, self_cv=0, loss=3.586, nll_loss=0.826, ppl=1.77, wps=24906.8, ups=1.59, wpb=15705.3, bsz=547.1, num_updates=2600, lr=3.468e-05, gnorm=1.217, train_wall=63, wall=1797
2021-01-16 16:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:20:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:20:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:20:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:20:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:20:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:20:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:20:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:20:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:20:54 | INFO | valid | epoch 007 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.773 | nll_loss 4.146 | ppl 17.7 | bleu 22.02 | wps 5448.4 | wpb 11799.1 | bsz 428.6 | num_updates 2625 | best_bleu 22.26
2021-01-16 16:20:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:20:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:20:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:20:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 7 @ 2625 updates, score 22.02) (writing took 3.211574384942651 seconds)
2021-01-16 16:20:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-01-16 16:20:57 | INFO | train | epoch 007 | symm_kl 0.633 | self_kl 0 | self_cv 0 | loss 3.579 | nll_loss 0.816 | ppl 1.76 | wps 22399.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 2625 | lr 3.50125e-05 | gnorm 1.227 | train_wall 236 | wall 1834
2021-01-16 16:20:57 | INFO | fairseq.trainer | begin training epoch 8
2021-01-16 16:20:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:21:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:21:48 | INFO | train_inner | epoch 008:     75 / 375 symm_kl=0.624, self_kl=0, self_cv=0, loss=3.569, nll_loss=0.818, ppl=1.76, wps=17568, ups=1.13, wpb=15502.3, bsz=548.6, num_updates=2700, lr=3.601e-05, gnorm=1.228, train_wall=62, wall=1885
2021-01-16 16:22:51 | INFO | train_inner | epoch 008:    175 / 375 symm_kl=0.612, self_kl=0, self_cv=0, loss=3.538, nll_loss=0.806, ppl=1.75, wps=24614.2, ups=1.57, wpb=15630.6, bsz=572, num_updates=2800, lr=3.734e-05, gnorm=1.196, train_wall=63, wall=1948
2021-01-16 16:23:54 | INFO | train_inner | epoch 008:    275 / 375 symm_kl=0.628, self_kl=0, self_cv=0, loss=3.582, nll_loss=0.828, ppl=1.78, wps=24560.7, ups=1.58, wpb=15542.7, bsz=543.7, num_updates=2900, lr=3.867e-05, gnorm=1.226, train_wall=63, wall=2012
2021-01-16 16:24:58 | INFO | train_inner | epoch 008:    375 / 375 symm_kl=0.618, self_kl=0, self_cv=0, loss=3.562, nll_loss=0.822, ppl=1.77, wps=24939.5, ups=1.57, wpb=15880.9, bsz=544.2, num_updates=3000, lr=4e-05, gnorm=1.206, train_wall=63, wall=2075
2021-01-16 16:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:24:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:24:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:24:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:25:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:25:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:25:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:25:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:25:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:25:18 | INFO | valid | epoch 008 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.773 | nll_loss 4.144 | ppl 17.68 | bleu 22.17 | wps 5303.4 | wpb 11799.1 | bsz 428.6 | num_updates 3000 | best_bleu 22.26
2021-01-16 16:25:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:25:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:25:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:25:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:25:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:25:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 8 @ 3000 updates, score 22.17) (writing took 3.02103753015399 seconds)
2021-01-16 16:25:21 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-01-16 16:25:21 | INFO | train | epoch 008 | symm_kl 0.62 | self_kl 0 | self_cv 0 | loss 3.562 | nll_loss 0.819 | ppl 1.76 | wps 22307.6 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 3000 | lr 4e-05 | gnorm 1.21 | train_wall 236 | wall 2098
2021-01-16 16:25:21 | INFO | fairseq.trainer | begin training epoch 9
2021-01-16 16:25:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:25:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:26:27 | INFO | train_inner | epoch 009:    100 / 375 symm_kl=0.624, self_kl=0, self_cv=0, loss=3.578, nll_loss=0.828, ppl=1.78, wps=17319.9, ups=1.13, wpb=15394.3, bsz=532.6, num_updates=3100, lr=3.93496e-05, gnorm=1.219, train_wall=62, wall=2164
2021-01-16 16:27:30 | INFO | train_inner | epoch 009:    200 / 375 symm_kl=0.599, self_kl=0, self_cv=0, loss=3.522, nll_loss=0.811, ppl=1.75, wps=24944.5, ups=1.57, wpb=15845.7, bsz=569.3, num_updates=3200, lr=3.87298e-05, gnorm=1.172, train_wall=63, wall=2228
2021-01-16 16:28:34 | INFO | train_inner | epoch 009:    300 / 375 symm_kl=0.608, self_kl=0, self_cv=0, loss=3.546, nll_loss=0.822, ppl=1.77, wps=24781.5, ups=1.58, wpb=15729.1, bsz=559.5, num_updates=3300, lr=3.81385e-05, gnorm=1.191, train_wall=63, wall=2291
2021-01-16 16:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:29:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:29:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:29:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:29:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:29:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:29:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:29:40 | INFO | valid | epoch 009 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.75 | nll_loss 4.129 | ppl 17.49 | bleu 22.08 | wps 5431.8 | wpb 11799.1 | bsz 428.6 | num_updates 3375 | best_bleu 22.26
2021-01-16 16:29:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:29:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:29:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:29:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 9 @ 3375 updates, score 22.08) (writing took 3.164471235126257 seconds)
2021-01-16 16:29:43 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-01-16 16:29:43 | INFO | train | epoch 009 | symm_kl 0.61 | self_kl 0 | self_cv 0 | loss 3.548 | nll_loss 0.82 | ppl 1.77 | wps 22387.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 3375 | lr 3.77124e-05 | gnorm 1.192 | train_wall 236 | wall 2361
2021-01-16 16:29:43 | INFO | fairseq.trainer | begin training epoch 10
2021-01-16 16:29:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:29:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:30:02 | INFO | train_inner | epoch 010:     25 / 375 symm_kl=0.605, self_kl=0, self_cv=0, loss=3.543, nll_loss=0.823, ppl=1.77, wps=17786.5, ups=1.13, wpb=15735.6, bsz=553, num_updates=3400, lr=3.75735e-05, gnorm=1.178, train_wall=63, wall=2380
2021-01-16 16:31:05 | INFO | train_inner | epoch 010:    125 / 375 symm_kl=0.601, self_kl=0, self_cv=0, loss=3.533, nll_loss=0.818, ppl=1.76, wps=24920.2, ups=1.6, wpb=15530.2, bsz=546.2, num_updates=3500, lr=3.70328e-05, gnorm=1.182, train_wall=62, wall=2442
2021-01-16 16:32:08 | INFO | train_inner | epoch 010:    225 / 375 symm_kl=0.595, self_kl=0, self_cv=0, loss=3.525, nll_loss=0.819, ppl=1.76, wps=24917.7, ups=1.58, wpb=15752.5, bsz=551.3, num_updates=3600, lr=3.65148e-05, gnorm=1.174, train_wall=63, wall=2505
2021-01-16 16:33:11 | INFO | train_inner | epoch 010:    325 / 375 symm_kl=0.597, self_kl=0, self_cv=0, loss=3.529, nll_loss=0.822, ppl=1.77, wps=24946.7, ups=1.58, wpb=15821.4, bsz=563.8, num_updates=3700, lr=3.6018e-05, gnorm=1.167, train_wall=63, wall=2569
2021-01-16 16:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:33:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:33:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:33:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:33:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:33:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:33:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:33:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:33:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:33:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:33:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:34:02 | INFO | valid | epoch 010 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.734 | nll_loss 4.111 | ppl 17.28 | bleu 22.27 | wps 5488.5 | wpb 11799.1 | bsz 428.6 | num_updates 3750 | best_bleu 22.27
2021-01-16 16:34:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:34:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:34:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:34:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:34:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:34:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 10 @ 3750 updates, score 22.27) (writing took 4.992474220693111 seconds)
2021-01-16 16:34:07 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-01-16 16:34:07 | INFO | train | epoch 010 | symm_kl 0.599 | self_kl 0 | self_cv 0 | loss 3.531 | nll_loss 0.821 | ppl 1.77 | wps 22331.6 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 3750 | lr 3.57771e-05 | gnorm 1.177 | train_wall 235 | wall 2624
2021-01-16 16:34:07 | INFO | fairseq.trainer | begin training epoch 11
2021-01-16 16:34:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:34:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:34:42 | INFO | train_inner | epoch 011:     50 / 375 symm_kl=0.596, self_kl=0, self_cv=0, loss=3.526, nll_loss=0.818, ppl=1.76, wps=17492.1, ups=1.11, wpb=15784.9, bsz=546.6, num_updates=3800, lr=3.55409e-05, gnorm=1.176, train_wall=63, wall=2659
2021-01-16 16:35:45 | INFO | train_inner | epoch 011:    150 / 375 symm_kl=0.592, self_kl=0, self_cv=0, loss=3.518, nll_loss=0.818, ppl=1.76, wps=24581.9, ups=1.59, wpb=15499.9, bsz=557.6, num_updates=3900, lr=3.50823e-05, gnorm=1.171, train_wall=63, wall=2722
2021-01-16 16:36:48 | INFO | train_inner | epoch 011:    250 / 375 symm_kl=0.585, self_kl=0, self_cv=0, loss=3.509, nll_loss=0.819, ppl=1.76, wps=24937.6, ups=1.58, wpb=15762.3, bsz=571.4, num_updates=4000, lr=3.4641e-05, gnorm=1.145, train_wall=63, wall=2785
2021-01-16 16:37:52 | INFO | train_inner | epoch 011:    350 / 375 symm_kl=0.598, self_kl=0, self_cv=0, loss=3.536, nll_loss=0.828, ppl=1.77, wps=24488.7, ups=1.57, wpb=15599.2, bsz=530, num_updates=4100, lr=3.4216e-05, gnorm=1.181, train_wall=63, wall=2849
2021-01-16 16:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:38:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:38:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:38:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:38:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:38:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:38:25 | INFO | valid | epoch 011 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.74 | nll_loss 4.117 | ppl 17.35 | bleu 22.22 | wps 5547.4 | wpb 11799.1 | bsz 428.6 | num_updates 4125 | best_bleu 22.27
2021-01-16 16:38:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:38:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:38:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 11 @ 4125 updates, score 22.22) (writing took 3.2379209119826555 seconds)
2021-01-16 16:38:29 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-01-16 16:38:29 | INFO | train | epoch 011 | symm_kl 0.59 | self_kl 0 | self_cv 0 | loss 3.518 | nll_loss 0.82 | ppl 1.77 | wps 22440.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 4125 | lr 3.41121e-05 | gnorm 1.16 | train_wall 236 | wall 2886
2021-01-16 16:38:29 | INFO | fairseq.trainer | begin training epoch 12
2021-01-16 16:38:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:38:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:39:19 | INFO | train_inner | epoch 012:     75 / 375 symm_kl=0.582, self_kl=0, self_cv=0, loss=3.504, nll_loss=0.818, ppl=1.76, wps=17929.4, ups=1.14, wpb=15670.1, bsz=549.2, num_updates=4200, lr=3.38062e-05, gnorm=1.147, train_wall=62, wall=2936
2021-01-16 16:40:22 | INFO | train_inner | epoch 012:    175 / 375 symm_kl=0.577, self_kl=0, self_cv=0, loss=3.489, nll_loss=0.81, ppl=1.75, wps=25107.4, ups=1.58, wpb=15936.4, bsz=567.3, num_updates=4300, lr=3.34108e-05, gnorm=1.135, train_wall=63, wall=3000
2021-01-16 16:41:26 | INFO | train_inner | epoch 012:    275 / 375 symm_kl=0.59, self_kl=0, self_cv=0, loss=3.522, nll_loss=0.827, ppl=1.77, wps=24627.3, ups=1.58, wpb=15574.5, bsz=544.3, num_updates=4400, lr=3.30289e-05, gnorm=1.168, train_wall=63, wall=3063
2021-01-16 16:42:29 | INFO | train_inner | epoch 012:    375 / 375 symm_kl=0.579, self_kl=0, self_cv=0, loss=3.502, nll_loss=0.822, ppl=1.77, wps=24630.1, ups=1.58, wpb=15610.6, bsz=552.7, num_updates=4500, lr=3.26599e-05, gnorm=1.145, train_wall=63, wall=3126
2021-01-16 16:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:42:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:42:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:42:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:42:47 | INFO | valid | epoch 012 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.733 | nll_loss 4.108 | ppl 17.25 | bleu 22.34 | wps 5438.7 | wpb 11799.1 | bsz 428.6 | num_updates 4500 | best_bleu 22.34
2021-01-16 16:42:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:42:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:42:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:42:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 12 @ 4500 updates, score 22.34) (writing took 5.341719416901469 seconds)
2021-01-16 16:42:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-01-16 16:42:53 | INFO | train | epoch 012 | symm_kl 0.583 | self_kl 0 | self_cv 0 | loss 3.506 | nll_loss 0.819 | ppl 1.76 | wps 22282.6 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 4500 | lr 3.26599e-05 | gnorm 1.151 | train_wall 236 | wall 3150
2021-01-16 16:42:53 | INFO | fairseq.trainer | begin training epoch 13
2021-01-16 16:42:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:42:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:43:59 | INFO | train_inner | epoch 013:    100 / 375 symm_kl=0.575, self_kl=0, self_cv=0, loss=3.484, nll_loss=0.808, ppl=1.75, wps=17329.1, ups=1.11, wpb=15617.9, bsz=553.1, num_updates=4600, lr=3.23029e-05, gnorm=1.142, train_wall=63, wall=3216
2021-01-16 16:45:03 | INFO | train_inner | epoch 013:    200 / 375 symm_kl=0.574, self_kl=0, self_cv=0, loss=3.488, nll_loss=0.813, ppl=1.76, wps=24647.4, ups=1.57, wpb=15683.9, bsz=555.7, num_updates=4700, lr=3.19574e-05, gnorm=1.135, train_wall=63, wall=3280
2021-01-16 16:46:06 | INFO | train_inner | epoch 013:    300 / 375 symm_kl=0.58, self_kl=0, self_cv=0, loss=3.506, nll_loss=0.825, ppl=1.77, wps=24726.9, ups=1.58, wpb=15679.5, bsz=537.8, num_updates=4800, lr=3.16228e-05, gnorm=1.15, train_wall=63, wall=3343
2021-01-16 16:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:46:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:46:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:46:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:46:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:46:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:46:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:46:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:46:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:46:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:46:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:46:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:46:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:46:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:46:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:46:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:47:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:47:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:47:12 | INFO | valid | epoch 013 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.728 | nll_loss 4.106 | ppl 17.22 | bleu 22.29 | wps 5554.9 | wpb 11799.1 | bsz 428.6 | num_updates 4875 | best_bleu 22.34
2021-01-16 16:47:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:47:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:47:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:47:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:47:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 13 @ 4875 updates, score 22.29) (writing took 2.9977492447942495 seconds)
2021-01-16 16:47:15 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-01-16 16:47:15 | INFO | train | epoch 013 | symm_kl 0.576 | self_kl 0 | self_cv 0 | loss 3.495 | nll_loss 0.818 | ppl 1.76 | wps 22446.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 4875 | lr 3.13786e-05 | gnorm 1.14 | train_wall 236 | wall 3412
2021-01-16 16:47:15 | INFO | fairseq.trainer | begin training epoch 14
2021-01-16 16:47:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:47:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:47:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:47:34 | INFO | train_inner | epoch 014:     25 / 375 symm_kl=0.577, self_kl=0, self_cv=0, loss=3.504, nll_loss=0.828, ppl=1.77, wps=17850.7, ups=1.14, wpb=15666.9, bsz=556.4, num_updates=4900, lr=3.12984e-05, gnorm=1.131, train_wall=62, wall=3431
2021-01-16 16:48:36 | INFO | train_inner | epoch 014:    125 / 375 symm_kl=0.572, self_kl=0, self_cv=0, loss=3.487, nll_loss=0.815, ppl=1.76, wps=25121.7, ups=1.6, wpb=15699.9, bsz=552.8, num_updates=5000, lr=3.09839e-05, gnorm=1.133, train_wall=62, wall=3494
2021-01-16 16:49:40 | INFO | train_inner | epoch 014:    225 / 375 symm_kl=0.571, self_kl=0, self_cv=0, loss=3.486, nll_loss=0.818, ppl=1.76, wps=24912.6, ups=1.58, wpb=15756.4, bsz=554.3, num_updates=5100, lr=3.06786e-05, gnorm=1.128, train_wall=63, wall=3557
2021-01-16 16:50:43 | INFO | train_inner | epoch 014:    325 / 375 symm_kl=0.572, self_kl=0, self_cv=0, loss=3.489, nll_loss=0.82, ppl=1.76, wps=24994.3, ups=1.58, wpb=15798.6, bsz=557.1, num_updates=5200, lr=3.03822e-05, gnorm=1.129, train_wall=63, wall=3620
2021-01-16 16:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:51:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:51:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:51:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:51:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:51:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:51:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:51:33 | INFO | valid | epoch 014 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.727 | nll_loss 4.102 | ppl 17.17 | bleu 22.39 | wps 5467.5 | wpb 11799.1 | bsz 428.6 | num_updates 5250 | best_bleu 22.39
2021-01-16 16:51:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:51:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:51:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:51:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 14 @ 5250 updates, score 22.39) (writing took 4.994279922917485 seconds)
2021-01-16 16:51:38 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-01-16 16:51:38 | INFO | train | epoch 014 | symm_kl 0.571 | self_kl 0 | self_cv 0 | loss 3.486 | nll_loss 0.817 | ppl 1.76 | wps 22340.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 5250 | lr 3.02372e-05 | gnorm 1.13 | train_wall 235 | wall 3675
2021-01-16 16:51:38 | INFO | fairseq.trainer | begin training epoch 15
2021-01-16 16:51:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:51:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:52:12 | INFO | train_inner | epoch 015:     50 / 375 symm_kl=0.567, self_kl=0, self_cv=0, loss=3.478, nll_loss=0.814, ppl=1.76, wps=17370.4, ups=1.12, wpb=15553.8, bsz=546.2, num_updates=5300, lr=3.00942e-05, gnorm=1.126, train_wall=62, wall=3710
2021-01-16 16:53:16 | INFO | train_inner | epoch 015:    150 / 375 symm_kl=0.565, self_kl=0, self_cv=0, loss=3.476, nll_loss=0.814, ppl=1.76, wps=24774.9, ups=1.58, wpb=15665.8, bsz=560.5, num_updates=5400, lr=2.98142e-05, gnorm=1.109, train_wall=63, wall=3773
2021-01-16 16:54:19 | INFO | train_inner | epoch 015:    250 / 375 symm_kl=0.572, self_kl=0, self_cv=0, loss=3.496, nll_loss=0.826, ppl=1.77, wps=25165.4, ups=1.58, wpb=15898, bsz=550.6, num_updates=5500, lr=2.9542e-05, gnorm=1.116, train_wall=63, wall=3836
2021-01-16 16:55:22 | INFO | train_inner | epoch 015:    350 / 375 symm_kl=0.553, self_kl=0, self_cv=0, loss=3.442, nll_loss=0.799, ppl=1.74, wps=24821.6, ups=1.59, wpb=15620.8, bsz=564.3, num_updates=5600, lr=2.9277e-05, gnorm=1.122, train_wall=63, wall=3899
2021-01-16 16:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 16:55:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:55:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:55:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:55:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:55:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:55:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 16:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 16:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 16:55:56 | INFO | valid | epoch 015 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.72 | nll_loss 4.096 | ppl 17.1 | bleu 22.35 | wps 5456.6 | wpb 11799.1 | bsz 428.6 | num_updates 5625 | best_bleu 22.39
2021-01-16 16:55:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 16:55:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:55:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:55:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:55:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:55:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 15 @ 5625 updates, score 22.35) (writing took 3.072668831795454 seconds)
2021-01-16 16:55:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-01-16 16:55:59 | INFO | train | epoch 015 | symm_kl 0.565 | self_kl 0 | self_cv 0 | loss 3.476 | nll_loss 0.815 | ppl 1.76 | wps 22494.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 5625 | lr 2.92119e-05 | gnorm 1.12 | train_wall 235 | wall 3937
2021-01-16 16:55:59 | INFO | fairseq.trainer | begin training epoch 16
2021-01-16 16:56:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 16:56:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 16:56:50 | INFO | train_inner | epoch 016:     75 / 375 symm_kl=0.561, self_kl=0, self_cv=0, loss=3.466, nll_loss=0.812, ppl=1.76, wps=17770.2, ups=1.14, wpb=15632.5, bsz=541.1, num_updates=5700, lr=2.90191e-05, gnorm=1.112, train_wall=62, wall=3987
2021-01-16 16:57:53 | INFO | train_inner | epoch 016:    175 / 375 symm_kl=0.564, self_kl=0, self_cv=0, loss=3.475, nll_loss=0.816, ppl=1.76, wps=24969.2, ups=1.59, wpb=15721.1, bsz=555.2, num_updates=5800, lr=2.87678e-05, gnorm=1.116, train_wall=63, wall=4050
2021-01-16 16:58:56 | INFO | train_inner | epoch 016:    275 / 375 symm_kl=0.563, self_kl=0, self_cv=0, loss=3.473, nll_loss=0.817, ppl=1.76, wps=24868.4, ups=1.59, wpb=15658.2, bsz=549, num_updates=5900, lr=2.8523e-05, gnorm=1.125, train_wall=63, wall=4113
2021-01-16 16:59:59 | INFO | train_inner | epoch 016:    375 / 375 symm_kl=0.56, self_kl=0, self_cv=0, loss=3.469, nll_loss=0.816, ppl=1.76, wps=24691.6, ups=1.58, wpb=15593.3, bsz=561, num_updates=6000, lr=2.82843e-05, gnorm=1.127, train_wall=63, wall=4176
2021-01-16 16:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:00:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:00:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:00:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:00:17 | INFO | valid | epoch 016 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.722 | nll_loss 4.098 | ppl 17.12 | bleu 22.17 | wps 5533.8 | wpb 11799.1 | bsz 428.6 | num_updates 6000 | best_bleu 22.39
2021-01-16 17:00:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:00:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 16 @ 6000 updates, score 22.17) (writing took 3.231027476489544 seconds)
2021-01-16 17:00:20 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-01-16 17:00:20 | INFO | train | epoch 016 | symm_kl 0.561 | self_kl 0 | self_cv 0 | loss 3.469 | nll_loss 0.814 | ppl 1.76 | wps 22533.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 6000 | lr 2.82843e-05 | gnorm 1.118 | train_wall 235 | wall 4198
2021-01-16 17:00:20 | INFO | fairseq.trainer | begin training epoch 17
2021-01-16 17:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:00:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:00:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:00:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:01:26 | INFO | train_inner | epoch 017:    100 / 375 symm_kl=0.557, self_kl=0, self_cv=0, loss=3.456, nll_loss=0.806, ppl=1.75, wps=17888.8, ups=1.15, wpb=15614.1, bsz=544.5, num_updates=6100, lr=2.80515e-05, gnorm=1.109, train_wall=62, wall=4263
2021-01-16 17:02:30 | INFO | train_inner | epoch 017:    200 / 375 symm_kl=0.558, self_kl=0, self_cv=0, loss=3.464, nll_loss=0.814, ppl=1.76, wps=24334.7, ups=1.57, wpb=15457.4, bsz=562.2, num_updates=6200, lr=2.78243e-05, gnorm=1.121, train_wall=63, wall=4327
2021-01-16 17:03:33 | INFO | train_inner | epoch 017:    300 / 375 symm_kl=0.554, self_kl=0, self_cv=0, loss=3.461, nll_loss=0.817, ppl=1.76, wps=25164.1, ups=1.58, wpb=15928.9, bsz=566.7, num_updates=6300, lr=2.76026e-05, gnorm=1.089, train_wall=63, wall=4390
2021-01-16 17:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:04:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:04:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:04:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:04:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:04:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:04:40 | INFO | valid | epoch 017 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.71 | nll_loss 4.088 | ppl 17.01 | bleu 22.23 | wps 4950.2 | wpb 11799.1 | bsz 428.6 | num_updates 6375 | best_bleu 22.39
2021-01-16 17:04:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:04:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:04:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:04:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 17 @ 6375 updates, score 22.23) (writing took 3.198869127780199 seconds)
2021-01-16 17:04:43 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-01-16 17:04:43 | INFO | train | epoch 017 | symm_kl 0.557 | self_kl 0 | self_cv 0 | loss 3.461 | nll_loss 0.812 | ppl 1.76 | wps 22367.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 6375 | lr 2.74398e-05 | gnorm 1.109 | train_wall 235 | wall 4461
2021-01-16 17:04:43 | INFO | fairseq.trainer | begin training epoch 18
2021-01-16 17:04:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:04:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:05:03 | INFO | train_inner | epoch 018:     25 / 375 symm_kl=0.56, self_kl=0, self_cv=0, loss=3.47, nll_loss=0.816, ppl=1.76, wps=17548.3, ups=1.12, wpb=15723.9, bsz=525.2, num_updates=6400, lr=2.73861e-05, gnorm=1.113, train_wall=62, wall=4480
2021-01-16 17:06:06 | INFO | train_inner | epoch 018:    125 / 375 symm_kl=0.543, self_kl=0, self_cv=0, loss=3.423, nll_loss=0.794, ppl=1.73, wps=25553.1, ups=1.59, wpb=16098.1, bsz=551, num_updates=6500, lr=2.71746e-05, gnorm=1.075, train_wall=63, wall=4543
2021-01-16 17:07:09 | INFO | train_inner | epoch 018:    225 / 375 symm_kl=0.56, self_kl=0, self_cv=0, loss=3.472, nll_loss=0.82, ppl=1.76, wps=24522.2, ups=1.58, wpb=15489.2, bsz=553.8, num_updates=6600, lr=2.6968e-05, gnorm=1.103, train_wall=63, wall=4606
2021-01-16 17:08:12 | INFO | train_inner | epoch 018:    325 / 375 symm_kl=0.558, self_kl=0, self_cv=0, loss=3.47, nll_loss=0.822, ppl=1.77, wps=24554.8, ups=1.57, wpb=15594.8, bsz=571.8, num_updates=6700, lr=2.6766e-05, gnorm=1.105, train_wall=63, wall=4670
2021-01-16 17:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:08:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:08:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:08:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:08:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:08:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:08:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:08:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:08:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:08:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:09:04 | INFO | valid | epoch 018 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.707 | nll_loss 4.085 | ppl 16.97 | bleu 22.33 | wps 5071.4 | wpb 11799.1 | bsz 428.6 | num_updates 6750 | best_bleu 22.39
2021-01-16 17:09:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:09:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:09:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:09:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 18 @ 6750 updates, score 22.33) (writing took 3.0145343709737062 seconds)
2021-01-16 17:09:07 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-01-16 17:09:07 | INFO | train | epoch 018 | symm_kl 0.553 | self_kl 0 | self_cv 0 | loss 3.455 | nll_loss 0.812 | ppl 1.76 | wps 22338.1 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 6750 | lr 2.66667e-05 | gnorm 1.098 | train_wall 236 | wall 4724
2021-01-16 17:09:07 | INFO | fairseq.trainer | begin training epoch 19
2021-01-16 17:09:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:09:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:09:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:09:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:09:42 | INFO | train_inner | epoch 019:     50 / 375 symm_kl=0.554, self_kl=0, self_cv=0, loss=3.457, nll_loss=0.811, ppl=1.75, wps=17510.6, ups=1.11, wpb=15736.7, bsz=546, num_updates=6800, lr=2.65684e-05, gnorm=1.106, train_wall=63, wall=4759
2021-01-16 17:10:45 | INFO | train_inner | epoch 019:    150 / 375 symm_kl=0.555, self_kl=0, self_cv=0, loss=3.46, nll_loss=0.814, ppl=1.76, wps=24582.4, ups=1.6, wpb=15371.9, bsz=539.2, num_updates=6900, lr=2.63752e-05, gnorm=1.11, train_wall=62, wall=4822
2021-01-16 17:11:48 | INFO | train_inner | epoch 019:    250 / 375 symm_kl=0.552, self_kl=0, self_cv=0, loss=3.453, nll_loss=0.812, ppl=1.76, wps=25004.8, ups=1.58, wpb=15847.6, bsz=553.6, num_updates=7000, lr=2.61861e-05, gnorm=1.095, train_wall=63, wall=4885
2021-01-16 17:12:51 | INFO | train_inner | epoch 019:    350 / 375 symm_kl=0.54, self_kl=0, self_cv=0, loss=3.427, nll_loss=0.803, ppl=1.74, wps=24833.7, ups=1.57, wpb=15768.6, bsz=575.9, num_updates=7100, lr=2.60011e-05, gnorm=1.074, train_wall=63, wall=4949
2021-01-16 17:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:13:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:13:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:13:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:13:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:13:27 | INFO | valid | epoch 019 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.711 | nll_loss 4.089 | ppl 17.02 | bleu 22.19 | wps 5212.9 | wpb 11799.1 | bsz 428.6 | num_updates 7125 | best_bleu 22.39
2021-01-16 17:13:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:13:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:13:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:13:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 19 @ 7125 updates, score 22.19) (writing took 3.3404129706323147 seconds)
2021-01-16 17:13:30 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-01-16 17:13:30 | INFO | train | epoch 019 | symm_kl 0.55 | self_kl 0 | self_cv 0 | loss 3.449 | nll_loss 0.81 | ppl 1.75 | wps 22339.8 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 7125 | lr 2.59554e-05 | gnorm 1.095 | train_wall 236 | wall 4987
2021-01-16 17:13:30 | INFO | fairseq.trainer | begin training epoch 20
2021-01-16 17:13:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:13:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:14:20 | INFO | train_inner | epoch 020:     75 / 375 symm_kl=0.554, self_kl=0, self_cv=0, loss=3.463, nll_loss=0.817, ppl=1.76, wps=17498.2, ups=1.12, wpb=15555.8, bsz=534.3, num_updates=7200, lr=2.58199e-05, gnorm=1.105, train_wall=62, wall=5038
2021-01-16 17:15:24 | INFO | train_inner | epoch 020:    175 / 375 symm_kl=0.538, self_kl=0, self_cv=0, loss=3.418, nll_loss=0.797, ppl=1.74, wps=24987.7, ups=1.58, wpb=15834.5, bsz=573.6, num_updates=7300, lr=2.56424e-05, gnorm=1.081, train_wall=63, wall=5101
2021-01-16 17:16:27 | INFO | train_inner | epoch 020:    275 / 375 symm_kl=0.547, self_kl=0, self_cv=0, loss=3.443, nll_loss=0.81, ppl=1.75, wps=24711.8, ups=1.57, wpb=15702.9, bsz=545.9, num_updates=7400, lr=2.54686e-05, gnorm=1.093, train_wall=63, wall=5165
2021-01-16 17:17:30 | INFO | train_inner | epoch 020:    375 / 375 symm_kl=0.548, self_kl=0, self_cv=0, loss=3.45, nll_loss=0.816, ppl=1.76, wps=24614, ups=1.59, wpb=15522.2, bsz=551.3, num_updates=7500, lr=2.52982e-05, gnorm=1.095, train_wall=63, wall=5228
2021-01-16 17:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:17:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:17:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:17:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:17:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:17:50 | INFO | valid | epoch 020 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.703 | nll_loss 4.084 | ppl 16.96 | bleu 22.32 | wps 5033.1 | wpb 11799.1 | bsz 428.6 | num_updates 7500 | best_bleu 22.39
2021-01-16 17:17:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:17:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 20 @ 7500 updates, score 22.32) (writing took 2.979790398851037 seconds)
2021-01-16 17:17:53 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-01-16 17:17:53 | INFO | train | epoch 020 | symm_kl 0.547 | self_kl 0 | self_cv 0 | loss 3.444 | nll_loss 0.81 | ppl 1.75 | wps 22334.5 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 7500 | lr 2.52982e-05 | gnorm 1.092 | train_wall 236 | wall 5251
2021-01-16 17:17:53 | INFO | fairseq.trainer | begin training epoch 21
2021-01-16 17:17:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:17:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:17:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:17:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:19:00 | INFO | train_inner | epoch 021:    100 / 375 symm_kl=0.538, self_kl=0, self_cv=0, loss=3.419, nll_loss=0.798, ppl=1.74, wps=17603.6, ups=1.12, wpb=15707.6, bsz=560.9, num_updates=7600, lr=2.51312e-05, gnorm=1.082, train_wall=62, wall=5317
2021-01-16 17:20:03 | INFO | train_inner | epoch 021:    200 / 375 symm_kl=0.554, self_kl=0, self_cv=0, loss=3.463, nll_loss=0.82, ppl=1.77, wps=24677.4, ups=1.58, wpb=15612.4, bsz=538.2, num_updates=7700, lr=2.49675e-05, gnorm=1.098, train_wall=63, wall=5380
2021-01-16 17:21:06 | INFO | train_inner | epoch 021:    300 / 375 symm_kl=0.541, self_kl=0, self_cv=0, loss=3.434, nll_loss=0.808, ppl=1.75, wps=25011.2, ups=1.58, wpb=15813.3, bsz=560.9, num_updates=7800, lr=2.48069e-05, gnorm=1.08, train_wall=63, wall=5443
2021-01-16 17:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:21:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:21:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:21:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:21:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:21:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:21:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:22:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:22:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:22:12 | INFO | valid | epoch 021 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.707 | nll_loss 4.085 | ppl 16.98 | bleu 22.43 | wps 5255.6 | wpb 11799.1 | bsz 428.6 | num_updates 7875 | best_bleu 22.43
2021-01-16 17:22:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:22:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:22:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:22:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:22:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:22:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 21 @ 7875 updates, score 22.43) (writing took 5.151521237567067 seconds)
2021-01-16 17:22:18 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-01-16 17:22:18 | INFO | train | epoch 021 | symm_kl 0.544 | self_kl 0 | self_cv 0 | loss 3.439 | nll_loss 0.809 | ppl 1.75 | wps 22247.2 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 7875 | lr 2.46885e-05 | gnorm 1.088 | train_wall 235 | wall 5515
2021-01-16 17:22:18 | INFO | fairseq.trainer | begin training epoch 22
2021-01-16 17:22:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:22:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:22:37 | INFO | train_inner | epoch 022:     25 / 375 symm_kl=0.542, self_kl=0, self_cv=0, loss=3.435, nll_loss=0.809, ppl=1.75, wps=17162.8, ups=1.1, wpb=15590.9, bsz=551.6, num_updates=7900, lr=2.46494e-05, gnorm=1.088, train_wall=63, wall=5534
2021-01-16 17:23:40 | INFO | train_inner | epoch 022:    125 / 375 symm_kl=0.534, self_kl=0, self_cv=0, loss=3.415, nll_loss=0.799, ppl=1.74, wps=25033.6, ups=1.6, wpb=15679.1, bsz=570.5, num_updates=8000, lr=2.44949e-05, gnorm=1.074, train_wall=62, wall=5597
2021-01-16 17:24:43 | INFO | train_inner | epoch 022:    225 / 375 symm_kl=0.538, self_kl=0, self_cv=0, loss=3.425, nll_loss=0.802, ppl=1.74, wps=24894.1, ups=1.58, wpb=15760.1, bsz=551.8, num_updates=8100, lr=2.43432e-05, gnorm=1.07, train_wall=63, wall=5660
2021-01-16 17:25:46 | INFO | train_inner | epoch 022:    325 / 375 symm_kl=0.543, self_kl=0, self_cv=0, loss=3.44, nll_loss=0.811, ppl=1.75, wps=25161.8, ups=1.58, wpb=15971.4, bsz=544.9, num_updates=8200, lr=2.41943e-05, gnorm=1.081, train_wall=63, wall=5724
2021-01-16 17:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:26:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:26:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:26:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:26:36 | INFO | valid | epoch 022 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.705 | nll_loss 4.086 | ppl 16.98 | bleu 22.32 | wps 5459.4 | wpb 11799.1 | bsz 428.6 | num_updates 8250 | best_bleu 22.43
2021-01-16 17:26:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:26:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:26:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:26:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 22 @ 8250 updates, score 22.32) (writing took 3.06012793071568 seconds)
2021-01-16 17:26:39 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-01-16 17:26:39 | INFO | train | epoch 022 | symm_kl 0.541 | self_kl 0 | self_cv 0 | loss 3.433 | nll_loss 0.808 | ppl 1.75 | wps 22490.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 8250 | lr 2.41209e-05 | gnorm 1.085 | train_wall 235 | wall 5776
2021-01-16 17:26:39 | INFO | fairseq.trainer | begin training epoch 23
2021-01-16 17:26:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:26:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:27:14 | INFO | train_inner | epoch 023:     50 / 375 symm_kl=0.55, self_kl=0, self_cv=0, loss=3.458, nll_loss=0.82, ppl=1.77, wps=17380.5, ups=1.14, wpb=15183.3, bsz=546.1, num_updates=8300, lr=2.40481e-05, gnorm=1.123, train_wall=62, wall=5811
2021-01-16 17:28:17 | INFO | train_inner | epoch 023:    150 / 375 symm_kl=0.529, self_kl=0, self_cv=0, loss=3.404, nll_loss=0.795, ppl=1.74, wps=24991.2, ups=1.58, wpb=15799.2, bsz=551.9, num_updates=8400, lr=2.39046e-05, gnorm=1.06, train_wall=63, wall=5874
2021-01-16 17:29:20 | INFO | train_inner | epoch 023:    250 / 375 symm_kl=0.54, self_kl=0, self_cv=0, loss=3.431, nll_loss=0.806, ppl=1.75, wps=24945.1, ups=1.58, wpb=15835.4, bsz=553.1, num_updates=8500, lr=2.37635e-05, gnorm=1.073, train_wall=63, wall=5938
2021-01-16 17:30:24 | INFO | train_inner | epoch 023:    350 / 375 symm_kl=0.543, self_kl=0, self_cv=0, loss=3.444, nll_loss=0.815, ppl=1.76, wps=24798.1, ups=1.57, wpb=15747, bsz=555.4, num_updates=8600, lr=2.3625e-05, gnorm=1.089, train_wall=63, wall=6001
2021-01-16 17:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:30:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:30:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:30:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:30:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:30:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:30:58 | INFO | valid | epoch 023 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.701 | nll_loss 4.081 | ppl 16.92 | bleu 22.23 | wps 5551 | wpb 11799.1 | bsz 428.6 | num_updates 8625 | best_bleu 22.43
2021-01-16 17:30:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:30:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:30:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:31:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 23 @ 8625 updates, score 22.23) (writing took 2.771381428465247 seconds)
2021-01-16 17:31:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-01-16 17:31:01 | INFO | train | epoch 023 | symm_kl 0.539 | self_kl 0 | self_cv 0 | loss 3.429 | nll_loss 0.807 | ppl 1.75 | wps 22445 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 8625 | lr 2.35907e-05 | gnorm 1.08 | train_wall 236 | wall 6038
2021-01-16 17:31:01 | INFO | fairseq.trainer | begin training epoch 24
2021-01-16 17:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:31:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:31:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:31:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:31:52 | INFO | train_inner | epoch 024:     75 / 375 symm_kl=0.537, self_kl=0, self_cv=0, loss=3.428, nll_loss=0.808, ppl=1.75, wps=17682.8, ups=1.14, wpb=15543.4, bsz=544.7, num_updates=8700, lr=2.34888e-05, gnorm=1.085, train_wall=62, wall=6089
2021-01-16 17:32:55 | INFO | train_inner | epoch 024:    175 / 375 symm_kl=0.53, self_kl=0, self_cv=0, loss=3.405, nll_loss=0.794, ppl=1.73, wps=25109.9, ups=1.58, wpb=15937.3, bsz=554.4, num_updates=8800, lr=2.3355e-05, gnorm=1.059, train_wall=63, wall=6153
2021-01-16 17:33:59 | INFO | train_inner | epoch 024:    275 / 375 symm_kl=0.54, self_kl=0, self_cv=0, loss=3.434, nll_loss=0.809, ppl=1.75, wps=24402.3, ups=1.58, wpb=15459.4, bsz=554.3, num_updates=8900, lr=2.32234e-05, gnorm=1.091, train_wall=63, wall=6216
2021-01-16 17:35:02 | INFO | train_inner | epoch 024:    375 / 375 symm_kl=0.539, self_kl=0, self_cv=0, loss=3.438, nll_loss=0.815, ppl=1.76, wps=24707.1, ups=1.58, wpb=15606.8, bsz=556.3, num_updates=9000, lr=2.3094e-05, gnorm=1.08, train_wall=63, wall=6279
2021-01-16 17:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:35:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:35:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:35:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:35:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:35:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:35:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:35:21 | INFO | valid | epoch 024 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.698 | nll_loss 4.076 | ppl 16.87 | bleu 22.25 | wps 5344.8 | wpb 11799.1 | bsz 428.6 | num_updates 9000 | best_bleu 22.43
2021-01-16 17:35:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:35:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:35:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:35:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 24 @ 9000 updates, score 22.25) (writing took 3.062912903726101 seconds)
2021-01-16 17:35:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-01-16 17:35:24 | INFO | train | epoch 024 | symm_kl 0.536 | self_kl 0 | self_cv 0 | loss 3.424 | nll_loss 0.805 | ppl 1.75 | wps 22385.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 9000 | lr 2.3094e-05 | gnorm 1.075 | train_wall 236 | wall 6301
2021-01-16 17:35:24 | INFO | fairseq.trainer | begin training epoch 25
2021-01-16 17:35:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:35:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:36:30 | INFO | train_inner | epoch 025:    100 / 375 symm_kl=0.535, self_kl=0, self_cv=0, loss=3.418, nll_loss=0.801, ppl=1.74, wps=17471.5, ups=1.13, wpb=15396, bsz=551.4, num_updates=9100, lr=2.29668e-05, gnorm=1.093, train_wall=62, wall=6367
2021-01-16 17:37:33 | INFO | train_inner | epoch 025:    200 / 375 symm_kl=0.536, self_kl=0, self_cv=0, loss=3.425, nll_loss=0.805, ppl=1.75, wps=25175.5, ups=1.59, wpb=15876.4, bsz=549.4, num_updates=9200, lr=2.28416e-05, gnorm=1.068, train_wall=63, wall=6430
2021-01-16 17:38:36 | INFO | train_inner | epoch 025:    300 / 375 symm_kl=0.531, self_kl=0, self_cv=0, loss=3.417, nll_loss=0.807, ppl=1.75, wps=24983.1, ups=1.58, wpb=15846.8, bsz=552, num_updates=9300, lr=2.27185e-05, gnorm=1.059, train_wall=63, wall=6494
2021-01-16 17:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:39:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:39:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:39:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:39:42 | INFO | valid | epoch 025 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.699 | nll_loss 4.079 | ppl 16.9 | bleu 22.37 | wps 5433.2 | wpb 11799.1 | bsz 428.6 | num_updates 9375 | best_bleu 22.43
2021-01-16 17:39:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:39:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:39:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:39:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 25 @ 9375 updates, score 22.37) (writing took 3.0577533673495054 seconds)
2021-01-16 17:39:45 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-01-16 17:39:45 | INFO | train | epoch 025 | symm_kl 0.534 | self_kl 0 | self_cv 0 | loss 3.42 | nll_loss 0.805 | ppl 1.75 | wps 22484.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 9375 | lr 2.26274e-05 | gnorm 1.073 | train_wall 235 | wall 6563
2021-01-16 17:39:45 | INFO | fairseq.trainer | begin training epoch 26
2021-01-16 17:39:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:39:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:40:04 | INFO | train_inner | epoch 026:     25 / 375 symm_kl=0.531, self_kl=0, self_cv=0, loss=3.416, nll_loss=0.806, ppl=1.75, wps=17751.2, ups=1.14, wpb=15618.8, bsz=574.8, num_updates=9400, lr=2.25973e-05, gnorm=1.067, train_wall=62, wall=6582
2021-01-16 17:41:07 | INFO | train_inner | epoch 026:    125 / 375 symm_kl=0.53, self_kl=0, self_cv=0, loss=3.408, nll_loss=0.799, ppl=1.74, wps=25042.2, ups=1.6, wpb=15678.5, bsz=534.1, num_updates=9500, lr=2.24781e-05, gnorm=1.065, train_wall=62, wall=6644
2021-01-16 17:42:11 | INFO | train_inner | epoch 026:    225 / 375 symm_kl=0.532, self_kl=0, self_cv=0, loss=3.417, nll_loss=0.803, ppl=1.75, wps=24942.5, ups=1.57, wpb=15878, bsz=559, num_updates=9600, lr=2.23607e-05, gnorm=1.069, train_wall=63, wall=6708
2021-01-16 17:43:14 | INFO | train_inner | epoch 026:    325 / 375 symm_kl=0.531, self_kl=0, self_cv=0, loss=3.419, nll_loss=0.808, ppl=1.75, wps=24860, ups=1.59, wpb=15636, bsz=568.3, num_updates=9700, lr=2.22451e-05, gnorm=1.061, train_wall=63, wall=6771
2021-01-16 17:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:43:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:43:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:43:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:43:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:43:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:43:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:43:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:43:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:44:04 | INFO | valid | epoch 026 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.703 | nll_loss 4.081 | ppl 16.93 | bleu 22.53 | wps 5590.2 | wpb 11799.1 | bsz 428.6 | num_updates 9750 | best_bleu 22.53
2021-01-16 17:44:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:44:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:44:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:44:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:44:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:44:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 26 @ 9750 updates, score 22.53) (writing took 5.4637354873120785 seconds)
2021-01-16 17:44:09 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-01-16 17:44:09 | INFO | train | epoch 026 | symm_kl 0.531 | self_kl 0 | self_cv 0 | loss 3.416 | nll_loss 0.805 | ppl 1.75 | wps 22300.9 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 9750 | lr 2.2188e-05 | gnorm 1.068 | train_wall 235 | wall 6826
2021-01-16 17:44:09 | INFO | fairseq.trainer | begin training epoch 27
2021-01-16 17:44:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:44:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:44:44 | INFO | train_inner | epoch 027:     50 / 375 symm_kl=0.527, self_kl=0, self_cv=0, loss=3.41, nll_loss=0.805, ppl=1.75, wps=17335.3, ups=1.11, wpb=15663.8, bsz=551, num_updates=9800, lr=2.21313e-05, gnorm=1.063, train_wall=63, wall=6861
2021-01-16 17:45:47 | INFO | train_inner | epoch 027:    150 / 375 symm_kl=0.531, self_kl=0, self_cv=0, loss=3.412, nll_loss=0.8, ppl=1.74, wps=24778.5, ups=1.59, wpb=15622.7, bsz=537.6, num_updates=9900, lr=2.20193e-05, gnorm=1.077, train_wall=63, wall=6924
2021-01-16 17:46:50 | INFO | train_inner | epoch 027:    250 / 375 symm_kl=0.529, self_kl=0, self_cv=0, loss=3.409, nll_loss=0.8, ppl=1.74, wps=24989, ups=1.58, wpb=15803, bsz=560.4, num_updates=10000, lr=2.19089e-05, gnorm=1.067, train_wall=63, wall=6988
2021-01-16 17:47:53 | INFO | train_inner | epoch 027:    350 / 375 symm_kl=0.534, self_kl=0, self_cv=0, loss=3.424, nll_loss=0.809, ppl=1.75, wps=24808.6, ups=1.59, wpb=15603.9, bsz=545.9, num_updates=10100, lr=2.18002e-05, gnorm=1.078, train_wall=63, wall=7050
2021-01-16 17:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:48:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:48:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:48:27 | INFO | valid | epoch 027 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.689 | nll_loss 4.069 | ppl 16.78 | bleu 22.62 | wps 5619.9 | wpb 11799.1 | bsz 428.6 | num_updates 10125 | best_bleu 22.62
2021-01-16 17:48:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:48:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 27 @ 10125 updates, score 22.62) (writing took 5.472566954791546 seconds)
2021-01-16 17:48:32 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-01-16 17:48:32 | INFO | train | epoch 027 | symm_kl 0.53 | self_kl 0 | self_cv 0 | loss 3.413 | nll_loss 0.804 | ppl 1.75 | wps 22330.3 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 10125 | lr 2.17732e-05 | gnorm 1.071 | train_wall 235 | wall 7090
2021-01-16 17:48:32 | INFO | fairseq.trainer | begin training epoch 28
2021-01-16 17:48:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:48:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:49:23 | INFO | train_inner | epoch 028:     75 / 375 symm_kl=0.533, self_kl=0, self_cv=0, loss=3.424, nll_loss=0.81, ppl=1.75, wps=17275.2, ups=1.12, wpb=15480, bsz=541.4, num_updates=10200, lr=2.1693e-05, gnorm=1.077, train_wall=62, wall=7140
2021-01-16 17:50:26 | INFO | train_inner | epoch 028:    175 / 375 symm_kl=0.534, self_kl=0, self_cv=0, loss=3.419, nll_loss=0.801, ppl=1.74, wps=24995.7, ups=1.59, wpb=15762.4, bsz=546.4, num_updates=10300, lr=2.15875e-05, gnorm=1.076, train_wall=63, wall=7203
2021-01-16 17:51:29 | INFO | train_inner | epoch 028:    275 / 375 symm_kl=0.522, self_kl=0, self_cv=0, loss=3.396, nll_loss=0.798, ppl=1.74, wps=25075.6, ups=1.58, wpb=15838.5, bsz=565.8, num_updates=10400, lr=2.14834e-05, gnorm=1.055, train_wall=63, wall=7266
2021-01-16 17:52:32 | INFO | train_inner | epoch 028:    375 / 375 symm_kl=0.528, self_kl=0, self_cv=0, loss=3.413, nll_loss=0.808, ppl=1.75, wps=24804.4, ups=1.6, wpb=15541.8, bsz=557.3, num_updates=10500, lr=2.13809e-05, gnorm=1.069, train_wall=62, wall=7329
2021-01-16 17:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:52:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:52:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:52:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:52:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:52:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:52:50 | INFO | valid | epoch 028 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.689 | nll_loss 4.069 | ppl 16.79 | bleu 22.51 | wps 5453.5 | wpb 11799.1 | bsz 428.6 | num_updates 10500 | best_bleu 22.62
2021-01-16 17:52:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:52:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:52:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 28 @ 10500 updates, score 22.51) (writing took 3.293315179646015 seconds)
2021-01-16 17:52:53 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-01-16 17:52:53 | INFO | train | epoch 028 | symm_kl 0.529 | self_kl 0 | self_cv 0 | loss 3.41 | nll_loss 0.802 | ppl 1.74 | wps 22534.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 10500 | lr 2.13809e-05 | gnorm 1.066 | train_wall 235 | wall 7351
2021-01-16 17:52:53 | INFO | fairseq.trainer | begin training epoch 29
2021-01-16 17:52:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:52:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:53:59 | INFO | train_inner | epoch 029:    100 / 375 symm_kl=0.525, self_kl=0, self_cv=0, loss=3.404, nll_loss=0.801, ppl=1.74, wps=17910, ups=1.14, wpb=15668.8, bsz=548.2, num_updates=10600, lr=2.12798e-05, gnorm=1.052, train_wall=62, wall=7416
2021-01-16 17:55:03 | INFO | train_inner | epoch 029:    200 / 375 symm_kl=0.518, self_kl=0, self_cv=0, loss=3.388, nll_loss=0.797, ppl=1.74, wps=24982.5, ups=1.58, wpb=15843.6, bsz=573.4, num_updates=10700, lr=2.11801e-05, gnorm=1.03, train_wall=63, wall=7480
2021-01-16 17:56:06 | INFO | train_inner | epoch 029:    300 / 375 symm_kl=0.528, self_kl=0, self_cv=0, loss=3.407, nll_loss=0.799, ppl=1.74, wps=24965.5, ups=1.58, wpb=15788, bsz=541.6, num_updates=10800, lr=2.10819e-05, gnorm=1.07, train_wall=63, wall=7543
2021-01-16 17:56:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 17:56:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:56:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:56:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:56:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:56:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:56:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:56:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:56:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:56:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:56:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:56:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 17:57:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 17:57:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 17:57:10 | INFO | valid | epoch 029 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.683 | nll_loss 4.064 | ppl 16.73 | bleu 22.38 | wps 5834 | wpb 11799.1 | bsz 428.6 | num_updates 10875 | best_bleu 22.62
2021-01-16 17:57:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 17:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:57:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 29 @ 10875 updates, score 22.38) (writing took 3.230587976053357 seconds)
2021-01-16 17:57:13 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-01-16 17:57:13 | INFO | train | epoch 029 | symm_kl 0.526 | self_kl 0 | self_cv 0 | loss 3.405 | nll_loss 0.802 | ppl 1.74 | wps 22631.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 10875 | lr 2.1009e-05 | gnorm 1.066 | train_wall 235 | wall 7611
2021-01-16 17:57:13 | INFO | fairseq.trainer | begin training epoch 30
2021-01-16 17:57:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:57:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:57:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 17:57:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 17:57:33 | INFO | train_inner | epoch 030:     25 / 375 symm_kl=0.53, self_kl=0, self_cv=0, loss=3.416, nll_loss=0.806, ppl=1.75, wps=17773.8, ups=1.15, wpb=15418.2, bsz=539, num_updates=10900, lr=2.09849e-05, gnorm=1.108, train_wall=62, wall=7630
2021-01-16 17:58:35 | INFO | train_inner | epoch 030:    125 / 375 symm_kl=0.523, self_kl=0, self_cv=0, loss=3.401, nll_loss=0.802, ppl=1.74, wps=25101.8, ups=1.59, wpb=15771.9, bsz=570, num_updates=11000, lr=2.08893e-05, gnorm=1.053, train_wall=63, wall=7693
2021-01-16 17:59:38 | INFO | train_inner | epoch 030:    225 / 375 symm_kl=0.523, self_kl=0, self_cv=0, loss=3.394, nll_loss=0.794, ppl=1.73, wps=24999.5, ups=1.59, wpb=15703.7, bsz=553.6, num_updates=11100, lr=2.0795e-05, gnorm=1.054, train_wall=63, wall=7755
2021-01-16 18:00:42 | INFO | train_inner | epoch 030:    325 / 375 symm_kl=0.529, self_kl=0, self_cv=0, loss=3.416, nll_loss=0.807, ppl=1.75, wps=24593.4, ups=1.58, wpb=15589.9, bsz=543, num_updates=11200, lr=2.0702e-05, gnorm=1.06, train_wall=63, wall=7819
2021-01-16 18:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:01:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:01:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:01:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:01:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:01:32 | INFO | valid | epoch 030 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.067 | ppl 16.76 | bleu 22.42 | wps 5418.9 | wpb 11799.1 | bsz 428.6 | num_updates 11250 | best_bleu 22.62
2021-01-16 18:01:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:01:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 30 @ 11250 updates, score 22.42) (writing took 3.205585239455104 seconds)
2021-01-16 18:01:35 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-01-16 18:01:35 | INFO | train | epoch 030 | symm_kl 0.525 | self_kl 0 | self_cv 0 | loss 3.404 | nll_loss 0.801 | ppl 1.74 | wps 22495.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 11250 | lr 2.06559e-05 | gnorm 1.058 | train_wall 235 | wall 7872
2021-01-16 18:01:35 | INFO | fairseq.trainer | begin training epoch 31
2021-01-16 18:01:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:01:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:02:10 | INFO | train_inner | epoch 031:     50 / 375 symm_kl=0.524, self_kl=0, self_cv=0, loss=3.405, nll_loss=0.805, ppl=1.75, wps=17930.5, ups=1.14, wpb=15792.9, bsz=573.4, num_updates=11300, lr=2.06102e-05, gnorm=1.059, train_wall=62, wall=7907
2021-01-16 18:03:12 | INFO | train_inner | epoch 031:    150 / 375 symm_kl=0.525, self_kl=0, self_cv=0, loss=3.401, nll_loss=0.797, ppl=1.74, wps=24982.1, ups=1.6, wpb=15640.2, bsz=527.3, num_updates=11400, lr=2.05196e-05, gnorm=1.07, train_wall=62, wall=7970
2021-01-16 18:04:15 | INFO | train_inner | epoch 031:    250 / 375 symm_kl=0.526, self_kl=0, self_cv=0, loss=3.409, nll_loss=0.806, ppl=1.75, wps=24763.1, ups=1.59, wpb=15614.9, bsz=559, num_updates=11500, lr=2.04302e-05, gnorm=1.061, train_wall=63, wall=8033
2021-01-16 18:05:18 | INFO | train_inner | epoch 031:    350 / 375 symm_kl=0.524, self_kl=0, self_cv=0, loss=3.404, nll_loss=0.805, ppl=1.75, wps=24931.1, ups=1.59, wpb=15701.6, bsz=546, num_updates=11600, lr=2.03419e-05, gnorm=1.056, train_wall=63, wall=8096
2021-01-16 18:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:05:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:05:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:05:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:05:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:05:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:05:52 | INFO | valid | epoch 031 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.697 | nll_loss 4.077 | ppl 16.88 | bleu 22.37 | wps 5493.4 | wpb 11799.1 | bsz 428.6 | num_updates 11625 | best_bleu 22.62
2021-01-16 18:05:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:05:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:05:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:05:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 31 @ 11625 updates, score 22.37) (writing took 3.223192421719432 seconds)
2021-01-16 18:05:56 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-01-16 18:05:56 | INFO | train | epoch 031 | symm_kl 0.523 | self_kl 0 | self_cv 0 | loss 3.401 | nll_loss 0.801 | ppl 1.74 | wps 22545.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 11625 | lr 2.032e-05 | gnorm 1.059 | train_wall 235 | wall 8133
2021-01-16 18:05:56 | INFO | fairseq.trainer | begin training epoch 32
2021-01-16 18:05:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:05:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:06:46 | INFO | train_inner | epoch 032:     75 / 375 symm_kl=0.518, self_kl=0, self_cv=0, loss=3.388, nll_loss=0.796, ppl=1.74, wps=17800.2, ups=1.15, wpb=15529, bsz=541.3, num_updates=11700, lr=2.02548e-05, gnorm=1.055, train_wall=62, wall=8183
2021-01-16 18:07:48 | INFO | train_inner | epoch 032:    175 / 375 symm_kl=0.522, self_kl=0, self_cv=0, loss=3.401, nll_loss=0.803, ppl=1.75, wps=25189.8, ups=1.59, wpb=15812.2, bsz=567.1, num_updates=11800, lr=2.01688e-05, gnorm=1.049, train_wall=63, wall=8246
2021-01-16 18:08:52 | INFO | train_inner | epoch 032:    275 / 375 symm_kl=0.529, self_kl=0, self_cv=0, loss=3.413, nll_loss=0.804, ppl=1.75, wps=24984, ups=1.58, wpb=15828.3, bsz=527.7, num_updates=11900, lr=2.00839e-05, gnorm=1.06, train_wall=63, wall=8309
2021-01-16 18:09:55 | INFO | train_inner | epoch 032:    375 / 375 symm_kl=0.513, self_kl=0, self_cv=0, loss=3.378, nll_loss=0.793, ppl=1.73, wps=24568.6, ups=1.58, wpb=15543.5, bsz=584.2, num_updates=12000, lr=2e-05, gnorm=1.048, train_wall=63, wall=8372
2021-01-16 18:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:09:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:09:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:09:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:09:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:09:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:09:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:10:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:10:12 | INFO | valid | epoch 032 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.693 | nll_loss 4.073 | ppl 16.83 | bleu 22.38 | wps 5879.2 | wpb 11799.1 | bsz 428.6 | num_updates 12000 | best_bleu 22.62
2021-01-16 18:10:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:10:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:10:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:10:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:10:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:10:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 32 @ 12000 updates, score 22.38) (writing took 3.322629062458873 seconds)
2021-01-16 18:10:16 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-01-16 18:10:16 | INFO | train | epoch 032 | symm_kl 0.521 | self_kl 0 | self_cv 0 | loss 3.397 | nll_loss 0.8 | ppl 1.74 | wps 22606 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 12000 | lr 2e-05 | gnorm 1.054 | train_wall 235 | wall 8393
2021-01-16 18:10:16 | INFO | fairseq.trainer | begin training epoch 33
2021-01-16 18:10:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:10:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:11:22 | INFO | train_inner | epoch 033:    100 / 375 symm_kl=0.519, self_kl=0, self_cv=0, loss=3.388, nll_loss=0.792, ppl=1.73, wps=18143, ups=1.14, wpb=15881.9, bsz=546.8, num_updates=12100, lr=1.99172e-05, gnorm=1.038, train_wall=63, wall=8460
2021-01-16 18:12:26 | INFO | train_inner | epoch 033:    200 / 375 symm_kl=0.517, self_kl=0, self_cv=0, loss=3.387, nll_loss=0.795, ppl=1.74, wps=25071.2, ups=1.58, wpb=15832.4, bsz=547.2, num_updates=12200, lr=1.98354e-05, gnorm=1.041, train_wall=63, wall=8523
2021-01-16 18:13:29 | INFO | train_inner | epoch 033:    300 / 375 symm_kl=0.523, self_kl=0, self_cv=0, loss=3.404, nll_loss=0.805, ppl=1.75, wps=24542, ups=1.58, wpb=15557.9, bsz=566.9, num_updates=12300, lr=1.97546e-05, gnorm=1.068, train_wall=63, wall=8586
2021-01-16 18:14:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:14:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:14:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:14:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:14:35 | INFO | valid | epoch 033 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.681 | nll_loss 4.066 | ppl 16.75 | bleu 22.44 | wps 5345.2 | wpb 11799.1 | bsz 428.6 | num_updates 12375 | best_bleu 22.62
2021-01-16 18:14:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:14:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 33 @ 12375 updates, score 22.44) (writing took 3.199756123125553 seconds)
2021-01-16 18:14:38 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-01-16 18:14:38 | INFO | train | epoch 033 | symm_kl 0.52 | self_kl 0 | self_cv 0 | loss 3.394 | nll_loss 0.798 | ppl 1.74 | wps 22394.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 12375 | lr 1.96946e-05 | gnorm 1.052 | train_wall 236 | wall 8656
2021-01-16 18:14:38 | INFO | fairseq.trainer | begin training epoch 34
2021-01-16 18:14:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:14:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:14:57 | INFO | train_inner | epoch 034:     25 / 375 symm_kl=0.524, self_kl=0, self_cv=0, loss=3.404, nll_loss=0.805, ppl=1.75, wps=17381.3, ups=1.13, wpb=15383.5, bsz=549, num_updates=12400, lr=1.96748e-05, gnorm=1.07, train_wall=63, wall=8675
2021-01-16 18:16:01 | INFO | train_inner | epoch 034:    125 / 375 symm_kl=0.507, self_kl=0, self_cv=0, loss=3.367, nll_loss=0.791, ppl=1.73, wps=25585.6, ups=1.58, wpb=16175.7, bsz=589, num_updates=12500, lr=1.95959e-05, gnorm=1.009, train_wall=63, wall=8738
2021-01-16 18:17:04 | INFO | train_inner | epoch 034:    225 / 375 symm_kl=0.519, self_kl=0, self_cv=0, loss=3.392, nll_loss=0.797, ppl=1.74, wps=24582, ups=1.58, wpb=15550.6, bsz=544.9, num_updates=12600, lr=1.9518e-05, gnorm=1.068, train_wall=63, wall=8801
2021-01-16 18:18:07 | INFO | train_inner | epoch 034:    325 / 375 symm_kl=0.518, self_kl=0, self_cv=0, loss=3.393, nll_loss=0.801, ppl=1.74, wps=24644.1, ups=1.59, wpb=15527.7, bsz=556.4, num_updates=12700, lr=1.9441e-05, gnorm=1.055, train_wall=63, wall=8864
2021-01-16 18:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:18:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:18:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:18:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:18:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:18:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:18:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:18:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:18:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:18:57 | INFO | valid | epoch 034 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.688 | nll_loss 4.07 | ppl 16.79 | bleu 22.5 | wps 5257.8 | wpb 11799.1 | bsz 428.6 | num_updates 12750 | best_bleu 22.62
2021-01-16 18:18:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:18:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:18:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:19:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:19:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:19:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 34 @ 12750 updates, score 22.5) (writing took 3.2466190941631794 seconds)
2021-01-16 18:19:01 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-01-16 18:19:01 | INFO | train | epoch 034 | symm_kl 0.518 | self_kl 0 | self_cv 0 | loss 3.391 | nll_loss 0.799 | ppl 1.74 | wps 22418.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 12750 | lr 1.94029e-05 | gnorm 1.052 | train_wall 235 | wall 8918
2021-01-16 18:19:01 | INFO | fairseq.trainer | begin training epoch 35
2021-01-16 18:19:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:19:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:19:35 | INFO | train_inner | epoch 035:     50 / 375 symm_kl=0.525, self_kl=0, self_cv=0, loss=3.41, nll_loss=0.806, ppl=1.75, wps=17500, ups=1.13, wpb=15458.7, bsz=534.8, num_updates=12800, lr=1.93649e-05, gnorm=1.069, train_wall=62, wall=8953
2021-01-16 18:20:39 | INFO | train_inner | epoch 035:    150 / 375 symm_kl=0.516, self_kl=0, self_cv=0, loss=3.387, nll_loss=0.796, ppl=1.74, wps=25376.3, ups=1.57, wpb=16124.4, bsz=559.2, num_updates=12900, lr=1.92897e-05, gnorm=1.03, train_wall=63, wall=9016
2021-01-16 18:21:42 | INFO | train_inner | epoch 035:    250 / 375 symm_kl=0.512, self_kl=0, self_cv=0, loss=3.376, nll_loss=0.793, ppl=1.73, wps=24546.2, ups=1.59, wpb=15483.2, bsz=562, num_updates=13000, lr=1.92154e-05, gnorm=1.047, train_wall=63, wall=9079
2021-01-16 18:22:45 | INFO | train_inner | epoch 035:    350 / 375 symm_kl=0.52, self_kl=0, self_cv=0, loss=3.397, nll_loss=0.801, ppl=1.74, wps=24916.8, ups=1.58, wpb=15767.2, bsz=537.4, num_updates=13100, lr=1.91419e-05, gnorm=1.055, train_wall=63, wall=9143
2021-01-16 18:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:23:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:23:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:23:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:23:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:23:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:23:20 | INFO | valid | epoch 035 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.067 | ppl 16.77 | bleu 22.47 | wps 5228.7 | wpb 11799.1 | bsz 428.6 | num_updates 13125 | best_bleu 22.62
2021-01-16 18:23:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:23:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:23:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:23:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 35 @ 13125 updates, score 22.47) (writing took 3.2022976353764534 seconds)
2021-01-16 18:23:23 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-01-16 18:23:23 | INFO | train | epoch 035 | symm_kl 0.517 | self_kl 0 | self_cv 0 | loss 3.388 | nll_loss 0.797 | ppl 1.74 | wps 22392.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 13125 | lr 1.91237e-05 | gnorm 1.048 | train_wall 236 | wall 9181
2021-01-16 18:23:23 | INFO | fairseq.trainer | begin training epoch 36
2021-01-16 18:23:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:23:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:24:14 | INFO | train_inner | epoch 036:     75 / 375 symm_kl=0.518, self_kl=0, self_cv=0, loss=3.389, nll_loss=0.795, ppl=1.74, wps=17233.2, ups=1.13, wpb=15303.9, bsz=529.2, num_updates=13200, lr=1.90693e-05, gnorm=1.064, train_wall=62, wall=9231
2021-01-16 18:25:17 | INFO | train_inner | epoch 036:    175 / 375 symm_kl=0.512, self_kl=0, self_cv=0, loss=3.377, nll_loss=0.793, ppl=1.73, wps=24865.3, ups=1.6, wpb=15551, bsz=565.9, num_updates=13300, lr=1.89974e-05, gnorm=1.042, train_wall=62, wall=9294
2021-01-16 18:26:20 | INFO | train_inner | epoch 036:    275 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.375, nll_loss=0.792, ppl=1.73, wps=25022.6, ups=1.58, wpb=15837.9, bsz=555.3, num_updates=13400, lr=1.89264e-05, gnorm=1.036, train_wall=63, wall=9357
2021-01-16 18:27:23 | INFO | train_inner | epoch 036:    375 / 375 symm_kl=0.522, self_kl=0, self_cv=0, loss=3.405, nll_loss=0.807, ppl=1.75, wps=25138.6, ups=1.59, wpb=15810.6, bsz=550.9, num_updates=13500, lr=1.88562e-05, gnorm=1.056, train_wall=63, wall=9420
2021-01-16 18:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:27:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:27:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:27:42 | INFO | valid | epoch 036 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.691 | nll_loss 4.071 | ppl 16.81 | bleu 22.38 | wps 5161.2 | wpb 11799.1 | bsz 428.6 | num_updates 13500 | best_bleu 22.62
2021-01-16 18:27:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:27:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:27:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:27:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 36 @ 13500 updates, score 22.38) (writing took 3.156040996313095 seconds)
2021-01-16 18:27:45 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-01-16 18:27:45 | INFO | train | epoch 036 | symm_kl 0.516 | self_kl 0 | self_cv 0 | loss 3.386 | nll_loss 0.797 | ppl 1.74 | wps 22451.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 13500 | lr 1.88562e-05 | gnorm 1.047 | train_wall 235 | wall 9443
2021-01-16 18:27:45 | INFO | fairseq.trainer | begin training epoch 37
2021-01-16 18:27:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:27:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:28:52 | INFO | train_inner | epoch 037:    100 / 375 symm_kl=0.514, self_kl=0, self_cv=0, loss=3.386, nll_loss=0.798, ppl=1.74, wps=17596.6, ups=1.12, wpb=15776.6, bsz=572, num_updates=13600, lr=1.87867e-05, gnorm=1.038, train_wall=63, wall=9510
2021-01-16 18:29:56 | INFO | train_inner | epoch 037:    200 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.376, nll_loss=0.794, ppl=1.73, wps=24937.2, ups=1.58, wpb=15766.2, bsz=545.2, num_updates=13700, lr=1.8718e-05, gnorm=1.037, train_wall=63, wall=9573
2021-01-16 18:30:59 | INFO | train_inner | epoch 037:    300 / 375 symm_kl=0.517, self_kl=0, self_cv=0, loss=3.389, nll_loss=0.797, ppl=1.74, wps=24572, ups=1.58, wpb=15579.3, bsz=556.1, num_updates=13800, lr=1.86501e-05, gnorm=1.053, train_wall=63, wall=9636
2021-01-16 18:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:31:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:31:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:31:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:31:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:31:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:31:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:31:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:31:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:31:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:32:04 | INFO | valid | epoch 037 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.067 | ppl 16.76 | bleu 22.42 | wps 5571.8 | wpb 11799.1 | bsz 428.6 | num_updates 13875 | best_bleu 22.62
2021-01-16 18:32:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:32:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:32:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:32:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:32:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:32:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 37 @ 13875 updates, score 22.42) (writing took 3.3518070727586746 seconds)
2021-01-16 18:32:08 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-01-16 18:32:08 | INFO | train | epoch 037 | symm_kl 0.515 | self_kl 0 | self_cv 0 | loss 3.384 | nll_loss 0.797 | ppl 1.74 | wps 22408.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 13875 | lr 1.85996e-05 | gnorm 1.052 | train_wall 236 | wall 9705
2021-01-16 18:32:08 | INFO | fairseq.trainer | begin training epoch 38
2021-01-16 18:32:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:32:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:32:27 | INFO | train_inner | epoch 038:     25 / 375 symm_kl=0.514, self_kl=0, self_cv=0, loss=3.383, nll_loss=0.797, ppl=1.74, wps=17704.1, ups=1.14, wpb=15562.8, bsz=540.9, num_updates=13900, lr=1.85829e-05, gnorm=1.076, train_wall=62, wall=9724
2021-01-16 18:33:29 | INFO | train_inner | epoch 038:    125 / 375 symm_kl=0.516, self_kl=0, self_cv=0, loss=3.388, nll_loss=0.797, ppl=1.74, wps=25256.3, ups=1.61, wpb=15683, bsz=562, num_updates=14000, lr=1.85164e-05, gnorm=1.041, train_wall=62, wall=9786
2021-01-16 18:34:33 | INFO | train_inner | epoch 038:    225 / 375 symm_kl=0.515, self_kl=0, self_cv=0, loss=3.386, nll_loss=0.798, ppl=1.74, wps=24822.8, ups=1.58, wpb=15759.1, bsz=553.9, num_updates=14100, lr=1.84506e-05, gnorm=1.05, train_wall=63, wall=9850
2021-01-16 18:35:36 | INFO | train_inner | epoch 038:    325 / 375 symm_kl=0.512, self_kl=0, self_cv=0, loss=3.384, nll_loss=0.8, ppl=1.74, wps=24991.6, ups=1.58, wpb=15786.3, bsz=555.2, num_updates=14200, lr=1.83855e-05, gnorm=1.031, train_wall=63, wall=9913
2021-01-16 18:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:36:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:36:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:36:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:36:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:36:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:36:25 | INFO | valid | epoch 038 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.068 | ppl 16.78 | bleu 22.47 | wps 5616.9 | wpb 11799.1 | bsz 428.6 | num_updates 14250 | best_bleu 22.62
2021-01-16 18:36:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:36:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:36:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:36:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 38 @ 14250 updates, score 22.47) (writing took 3.2037718389183283 seconds)
2021-01-16 18:36:29 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-01-16 18:36:29 | INFO | train | epoch 038 | symm_kl 0.514 | self_kl 0 | self_cv 0 | loss 3.382 | nll_loss 0.797 | ppl 1.74 | wps 22551.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 14250 | lr 1.83533e-05 | gnorm 1.042 | train_wall 235 | wall 9966
2021-01-16 18:36:29 | INFO | fairseq.trainer | begin training epoch 39
2021-01-16 18:36:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:36:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:37:03 | INFO | train_inner | epoch 039:     50 / 375 symm_kl=0.512, self_kl=0, self_cv=0, loss=3.38, nll_loss=0.797, ppl=1.74, wps=17845.4, ups=1.15, wpb=15568.7, bsz=551.8, num_updates=14300, lr=1.83211e-05, gnorm=1.038, train_wall=62, wall=10000
2021-01-16 18:38:06 | INFO | train_inner | epoch 039:    150 / 375 symm_kl=0.509, self_kl=0, self_cv=0, loss=3.371, nll_loss=0.792, ppl=1.73, wps=25079.1, ups=1.59, wpb=15777.1, bsz=563, num_updates=14400, lr=1.82574e-05, gnorm=1.033, train_wall=63, wall=10063
2021-01-16 18:39:09 | INFO | train_inner | epoch 039:    250 / 375 symm_kl=0.509, self_kl=0, self_cv=0, loss=3.371, nll_loss=0.792, ppl=1.73, wps=24544.2, ups=1.57, wpb=15613.7, bsz=555, num_updates=14500, lr=1.81944e-05, gnorm=1.032, train_wall=63, wall=10127
2021-01-16 18:40:13 | INFO | train_inner | epoch 039:    350 / 375 symm_kl=0.517, self_kl=0, self_cv=0, loss=3.391, nll_loss=0.798, ppl=1.74, wps=24762.5, ups=1.58, wpb=15703.3, bsz=527.1, num_updates=14600, lr=1.81319e-05, gnorm=1.054, train_wall=63, wall=10190
2021-01-16 18:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:40:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:40:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:40:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:40:48 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.064 | ppl 16.73 | bleu 22.41 | wps 5280.8 | wpb 11799.1 | bsz 428.6 | num_updates 14625 | best_bleu 22.62
2021-01-16 18:40:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:40:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:40:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:40:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 39 @ 14625 updates, score 22.41) (writing took 3.3588706851005554 seconds)
2021-01-16 18:40:51 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-01-16 18:40:51 | INFO | train | epoch 039 | symm_kl 0.512 | self_kl 0 | self_cv 0 | loss 3.379 | nll_loss 0.796 | ppl 1.74 | wps 22371.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 14625 | lr 1.81164e-05 | gnorm 1.039 | train_wall 236 | wall 10229
2021-01-16 18:40:51 | INFO | fairseq.trainer | begin training epoch 40
2021-01-16 18:40:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:41:42 | INFO | train_inner | epoch 040:     75 / 375 symm_kl=0.514, self_kl=0, self_cv=0, loss=3.382, nll_loss=0.795, ppl=1.74, wps=17475.7, ups=1.12, wpb=15544.2, bsz=536.6, num_updates=14700, lr=1.80702e-05, gnorm=1.061, train_wall=63, wall=10279
2021-01-16 18:42:45 | INFO | train_inner | epoch 040:    175 / 375 symm_kl=0.52, self_kl=0, self_cv=0, loss=3.398, nll_loss=0.801, ppl=1.74, wps=24938.7, ups=1.59, wpb=15702.8, bsz=535.3, num_updates=14800, lr=1.8009e-05, gnorm=1.055, train_wall=63, wall=10342
2021-01-16 18:43:48 | INFO | train_inner | epoch 040:    275 / 375 symm_kl=0.504, self_kl=0, self_cv=0, loss=3.361, nll_loss=0.791, ppl=1.73, wps=24963.4, ups=1.58, wpb=15836.4, bsz=576.5, num_updates=14900, lr=1.79485e-05, gnorm=1.026, train_wall=63, wall=10406
2021-01-16 18:44:52 | INFO | train_inner | epoch 040:    375 / 375 symm_kl=0.505, self_kl=0, self_cv=0, loss=3.364, nll_loss=0.792, ppl=1.73, wps=24544.1, ups=1.57, wpb=15587.1, bsz=564.3, num_updates=15000, lr=1.78885e-05, gnorm=1.031, train_wall=63, wall=10469
2021-01-16 18:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:45:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:45:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:45:10 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.685 | nll_loss 4.067 | ppl 16.76 | bleu 22.44 | wps 5404.9 | wpb 11799.1 | bsz 428.6 | num_updates 15000 | best_bleu 22.62
2021-01-16 18:45:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:45:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:45:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:45:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:45:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:45:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 40 @ 15000 updates, score 22.44) (writing took 3.066771447658539 seconds)
2021-01-16 18:45:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-01-16 18:45:13 | INFO | train | epoch 040 | symm_kl 0.511 | self_kl 0 | self_cv 0 | loss 3.377 | nll_loss 0.795 | ppl 1.73 | wps 22448.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 15000 | lr 1.78885e-05 | gnorm 1.042 | train_wall 236 | wall 10491
2021-01-16 18:45:13 | INFO | fairseq.trainer | begin training epoch 41
2021-01-16 18:45:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:45:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:46:19 | INFO | train_inner | epoch 041:    100 / 375 symm_kl=0.512, self_kl=0, self_cv=0, loss=3.384, nll_loss=0.801, ppl=1.74, wps=17956.6, ups=1.14, wpb=15749.9, bsz=563, num_updates=15100, lr=1.78292e-05, gnorm=1.033, train_wall=62, wall=10557
2021-01-16 18:47:23 | INFO | train_inner | epoch 041:    200 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.364, nll_loss=0.789, ppl=1.73, wps=24632.2, ups=1.58, wpb=15572.6, bsz=565.2, num_updates=15200, lr=1.77705e-05, gnorm=1.039, train_wall=63, wall=10620
2021-01-16 18:48:26 | INFO | train_inner | epoch 041:    300 / 375 symm_kl=0.51, self_kl=0, self_cv=0, loss=3.372, nll_loss=0.792, ppl=1.73, wps=24878.8, ups=1.59, wpb=15651.1, bsz=540.4, num_updates=15300, lr=1.77123e-05, gnorm=1.05, train_wall=63, wall=10683
2021-01-16 18:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:49:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:49:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:49:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:49:33 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.065 | ppl 16.74 | bleu 22.33 | wps 4733.9 | wpb 11799.1 | bsz 428.6 | num_updates 15375 | best_bleu 22.62
2021-01-16 18:49:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:49:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 41 @ 15375 updates, score 22.33) (writing took 3.874957147985697 seconds)
2021-01-16 18:49:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-01-16 18:49:37 | INFO | train | epoch 041 | symm_kl 0.51 | self_kl 0 | self_cv 0 | loss 3.375 | nll_loss 0.794 | ppl 1.73 | wps 22286.9 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 15375 | lr 1.7669e-05 | gnorm 1.041 | train_wall 235 | wall 10755
2021-01-16 18:49:37 | INFO | fairseq.trainer | begin training epoch 42
2021-01-16 18:49:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:49:57 | INFO | train_inner | epoch 042:     25 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.378, nll_loss=0.795, ppl=1.74, wps=17444.3, ups=1.1, wpb=15878.7, bsz=543.9, num_updates=15400, lr=1.76547e-05, gnorm=1.032, train_wall=63, wall=10774
2021-01-16 18:51:00 | INFO | train_inner | epoch 042:    125 / 375 symm_kl=0.508, self_kl=0, self_cv=0, loss=3.367, nll_loss=0.788, ppl=1.73, wps=24903.8, ups=1.58, wpb=15761.9, bsz=539, num_updates=15500, lr=1.75977e-05, gnorm=1.029, train_wall=63, wall=10837
2021-01-16 18:52:03 | INFO | train_inner | epoch 042:    225 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.379, nll_loss=0.798, ppl=1.74, wps=24762.9, ups=1.58, wpb=15709.8, bsz=546, num_updates=15600, lr=1.75412e-05, gnorm=1.044, train_wall=63, wall=10901
2021-01-16 18:53:07 | INFO | train_inner | epoch 042:    325 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.368, nll_loss=0.794, ppl=1.73, wps=24571.7, ups=1.57, wpb=15622.7, bsz=575.1, num_updates=15700, lr=1.74852e-05, gnorm=1.033, train_wall=63, wall=10964
2021-01-16 18:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:53:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:53:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:53:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:53:58 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.683 | nll_loss 4.065 | ppl 16.74 | bleu 22.44 | wps 5292.3 | wpb 11799.1 | bsz 428.6 | num_updates 15750 | best_bleu 22.62
2021-01-16 18:53:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:53:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:53:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:54:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:54:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:54:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 42 @ 15750 updates, score 22.44) (writing took 3.0849360059946775 seconds)
2021-01-16 18:54:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-01-16 18:54:01 | INFO | train | epoch 042 | symm_kl 0.509 | self_kl 0 | self_cv 0 | loss 3.373 | nll_loss 0.794 | ppl 1.73 | wps 22267 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 15750 | lr 1.74574e-05 | gnorm 1.037 | train_wall 237 | wall 11019
2021-01-16 18:54:01 | INFO | fairseq.trainer | begin training epoch 43
2021-01-16 18:54:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:54:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:54:37 | INFO | train_inner | epoch 043:     50 / 375 symm_kl=0.504, self_kl=0, self_cv=0, loss=3.36, nll_loss=0.788, ppl=1.73, wps=17208, ups=1.11, wpb=15461.1, bsz=560.6, num_updates=15800, lr=1.74298e-05, gnorm=1.041, train_wall=63, wall=11054
2021-01-16 18:55:40 | INFO | train_inner | epoch 043:    150 / 375 symm_kl=0.509, self_kl=0, self_cv=0, loss=3.371, nll_loss=0.789, ppl=1.73, wps=25031.2, ups=1.58, wpb=15868.6, bsz=538.3, num_updates=15900, lr=1.73749e-05, gnorm=1.039, train_wall=63, wall=11117
2021-01-16 18:56:44 | INFO | train_inner | epoch 043:    250 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.381, nll_loss=0.798, ppl=1.74, wps=24287.4, ups=1.57, wpb=15443.6, bsz=558.9, num_updates=16000, lr=1.73205e-05, gnorm=1.051, train_wall=63, wall=11181
2021-01-16 18:57:47 | INFO | train_inner | epoch 043:    350 / 375 symm_kl=0.51, self_kl=0, self_cv=0, loss=3.383, nll_loss=0.803, ppl=1.74, wps=24886.9, ups=1.57, wpb=15842.6, bsz=544.9, num_updates=16100, lr=1.72666e-05, gnorm=1.028, train_wall=63, wall=11245
2021-01-16 18:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 18:58:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:58:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:58:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:58:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 18:58:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 18:58:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 18:58:21 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.686 | nll_loss 4.067 | ppl 16.76 | bleu 22.44 | wps 5779.8 | wpb 11799.1 | bsz 428.6 | num_updates 16125 | best_bleu 22.62
2021-01-16 18:58:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 18:58:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:58:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:58:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 43 @ 16125 updates, score 22.44) (writing took 3.0444331597536802 seconds)
2021-01-16 18:58:25 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-01-16 18:58:25 | INFO | train | epoch 043 | symm_kl 0.508 | self_kl 0 | self_cv 0 | loss 3.371 | nll_loss 0.793 | ppl 1.73 | wps 22353.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 16125 | lr 1.72532e-05 | gnorm 1.039 | train_wall 237 | wall 11282
2021-01-16 18:58:25 | INFO | fairseq.trainer | begin training epoch 44
2021-01-16 18:58:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 18:58:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 18:59:15 | INFO | train_inner | epoch 044:     75 / 375 symm_kl=0.507, self_kl=0, self_cv=0, loss=3.366, nll_loss=0.788, ppl=1.73, wps=17675.7, ups=1.14, wpb=15515.3, bsz=547.3, num_updates=16200, lr=1.72133e-05, gnorm=1.05, train_wall=63, wall=11333
2021-01-16 19:00:19 | INFO | train_inner | epoch 044:    175 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.353, nll_loss=0.784, ppl=1.72, wps=24778.2, ups=1.57, wpb=15776, bsz=577.4, num_updates=16300, lr=1.71604e-05, gnorm=1.022, train_wall=63, wall=11396
2021-01-16 19:01:22 | INFO | train_inner | epoch 044:    275 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.373, nll_loss=0.8, ppl=1.74, wps=24886.5, ups=1.58, wpb=15750.8, bsz=566.6, num_updates=16400, lr=1.7108e-05, gnorm=1.024, train_wall=63, wall=11459
2021-01-16 19:02:25 | INFO | train_inner | epoch 044:    375 / 375 symm_kl=0.513, self_kl=0, self_cv=0, loss=3.381, nll_loss=0.796, ppl=1.74, wps=24734.7, ups=1.58, wpb=15641.8, bsz=528.1, num_updates=16500, lr=1.70561e-05, gnorm=1.061, train_wall=63, wall=11523
2021-01-16 19:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:02:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:02:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:02:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:02:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:02:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:02:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:02:45 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.07 | ppl 16.8 | bleu 22.46 | wps 5049.8 | wpb 11799.1 | bsz 428.6 | num_updates 16500 | best_bleu 22.62
2021-01-16 19:02:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:02:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 44 @ 16500 updates, score 22.46) (writing took 3.0961684603244066 seconds)
2021-01-16 19:02:48 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-01-16 19:02:48 | INFO | train | epoch 044 | symm_kl 0.507 | self_kl 0 | self_cv 0 | loss 3.37 | nll_loss 0.793 | ppl 1.73 | wps 22305.5 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 16500 | lr 1.70561e-05 | gnorm 1.037 | train_wall 236 | wall 11546
2021-01-16 19:02:48 | INFO | fairseq.trainer | begin training epoch 45
2021-01-16 19:02:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:02:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:02:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:02:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:03:55 | INFO | train_inner | epoch 045:    100 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.359, nll_loss=0.79, ppl=1.73, wps=17537, ups=1.12, wpb=15704.9, bsz=577.5, num_updates=16600, lr=1.70046e-05, gnorm=1.018, train_wall=63, wall=11612
2021-01-16 19:04:58 | INFO | train_inner | epoch 045:    200 / 375 symm_kl=0.505, self_kl=0, self_cv=0, loss=3.37, nll_loss=0.796, ppl=1.74, wps=24895.4, ups=1.59, wpb=15609.7, bsz=557.6, num_updates=16700, lr=1.69536e-05, gnorm=1.036, train_wall=62, wall=11675
2021-01-16 19:06:01 | INFO | train_inner | epoch 045:    300 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.381, nll_loss=0.798, ppl=1.74, wps=24718.5, ups=1.57, wpb=15708.3, bsz=540.3, num_updates=16800, lr=1.69031e-05, gnorm=1.037, train_wall=63, wall=11739
2021-01-16 19:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:06:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:06:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:06:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:06:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:06:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:06:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:06:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:06:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:06:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:06:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:07:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:07:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:07:08 | INFO | valid | epoch 045 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.684 | nll_loss 4.067 | ppl 16.76 | bleu 22.33 | wps 5023.2 | wpb 11799.1 | bsz 428.6 | num_updates 16875 | best_bleu 22.62
2021-01-16 19:07:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:07:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:07:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:07:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:07:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:07:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 45 @ 16875 updates, score 22.33) (writing took 3.1690331865102053 seconds)
2021-01-16 19:07:11 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-01-16 19:07:11 | INFO | train | epoch 045 | symm_kl 0.505 | self_kl 0 | self_cv 0 | loss 3.366 | nll_loss 0.793 | ppl 1.73 | wps 22338 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 16875 | lr 1.68655e-05 | gnorm 1.03 | train_wall 236 | wall 11809
2021-01-16 19:07:11 | INFO | fairseq.trainer | begin training epoch 46
2021-01-16 19:07:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:07:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:07:31 | INFO | train_inner | epoch 046:     25 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.365, nll_loss=0.79, ppl=1.73, wps=17405.6, ups=1.11, wpb=15618.6, bsz=525.8, num_updates=16900, lr=1.6853e-05, gnorm=1.04, train_wall=63, wall=11828
2021-01-16 19:08:34 | INFO | train_inner | epoch 046:    125 / 375 symm_kl=0.505, self_kl=0, self_cv=0, loss=3.361, nll_loss=0.786, ppl=1.72, wps=24845, ups=1.59, wpb=15602.4, bsz=544.1, num_updates=17000, lr=1.68034e-05, gnorm=1.037, train_wall=63, wall=11891
2021-01-16 19:09:37 | INFO | train_inner | epoch 046:    225 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.368, nll_loss=0.794, ppl=1.73, wps=24723.6, ups=1.58, wpb=15683.9, bsz=558, num_updates=17100, lr=1.67542e-05, gnorm=1.037, train_wall=63, wall=11954
2021-01-16 19:10:40 | INFO | train_inner | epoch 046:    325 / 375 symm_kl=0.5, self_kl=0, self_cv=0, loss=3.357, nll_loss=0.792, ppl=1.73, wps=24894.4, ups=1.59, wpb=15696.9, bsz=569.4, num_updates=17200, lr=1.67054e-05, gnorm=1.018, train_wall=63, wall=12018
2021-01-16 19:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:11:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:11:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:11:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:11:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:11:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:11:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:11:31 | INFO | valid | epoch 046 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.684 | nll_loss 4.069 | ppl 16.78 | bleu 22.21 | wps 5272 | wpb 11799.1 | bsz 428.6 | num_updates 17250 | best_bleu 22.62
2021-01-16 19:11:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:11:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:11:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:11:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 46 @ 17250 updates, score 22.21) (writing took 3.2187995687127113 seconds)
2021-01-16 19:11:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-01-16 19:11:35 | INFO | train | epoch 046 | symm_kl 0.505 | self_kl 0 | self_cv 0 | loss 3.365 | nll_loss 0.792 | ppl 1.73 | wps 22358.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 17250 | lr 1.66812e-05 | gnorm 1.033 | train_wall 236 | wall 12072
2021-01-16 19:11:35 | INFO | fairseq.trainer | begin training epoch 47
2021-01-16 19:11:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:11:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:12:10 | INFO | train_inner | epoch 047:     50 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.356, nll_loss=0.786, ppl=1.72, wps=17595.7, ups=1.12, wpb=15775.5, bsz=544.8, num_updates=17300, lr=1.6657e-05, gnorm=1.032, train_wall=63, wall=12107
2021-01-16 19:13:13 | INFO | train_inner | epoch 047:    150 / 375 symm_kl=0.504, self_kl=0, self_cv=0, loss=3.367, nll_loss=0.795, ppl=1.74, wps=25036.3, ups=1.59, wpb=15720.9, bsz=563.9, num_updates=17400, lr=1.66091e-05, gnorm=1.025, train_wall=63, wall=12170
2021-01-16 19:14:16 | INFO | train_inner | epoch 047:    250 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.355, nll_loss=0.785, ppl=1.72, wps=24872.7, ups=1.58, wpb=15714.1, bsz=561, num_updates=17500, lr=1.65616e-05, gnorm=1.04, train_wall=63, wall=12233
2021-01-16 19:15:19 | INFO | train_inner | epoch 047:    350 / 375 symm_kl=0.505, self_kl=0, self_cv=0, loss=3.368, nll_loss=0.795, ppl=1.73, wps=24748, ups=1.57, wpb=15724.4, bsz=538.3, num_updates=17600, lr=1.65145e-05, gnorm=1.032, train_wall=63, wall=12297
2021-01-16 19:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:15:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:15:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:15:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:15:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:15:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:15:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:15:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:15:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:15:54 | INFO | valid | epoch 047 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.061 | ppl 16.69 | bleu 22.38 | wps 5341.8 | wpb 11799.1 | bsz 428.6 | num_updates 17625 | best_bleu 22.62
2021-01-16 19:15:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:15:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:15:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:15:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 47 @ 17625 updates, score 22.38) (writing took 3.042334023863077 seconds)
2021-01-16 19:15:57 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-01-16 19:15:57 | INFO | train | epoch 047 | symm_kl 0.504 | self_kl 0 | self_cv 0 | loss 3.363 | nll_loss 0.791 | ppl 1.73 | wps 22372.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 17625 | lr 1.65027e-05 | gnorm 1.034 | train_wall 236 | wall 12335
2021-01-16 19:15:57 | INFO | fairseq.trainer | begin training epoch 48
2021-01-16 19:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:15:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:16:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:16:48 | INFO | train_inner | epoch 048:     75 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.78, ppl=1.72, wps=17852.3, ups=1.12, wpb=15874.1, bsz=572.2, num_updates=17700, lr=1.64677e-05, gnorm=1.015, train_wall=63, wall=12386
2021-01-16 19:17:51 | INFO | train_inner | epoch 048:    175 / 375 symm_kl=0.511, self_kl=0, self_cv=0, loss=3.382, nll_loss=0.798, ppl=1.74, wps=24691.7, ups=1.59, wpb=15525.3, bsz=523, num_updates=17800, lr=1.64214e-05, gnorm=1.057, train_wall=63, wall=12449
2021-01-16 19:18:54 | INFO | train_inner | epoch 048:    275 / 375 symm_kl=0.504, self_kl=0, self_cv=0, loss=3.361, nll_loss=0.788, ppl=1.73, wps=24811.6, ups=1.58, wpb=15703.3, bsz=542.9, num_updates=17900, lr=1.63755e-05, gnorm=1.041, train_wall=63, wall=12512
2021-01-16 19:19:58 | INFO | train_inner | epoch 048:    375 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.368, nll_loss=0.8, ppl=1.74, wps=24497.6, ups=1.57, wpb=15584.4, bsz=576.2, num_updates=18000, lr=1.63299e-05, gnorm=1.036, train_wall=63, wall=12575
2021-01-16 19:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:19:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:19:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:19:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:20:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:20:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:20:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:20:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:20:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:20:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:20:17 | INFO | valid | epoch 048 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.063 | ppl 16.72 | bleu 22.34 | wps 5329.4 | wpb 11799.1 | bsz 428.6 | num_updates 18000 | best_bleu 22.62
2021-01-16 19:20:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:20:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:20:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:20:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 48 @ 18000 updates, score 22.34) (writing took 3.007703945040703 seconds)
2021-01-16 19:20:20 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-01-16 19:20:20 | INFO | train | epoch 048 | symm_kl 0.502 | self_kl 0 | self_cv 0 | loss 3.36 | nll_loss 0.791 | ppl 1.73 | wps 22397.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 18000 | lr 1.63299e-05 | gnorm 1.037 | train_wall 236 | wall 12597
2021-01-16 19:20:20 | INFO | fairseq.trainer | begin training epoch 49
2021-01-16 19:20:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:20:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:21:26 | INFO | train_inner | epoch 049:    100 / 375 symm_kl=0.509, self_kl=0, self_cv=0, loss=3.376, nll_loss=0.796, ppl=1.74, wps=17409.3, ups=1.13, wpb=15367.5, bsz=537.1, num_updates=18100, lr=1.62848e-05, gnorm=1.051, train_wall=62, wall=12664
2021-01-16 19:22:30 | INFO | train_inner | epoch 049:    200 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.342, nll_loss=0.784, ppl=1.72, wps=24779.5, ups=1.57, wpb=15830.5, bsz=563, num_updates=18200, lr=1.624e-05, gnorm=1.009, train_wall=64, wall=12728
2021-01-16 19:23:33 | INFO | train_inner | epoch 049:    300 / 375 symm_kl=0.503, self_kl=0, self_cv=0, loss=3.363, nll_loss=0.79, ppl=1.73, wps=24963.6, ups=1.59, wpb=15685.6, bsz=553, num_updates=18300, lr=1.61955e-05, gnorm=1.028, train_wall=63, wall=12790
2021-01-16 19:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:24:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:24:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:24:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:24:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:24:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:24:40 | INFO | valid | epoch 049 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.065 | ppl 16.73 | bleu 22.32 | wps 5257.6 | wpb 11799.1 | bsz 428.6 | num_updates 18375 | best_bleu 22.62
2021-01-16 19:24:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:24:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:24:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 49 @ 18375 updates, score 22.32) (writing took 2.9961000457406044 seconds)
2021-01-16 19:24:43 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-01-16 19:24:43 | INFO | train | epoch 049 | symm_kl 0.502 | self_kl 0 | self_cv 0 | loss 3.359 | nll_loss 0.79 | ppl 1.73 | wps 22390.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 18375 | lr 1.61624e-05 | gnorm 1.03 | train_wall 236 | wall 12860
2021-01-16 19:24:43 | INFO | fairseq.trainer | begin training epoch 50
2021-01-16 19:24:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:24:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:24:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:25:02 | INFO | train_inner | epoch 050:     25 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.358, nll_loss=0.79, ppl=1.73, wps=17764.3, ups=1.13, wpb=15739.6, bsz=559.8, num_updates=18400, lr=1.61515e-05, gnorm=1.039, train_wall=63, wall=12879
2021-01-16 19:26:04 | INFO | train_inner | epoch 050:    125 / 375 symm_kl=0.505, self_kl=0, self_cv=0, loss=3.37, nll_loss=0.797, ppl=1.74, wps=25312.3, ups=1.6, wpb=15796.1, bsz=553.5, num_updates=18500, lr=1.61077e-05, gnorm=1.027, train_wall=62, wall=12941
2021-01-16 19:27:08 | INFO | train_inner | epoch 050:    225 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.34, nll_loss=0.781, ppl=1.72, wps=24873.7, ups=1.57, wpb=15817.1, bsz=550.5, num_updates=18600, lr=1.60644e-05, gnorm=1.014, train_wall=63, wall=13005
2021-01-16 19:28:11 | INFO | train_inner | epoch 050:    325 / 375 symm_kl=0.497, self_kl=0, self_cv=0, loss=3.349, nll_loss=0.789, ppl=1.73, wps=24878.5, ups=1.59, wpb=15687.5, bsz=576.6, num_updates=18700, lr=1.60214e-05, gnorm=1.008, train_wall=63, wall=13068
2021-01-16 19:28:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:28:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:28:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:28:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:28:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:28:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:28:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:28:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:28:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:28:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:29:01 | INFO | valid | epoch 050 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.061 | ppl 16.69 | bleu 22.38 | wps 5505.5 | wpb 11799.1 | bsz 428.6 | num_updates 18750 | best_bleu 22.62
2021-01-16 19:29:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:29:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:29:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:29:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:29:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:29:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 50 @ 18750 updates, score 22.38) (writing took 3.14129058457911 seconds)
2021-01-16 19:29:05 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-01-16 19:29:05 | INFO | train | epoch 050 | symm_kl 0.501 | self_kl 0 | self_cv 0 | loss 3.357 | nll_loss 0.79 | ppl 1.73 | wps 22456.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 18750 | lr 1.6e-05 | gnorm 1.025 | train_wall 235 | wall 13122
2021-01-16 19:29:05 | INFO | fairseq.trainer | begin training epoch 51
2021-01-16 19:29:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:29:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:29:40 | INFO | train_inner | epoch 051:     50 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.341, nll_loss=0.781, ppl=1.72, wps=17551.5, ups=1.13, wpb=15590.2, bsz=546.5, num_updates=18800, lr=1.59787e-05, gnorm=1.025, train_wall=63, wall=13157
2021-01-16 19:30:43 | INFO | train_inner | epoch 051:    150 / 375 symm_kl=0.501, self_kl=0, self_cv=0, loss=3.361, nll_loss=0.792, ppl=1.73, wps=24726.7, ups=1.58, wpb=15658.8, bsz=555.5, num_updates=18900, lr=1.59364e-05, gnorm=1.028, train_wall=63, wall=13220
2021-01-16 19:31:46 | INFO | train_inner | epoch 051:    250 / 375 symm_kl=0.504, self_kl=0, self_cv=0, loss=3.371, nll_loss=0.799, ppl=1.74, wps=25148, ups=1.59, wpb=15809, bsz=547.4, num_updates=19000, lr=1.58944e-05, gnorm=1.028, train_wall=63, wall=13283
2021-01-16 19:32:49 | INFO | train_inner | epoch 051:    350 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.358, nll_loss=0.789, ppl=1.73, wps=24983.5, ups=1.58, wpb=15811.5, bsz=556.6, num_updates=19100, lr=1.58527e-05, gnorm=1.026, train_wall=63, wall=13346
2021-01-16 19:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:33:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:33:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:33:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:33:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:33:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:33:22 | INFO | valid | epoch 051 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.057 | ppl 16.64 | bleu 22.33 | wps 5996.4 | wpb 11799.1 | bsz 428.6 | num_updates 19125 | best_bleu 22.62
2021-01-16 19:33:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:33:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:33:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:33:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 51 @ 19125 updates, score 22.33) (writing took 3.088382499292493 seconds)
2021-01-16 19:33:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-01-16 19:33:25 | INFO | train | epoch 051 | symm_kl 0.5 | self_kl 0 | self_cv 0 | loss 3.356 | nll_loss 0.79 | ppl 1.73 | wps 22540.5 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 19125 | lr 1.58424e-05 | gnorm 1.027 | train_wall 236 | wall 13383
2021-01-16 19:33:25 | INFO | fairseq.trainer | begin training epoch 52
2021-01-16 19:33:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:33:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:34:16 | INFO | train_inner | epoch 052:     75 / 375 symm_kl=0.51, self_kl=0, self_cv=0, loss=3.38, nll_loss=0.801, ppl=1.74, wps=17844.7, ups=1.16, wpb=15443, bsz=530.3, num_updates=19200, lr=1.58114e-05, gnorm=1.051, train_wall=62, wall=13433
2021-01-16 19:35:19 | INFO | train_inner | epoch 052:    175 / 375 symm_kl=0.501, self_kl=0, self_cv=0, loss=3.357, nll_loss=0.787, ppl=1.73, wps=24401.8, ups=1.58, wpb=15463.6, bsz=541.9, num_updates=19300, lr=1.57704e-05, gnorm=1.034, train_wall=63, wall=13496
2021-01-16 19:36:22 | INFO | train_inner | epoch 052:    275 / 375 symm_kl=0.501, self_kl=0, self_cv=0, loss=3.36, nll_loss=0.791, ppl=1.73, wps=24814.3, ups=1.58, wpb=15754.5, bsz=538, num_updates=19400, lr=1.57297e-05, gnorm=1.028, train_wall=63, wall=13560
2021-01-16 19:37:26 | INFO | train_inner | epoch 052:    375 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.326, nll_loss=0.775, ppl=1.71, wps=24841.3, ups=1.57, wpb=15792.2, bsz=585.2, num_updates=19500, lr=1.56893e-05, gnorm=1.009, train_wall=63, wall=13623
2021-01-16 19:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:37:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:37:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:37:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:37:45 | INFO | valid | epoch 052 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.065 | ppl 16.74 | bleu 22.44 | wps 5199.6 | wpb 11799.1 | bsz 428.6 | num_updates 19500 | best_bleu 22.62
2021-01-16 19:37:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:37:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 52 @ 19500 updates, score 22.44) (writing took 2.9533047284930944 seconds)
2021-01-16 19:37:48 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-01-16 19:37:48 | INFO | train | epoch 052 | symm_kl 0.5 | self_kl 0 | self_cv 0 | loss 3.354 | nll_loss 0.788 | ppl 1.73 | wps 22373.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 19500 | lr 1.56893e-05 | gnorm 1.026 | train_wall 236 | wall 13646
2021-01-16 19:37:48 | INFO | fairseq.trainer | begin training epoch 53
2021-01-16 19:37:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:37:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:37:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:38:55 | INFO | train_inner | epoch 053:    100 / 375 symm_kl=0.492, self_kl=0, self_cv=0, loss=3.338, nll_loss=0.783, ppl=1.72, wps=17628.9, ups=1.12, wpb=15709.6, bsz=567.6, num_updates=19600, lr=1.56492e-05, gnorm=1.008, train_wall=63, wall=13712
2021-01-16 19:39:59 | INFO | train_inner | epoch 053:    200 / 375 symm_kl=0.5, self_kl=0, self_cv=0, loss=3.354, nll_loss=0.786, ppl=1.72, wps=24490.2, ups=1.57, wpb=15643.3, bsz=549.1, num_updates=19700, lr=1.56094e-05, gnorm=1.03, train_wall=64, wall=13776
2021-01-16 19:41:03 | INFO | train_inner | epoch 053:    300 / 375 symm_kl=0.5, self_kl=0, self_cv=0, loss=3.356, nll_loss=0.789, ppl=1.73, wps=24434.5, ups=1.56, wpb=15651.7, bsz=540.2, num_updates=19800, lr=1.557e-05, gnorm=1.029, train_wall=64, wall=13840
2021-01-16 19:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:41:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:41:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:41:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:41:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:41:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:41:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:41:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:41:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:41:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:41:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:41:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:41:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:41:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:41:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:42:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:42:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:42:10 | INFO | valid | epoch 053 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.68 | nll_loss 4.062 | ppl 16.71 | bleu 22.4 | wps 5471.7 | wpb 11799.1 | bsz 428.6 | num_updates 19875 | best_bleu 22.62
2021-01-16 19:42:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:42:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:42:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:42:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 53 @ 19875 updates, score 22.4) (writing took 2.9006297159940004 seconds)
2021-01-16 19:42:13 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-01-16 19:42:13 | INFO | train | epoch 053 | symm_kl 0.498 | self_kl 0 | self_cv 0 | loss 3.352 | nll_loss 0.788 | ppl 1.73 | wps 22216.3 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 19875 | lr 1.55406e-05 | gnorm 1.025 | train_wall 238 | wall 13910
2021-01-16 19:42:13 | INFO | fairseq.trainer | begin training epoch 54
2021-01-16 19:42:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:42:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:42:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:42:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:42:32 | INFO | train_inner | epoch 054:     25 / 375 symm_kl=0.499, self_kl=0, self_cv=0, loss=3.357, nll_loss=0.792, ppl=1.73, wps=17716.8, ups=1.12, wpb=15800.3, bsz=550.9, num_updates=19900, lr=1.55308e-05, gnorm=1.03, train_wall=63, wall=13930
2021-01-16 19:43:35 | INFO | train_inner | epoch 054:    125 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.345, nll_loss=0.788, ppl=1.73, wps=25089.9, ups=1.59, wpb=15820.6, bsz=573, num_updates=20000, lr=1.54919e-05, gnorm=1.005, train_wall=63, wall=13993
2021-01-16 19:44:39 | INFO | train_inner | epoch 054:    225 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.342, nll_loss=0.783, ppl=1.72, wps=24746.4, ups=1.58, wpb=15711, bsz=557.3, num_updates=20100, lr=1.54533e-05, gnorm=1.023, train_wall=63, wall=14056
2021-01-16 19:45:42 | INFO | train_inner | epoch 054:    325 / 375 symm_kl=0.506, self_kl=0, self_cv=0, loss=3.37, nll_loss=0.795, ppl=1.73, wps=24500.2, ups=1.58, wpb=15523.9, bsz=530, num_updates=20200, lr=1.5415e-05, gnorm=1.042, train_wall=63, wall=14119
2021-01-16 19:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:46:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:46:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:46:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:46:32 | INFO | valid | epoch 054 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.68 | nll_loss 4.062 | ppl 16.7 | bleu 22.44 | wps 5386.1 | wpb 11799.1 | bsz 428.6 | num_updates 20250 | best_bleu 22.62
2021-01-16 19:46:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:46:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:46:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:46:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 54 @ 20250 updates, score 22.44) (writing took 3.0939511358737946 seconds)
2021-01-16 19:46:36 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-01-16 19:46:36 | INFO | train | epoch 054 | symm_kl 0.498 | self_kl 0 | self_cv 0 | loss 3.351 | nll_loss 0.788 | ppl 1.73 | wps 22402.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 20250 | lr 1.5396e-05 | gnorm 1.024 | train_wall 236 | wall 14173
2021-01-16 19:46:36 | INFO | fairseq.trainer | begin training epoch 55
2021-01-16 19:46:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:46:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:47:11 | INFO | train_inner | epoch 055:     50 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.338, nll_loss=0.782, ppl=1.72, wps=17621, ups=1.13, wpb=15572.8, bsz=564.3, num_updates=20300, lr=1.5377e-05, gnorm=1.039, train_wall=63, wall=14208
2021-01-16 19:48:14 | INFO | train_inner | epoch 055:    150 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.342, nll_loss=0.785, ppl=1.72, wps=25030.3, ups=1.58, wpb=15869.2, bsz=539, num_updates=20400, lr=1.53393e-05, gnorm=1.013, train_wall=63, wall=14271
2021-01-16 19:49:17 | INFO | train_inner | epoch 055:    250 / 375 symm_kl=0.498, self_kl=0, self_cv=0, loss=3.352, nll_loss=0.786, ppl=1.72, wps=24708.2, ups=1.57, wpb=15690.8, bsz=545.1, num_updates=20500, lr=1.53018e-05, gnorm=1.029, train_wall=63, wall=14335
2021-01-16 19:50:21 | INFO | train_inner | epoch 055:    350 / 375 symm_kl=0.5, self_kl=0, self_cv=0, loss=3.358, nll_loss=0.793, ppl=1.73, wps=24641.6, ups=1.57, wpb=15687, bsz=570.3, num_updates=20600, lr=1.52647e-05, gnorm=1.02, train_wall=63, wall=14398
2021-01-16 19:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:50:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:50:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:50:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:50:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:50:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:50:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:50:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:50:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:50:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:50:55 | INFO | valid | epoch 055 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.059 | ppl 16.67 | bleu 22.48 | wps 5566.6 | wpb 11799.1 | bsz 428.6 | num_updates 20625 | best_bleu 22.62
2021-01-16 19:50:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:50:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:50:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:50:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:50:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:50:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 55 @ 20625 updates, score 22.48) (writing took 3.239631140604615 seconds)
2021-01-16 19:50:58 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-01-16 19:50:58 | INFO | train | epoch 055 | symm_kl 0.497 | self_kl 0 | self_cv 0 | loss 3.349 | nll_loss 0.787 | ppl 1.73 | wps 22371.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 20625 | lr 1.52554e-05 | gnorm 1.028 | train_wall 237 | wall 14436
2021-01-16 19:50:58 | INFO | fairseq.trainer | begin training epoch 56
2021-01-16 19:50:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:51:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:51:49 | INFO | train_inner | epoch 056:     75 / 375 symm_kl=0.498, self_kl=0, self_cv=0, loss=3.36, nll_loss=0.798, ppl=1.74, wps=17645.4, ups=1.13, wpb=15587.4, bsz=557.2, num_updates=20700, lr=1.52277e-05, gnorm=1.028, train_wall=63, wall=14487
2021-01-16 19:52:52 | INFO | train_inner | epoch 056:    175 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.345, nll_loss=0.783, ppl=1.72, wps=25160.8, ups=1.59, wpb=15801.6, bsz=539.6, num_updates=20800, lr=1.51911e-05, gnorm=1.018, train_wall=63, wall=14550
2021-01-16 19:53:56 | INFO | train_inner | epoch 056:    275 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.345, nll_loss=0.784, ppl=1.72, wps=24897.8, ups=1.58, wpb=15749.1, bsz=565, num_updates=20900, lr=1.51547e-05, gnorm=1.018, train_wall=63, wall=14613
2021-01-16 19:54:59 | INFO | train_inner | epoch 056:    375 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.343, nll_loss=0.786, ppl=1.72, wps=24345.9, ups=1.58, wpb=15428.3, bsz=546.3, num_updates=21000, lr=1.51186e-05, gnorm=1.034, train_wall=63, wall=14676
2021-01-16 19:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:55:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:55:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:55:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:55:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:55:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:55:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:55:18 | INFO | valid | epoch 056 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.063 | ppl 16.72 | bleu 22.3 | wps 5245.7 | wpb 11799.1 | bsz 428.6 | num_updates 21000 | best_bleu 22.62
2021-01-16 19:55:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:55:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:55:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:55:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 56 @ 21000 updates, score 22.3) (writing took 3.2581355329602957 seconds)
2021-01-16 19:55:21 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-01-16 19:55:21 | INFO | train | epoch 056 | symm_kl 0.495 | self_kl 0 | self_cv 0 | loss 3.347 | nll_loss 0.787 | ppl 1.73 | wps 22372.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 21000 | lr 1.51186e-05 | gnorm 1.021 | train_wall 236 | wall 14699
2021-01-16 19:55:21 | INFO | fairseq.trainer | begin training epoch 57
2021-01-16 19:55:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:55:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:56:28 | INFO | train_inner | epoch 057:    100 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.34, nll_loss=0.785, ppl=1.72, wps=17853, ups=1.13, wpb=15826.1, bsz=555.1, num_updates=21100, lr=1.50827e-05, gnorm=1.016, train_wall=62, wall=14765
2021-01-16 19:57:31 | INFO | train_inner | epoch 057:    200 / 375 symm_kl=0.492, self_kl=0, self_cv=0, loss=3.335, nll_loss=0.78, ppl=1.72, wps=24773.5, ups=1.59, wpb=15621.9, bsz=570, num_updates=21200, lr=1.50471e-05, gnorm=1.021, train_wall=63, wall=14828
2021-01-16 19:58:34 | INFO | train_inner | epoch 057:    300 / 375 symm_kl=0.502, self_kl=0, self_cv=0, loss=3.367, nll_loss=0.797, ppl=1.74, wps=24631.7, ups=1.58, wpb=15588.4, bsz=539.4, num_updates=21300, lr=1.50117e-05, gnorm=1.032, train_wall=63, wall=14891
2021-01-16 19:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 19:59:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:59:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 19:59:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 19:59:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 19:59:41 | INFO | valid | epoch 057 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.058 | ppl 16.66 | bleu 22.31 | wps 4868.9 | wpb 11799.1 | bsz 428.6 | num_updates 21375 | best_bleu 22.62
2021-01-16 19:59:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 19:59:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:59:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 57 @ 21375 updates, score 22.31) (writing took 3.1157836746424437 seconds)
2021-01-16 19:59:45 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-01-16 19:59:45 | INFO | train | epoch 057 | symm_kl 0.495 | self_kl 0 | self_cv 0 | loss 3.346 | nll_loss 0.787 | ppl 1.73 | wps 22342.4 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 21375 | lr 1.49854e-05 | gnorm 1.024 | train_wall 235 | wall 14962
2021-01-16 19:59:45 | INFO | fairseq.trainer | begin training epoch 58
2021-01-16 19:59:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 19:59:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 19:59:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:00:04 | INFO | train_inner | epoch 058:     25 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.347, nll_loss=0.787, ppl=1.73, wps=17443.5, ups=1.11, wpb=15680.1, bsz=547.9, num_updates=21400, lr=1.49766e-05, gnorm=1.027, train_wall=63, wall=14981
2021-01-16 20:01:07 | INFO | train_inner | epoch 058:    125 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.778, ppl=1.71, wps=25094.4, ups=1.59, wpb=15743, bsz=583.5, num_updates=21500, lr=1.49417e-05, gnorm=1.008, train_wall=62, wall=15044
2021-01-16 20:02:10 | INFO | train_inner | epoch 058:    225 / 375 symm_kl=0.497, self_kl=0, self_cv=0, loss=3.35, nll_loss=0.786, ppl=1.72, wps=24673.7, ups=1.58, wpb=15627.2, bsz=539.4, num_updates=21600, lr=1.49071e-05, gnorm=1.03, train_wall=63, wall=15107
2021-01-16 20:03:13 | INFO | train_inner | epoch 058:    325 / 375 symm_kl=0.499, self_kl=0, self_cv=0, loss=3.358, nll_loss=0.794, ppl=1.73, wps=25189.1, ups=1.6, wpb=15781.9, bsz=531.2, num_updates=21700, lr=1.48727e-05, gnorm=1.023, train_wall=62, wall=15170
2021-01-16 20:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:03:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:03:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:03:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:03:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:03:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:03:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:03:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:03:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:03:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:03:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:04:04 | INFO | valid | epoch 058 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.061 | ppl 16.7 | bleu 22.26 | wps 5114.7 | wpb 11799.1 | bsz 428.6 | num_updates 21750 | best_bleu 22.62
2021-01-16 20:04:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:04:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:04:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:04:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:04:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:04:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 58 @ 21750 updates, score 22.26) (writing took 3.172960940748453 seconds)
2021-01-16 20:04:07 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-01-16 20:04:07 | INFO | train | epoch 058 | symm_kl 0.494 | self_kl 0 | self_cv 0 | loss 3.345 | nll_loss 0.786 | ppl 1.72 | wps 22428.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 21750 | lr 1.48556e-05 | gnorm 1.022 | train_wall 235 | wall 15224
2021-01-16 20:04:07 | INFO | fairseq.trainer | begin training epoch 59
2021-01-16 20:04:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:04:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:04:42 | INFO | train_inner | epoch 059:     50 / 375 symm_kl=0.497, self_kl=0, self_cv=0, loss=3.348, nll_loss=0.787, ppl=1.73, wps=17260.3, ups=1.12, wpb=15388.2, bsz=534.6, num_updates=21800, lr=1.48386e-05, gnorm=1.039, train_wall=62, wall=15259
2021-01-16 20:05:45 | INFO | train_inner | epoch 059:    150 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.352, nll_loss=0.79, ppl=1.73, wps=25202.8, ups=1.59, wpb=15865.2, bsz=560.4, num_updates=21900, lr=1.48047e-05, gnorm=1.019, train_wall=63, wall=15322
2021-01-16 20:06:48 | INFO | train_inner | epoch 059:    250 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.34, nll_loss=0.783, ppl=1.72, wps=25088, ups=1.58, wpb=15848.2, bsz=547.4, num_updates=22000, lr=1.4771e-05, gnorm=1.008, train_wall=63, wall=15385
2021-01-16 20:07:50 | INFO | train_inner | epoch 059:    350 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.349, nll_loss=0.79, ppl=1.73, wps=24859.6, ups=1.59, wpb=15589.8, bsz=568.3, num_updates=22100, lr=1.47375e-05, gnorm=1.023, train_wall=62, wall=15448
2021-01-16 20:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:08:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:08:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:08:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:08:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:08:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:08:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:08:25 | INFO | valid | epoch 059 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.687 | nll_loss 4.069 | ppl 16.79 | bleu 22.4 | wps 5499.4 | wpb 11799.1 | bsz 428.6 | num_updates 22125 | best_bleu 22.62
2021-01-16 20:08:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:08:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:08:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:08:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 59 @ 22125 updates, score 22.4) (writing took 3.0442802887409925 seconds)
2021-01-16 20:08:28 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-01-16 20:08:28 | INFO | train | epoch 059 | symm_kl 0.494 | self_kl 0 | self_cv 0 | loss 3.344 | nll_loss 0.786 | ppl 1.72 | wps 22545 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 22125 | lr 1.47292e-05 | gnorm 1.021 | train_wall 235 | wall 15485
2021-01-16 20:08:28 | INFO | fairseq.trainer | begin training epoch 60
2021-01-16 20:08:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:08:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:09:18 | INFO | train_inner | epoch 060:     75 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.33, nll_loss=0.778, ppl=1.71, wps=17593.1, ups=1.14, wpb=15424.1, bsz=562.5, num_updates=22200, lr=1.47043e-05, gnorm=1.026, train_wall=62, wall=15535
2021-01-16 20:10:21 | INFO | train_inner | epoch 060:    175 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.348, nll_loss=0.787, ppl=1.73, wps=24860.1, ups=1.6, wpb=15564.1, bsz=544.6, num_updates=22300, lr=1.46713e-05, gnorm=1.027, train_wall=62, wall=15598
2021-01-16 20:11:24 | INFO | train_inner | epoch 060:    275 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.331, nll_loss=0.78, ppl=1.72, wps=25316.8, ups=1.59, wpb=15932.8, bsz=559.9, num_updates=22400, lr=1.46385e-05, gnorm=1.005, train_wall=63, wall=15661
2021-01-16 20:12:27 | INFO | train_inner | epoch 060:    375 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.346, nll_loss=0.789, ppl=1.73, wps=25039.6, ups=1.59, wpb=15765.5, bsz=550.9, num_updates=22500, lr=1.46059e-05, gnorm=1.03, train_wall=63, wall=15724
2021-01-16 20:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:12:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:12:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:12:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:12:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:12:46 | INFO | valid | epoch 060 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.062 | ppl 16.7 | bleu 22.31 | wps 5268 | wpb 11799.1 | bsz 428.6 | num_updates 22500 | best_bleu 22.62
2021-01-16 20:12:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:12:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 60 @ 22500 updates, score 22.31) (writing took 3.133199328556657 seconds)
2021-01-16 20:12:49 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-01-16 20:12:49 | INFO | train | epoch 060 | symm_kl 0.493 | self_kl 0 | self_cv 0 | loss 3.342 | nll_loss 0.785 | ppl 1.72 | wps 22524.9 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 22500 | lr 1.46059e-05 | gnorm 1.022 | train_wall 234 | wall 15746
2021-01-16 20:12:49 | INFO | fairseq.trainer | begin training epoch 61
2021-01-16 20:12:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:12:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:12:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:12:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:13:56 | INFO | train_inner | epoch 061:    100 / 375 symm_kl=0.492, self_kl=0, self_cv=0, loss=3.341, nll_loss=0.785, ppl=1.72, wps=17592.3, ups=1.13, wpb=15629.9, bsz=549.4, num_updates=22600, lr=1.45736e-05, gnorm=1.013, train_wall=63, wall=15813
2021-01-16 20:14:58 | INFO | train_inner | epoch 061:    200 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.329, nll_loss=0.778, ppl=1.71, wps=25219, ups=1.59, wpb=15839.3, bsz=560.5, num_updates=22700, lr=1.45414e-05, gnorm=1.004, train_wall=63, wall=15876
2021-01-16 20:16:01 | INFO | train_inner | epoch 061:    300 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.351, nll_loss=0.79, ppl=1.73, wps=25008.4, ups=1.59, wpb=15717.8, bsz=548.4, num_updates=22800, lr=1.45095e-05, gnorm=1.016, train_wall=63, wall=15938
2021-01-16 20:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:16:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:16:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:16:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:16:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:16:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:16:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:16:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:17:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:17:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:17:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:17:07 | INFO | valid | epoch 061 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.68 | nll_loss 4.064 | ppl 16.73 | bleu 22.41 | wps 5403.4 | wpb 11799.1 | bsz 428.6 | num_updates 22875 | best_bleu 22.62
2021-01-16 20:17:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:17:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:17:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:17:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:17:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:17:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 61 @ 22875 updates, score 22.41) (writing took 3.1766288317739964 seconds)
2021-01-16 20:17:10 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-01-16 20:17:10 | INFO | train | epoch 061 | symm_kl 0.493 | self_kl 0 | self_cv 0 | loss 3.341 | nll_loss 0.785 | ppl 1.72 | wps 22510.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 22875 | lr 1.44857e-05 | gnorm 1.017 | train_wall 235 | wall 16007
2021-01-16 20:17:10 | INFO | fairseq.trainer | begin training epoch 62
2021-01-16 20:17:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:17:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:17:29 | INFO | train_inner | epoch 062:     25 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.339, nll_loss=0.787, ppl=1.73, wps=17661, ups=1.14, wpb=15532.9, bsz=566.9, num_updates=22900, lr=1.44778e-05, gnorm=1.027, train_wall=62, wall=16026
2021-01-16 20:18:31 | INFO | train_inner | epoch 062:    125 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.335, nll_loss=0.787, ppl=1.73, wps=25107.6, ups=1.6, wpb=15656.2, bsz=569.2, num_updates=23000, lr=1.44463e-05, gnorm=1.005, train_wall=62, wall=16089
2021-01-16 20:19:35 | INFO | train_inner | epoch 062:    225 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.34, nll_loss=0.781, ppl=1.72, wps=24719.8, ups=1.57, wpb=15728.2, bsz=537.4, num_updates=23100, lr=1.4415e-05, gnorm=1.018, train_wall=63, wall=16152
2021-01-16 20:20:38 | INFO | train_inner | epoch 062:    325 / 375 symm_kl=0.495, self_kl=0, self_cv=0, loss=3.343, nll_loss=0.783, ppl=1.72, wps=24962.4, ups=1.59, wpb=15709.2, bsz=540.5, num_updates=23200, lr=1.43839e-05, gnorm=1.025, train_wall=63, wall=16215
2021-01-16 20:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:21:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:21:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:21:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:21:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:21:29 | INFO | valid | epoch 062 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.06 | ppl 16.68 | bleu 22.47 | wps 5014 | wpb 11799.1 | bsz 428.6 | num_updates 23250 | best_bleu 22.62
2021-01-16 20:21:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:21:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 62 @ 23250 updates, score 22.47) (writing took 3.1584965363144875 seconds)
2021-01-16 20:21:33 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2021-01-16 20:21:33 | INFO | train | epoch 062 | symm_kl 0.492 | self_kl 0 | self_cv 0 | loss 3.339 | nll_loss 0.785 | ppl 1.72 | wps 22395.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 23250 | lr 1.43684e-05 | gnorm 1.016 | train_wall 235 | wall 16270
2021-01-16 20:21:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:21:33 | INFO | fairseq.trainer | begin training epoch 63
2021-01-16 20:21:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:21:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:22:07 | INFO | train_inner | epoch 063:     50 / 375 symm_kl=0.498, self_kl=0, self_cv=0, loss=3.355, nll_loss=0.791, ppl=1.73, wps=17350.2, ups=1.12, wpb=15481, bsz=536.5, num_updates=23300, lr=1.4353e-05, gnorm=1.041, train_wall=62, wall=16305
2021-01-16 20:23:10 | INFO | train_inner | epoch 063:    150 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.773, ppl=1.71, wps=25391.8, ups=1.58, wpb=16027.1, bsz=579.1, num_updates=23400, lr=1.43223e-05, gnorm=0.99, train_wall=63, wall=16368
2021-01-16 20:24:14 | INFO | train_inner | epoch 063:    250 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.35, nll_loss=0.793, ppl=1.73, wps=24814.1, ups=1.57, wpb=15831, bsz=544.8, num_updates=23500, lr=1.42918e-05, gnorm=1.013, train_wall=64, wall=16432
2021-01-16 20:25:17 | INFO | train_inner | epoch 063:    350 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.783, ppl=1.72, wps=24427.8, ups=1.58, wpb=15424.2, bsz=571.2, num_updates=23600, lr=1.42615e-05, gnorm=1.022, train_wall=63, wall=16495
2021-01-16 20:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:25:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:25:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:25:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:25:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:25:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:25:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:25:53 | INFO | valid | epoch 063 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.063 | ppl 16.72 | bleu 22.34 | wps 5143 | wpb 11799.1 | bsz 428.6 | num_updates 23625 | best_bleu 22.62
2021-01-16 20:25:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:25:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:25:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:25:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 63 @ 23625 updates, score 22.34) (writing took 3.092715108767152 seconds)
2021-01-16 20:25:56 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2021-01-16 20:25:56 | INFO | train | epoch 063 | symm_kl 0.491 | self_kl 0 | self_cv 0 | loss 3.338 | nll_loss 0.784 | ppl 1.72 | wps 22337 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 23625 | lr 1.42539e-05 | gnorm 1.02 | train_wall 236 | wall 16533
2021-01-16 20:25:56 | INFO | fairseq.trainer | begin training epoch 64
2021-01-16 20:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:25:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:26:47 | INFO | train_inner | epoch 064:     75 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.781, ppl=1.72, wps=17512.6, ups=1.12, wpb=15675.6, bsz=537, num_updates=23700, lr=1.42314e-05, gnorm=1.024, train_wall=63, wall=16584
2021-01-16 20:27:51 | INFO | train_inner | epoch 064:    175 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.33, nll_loss=0.783, ppl=1.72, wps=24568.6, ups=1.57, wpb=15692.4, bsz=567.8, num_updates=23800, lr=1.42014e-05, gnorm=0.997, train_wall=64, wall=16648
2021-01-16 20:28:54 | INFO | train_inner | epoch 064:    275 / 375 symm_kl=0.5, self_kl=0, self_cv=0, loss=3.359, nll_loss=0.79, ppl=1.73, wps=24715.2, ups=1.58, wpb=15631.8, bsz=547.2, num_updates=23900, lr=1.41717e-05, gnorm=1.036, train_wall=63, wall=16711
2021-01-16 20:29:58 | INFO | train_inner | epoch 064:    375 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.329, nll_loss=0.78, ppl=1.72, wps=24500.9, ups=1.56, wpb=15670, bsz=539.2, num_updates=24000, lr=1.41421e-05, gnorm=1.01, train_wall=64, wall=16775
2021-01-16 20:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:29:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:29:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:29:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:30:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:30:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:30:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:30:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:30:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:30:17 | INFO | valid | epoch 064 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.062 | ppl 16.7 | bleu 22.27 | wps 5429 | wpb 11799.1 | bsz 428.6 | num_updates 24000 | best_bleu 22.62
2021-01-16 20:30:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:30:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:30:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:30:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:30:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:30:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 64 @ 24000 updates, score 22.27) (writing took 3.076752007007599 seconds)
2021-01-16 20:30:20 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2021-01-16 20:30:20 | INFO | train | epoch 064 | symm_kl 0.491 | self_kl 0 | self_cv 0 | loss 3.337 | nll_loss 0.783 | ppl 1.72 | wps 22282.8 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 24000 | lr 1.41421e-05 | gnorm 1.012 | train_wall 237 | wall 16797
2021-01-16 20:30:20 | INFO | fairseq.trainer | begin training epoch 65
2021-01-16 20:30:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:30:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:31:26 | INFO | train_inner | epoch 065:    100 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.333, nll_loss=0.779, ppl=1.72, wps=17768.5, ups=1.13, wpb=15700.3, bsz=540, num_updates=24100, lr=1.41128e-05, gnorm=1.015, train_wall=62, wall=16864
2021-01-16 20:32:30 | INFO | train_inner | epoch 065:    200 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.335, nll_loss=0.781, ppl=1.72, wps=24399.7, ups=1.57, wpb=15564.4, bsz=551.6, num_updates=24200, lr=1.40836e-05, gnorm=1.023, train_wall=64, wall=16927
2021-01-16 20:33:33 | INFO | train_inner | epoch 065:    300 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.785, ppl=1.72, wps=24931.1, ups=1.58, wpb=15783.4, bsz=567.3, num_updates=24300, lr=1.40546e-05, gnorm=1.009, train_wall=63, wall=16991
2021-01-16 20:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:34:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:34:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:34:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:34:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:34:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:34:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:34:41 | INFO | valid | epoch 065 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.68 | nll_loss 4.065 | ppl 16.74 | bleu 22.25 | wps 5054.8 | wpb 11799.1 | bsz 428.6 | num_updates 24375 | best_bleu 22.62
2021-01-16 20:34:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:34:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:34:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 65 @ 24375 updates, score 22.25) (writing took 3.119025832042098 seconds)
2021-01-16 20:34:44 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2021-01-16 20:34:44 | INFO | train | epoch 065 | symm_kl 0.49 | self_kl 0 | self_cv 0 | loss 3.336 | nll_loss 0.784 | ppl 1.72 | wps 22237.5 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 24375 | lr 1.40329e-05 | gnorm 1.017 | train_wall 237 | wall 17062
2021-01-16 20:34:44 | INFO | fairseq.trainer | begin training epoch 66
2021-01-16 20:34:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:34:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:34:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:35:04 | INFO | train_inner | epoch 066:     25 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.323, nll_loss=0.781, ppl=1.72, wps=17563.9, ups=1.11, wpb=15867.1, bsz=573.8, num_updates=24400, lr=1.40257e-05, gnorm=1.004, train_wall=63, wall=17081
2021-01-16 20:36:07 | INFO | train_inner | epoch 066:    125 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.778, ppl=1.71, wps=24916.9, ups=1.58, wpb=15812.5, bsz=562.6, num_updates=24500, lr=1.39971e-05, gnorm=1.009, train_wall=63, wall=17144
2021-01-16 20:37:11 | INFO | train_inner | epoch 066:    225 / 375 symm_kl=0.498, self_kl=0, self_cv=0, loss=3.354, nll_loss=0.79, ppl=1.73, wps=24578.9, ups=1.58, wpb=15581.6, bsz=521.9, num_updates=24600, lr=1.39686e-05, gnorm=1.024, train_wall=63, wall=17208
2021-01-16 20:38:14 | INFO | train_inner | epoch 066:    325 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.332, nll_loss=0.784, ppl=1.72, wps=24648.4, ups=1.57, wpb=15701.8, bsz=567.7, num_updates=24700, lr=1.39403e-05, gnorm=1.014, train_wall=63, wall=17272
2021-01-16 20:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:38:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:38:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:38:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:38:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:38:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:38:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:38:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:39:05 | INFO | valid | epoch 066 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.064 | ppl 16.73 | bleu 22.39 | wps 5104.5 | wpb 11799.1 | bsz 428.6 | num_updates 24750 | best_bleu 22.62
2021-01-16 20:39:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:39:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:39:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:39:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:39:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:39:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 66 @ 24750 updates, score 22.39) (writing took 2.911668563261628 seconds)
2021-01-16 20:39:08 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2021-01-16 20:39:08 | INFO | train | epoch 066 | symm_kl 0.489 | self_kl 0 | self_cv 0 | loss 3.334 | nll_loss 0.783 | ppl 1.72 | wps 22289.3 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 24750 | lr 1.39262e-05 | gnorm 1.015 | train_wall 237 | wall 17325
2021-01-16 20:39:08 | INFO | fairseq.trainer | begin training epoch 67
2021-01-16 20:39:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:39:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:39:43 | INFO | train_inner | epoch 067:     50 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.784, ppl=1.72, wps=17492.2, ups=1.13, wpb=15488.9, bsz=555, num_updates=24800, lr=1.39122e-05, gnorm=1.021, train_wall=62, wall=17360
2021-01-16 20:40:46 | INFO | train_inner | epoch 067:    150 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.337, nll_loss=0.784, ppl=1.72, wps=25022.6, ups=1.58, wpb=15812.2, bsz=544.2, num_updates=24900, lr=1.38842e-05, gnorm=1.019, train_wall=63, wall=17423
2021-01-16 20:41:49 | INFO | train_inner | epoch 067:    250 / 375 symm_kl=0.492, self_kl=0, self_cv=0, loss=3.343, nll_loss=0.789, ppl=1.73, wps=24552.2, ups=1.58, wpb=15491, bsz=552.4, num_updates=25000, lr=1.38564e-05, gnorm=1.026, train_wall=63, wall=17486
2021-01-16 20:42:53 | INFO | train_inner | epoch 067:    350 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.333, nll_loss=0.781, ppl=1.72, wps=24839, ups=1.57, wpb=15794.5, bsz=551.4, num_updates=25100, lr=1.38288e-05, gnorm=1.007, train_wall=63, wall=17550
2021-01-16 20:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:43:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:43:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:43:28 | INFO | valid | epoch 067 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.063 | ppl 16.72 | bleu 22.4 | wps 5229.7 | wpb 11799.1 | bsz 428.6 | num_updates 25125 | best_bleu 22.62
2021-01-16 20:43:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:43:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:43:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 67 @ 25125 updates, score 22.4) (writing took 3.178738594055176 seconds)
2021-01-16 20:43:31 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2021-01-16 20:43:31 | INFO | train | epoch 067 | symm_kl 0.488 | self_kl 0 | self_cv 0 | loss 3.333 | nll_loss 0.783 | ppl 1.72 | wps 22379.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 25125 | lr 1.38219e-05 | gnorm 1.016 | train_wall 236 | wall 17588
2021-01-16 20:43:31 | INFO | fairseq.trainer | begin training epoch 68
2021-01-16 20:43:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:43:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:43:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:44:22 | INFO | train_inner | epoch 068:     75 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.763, ppl=1.7, wps=17522.9, ups=1.12, wpb=15616.6, bsz=561.3, num_updates=25200, lr=1.38013e-05, gnorm=1, train_wall=62, wall=17639
2021-01-16 20:45:25 | INFO | train_inner | epoch 068:    175 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.781, ppl=1.72, wps=24534.1, ups=1.57, wpb=15600.1, bsz=548.3, num_updates=25300, lr=1.3774e-05, gnorm=1.019, train_wall=63, wall=17703
2021-01-16 20:46:29 | INFO | train_inner | epoch 068:    275 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.337, nll_loss=0.787, ppl=1.73, wps=24782.8, ups=1.57, wpb=15768.8, bsz=568.8, num_updates=25400, lr=1.37469e-05, gnorm=1.011, train_wall=63, wall=17766
2021-01-16 20:47:32 | INFO | train_inner | epoch 068:    375 / 375 symm_kl=0.496, self_kl=0, self_cv=0, loss=3.352, nll_loss=0.792, ppl=1.73, wps=24862, ups=1.59, wpb=15663.4, bsz=528.7, num_updates=25500, lr=1.37199e-05, gnorm=1.028, train_wall=63, wall=17829
2021-01-16 20:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:47:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:47:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:47:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:47:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:47:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:47:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:47:50 | INFO | valid | epoch 068 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.066 | ppl 16.74 | bleu 22.47 | wps 5448.1 | wpb 11799.1 | bsz 428.6 | num_updates 25500 | best_bleu 22.62
2021-01-16 20:47:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:47:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:47:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:47:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 68 @ 25500 updates, score 22.47) (writing took 3.0466190613806248 seconds)
2021-01-16 20:47:54 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2021-01-16 20:47:54 | INFO | train | epoch 068 | symm_kl 0.488 | self_kl 0 | self_cv 0 | loss 3.331 | nll_loss 0.782 | ppl 1.72 | wps 22397.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 25500 | lr 1.37199e-05 | gnorm 1.013 | train_wall 236 | wall 17851
2021-01-16 20:47:54 | INFO | fairseq.trainer | begin training epoch 69
2021-01-16 20:47:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:47:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:49:00 | INFO | train_inner | epoch 069:    100 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.779, ppl=1.72, wps=17910.6, ups=1.14, wpb=15669.5, bsz=547.9, num_updates=25600, lr=1.36931e-05, gnorm=1.007, train_wall=62, wall=17917
2021-01-16 20:50:03 | INFO | train_inner | epoch 069:    200 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.33, nll_loss=0.782, ppl=1.72, wps=24990.2, ups=1.58, wpb=15782.3, bsz=560, num_updates=25700, lr=1.36664e-05, gnorm=1.003, train_wall=63, wall=17980
2021-01-16 20:51:06 | INFO | train_inner | epoch 069:    300 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.333, nll_loss=0.782, ppl=1.72, wps=24544.6, ups=1.58, wpb=15501.8, bsz=542.6, num_updates=25800, lr=1.36399e-05, gnorm=1.02, train_wall=63, wall=18043
2021-01-16 20:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:51:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:51:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:51:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:51:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:51:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:51:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:51:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:51:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:51:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:51:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:51:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:51:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:52:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:52:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:52:11 | INFO | valid | epoch 069 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.057 | ppl 16.64 | bleu 22.45 | wps 5645.4 | wpb 11799.1 | bsz 428.6 | num_updates 25875 | best_bleu 22.62
2021-01-16 20:52:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:52:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:52:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:52:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 69 @ 25875 updates, score 22.45) (writing took 2.905516181141138 seconds)
2021-01-16 20:52:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2021-01-16 20:52:14 | INFO | train | epoch 069 | symm_kl 0.487 | self_kl 0 | self_cv 0 | loss 3.33 | nll_loss 0.781 | ppl 1.72 | wps 22567.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 25875 | lr 1.36201e-05 | gnorm 1.01 | train_wall 235 | wall 18111
2021-01-16 20:52:14 | INFO | fairseq.trainer | begin training epoch 70
2021-01-16 20:52:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:52:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:52:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:52:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:52:33 | INFO | train_inner | epoch 070:     25 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.333, nll_loss=0.783, ppl=1.72, wps=17956.6, ups=1.14, wpb=15721.9, bsz=561.8, num_updates=25900, lr=1.36135e-05, gnorm=1.012, train_wall=63, wall=18131
2021-01-16 20:53:36 | INFO | train_inner | epoch 070:    125 / 375 symm_kl=0.486, self_kl=0, self_cv=0, loss=3.325, nll_loss=0.778, ppl=1.71, wps=25067.2, ups=1.59, wpb=15767.8, bsz=554.6, num_updates=26000, lr=1.35873e-05, gnorm=1.001, train_wall=63, wall=18194
2021-01-16 20:54:40 | INFO | train_inner | epoch 070:    225 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.331, nll_loss=0.783, ppl=1.72, wps=24847.4, ups=1.58, wpb=15771.2, bsz=544.2, num_updates=26100, lr=1.35613e-05, gnorm=1.009, train_wall=63, wall=18257
2021-01-16 20:55:43 | INFO | train_inner | epoch 070:    325 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.331, nll_loss=0.783, ppl=1.72, wps=24711.7, ups=1.58, wpb=15620.6, bsz=563.1, num_updates=26200, lr=1.35354e-05, gnorm=1.014, train_wall=63, wall=18320
2021-01-16 20:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 20:56:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:56:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:56:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 20:56:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 20:56:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 20:56:33 | INFO | valid | epoch 070 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.057 | ppl 16.64 | bleu 22.52 | wps 5680.7 | wpb 11799.1 | bsz 428.6 | num_updates 26250 | best_bleu 22.62
2021-01-16 20:56:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 20:56:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:56:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:56:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 70 @ 26250 updates, score 22.52) (writing took 2.9692739713937044 seconds)
2021-01-16 20:56:36 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2021-01-16 20:56:36 | INFO | train | epoch 070 | symm_kl 0.488 | self_kl 0 | self_cv 0 | loss 3.331 | nll_loss 0.782 | ppl 1.72 | wps 22491.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 26250 | lr 1.35225e-05 | gnorm 1.012 | train_wall 236 | wall 18373
2021-01-16 20:56:36 | INFO | fairseq.trainer | begin training epoch 71
2021-01-16 20:56:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 20:56:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 20:57:10 | INFO | train_inner | epoch 071:     50 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.337, nll_loss=0.784, ppl=1.72, wps=18018.7, ups=1.15, wpb=15704.8, bsz=534.1, num_updates=26300, lr=1.35096e-05, gnorm=1.021, train_wall=62, wall=18407
2021-01-16 20:58:13 | INFO | train_inner | epoch 071:    150 / 375 symm_kl=0.486, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.782, ppl=1.72, wps=24932.8, ups=1.58, wpb=15735.2, bsz=548, num_updates=26400, lr=1.3484e-05, gnorm=0.998, train_wall=63, wall=18471
2021-01-16 20:59:17 | INFO | train_inner | epoch 071:    250 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.778, ppl=1.71, wps=24852.6, ups=1.58, wpb=15752.3, bsz=558.5, num_updates=26500, lr=1.34585e-05, gnorm=1.008, train_wall=63, wall=18534
2021-01-16 21:00:20 | INFO | train_inner | epoch 071:    350 / 375 symm_kl=0.484, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.78, ppl=1.72, wps=24951.8, ups=1.59, wpb=15706.5, bsz=581.2, num_updates=26600, lr=1.34332e-05, gnorm=1.01, train_wall=63, wall=18597
2021-01-16 21:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:00:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:00:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:00:54 | INFO | valid | epoch 071 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.057 | ppl 16.65 | bleu 22.45 | wps 5246.3 | wpb 11799.1 | bsz 428.6 | num_updates 26625 | best_bleu 22.62
2021-01-16 21:00:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:00:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:00:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:00:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:00:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:00:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 71 @ 26625 updates, score 22.45) (writing took 3.324547527357936 seconds)
2021-01-16 21:00:58 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2021-01-16 21:00:58 | INFO | train | epoch 071 | symm_kl 0.487 | self_kl 0 | self_cv 0 | loss 3.328 | nll_loss 0.781 | ppl 1.72 | wps 22431.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 26625 | lr 1.34269e-05 | gnorm 1.012 | train_wall 235 | wall 18635
2021-01-16 21:00:58 | INFO | fairseq.trainer | begin training epoch 72
2021-01-16 21:00:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:01:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:01:49 | INFO | train_inner | epoch 072:     75 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.336, nll_loss=0.783, ppl=1.72, wps=17195.6, ups=1.12, wpb=15353, bsz=527.3, num_updates=26700, lr=1.3408e-05, gnorm=1.028, train_wall=63, wall=18686
2021-01-16 21:02:52 | INFO | train_inner | epoch 072:    175 / 375 symm_kl=0.492, self_kl=0, self_cv=0, loss=3.343, nll_loss=0.786, ppl=1.72, wps=24588.5, ups=1.59, wpb=15465.1, bsz=539, num_updates=26800, lr=1.3383e-05, gnorm=1.023, train_wall=63, wall=18749
2021-01-16 21:03:55 | INFO | train_inner | epoch 072:    275 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.781, ppl=1.72, wps=25364.9, ups=1.58, wpb=16006.9, bsz=598.9, num_updates=26900, lr=1.33581e-05, gnorm=0.981, train_wall=63, wall=18812
2021-01-16 21:04:58 | INFO | train_inner | epoch 072:    375 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.321, nll_loss=0.775, ppl=1.71, wps=24727.8, ups=1.58, wpb=15687.7, bsz=533.6, num_updates=27000, lr=1.33333e-05, gnorm=1.03, train_wall=63, wall=18876
2021-01-16 21:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:04:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:05:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:05:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:05:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:05:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:05:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:05:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:05:18 | INFO | valid | epoch 072 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.057 | ppl 16.65 | bleu 22.4 | wps 5183.9 | wpb 11799.1 | bsz 428.6 | num_updates 27000 | best_bleu 22.62
2021-01-16 21:05:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:05:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:05:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:05:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 72 @ 27000 updates, score 22.4) (writing took 3.155444707721472 seconds)
2021-01-16 21:05:21 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2021-01-16 21:05:21 | INFO | train | epoch 072 | symm_kl 0.486 | self_kl 0 | self_cv 0 | loss 3.326 | nll_loss 0.78 | ppl 1.72 | wps 22336.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 27000 | lr 1.33333e-05 | gnorm 1.011 | train_wall 236 | wall 18898
2021-01-16 21:05:21 | INFO | fairseq.trainer | begin training epoch 73
2021-01-16 21:05:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:05:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:06:28 | INFO | train_inner | epoch 073:    100 / 375 symm_kl=0.494, self_kl=0, self_cv=0, loss=3.345, nll_loss=0.786, ppl=1.72, wps=17590.8, ups=1.12, wpb=15741.3, bsz=535.1, num_updates=27100, lr=1.33087e-05, gnorm=1.015, train_wall=63, wall=18965
2021-01-16 21:07:32 | INFO | train_inner | epoch 073:    200 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.319, nll_loss=0.777, ppl=1.71, wps=24565.2, ups=1.57, wpb=15654, bsz=545.5, num_updates=27200, lr=1.32842e-05, gnorm=1.001, train_wall=63, wall=19029
2021-01-16 21:08:35 | INFO | train_inner | epoch 073:    300 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.312, nll_loss=0.775, ppl=1.71, wps=24592.5, ups=1.57, wpb=15626.6, bsz=584.2, num_updates=27300, lr=1.32599e-05, gnorm=1.001, train_wall=63, wall=19092
2021-01-16 21:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:09:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:09:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:09:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:09:40 | INFO | valid | epoch 073 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.055 | ppl 16.63 | bleu 22.35 | wps 5862.4 | wpb 11799.1 | bsz 428.6 | num_updates 27375 | best_bleu 22.62
2021-01-16 21:09:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:09:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:09:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:09:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 73 @ 27375 updates, score 22.35) (writing took 3.1904064808040857 seconds)
2021-01-16 21:09:43 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2021-01-16 21:09:43 | INFO | train | epoch 073 | symm_kl 0.486 | self_kl 0 | self_cv 0 | loss 3.326 | nll_loss 0.78 | ppl 1.72 | wps 22435.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 27375 | lr 1.32417e-05 | gnorm 1.006 | train_wall 237 | wall 19161
2021-01-16 21:09:43 | INFO | fairseq.trainer | begin training epoch 74
2021-01-16 21:09:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:09:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:10:02 | INFO | train_inner | epoch 074:     25 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.337, nll_loss=0.787, ppl=1.73, wps=18091.5, ups=1.15, wpb=15783.7, bsz=555.6, num_updates=27400, lr=1.32357e-05, gnorm=1.006, train_wall=63, wall=19180
2021-01-16 21:11:06 | INFO | train_inner | epoch 074:    125 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.32, nll_loss=0.78, ppl=1.72, wps=24801.9, ups=1.57, wpb=15811.2, bsz=561.2, num_updates=27500, lr=1.32116e-05, gnorm=0.996, train_wall=64, wall=19243
2021-01-16 21:12:10 | INFO | train_inner | epoch 074:    225 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.343, nll_loss=0.785, ppl=1.72, wps=24392.7, ups=1.58, wpb=15475.5, bsz=532.1, num_updates=27600, lr=1.31876e-05, gnorm=1.029, train_wall=63, wall=19307
2021-01-16 21:13:13 | INFO | train_inner | epoch 074:    325 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.771, ppl=1.71, wps=24900.1, ups=1.57, wpb=15872.9, bsz=556.2, num_updates=27700, lr=1.31638e-05, gnorm=0.989, train_wall=64, wall=19371
2021-01-16 21:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:13:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:13:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:13:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:13:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:13:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:13:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:13:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:13:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:13:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:13:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:14:03 | INFO | valid | epoch 074 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.06 | ppl 16.68 | bleu 22.45 | wps 5688.7 | wpb 11799.1 | bsz 428.6 | num_updates 27750 | best_bleu 22.62
2021-01-16 21:14:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:14:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:14:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:14:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 74 @ 27750 updates, score 22.45) (writing took 3.4326824881136417 seconds)
2021-01-16 21:14:07 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2021-01-16 21:14:07 | INFO | train | epoch 074 | symm_kl 0.485 | self_kl 0 | self_cv 0 | loss 3.324 | nll_loss 0.78 | ppl 1.72 | wps 22326 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 27750 | lr 1.31519e-05 | gnorm 1.007 | train_wall 237 | wall 19424
2021-01-16 21:14:07 | INFO | fairseq.trainer | begin training epoch 75
2021-01-16 21:14:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:14:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:14:42 | INFO | train_inner | epoch 075:     50 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.315, nll_loss=0.774, ppl=1.71, wps=17653.7, ups=1.13, wpb=15584.2, bsz=560, num_updates=27800, lr=1.31401e-05, gnorm=1.011, train_wall=63, wall=19459
2021-01-16 21:15:45 | INFO | train_inner | epoch 075:    150 / 375 symm_kl=0.488, self_kl=0, self_cv=0, loss=3.335, nll_loss=0.785, ppl=1.72, wps=24430.5, ups=1.57, wpb=15591.7, bsz=548.8, num_updates=27900, lr=1.31165e-05, gnorm=1.012, train_wall=64, wall=19523
2021-01-16 21:16:49 | INFO | train_inner | epoch 075:    250 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.302, nll_loss=0.769, ppl=1.7, wps=25021.6, ups=1.57, wpb=15902.1, bsz=567.7, num_updates=28000, lr=1.30931e-05, gnorm=0.998, train_wall=63, wall=19586
2021-01-16 21:17:53 | INFO | train_inner | epoch 075:    350 / 375 symm_kl=0.493, self_kl=0, self_cv=0, loss=3.347, nll_loss=0.791, ppl=1.73, wps=24470.3, ups=1.57, wpb=15629.3, bsz=539.9, num_updates=28100, lr=1.30698e-05, gnorm=1.016, train_wall=64, wall=19650
2021-01-16 21:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:18:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:18:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:18:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:18:29 | INFO | valid | epoch 075 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.058 | ppl 16.66 | bleu 22.36 | wps 5041.5 | wpb 11799.1 | bsz 428.6 | num_updates 28125 | best_bleu 22.62
2021-01-16 21:18:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:18:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 75 @ 28125 updates, score 22.36) (writing took 3.0689842831343412 seconds)
2021-01-16 21:18:32 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2021-01-16 21:18:32 | INFO | train | epoch 075 | symm_kl 0.485 | self_kl 0 | self_cv 0 | loss 3.325 | nll_loss 0.78 | ppl 1.72 | wps 22203 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 28125 | lr 1.30639e-05 | gnorm 1.009 | train_wall 237 | wall 19689
2021-01-16 21:18:32 | INFO | fairseq.trainer | begin training epoch 76
2021-01-16 21:18:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:18:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:18:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:18:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:19:22 | INFO | train_inner | epoch 076:     75 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.325, nll_loss=0.78, ppl=1.72, wps=17236, ups=1.12, wpb=15377.9, bsz=559, num_updates=28200, lr=1.30466e-05, gnorm=1.018, train_wall=62, wall=19739
2021-01-16 21:20:26 | INFO | train_inner | epoch 076:    175 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.318, nll_loss=0.778, ppl=1.72, wps=24646.5, ups=1.57, wpb=15690.6, bsz=574.2, num_updates=28300, lr=1.30235e-05, gnorm=1.004, train_wall=63, wall=19803
2021-01-16 21:21:29 | INFO | train_inner | epoch 076:    275 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.324, nll_loss=0.778, ppl=1.71, wps=24976.3, ups=1.58, wpb=15810.9, bsz=534.6, num_updates=28400, lr=1.30005e-05, gnorm=1.003, train_wall=63, wall=19866
2021-01-16 21:22:33 | INFO | train_inner | epoch 076:    375 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.782, ppl=1.72, wps=24706.6, ups=1.57, wpb=15694.5, bsz=540.8, num_updates=28500, lr=1.29777e-05, gnorm=1.01, train_wall=63, wall=19930
2021-01-16 21:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:22:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:22:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:22:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:22:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:22:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:22:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:22:52 | INFO | valid | epoch 076 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.06 | ppl 16.67 | bleu 22.26 | wps 5159.5 | wpb 11799.1 | bsz 428.6 | num_updates 28500 | best_bleu 22.62
2021-01-16 21:22:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 76 @ 28500 updates, score 22.26) (writing took 3.3940553963184357 seconds)
2021-01-16 21:22:55 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2021-01-16 21:22:55 | INFO | train | epoch 076 | symm_kl 0.484 | self_kl 0 | self_cv 0 | loss 3.323 | nll_loss 0.78 | ppl 1.72 | wps 22310.3 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 28500 | lr 1.29777e-05 | gnorm 1.007 | train_wall 236 | wall 19952
2021-01-16 21:22:55 | INFO | fairseq.trainer | begin training epoch 77
2021-01-16 21:22:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:22:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:22:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:22:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:24:02 | INFO | train_inner | epoch 077:    100 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.31, nll_loss=0.774, ppl=1.71, wps=17749.4, ups=1.12, wpb=15817.7, bsz=560.6, num_updates=28600, lr=1.2955e-05, gnorm=0.998, train_wall=62, wall=20019
2021-01-16 21:25:05 | INFO | train_inner | epoch 077:    200 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.313, nll_loss=0.771, ppl=1.71, wps=24869.1, ups=1.58, wpb=15780, bsz=550.6, num_updates=28700, lr=1.29324e-05, gnorm=1.005, train_wall=63, wall=20082
2021-01-16 21:26:08 | INFO | train_inner | epoch 077:    300 / 375 symm_kl=0.49, self_kl=0, self_cv=0, loss=3.341, nll_loss=0.789, ppl=1.73, wps=24650.7, ups=1.58, wpb=15571.6, bsz=553.9, num_updates=28800, lr=1.29099e-05, gnorm=1.017, train_wall=63, wall=20146
2021-01-16 21:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:26:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:26:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:26:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:26:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:26:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:26:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:27:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:27:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:27:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:27:15 | INFO | valid | epoch 077 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.681 | nll_loss 4.066 | ppl 16.75 | bleu 22.28 | wps 5301.7 | wpb 11799.1 | bsz 428.6 | num_updates 28875 | best_bleu 22.62
2021-01-16 21:27:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:27:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:27:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:27:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 77 @ 28875 updates, score 22.28) (writing took 3.0619218964129686 seconds)
2021-01-16 21:27:18 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2021-01-16 21:27:18 | INFO | train | epoch 077 | symm_kl 0.484 | self_kl 0 | self_cv 0 | loss 3.322 | nll_loss 0.779 | ppl 1.72 | wps 22345.1 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 28875 | lr 1.28932e-05 | gnorm 1.008 | train_wall 236 | wall 20216
2021-01-16 21:27:18 | INFO | fairseq.trainer | begin training epoch 78
2021-01-16 21:27:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:27:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:27:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:27:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:27:38 | INFO | train_inner | epoch 078:     25 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.78, ppl=1.72, wps=17290.3, ups=1.11, wpb=15532.8, bsz=539.8, num_updates=28900, lr=1.28876e-05, gnorm=1.016, train_wall=63, wall=20235
2021-01-16 21:28:41 | INFO | train_inner | epoch 078:    125 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.313, nll_loss=0.772, ppl=1.71, wps=24759.9, ups=1.58, wpb=15623.2, bsz=551.4, num_updates=29000, lr=1.28654e-05, gnorm=1.01, train_wall=63, wall=20298
2021-01-16 21:29:45 | INFO | train_inner | epoch 078:    225 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.77, ppl=1.71, wps=25031.4, ups=1.57, wpb=15962.6, bsz=559.6, num_updates=29100, lr=1.28432e-05, gnorm=0.986, train_wall=64, wall=20362
2021-01-16 21:30:48 | INFO | train_inner | epoch 078:    325 / 375 symm_kl=0.491, self_kl=0, self_cv=0, loss=3.344, nll_loss=0.792, ppl=1.73, wps=24572.8, ups=1.58, wpb=15525.6, bsz=557, num_updates=29200, lr=1.28212e-05, gnorm=1.026, train_wall=63, wall=20425
2021-01-16 21:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:31:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:31:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:31:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:31:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:31:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:31:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:31:39 | INFO | valid | epoch 078 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.057 | ppl 16.64 | bleu 22.49 | wps 5333.1 | wpb 11799.1 | bsz 428.6 | num_updates 29250 | best_bleu 22.62
2021-01-16 21:31:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:31:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:31:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:31:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 78 @ 29250 updates, score 22.49) (writing took 3.0477330312132835 seconds)
2021-01-16 21:31:42 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2021-01-16 21:31:42 | INFO | train | epoch 078 | symm_kl 0.483 | self_kl 0 | self_cv 0 | loss 3.32 | nll_loss 0.778 | ppl 1.71 | wps 22297.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 29250 | lr 1.28103e-05 | gnorm 1.009 | train_wall 237 | wall 20479
2021-01-16 21:31:42 | INFO | fairseq.trainer | begin training epoch 79
2021-01-16 21:31:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:31:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:32:18 | INFO | train_inner | epoch 079:     50 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.321, nll_loss=0.779, ppl=1.72, wps=17648.9, ups=1.12, wpb=15805.8, bsz=563.6, num_updates=29300, lr=1.27993e-05, gnorm=1.002, train_wall=63, wall=20515
2021-01-16 21:33:21 | INFO | train_inner | epoch 079:    150 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.323, nll_loss=0.777, ppl=1.71, wps=25151.3, ups=1.58, wpb=15873.7, bsz=529.9, num_updates=29400, lr=1.27775e-05, gnorm=1.002, train_wall=63, wall=20578
2021-01-16 21:34:25 | INFO | train_inner | epoch 079:    250 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.776, ppl=1.71, wps=24706.5, ups=1.57, wpb=15766.3, bsz=553.1, num_updates=29500, lr=1.27559e-05, gnorm=0.996, train_wall=64, wall=20642
2021-01-16 21:35:28 | INFO | train_inner | epoch 079:    350 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.325, nll_loss=0.784, ppl=1.72, wps=24369.4, ups=1.59, wpb=15359.6, bsz=560.8, num_updates=29600, lr=1.27343e-05, gnorm=1.008, train_wall=63, wall=20705
2021-01-16 21:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:35:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:35:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:35:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:35:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:35:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:35:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:35:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:35:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:35:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:35:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:36:03 | INFO | valid | epoch 079 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.058 | ppl 16.66 | bleu 22.39 | wps 5206.5 | wpb 11799.1 | bsz 428.6 | num_updates 29625 | best_bleu 22.62
2021-01-16 21:36:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:36:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:36:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:36:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:36:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:36:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 79 @ 29625 updates, score 22.39) (writing took 3.0955829713493586 seconds)
2021-01-16 21:36:06 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2021-01-16 21:36:06 | INFO | train | epoch 079 | symm_kl 0.482 | self_kl 0 | self_cv 0 | loss 3.32 | nll_loss 0.779 | ppl 1.72 | wps 22295.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 29625 | lr 1.27289e-05 | gnorm 1.002 | train_wall 237 | wall 20743
2021-01-16 21:36:06 | INFO | fairseq.trainer | begin training epoch 80
2021-01-16 21:36:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:36:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:36:57 | INFO | train_inner | epoch 080:     75 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.31, nll_loss=0.776, ppl=1.71, wps=17512.7, ups=1.12, wpb=15641.6, bsz=573.3, num_updates=29700, lr=1.27128e-05, gnorm=1.003, train_wall=63, wall=20794
2021-01-16 21:38:01 | INFO | train_inner | epoch 080:    175 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.768, ppl=1.7, wps=24609.4, ups=1.57, wpb=15675.7, bsz=568.2, num_updates=29800, lr=1.26915e-05, gnorm=1.004, train_wall=63, wall=20858
2021-01-16 21:39:05 | INFO | train_inner | epoch 080:    275 / 375 symm_kl=0.487, self_kl=0, self_cv=0, loss=3.333, nll_loss=0.784, ppl=1.72, wps=24615.8, ups=1.57, wpb=15726.8, bsz=522, num_updates=29900, lr=1.26702e-05, gnorm=1.011, train_wall=64, wall=20922
2021-01-16 21:40:08 | INFO | train_inner | epoch 080:    375 / 375 symm_kl=0.484, self_kl=0, self_cv=0, loss=3.327, nll_loss=0.785, ppl=1.72, wps=24613.6, ups=1.58, wpb=15583.5, bsz=551, num_updates=30000, lr=1.26491e-05, gnorm=1.013, train_wall=63, wall=20985
2021-01-16 21:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:40:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:40:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:40:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:40:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:40:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:40:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:40:27 | INFO | valid | epoch 080 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.059 | ppl 16.67 | bleu 22.44 | wps 5356.2 | wpb 11799.1 | bsz 428.6 | num_updates 30000 | best_bleu 22.62
2021-01-16 21:40:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:40:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:40:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 80 @ 30000 updates, score 22.44) (writing took 3.032544692978263 seconds)
2021-01-16 21:40:30 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2021-01-16 21:40:30 | INFO | train | epoch 080 | symm_kl 0.482 | self_kl 0 | self_cv 0 | loss 3.319 | nll_loss 0.778 | ppl 1.72 | wps 22295.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 30000 | lr 1.26491e-05 | gnorm 1.006 | train_wall 237 | wall 21007
2021-01-16 21:40:30 | INFO | fairseq.trainer | begin training epoch 81
2021-01-16 21:40:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:40:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:40:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:41:37 | INFO | train_inner | epoch 081:    100 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.78, ppl=1.72, wps=17724.8, ups=1.12, wpb=15756.6, bsz=565.4, num_updates=30100, lr=1.26281e-05, gnorm=0.998, train_wall=63, wall=21074
2021-01-16 21:42:40 | INFO | train_inner | epoch 081:    200 / 375 symm_kl=0.484, self_kl=0, self_cv=0, loss=3.325, nll_loss=0.781, ppl=1.72, wps=24550.1, ups=1.58, wpb=15577, bsz=542.2, num_updates=30200, lr=1.26072e-05, gnorm=1.009, train_wall=63, wall=21138
2021-01-16 21:43:43 | INFO | train_inner | epoch 081:    300 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.774, ppl=1.71, wps=24936.5, ups=1.59, wpb=15714.8, bsz=561.3, num_updates=30300, lr=1.25863e-05, gnorm=1.001, train_wall=63, wall=21201
2021-01-16 21:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:44:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:44:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:44:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:44:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:44:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:44:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:44:49 | INFO | valid | epoch 081 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.061 | ppl 16.69 | bleu 22.41 | wps 5476.2 | wpb 11799.1 | bsz 428.6 | num_updates 30375 | best_bleu 22.62
2021-01-16 21:44:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:44:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:44:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 81 @ 30375 updates, score 22.41) (writing took 2.8793527465313673 seconds)
2021-01-16 21:44:52 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2021-01-16 21:44:52 | INFO | train | epoch 081 | symm_kl 0.482 | self_kl 0 | self_cv 0 | loss 3.318 | nll_loss 0.778 | ppl 1.71 | wps 22401.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 30375 | lr 1.25708e-05 | gnorm 1.005 | train_wall 236 | wall 21270
2021-01-16 21:44:52 | INFO | fairseq.trainer | begin training epoch 82
2021-01-16 21:44:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:45:12 | INFO | train_inner | epoch 082:     25 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.776, ppl=1.71, wps=17771.6, ups=1.13, wpb=15715.6, bsz=554.6, num_updates=30400, lr=1.25656e-05, gnorm=1.005, train_wall=63, wall=21289
2021-01-16 21:46:15 | INFO | train_inner | epoch 082:    125 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.77, ppl=1.7, wps=24891.4, ups=1.57, wpb=15814.3, bsz=533.3, num_updates=30500, lr=1.2545e-05, gnorm=1.002, train_wall=63, wall=21353
2021-01-16 21:47:19 | INFO | train_inner | epoch 082:    225 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.775, ppl=1.71, wps=24822, ups=1.57, wpb=15794, bsz=572.2, num_updates=30600, lr=1.25245e-05, gnorm=1.001, train_wall=63, wall=21416
2021-01-16 21:48:22 | INFO | train_inner | epoch 082:    325 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.326, nll_loss=0.783, ppl=1.72, wps=24680.8, ups=1.58, wpb=15578.4, bsz=545.4, num_updates=30700, lr=1.25041e-05, gnorm=1.019, train_wall=63, wall=21479
2021-01-16 21:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:48:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:48:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:48:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:48:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:48:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:48:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:48:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:48:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:48:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:48:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:48:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:48:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:48:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:48:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:48:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:49:13 | INFO | valid | epoch 082 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.062 | ppl 16.7 | bleu 22.4 | wps 5167.7 | wpb 11799.1 | bsz 428.6 | num_updates 30750 | best_bleu 22.62
2021-01-16 21:49:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:49:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:49:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:49:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 82 @ 30750 updates, score 22.4) (writing took 3.156697753816843 seconds)
2021-01-16 21:49:16 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2021-01-16 21:49:16 | INFO | train | epoch 082 | symm_kl 0.481 | self_kl 0 | self_cv 0 | loss 3.317 | nll_loss 0.777 | ppl 1.71 | wps 22281.9 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 30750 | lr 1.24939e-05 | gnorm 1.008 | train_wall 237 | wall 21534
2021-01-16 21:49:16 | INFO | fairseq.trainer | begin training epoch 83
2021-01-16 21:49:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:49:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:49:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:49:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:49:52 | INFO | train_inner | epoch 083:     50 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.772, ppl=1.71, wps=17374.4, ups=1.11, wpb=15594.3, bsz=569, num_updates=30800, lr=1.24838e-05, gnorm=1.001, train_wall=63, wall=21569
2021-01-16 21:50:56 | INFO | train_inner | epoch 083:    150 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.775, ppl=1.71, wps=24870, ups=1.57, wpb=15872.5, bsz=528, num_updates=30900, lr=1.24635e-05, gnorm=1.004, train_wall=64, wall=21633
2021-01-16 21:51:59 | INFO | train_inner | epoch 083:    250 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.32, nll_loss=0.783, ppl=1.72, wps=24840.3, ups=1.57, wpb=15823.1, bsz=567.1, num_updates=31000, lr=1.24434e-05, gnorm=0.997, train_wall=63, wall=21697
2021-01-16 21:53:03 | INFO | train_inner | epoch 083:    350 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.328, nll_loss=0.782, ppl=1.72, wps=24144.3, ups=1.57, wpb=15388.5, bsz=547.1, num_updates=31100, lr=1.24234e-05, gnorm=1.02, train_wall=63, wall=21760
2021-01-16 21:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:53:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:53:38 | INFO | valid | epoch 083 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.065 | ppl 16.74 | bleu 22.44 | wps 5371.4 | wpb 11799.1 | bsz 428.6 | num_updates 31125 | best_bleu 22.62
2021-01-16 21:53:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 83 @ 31125 updates, score 22.44) (writing took 3.200709519907832 seconds)
2021-01-16 21:53:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2021-01-16 21:53:41 | INFO | train | epoch 083 | symm_kl 0.48 | self_kl 0 | self_cv 0 | loss 3.315 | nll_loss 0.777 | ppl 1.71 | wps 22191.5 | ups 1.41 | wpb 15683.1 | bsz 553 | num_updates 31125 | lr 1.24184e-05 | gnorm 1.004 | train_wall 238 | wall 21799
2021-01-16 21:53:41 | INFO | fairseq.trainer | begin training epoch 84
2021-01-16 21:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:53:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:53:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:54:32 | INFO | train_inner | epoch 084:     75 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.307, nll_loss=0.776, ppl=1.71, wps=17605.9, ups=1.12, wpb=15721.3, bsz=563.3, num_updates=31200, lr=1.24035e-05, gnorm=0.996, train_wall=62, wall=21850
2021-01-16 21:55:36 | INFO | train_inner | epoch 084:    175 / 375 symm_kl=0.486, self_kl=0, self_cv=0, loss=3.325, nll_loss=0.777, ppl=1.71, wps=24117.9, ups=1.58, wpb=15308.7, bsz=534.2, num_updates=31300, lr=1.23836e-05, gnorm=1.029, train_wall=63, wall=21913
2021-01-16 21:56:39 | INFO | train_inner | epoch 084:    275 / 375 symm_kl=0.486, self_kl=0, self_cv=0, loss=3.332, nll_loss=0.787, ppl=1.72, wps=24867.1, ups=1.57, wpb=15814, bsz=553.4, num_updates=31400, lr=1.23639e-05, gnorm=0.999, train_wall=63, wall=21977
2021-01-16 21:57:43 | INFO | train_inner | epoch 084:    375 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.768, ppl=1.7, wps=24874.7, ups=1.58, wpb=15773.5, bsz=558.3, num_updates=31500, lr=1.23443e-05, gnorm=0.991, train_wall=63, wall=22040
2021-01-16 21:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 21:57:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:57:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:57:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:57:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:57:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:57:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:57:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:57:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 21:57:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 21:57:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 21:58:02 | INFO | valid | epoch 084 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.056 | ppl 16.64 | bleu 22.47 | wps 5174.5 | wpb 11799.1 | bsz 428.6 | num_updates 31500 | best_bleu 22.62
2021-01-16 21:58:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 21:58:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:58:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:58:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:58:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 84 @ 31500 updates, score 22.47) (writing took 3.02407918125391 seconds)
2021-01-16 21:58:05 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2021-01-16 21:58:05 | INFO | train | epoch 084 | symm_kl 0.48 | self_kl 0 | self_cv 0 | loss 3.314 | nll_loss 0.777 | ppl 1.71 | wps 22282.8 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 31500 | lr 1.23443e-05 | gnorm 1.002 | train_wall 237 | wall 22062
2021-01-16 21:58:05 | INFO | fairseq.trainer | begin training epoch 85
2021-01-16 21:58:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:58:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 21:58:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 21:59:13 | INFO | train_inner | epoch 085:    100 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.773, ppl=1.71, wps=17672.5, ups=1.11, wpb=15882, bsz=583, num_updates=31600, lr=1.23247e-05, gnorm=0.984, train_wall=63, wall=22130
2021-01-16 22:00:16 | INFO | train_inner | epoch 085:    200 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.31, nll_loss=0.776, ppl=1.71, wps=24209.5, ups=1.57, wpb=15436.2, bsz=562, num_updates=31700, lr=1.23053e-05, gnorm=1.024, train_wall=64, wall=22194
2021-01-16 22:01:20 | INFO | train_inner | epoch 085:    300 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.772, ppl=1.71, wps=24606.1, ups=1.56, wpb=15743.3, bsz=542.5, num_updates=31800, lr=1.22859e-05, gnorm=1.002, train_wall=64, wall=22258
2021-01-16 22:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:02:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:02:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:02:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:02:28 | INFO | valid | epoch 085 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.668 | nll_loss 4.054 | ppl 16.61 | bleu 22.39 | wps 5102.5 | wpb 11799.1 | bsz 428.6 | num_updates 31875 | best_bleu 22.62
2021-01-16 22:02:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:02:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 85 @ 31875 updates, score 22.39) (writing took 3.047384638339281 seconds)
2021-01-16 22:02:31 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2021-01-16 22:02:31 | INFO | train | epoch 085 | symm_kl 0.48 | self_kl 0 | self_cv 0 | loss 3.314 | nll_loss 0.776 | ppl 1.71 | wps 22082.7 | ups 1.41 | wpb 15683.1 | bsz 553 | num_updates 31875 | lr 1.22714e-05 | gnorm 1.008 | train_wall 238 | wall 22329
2021-01-16 22:02:31 | INFO | fairseq.trainer | begin training epoch 86
2021-01-16 22:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:02:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:02:51 | INFO | train_inner | epoch 086:     25 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.339, nll_loss=0.787, ppl=1.73, wps=17138, ups=1.1, wpb=15557.1, bsz=521.8, num_updates=31900, lr=1.22666e-05, gnorm=1.032, train_wall=63, wall=22348
2021-01-16 22:03:55 | INFO | train_inner | epoch 086:    125 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.772, ppl=1.71, wps=24853.1, ups=1.56, wpb=15884.1, bsz=565.8, num_updates=32000, lr=1.22474e-05, gnorm=0.998, train_wall=64, wall=22412
2021-01-16 22:04:59 | INFO | train_inner | epoch 086:    225 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.775, ppl=1.71, wps=24593.1, ups=1.56, wpb=15761, bsz=557.4, num_updates=32100, lr=1.22284e-05, gnorm=0.995, train_wall=64, wall=22476
2021-01-16 22:06:03 | INFO | train_inner | epoch 086:    325 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.78, ppl=1.72, wps=24564.3, ups=1.56, wpb=15706.1, bsz=536.7, num_updates=32200, lr=1.22094e-05, gnorm=1.005, train_wall=64, wall=22540
2021-01-16 22:06:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:06:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:06:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:06:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:06:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:06:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:06:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:06:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:06:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:06:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:06:55 | INFO | valid | epoch 086 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.059 | ppl 16.67 | bleu 22.4 | wps 5005.7 | wpb 11799.1 | bsz 428.6 | num_updates 32250 | best_bleu 22.62
2021-01-16 22:06:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:06:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:06:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:06:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 86 @ 32250 updates, score 22.4) (writing took 3.01615309715271 seconds)
2021-01-16 22:06:58 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2021-01-16 22:06:58 | INFO | train | epoch 086 | symm_kl 0.479 | self_kl 0 | self_cv 0 | loss 3.313 | nll_loss 0.776 | ppl 1.71 | wps 22089 | ups 1.41 | wpb 15683.1 | bsz 553 | num_updates 32250 | lr 1.21999e-05 | gnorm 1.004 | train_wall 238 | wall 22595
2021-01-16 22:06:58 | INFO | fairseq.trainer | begin training epoch 87
2021-01-16 22:06:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:06:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:06:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:07:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:07:33 | INFO | train_inner | epoch 087:     50 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.769, ppl=1.7, wps=17331.1, ups=1.11, wpb=15610.9, bsz=569.3, num_updates=32300, lr=1.21904e-05, gnorm=0.991, train_wall=63, wall=22630
2021-01-16 22:08:37 | INFO | train_inner | epoch 087:    150 / 375 symm_kl=0.489, self_kl=0, self_cv=0, loss=3.335, nll_loss=0.783, ppl=1.72, wps=24475.8, ups=1.57, wpb=15562.6, bsz=510, num_updates=32400, lr=1.21716e-05, gnorm=1.025, train_wall=63, wall=22694
2021-01-16 22:09:40 | INFO | train_inner | epoch 087:    250 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.776, ppl=1.71, wps=24858.1, ups=1.57, wpb=15814, bsz=563.2, num_updates=32500, lr=1.21529e-05, gnorm=0.997, train_wall=63, wall=22758
2021-01-16 22:10:44 | INFO | train_inner | epoch 087:    350 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.777, ppl=1.71, wps=24702.9, ups=1.58, wpb=15635.8, bsz=583.8, num_updates=32600, lr=1.21342e-05, gnorm=0.996, train_wall=63, wall=22821
2021-01-16 22:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:11:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:11:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:11:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:11:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:11:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:11:20 | INFO | valid | epoch 087 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.059 | ppl 16.66 | bleu 22.53 | wps 5083.6 | wpb 11799.1 | bsz 428.6 | num_updates 32625 | best_bleu 22.62
2021-01-16 22:11:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:11:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 87 @ 32625 updates, score 22.53) (writing took 2.9467226155102253 seconds)
2021-01-16 22:11:23 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2021-01-16 22:11:23 | INFO | train | epoch 087 | symm_kl 0.479 | self_kl 0 | self_cv 0 | loss 3.312 | nll_loss 0.776 | ppl 1.71 | wps 22139.4 | ups 1.41 | wpb 15683.1 | bsz 553 | num_updates 32625 | lr 1.21296e-05 | gnorm 1.002 | train_wall 237 | wall 22861
2021-01-16 22:11:23 | INFO | fairseq.trainer | begin training epoch 88
2021-01-16 22:11:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:11:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:11:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:11:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:12:14 | INFO | train_inner | epoch 088:     75 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.777, ppl=1.71, wps=17240.2, ups=1.1, wpb=15617.9, bsz=543.5, num_updates=32700, lr=1.21157e-05, gnorm=1.01, train_wall=63, wall=22912
2021-01-16 22:13:18 | INFO | train_inner | epoch 088:    175 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.779, ppl=1.72, wps=24861, ups=1.57, wpb=15804.8, bsz=560.4, num_updates=32800, lr=1.20972e-05, gnorm=0.989, train_wall=63, wall=22975
2021-01-16 22:14:21 | INFO | train_inner | epoch 088:    275 / 375 symm_kl=0.483, self_kl=0, self_cv=0, loss=3.319, nll_loss=0.775, ppl=1.71, wps=24534.7, ups=1.58, wpb=15520.1, bsz=541.6, num_updates=32900, lr=1.20788e-05, gnorm=1.013, train_wall=63, wall=23038
2021-01-16 22:15:25 | INFO | train_inner | epoch 088:    375 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.292, nll_loss=0.768, ppl=1.7, wps=24624.9, ups=1.57, wpb=15710.8, bsz=554.1, num_updates=33000, lr=1.20605e-05, gnorm=1.001, train_wall=64, wall=23102
2021-01-16 22:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:15:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:15:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:15:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:15:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:15:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:15:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:15:44 | INFO | valid | epoch 088 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.059 | ppl 16.67 | bleu 22.49 | wps 5355.1 | wpb 11799.1 | bsz 428.6 | num_updates 33000 | best_bleu 22.62
2021-01-16 22:15:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:15:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 88 @ 33000 updates, score 22.49) (writing took 2.930887905880809 seconds)
2021-01-16 22:15:47 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2021-01-16 22:15:47 | INFO | train | epoch 088 | symm_kl 0.478 | self_kl 0 | self_cv 0 | loss 3.311 | nll_loss 0.776 | ppl 1.71 | wps 22331.4 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 33000 | lr 1.20605e-05 | gnorm 1.002 | train_wall 237 | wall 23124
2021-01-16 22:15:47 | INFO | fairseq.trainer | begin training epoch 89
2021-01-16 22:15:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:15:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:15:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:15:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:16:53 | INFO | train_inner | epoch 089:    100 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.77, ppl=1.71, wps=17640.5, ups=1.14, wpb=15500.5, bsz=573.1, num_updates=33100, lr=1.20422e-05, gnorm=1.002, train_wall=62, wall=23190
2021-01-16 22:17:56 | INFO | train_inner | epoch 089:    200 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.315, nll_loss=0.776, ppl=1.71, wps=24767.5, ups=1.57, wpb=15782.2, bsz=528.4, num_updates=33200, lr=1.20241e-05, gnorm=1.015, train_wall=63, wall=23254
2021-01-16 22:19:00 | INFO | train_inner | epoch 089:    300 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.311, nll_loss=0.777, ppl=1.71, wps=24992.2, ups=1.58, wpb=15782.5, bsz=550.2, num_updates=33300, lr=1.2006e-05, gnorm=1.001, train_wall=63, wall=23317
2021-01-16 22:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:19:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:19:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:19:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:19:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:19:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:19:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:19:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:19:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:19:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:19:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:20:06 | INFO | valid | epoch 089 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.057 | ppl 16.65 | bleu 22.42 | wps 5405.7 | wpb 11799.1 | bsz 428.6 | num_updates 33375 | best_bleu 22.62
2021-01-16 22:20:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:20:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:20:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:20:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:20:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:20:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 89 @ 33375 updates, score 22.42) (writing took 3.0497354436665773 seconds)
2021-01-16 22:20:09 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2021-01-16 22:20:09 | INFO | train | epoch 089 | symm_kl 0.478 | self_kl 0 | self_cv 0 | loss 3.311 | nll_loss 0.776 | ppl 1.71 | wps 22433.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 33375 | lr 1.19925e-05 | gnorm 1.006 | train_wall 236 | wall 23386
2021-01-16 22:20:09 | INFO | fairseq.trainer | begin training epoch 90
2021-01-16 22:20:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:20:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:20:29 | INFO | train_inner | epoch 090:     25 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.777, ppl=1.71, wps=17664.1, ups=1.12, wpb=15705.8, bsz=551.2, num_updates=33400, lr=1.1988e-05, gnorm=0.999, train_wall=63, wall=23406
2021-01-16 22:21:32 | INFO | train_inner | epoch 090:    125 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.317, nll_loss=0.78, ppl=1.72, wps=24562.8, ups=1.59, wpb=15482.7, bsz=561.8, num_updates=33500, lr=1.19701e-05, gnorm=0.999, train_wall=63, wall=23469
2021-01-16 22:22:35 | INFO | train_inner | epoch 090:    225 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.775, ppl=1.71, wps=24849.6, ups=1.59, wpb=15661.4, bsz=547.5, num_updates=33600, lr=1.19523e-05, gnorm=1.005, train_wall=63, wall=23532
2021-01-16 22:23:38 | INFO | train_inner | epoch 090:    325 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.772, ppl=1.71, wps=24821.5, ups=1.57, wpb=15818.3, bsz=540.1, num_updates=33700, lr=1.19345e-05, gnorm=1.002, train_wall=63, wall=23596
2021-01-16 22:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:24:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:24:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:24:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:24:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:24:29 | INFO | valid | epoch 090 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.06 | ppl 16.67 | bleu 22.41 | wps 5639.9 | wpb 11799.1 | bsz 428.6 | num_updates 33750 | best_bleu 22.62
2021-01-16 22:24:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:24:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:24:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:24:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 90 @ 33750 updates, score 22.41) (writing took 3.2035806514322758 seconds)
2021-01-16 22:24:32 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2021-01-16 22:24:32 | INFO | train | epoch 090 | symm_kl 0.478 | self_kl 0 | self_cv 0 | loss 3.31 | nll_loss 0.775 | ppl 1.71 | wps 22378.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 33750 | lr 1.19257e-05 | gnorm 0.998 | train_wall 236 | wall 23649
2021-01-16 22:24:32 | INFO | fairseq.trainer | begin training epoch 91
2021-01-16 22:24:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:24:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:25:07 | INFO | train_inner | epoch 091:     50 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.774, ppl=1.71, wps=17620.5, ups=1.13, wpb=15560.5, bsz=578.8, num_updates=33800, lr=1.19169e-05, gnorm=1, train_wall=63, wall=23684
2021-01-16 22:26:10 | INFO | train_inner | epoch 091:    150 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.311, nll_loss=0.78, ppl=1.72, wps=24995, ups=1.58, wpb=15806.9, bsz=570.7, num_updates=33900, lr=1.18993e-05, gnorm=0.99, train_wall=63, wall=23747
2021-01-16 22:27:13 | INFO | train_inner | epoch 091:    250 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.312, nll_loss=0.773, ppl=1.71, wps=24687.2, ups=1.58, wpb=15588, bsz=534.2, num_updates=34000, lr=1.18818e-05, gnorm=1.006, train_wall=63, wall=23810
2021-01-16 22:28:17 | INFO | train_inner | epoch 091:    350 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.772, ppl=1.71, wps=24876.5, ups=1.57, wpb=15800.9, bsz=550.2, num_updates=34100, lr=1.18643e-05, gnorm=1.004, train_wall=63, wall=23874
2021-01-16 22:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:28:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:28:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:28:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:28:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:28:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:28:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:28:51 | INFO | valid | epoch 091 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.063 | ppl 16.71 | bleu 22.42 | wps 5303 | wpb 11799.1 | bsz 428.6 | num_updates 34125 | best_bleu 22.62
2021-01-16 22:28:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:28:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:28:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:28:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 91 @ 34125 updates, score 22.42) (writing took 3.0823847260326147 seconds)
2021-01-16 22:28:54 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2021-01-16 22:28:54 | INFO | train | epoch 091 | symm_kl 0.477 | self_kl 0 | self_cv 0 | loss 3.308 | nll_loss 0.774 | ppl 1.71 | wps 22392.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 34125 | lr 1.186e-05 | gnorm 1.002 | train_wall 236 | wall 23912
2021-01-16 22:28:54 | INFO | fairseq.trainer | begin training epoch 92
2021-01-16 22:28:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:28:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:29:45 | INFO | train_inner | epoch 092:     75 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.767, ppl=1.7, wps=17772.1, ups=1.13, wpb=15771.7, bsz=558.1, num_updates=34200, lr=1.1847e-05, gnorm=0.997, train_wall=63, wall=23963
2021-01-16 22:30:48 | INFO | train_inner | epoch 092:    175 / 375 symm_kl=0.478, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.778, ppl=1.71, wps=24771, ups=1.59, wpb=15608.2, bsz=551, num_updates=34300, lr=1.18297e-05, gnorm=1.005, train_wall=63, wall=24026
2021-01-16 22:31:52 | INFO | train_inner | epoch 092:    275 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.3, nll_loss=0.768, ppl=1.7, wps=24571.1, ups=1.57, wpb=15616.2, bsz=531.6, num_updates=34400, lr=1.18125e-05, gnorm=1.003, train_wall=63, wall=24089
2021-01-16 22:32:55 | INFO | train_inner | epoch 092:    375 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.321, nll_loss=0.785, ppl=1.72, wps=24896.7, ups=1.58, wpb=15760.6, bsz=568.2, num_updates=34500, lr=1.17954e-05, gnorm=1.023, train_wall=63, wall=24152
2021-01-16 22:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:32:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:32:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:32:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:32:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:32:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:32:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:33:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:33:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:33:14 | INFO | valid | epoch 092 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.058 | ppl 16.66 | bleu 22.45 | wps 5341.7 | wpb 11799.1 | bsz 428.6 | num_updates 34500 | best_bleu 22.62
2021-01-16 22:33:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:33:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:33:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:33:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 92 @ 34500 updates, score 22.45) (writing took 2.710240690037608 seconds)
2021-01-16 22:33:17 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2021-01-16 22:33:17 | INFO | train | epoch 092 | symm_kl 0.477 | self_kl 0 | self_cv 0 | loss 3.308 | nll_loss 0.774 | ppl 1.71 | wps 22418.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 34500 | lr 1.17954e-05 | gnorm 1.008 | train_wall 236 | wall 24174
2021-01-16 22:33:17 | INFO | fairseq.trainer | begin training epoch 93
2021-01-16 22:33:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:33:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:33:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:33:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:34:23 | INFO | train_inner | epoch 093:    100 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.765, ppl=1.7, wps=17951.6, ups=1.13, wpb=15822.9, bsz=562.8, num_updates=34600, lr=1.17783e-05, gnorm=0.994, train_wall=63, wall=24241
2021-01-16 22:35:26 | INFO | train_inner | epoch 093:    200 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.32, nll_loss=0.781, ppl=1.72, wps=24604.6, ups=1.59, wpb=15453.7, bsz=545.6, num_updates=34700, lr=1.17613e-05, gnorm=1.012, train_wall=63, wall=24303
2021-01-16 22:36:30 | INFO | train_inner | epoch 093:    300 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.306, nll_loss=0.774, ppl=1.71, wps=24852.9, ups=1.57, wpb=15810.6, bsz=557.4, num_updates=34800, lr=1.17444e-05, gnorm=0.996, train_wall=63, wall=24367
2021-01-16 22:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:37:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:37:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:37:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:37:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:37:37 | INFO | valid | epoch 093 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.056 | ppl 16.63 | bleu 22.43 | wps 5078.5 | wpb 11799.1 | bsz 428.6 | num_updates 34875 | best_bleu 22.62
2021-01-16 22:37:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:37:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 93 @ 34875 updates, score 22.43) (writing took 3.2034514136612415 seconds)
2021-01-16 22:37:40 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2021-01-16 22:37:40 | INFO | train | epoch 093 | symm_kl 0.477 | self_kl 0 | self_cv 0 | loss 3.307 | nll_loss 0.774 | ppl 1.71 | wps 22310.7 | ups 1.42 | wpb 15683.1 | bsz 553 | num_updates 34875 | lr 1.17318e-05 | gnorm 1 | train_wall 236 | wall 24438
2021-01-16 22:37:40 | INFO | fairseq.trainer | begin training epoch 94
2021-01-16 22:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:37:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:37:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:37:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:38:00 | INFO | train_inner | epoch 094:     25 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.769, ppl=1.7, wps=17441.1, ups=1.11, wpb=15672, bsz=543.3, num_updates=34900, lr=1.17276e-05, gnorm=0.996, train_wall=63, wall=24457
2021-01-16 22:39:03 | INFO | train_inner | epoch 094:    125 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.773, ppl=1.71, wps=24905.5, ups=1.59, wpb=15708.4, bsz=520.7, num_updates=35000, lr=1.17108e-05, gnorm=1.01, train_wall=63, wall=24520
2021-01-16 22:40:06 | INFO | train_inner | epoch 094:    225 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.78, ppl=1.72, wps=24930.1, ups=1.58, wpb=15818, bsz=571.1, num_updates=35100, lr=1.16941e-05, gnorm=0.984, train_wall=63, wall=24583
2021-01-16 22:41:09 | INFO | train_inner | epoch 094:    325 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.781, ppl=1.72, wps=24545.5, ups=1.58, wpb=15520.2, bsz=562.5, num_updates=35200, lr=1.16775e-05, gnorm=1.014, train_wall=63, wall=24647
2021-01-16 22:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:41:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:41:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:41:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:42:00 | INFO | valid | epoch 094 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.06 | ppl 16.67 | bleu 22.35 | wps 5560.9 | wpb 11799.1 | bsz 428.6 | num_updates 35250 | best_bleu 22.62
2021-01-16 22:42:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:42:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:42:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:42:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:42:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 94 @ 35250 updates, score 22.35) (writing took 3.022173773497343 seconds)
2021-01-16 22:42:03 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2021-01-16 22:42:03 | INFO | train | epoch 094 | symm_kl 0.476 | self_kl 0 | self_cv 0 | loss 3.306 | nll_loss 0.774 | ppl 1.71 | wps 22398.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 35250 | lr 1.16692e-05 | gnorm 0.998 | train_wall 236 | wall 24700
2021-01-16 22:42:03 | INFO | fairseq.trainer | begin training epoch 95
2021-01-16 22:42:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:42:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:42:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:42:38 | INFO | train_inner | epoch 095:     50 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.281, nll_loss=0.761, ppl=1.7, wps=17724.1, ups=1.13, wpb=15655.2, bsz=577.2, num_updates=35300, lr=1.16609e-05, gnorm=0.98, train_wall=62, wall=24735
2021-01-16 22:43:40 | INFO | train_inner | epoch 095:    150 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.318, nll_loss=0.779, ppl=1.72, wps=25061.7, ups=1.59, wpb=15749.8, bsz=537.8, num_updates=35400, lr=1.16445e-05, gnorm=1.005, train_wall=63, wall=24798
2021-01-16 22:44:44 | INFO | train_inner | epoch 095:    250 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.322, nll_loss=0.781, ppl=1.72, wps=24439.6, ups=1.58, wpb=15466.7, bsz=537.1, num_updates=35500, lr=1.1628e-05, gnorm=1.011, train_wall=63, wall=24861
2021-01-16 22:45:47 | INFO | train_inner | epoch 095:    350 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.768, ppl=1.7, wps=25301, ups=1.59, wpb=15888.9, bsz=572.5, num_updates=35600, lr=1.16117e-05, gnorm=0.989, train_wall=63, wall=24924
2021-01-16 22:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:46:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:46:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:46:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:46:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:46:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:46:21 | INFO | valid | epoch 095 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.063 | ppl 16.71 | bleu 22.44 | wps 5480.1 | wpb 11799.1 | bsz 428.6 | num_updates 35625 | best_bleu 22.62
2021-01-16 22:46:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:46:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 95 @ 35625 updates, score 22.44) (writing took 3.1771053466945887 seconds)
2021-01-16 22:46:24 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2021-01-16 22:46:24 | INFO | train | epoch 095 | symm_kl 0.475 | self_kl 0 | self_cv 0 | loss 3.304 | nll_loss 0.773 | ppl 1.71 | wps 22517.3 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 35625 | lr 1.16076e-05 | gnorm 0.999 | train_wall 235 | wall 24961
2021-01-16 22:46:24 | INFO | fairseq.trainer | begin training epoch 96
2021-01-16 22:46:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:46:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:46:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:46:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:47:15 | INFO | train_inner | epoch 096:     75 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.76, ppl=1.69, wps=17869.6, ups=1.13, wpb=15768.8, bsz=568.7, num_updates=35700, lr=1.15954e-05, gnorm=0.988, train_wall=63, wall=25012
2021-01-16 22:48:17 | INFO | train_inner | epoch 096:    175 / 375 symm_kl=0.482, self_kl=0, self_cv=0, loss=3.316, nll_loss=0.773, ppl=1.71, wps=24558.9, ups=1.61, wpb=15248.8, bsz=547.6, num_updates=35800, lr=1.15792e-05, gnorm=1.026, train_wall=62, wall=25074
2021-01-16 22:49:20 | INFO | train_inner | epoch 096:    275 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.307, nll_loss=0.777, ppl=1.71, wps=25062.4, ups=1.57, wpb=15926.8, bsz=567.5, num_updates=35900, lr=1.15631e-05, gnorm=1.005, train_wall=63, wall=25138
2021-01-16 22:50:23 | INFO | train_inner | epoch 096:    375 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.317, nll_loss=0.781, ppl=1.72, wps=25209.5, ups=1.6, wpb=15735.8, bsz=523, num_updates=36000, lr=1.1547e-05, gnorm=1.007, train_wall=62, wall=25200
2021-01-16 22:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:50:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:50:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:50:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:50:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:50:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:50:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:50:41 | INFO | valid | epoch 096 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.058 | ppl 16.65 | bleu 22.37 | wps 5542.7 | wpb 11799.1 | bsz 428.6 | num_updates 36000 | best_bleu 22.62
2021-01-16 22:50:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:50:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:50:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:50:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 96 @ 36000 updates, score 22.37) (writing took 3.169851226732135 seconds)
2021-01-16 22:50:44 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2021-01-16 22:50:44 | INFO | train | epoch 096 | symm_kl 0.476 | self_kl 0 | self_cv 0 | loss 3.305 | nll_loss 0.773 | ppl 1.71 | wps 22605.4 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 36000 | lr 1.1547e-05 | gnorm 1.007 | train_wall 234 | wall 25222
2021-01-16 22:50:44 | INFO | fairseq.trainer | begin training epoch 97
2021-01-16 22:50:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:50:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:51:51 | INFO | train_inner | epoch 097:    100 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.288, nll_loss=0.767, ppl=1.7, wps=17947.3, ups=1.14, wpb=15729.1, bsz=567.5, num_updates=36100, lr=1.1531e-05, gnorm=0.987, train_wall=63, wall=25288
2021-01-16 22:52:54 | INFO | train_inner | epoch 097:    200 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.771, ppl=1.71, wps=24886.3, ups=1.58, wpb=15758.6, bsz=539.8, num_updates=36200, lr=1.15151e-05, gnorm=0.992, train_wall=63, wall=25351
2021-01-16 22:53:57 | INFO | train_inner | epoch 097:    300 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.318, nll_loss=0.779, ppl=1.72, wps=24821.2, ups=1.59, wpb=15656.6, bsz=556.4, num_updates=36300, lr=1.14992e-05, gnorm=1.004, train_wall=63, wall=25414
2021-01-16 22:54:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:54:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:54:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:54:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:54:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:54:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:54:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:54:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:54:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:54:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:54:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:55:03 | INFO | valid | epoch 097 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.057 | ppl 16.65 | bleu 22.35 | wps 5392.1 | wpb 11799.1 | bsz 428.6 | num_updates 36375 | best_bleu 22.62
2021-01-16 22:55:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:55:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:55:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:55:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:55:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:55:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 97 @ 36375 updates, score 22.35) (writing took 3.078388709574938 seconds)
2021-01-16 22:55:06 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2021-01-16 22:55:06 | INFO | train | epoch 097 | symm_kl 0.475 | self_kl 0 | self_cv 0 | loss 3.304 | nll_loss 0.773 | ppl 1.71 | wps 22462.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 36375 | lr 1.14873e-05 | gnorm 0.996 | train_wall 236 | wall 25483
2021-01-16 22:55:06 | INFO | fairseq.trainer | begin training epoch 98
2021-01-16 22:55:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:55:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:55:25 | INFO | train_inner | epoch 098:     25 / 375 symm_kl=0.481, self_kl=0, self_cv=0, loss=3.32, nll_loss=0.782, ppl=1.72, wps=17659.9, ups=1.13, wpb=15574.2, bsz=542.6, num_updates=36400, lr=1.14834e-05, gnorm=1.005, train_wall=62, wall=25502
2021-01-16 22:56:28 | INFO | train_inner | epoch 098:    125 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.765, ppl=1.7, wps=24579, ups=1.58, wpb=15576.8, bsz=553, num_updates=36500, lr=1.14676e-05, gnorm=0.995, train_wall=63, wall=25566
2021-01-16 22:57:32 | INFO | train_inner | epoch 098:    225 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.765, ppl=1.7, wps=25124.7, ups=1.58, wpb=15889.2, bsz=568.7, num_updates=36600, lr=1.1452e-05, gnorm=0.983, train_wall=63, wall=25629
2021-01-16 22:58:34 | INFO | train_inner | epoch 098:    325 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.314, nll_loss=0.778, ppl=1.71, wps=24927.4, ups=1.6, wpb=15562.7, bsz=537.9, num_updates=36700, lr=1.14364e-05, gnorm=1.009, train_wall=62, wall=25691
2021-01-16 22:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 22:59:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:59:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:59:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:59:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 22:59:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 22:59:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 22:59:24 | INFO | valid | epoch 098 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.058 | ppl 16.65 | bleu 22.35 | wps 5560.9 | wpb 11799.1 | bsz 428.6 | num_updates 36750 | best_bleu 22.62
2021-01-16 22:59:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 22:59:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:59:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 22:59:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 98 @ 36750 updates, score 22.35) (writing took 3.137499926611781 seconds)
2021-01-16 22:59:27 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2021-01-16 22:59:27 | INFO | train | epoch 098 | symm_kl 0.475 | self_kl 0 | self_cv 0 | loss 3.303 | nll_loss 0.773 | ppl 1.71 | wps 22517.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 36750 | lr 1.14286e-05 | gnorm 0.997 | train_wall 235 | wall 25745
2021-01-16 22:59:27 | INFO | fairseq.trainer | begin training epoch 99
2021-01-16 22:59:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 22:59:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:00:02 | INFO | train_inner | epoch 099:     50 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.303, nll_loss=0.776, ppl=1.71, wps=18031.2, ups=1.14, wpb=15809.2, bsz=577.1, num_updates=36800, lr=1.14208e-05, gnorm=0.99, train_wall=62, wall=25779
2021-01-16 23:01:05 | INFO | train_inner | epoch 099:    150 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.3, nll_loss=0.771, ppl=1.71, wps=24809.9, ups=1.59, wpb=15577, bsz=541, num_updates=36900, lr=1.14053e-05, gnorm=0.997, train_wall=63, wall=25842
2021-01-16 23:02:08 | INFO | train_inner | epoch 099:    250 / 375 symm_kl=0.48, self_kl=0, self_cv=0, loss=3.311, nll_loss=0.773, ppl=1.71, wps=24803, ups=1.59, wpb=15601.3, bsz=552.4, num_updates=37000, lr=1.13899e-05, gnorm=1.007, train_wall=63, wall=25905
2021-01-16 23:03:11 | INFO | train_inner | epoch 099:    350 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.31, nll_loss=0.778, ppl=1.71, wps=25126, ups=1.58, wpb=15898.2, bsz=541.4, num_updates=37100, lr=1.13745e-05, gnorm=1.003, train_wall=63, wall=25968
2021-01-16 23:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:03:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:03:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:03:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:03:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:03:45 | INFO | valid | epoch 099 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.061 | ppl 16.69 | bleu 22.45 | wps 5566 | wpb 11799.1 | bsz 428.6 | num_updates 37125 | best_bleu 22.62
2021-01-16 23:03:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:03:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:03:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:03:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 99 @ 37125 updates, score 22.45) (writing took 3.2073649428784847 seconds)
2021-01-16 23:03:48 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2021-01-16 23:03:48 | INFO | train | epoch 099 | symm_kl 0.475 | self_kl 0 | self_cv 0 | loss 3.303 | nll_loss 0.773 | ppl 1.71 | wps 22554.4 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 37125 | lr 1.13707e-05 | gnorm 0.999 | train_wall 235 | wall 26005
2021-01-16 23:03:48 | INFO | fairseq.trainer | begin training epoch 100
2021-01-16 23:03:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:03:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:04:39 | INFO | train_inner | epoch 100:     75 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.292, nll_loss=0.768, ppl=1.7, wps=17635.7, ups=1.14, wpb=15523.1, bsz=574.9, num_updates=37200, lr=1.13592e-05, gnorm=0.998, train_wall=63, wall=26056
2021-01-16 23:05:42 | INFO | train_inner | epoch 100:    175 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.306, nll_loss=0.774, ppl=1.71, wps=24957, ups=1.58, wpb=15791.6, bsz=535, num_updates=37300, lr=1.1344e-05, gnorm=0.996, train_wall=63, wall=26119
2021-01-16 23:06:45 | INFO | train_inner | epoch 100:    275 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.306, nll_loss=0.773, ppl=1.71, wps=24868.6, ups=1.58, wpb=15748.5, bsz=548.2, num_updates=37400, lr=1.13288e-05, gnorm=0.992, train_wall=63, wall=26183
2021-01-16 23:07:49 | INFO | train_inner | epoch 100:    375 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.297, nll_loss=0.77, ppl=1.7, wps=24508.4, ups=1.58, wpb=15550.4, bsz=559.1, num_updates=37500, lr=1.13137e-05, gnorm=1.008, train_wall=63, wall=26246
2021-01-16 23:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:07:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:07:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:07:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:07:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:07:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:07:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:07:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:07:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:07:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:07:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:08:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:08:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:08:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:08:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:08:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:08:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:08:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:08:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:08:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:08:07 | INFO | valid | epoch 100 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.058 | ppl 16.65 | bleu 22.47 | wps 5505.5 | wpb 11799.1 | bsz 428.6 | num_updates 37500 | best_bleu 22.62
2021-01-16 23:08:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:08:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:08:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:08:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:08:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:08:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 100 @ 37500 updates, score 22.47) (writing took 3.189923634752631 seconds)
2021-01-16 23:08:10 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2021-01-16 23:08:10 | INFO | train | epoch 100 | symm_kl 0.475 | self_kl 0 | self_cv 0 | loss 3.302 | nll_loss 0.772 | ppl 1.71 | wps 22419.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 37500 | lr 1.13137e-05 | gnorm 0.998 | train_wall 236 | wall 26268
2021-01-16 23:08:10 | INFO | fairseq.trainer | begin training epoch 101
2021-01-16 23:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:09:16 | INFO | train_inner | epoch 101:    100 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.771, ppl=1.71, wps=17981.2, ups=1.15, wpb=15687.5, bsz=541.3, num_updates=37600, lr=1.12987e-05, gnorm=1.002, train_wall=62, wall=26333
2021-01-16 23:10:20 | INFO | train_inner | epoch 101:    200 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.297, nll_loss=0.768, ppl=1.7, wps=24384.6, ups=1.58, wpb=15464.9, bsz=553, num_updates=37700, lr=1.12837e-05, gnorm=1.008, train_wall=63, wall=26397
2021-01-16 23:11:23 | INFO | train_inner | epoch 101:    300 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.774, ppl=1.71, wps=24872.8, ups=1.58, wpb=15782.7, bsz=561.1, num_updates=37800, lr=1.12687e-05, gnorm=0.997, train_wall=63, wall=26460
2021-01-16 23:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:12:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:12:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:12:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:12:29 | INFO | valid | epoch 101 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.06 | ppl 16.68 | bleu 22.35 | wps 5551.8 | wpb 11799.1 | bsz 428.6 | num_updates 37875 | best_bleu 22.62
2021-01-16 23:12:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:12:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 101 @ 37875 updates, score 22.35) (writing took 3.163083616644144 seconds)
2021-01-16 23:12:32 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2021-01-16 23:12:32 | INFO | train | epoch 101 | symm_kl 0.474 | self_kl 0 | self_cv 0 | loss 3.302 | nll_loss 0.772 | ppl 1.71 | wps 22490.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 37875 | lr 1.12576e-05 | gnorm 0.999 | train_wall 236 | wall 26529
2021-01-16 23:12:32 | INFO | fairseq.trainer | begin training epoch 102
2021-01-16 23:12:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:12:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:12:51 | INFO | train_inner | epoch 102:     25 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.306, nll_loss=0.775, ppl=1.71, wps=17896.2, ups=1.14, wpb=15766.3, bsz=552.5, num_updates=37900, lr=1.12538e-05, gnorm=0.988, train_wall=63, wall=26548
2021-01-16 23:13:54 | INFO | train_inner | epoch 102:    125 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.297, nll_loss=0.773, ppl=1.71, wps=25346.3, ups=1.6, wpb=15875.2, bsz=570.9, num_updates=38000, lr=1.1239e-05, gnorm=0.978, train_wall=62, wall=26611
2021-01-16 23:14:57 | INFO | train_inner | epoch 102:    225 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.306, nll_loss=0.775, ppl=1.71, wps=24883.7, ups=1.58, wpb=15709.6, bsz=562.2, num_updates=38100, lr=1.12243e-05, gnorm=0.992, train_wall=63, wall=26674
2021-01-16 23:16:00 | INFO | train_inner | epoch 102:    325 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.299, nll_loss=0.769, ppl=1.7, wps=24818.7, ups=1.59, wpb=15566.4, bsz=538.1, num_updates=38200, lr=1.12096e-05, gnorm=1.007, train_wall=62, wall=26737
2021-01-16 23:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:16:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:16:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:16:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:16:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:16:50 | INFO | valid | epoch 102 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.061 | ppl 16.69 | bleu 22.36 | wps 5537.5 | wpb 11799.1 | bsz 428.6 | num_updates 38250 | best_bleu 22.62
2021-01-16 23:16:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:16:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:16:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 102 @ 38250 updates, score 22.36) (writing took 3.207645196467638 seconds)
2021-01-16 23:16:53 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2021-01-16 23:16:53 | INFO | train | epoch 102 | symm_kl 0.473 | self_kl 0 | self_cv 0 | loss 3.3 | nll_loss 0.772 | ppl 1.71 | wps 22535.5 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 38250 | lr 1.12022e-05 | gnorm 0.996 | train_wall 235 | wall 26790
2021-01-16 23:16:53 | INFO | fairseq.trainer | begin training epoch 103
2021-01-16 23:16:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:16:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:17:27 | INFO | train_inner | epoch 103:     50 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.766, ppl=1.7, wps=17817.4, ups=1.14, wpb=15658.3, bsz=556.1, num_updates=38300, lr=1.11949e-05, gnorm=1.008, train_wall=62, wall=26825
2021-01-16 23:18:31 | INFO | train_inner | epoch 103:    150 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.771, ppl=1.71, wps=25072.5, ups=1.58, wpb=15829.4, bsz=564.1, num_updates=38400, lr=1.11803e-05, gnorm=0.981, train_wall=63, wall=26888
2021-01-16 23:19:34 | INFO | train_inner | epoch 103:    250 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.775, ppl=1.71, wps=24817.2, ups=1.58, wpb=15738, bsz=549.8, num_updates=38500, lr=1.11658e-05, gnorm=0.995, train_wall=63, wall=26951
2021-01-16 23:20:37 | INFO | train_inner | epoch 103:    350 / 375 symm_kl=0.477, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.775, ppl=1.71, wps=24818.6, ups=1.59, wpb=15646.1, bsz=535, num_updates=38600, lr=1.11513e-05, gnorm=1.005, train_wall=63, wall=27014
2021-01-16 23:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:20:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:20:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:20:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:20:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:20:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:20:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:20:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:20:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:20:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:20:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:20:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:20:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:20:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:20:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:20:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:21:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:21:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:21:12 | INFO | valid | epoch 103 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.062 | ppl 16.7 | bleu 22.35 | wps 5134.6 | wpb 11799.1 | bsz 428.6 | num_updates 38625 | best_bleu 22.62
2021-01-16 23:21:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:21:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:21:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:21:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:21:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 103 @ 38625 updates, score 22.35) (writing took 3.3241920806467533 seconds)
2021-01-16 23:21:16 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2021-01-16 23:21:16 | INFO | train | epoch 103 | symm_kl 0.473 | self_kl 0 | self_cv 0 | loss 3.3 | nll_loss 0.772 | ppl 1.71 | wps 22365.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 38625 | lr 1.11477e-05 | gnorm 0.997 | train_wall 236 | wall 27053
2021-01-16 23:21:16 | INFO | fairseq.trainer | begin training epoch 104
2021-01-16 23:21:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:21:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:22:06 | INFO | train_inner | epoch 104:     75 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.299, nll_loss=0.772, ppl=1.71, wps=17429.8, ups=1.12, wpb=15537.1, bsz=563.3, num_updates=38700, lr=1.11369e-05, gnorm=0.999, train_wall=63, wall=27104
2021-01-16 23:23:09 | INFO | train_inner | epoch 104:    175 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.764, ppl=1.7, wps=24921.7, ups=1.58, wpb=15754.6, bsz=555.4, num_updates=38800, lr=1.11226e-05, gnorm=0.984, train_wall=63, wall=27167
2021-01-16 23:24:13 | INFO | train_inner | epoch 104:    275 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.305, nll_loss=0.775, ppl=1.71, wps=24970.4, ups=1.58, wpb=15835.9, bsz=535.8, num_updates=38900, lr=1.11083e-05, gnorm=0.993, train_wall=63, wall=27230
2021-01-16 23:25:16 | INFO | train_inner | epoch 104:    375 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.302, nll_loss=0.774, ppl=1.71, wps=24360.5, ups=1.58, wpb=15394.5, bsz=556.2, num_updates=39000, lr=1.1094e-05, gnorm=1.016, train_wall=63, wall=27293
2021-01-16 23:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:25:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:25:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:25:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:25:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:25:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:25:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:25:34 | INFO | valid | epoch 104 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.06 | ppl 16.68 | bleu 22.54 | wps 5678.3 | wpb 11799.1 | bsz 428.6 | num_updates 39000 | best_bleu 22.62
2021-01-16 23:25:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:25:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:25:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:25:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 104 @ 39000 updates, score 22.54) (writing took 3.249987993389368 seconds)
2021-01-16 23:25:37 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2021-01-16 23:25:37 | INFO | train | epoch 104 | symm_kl 0.472 | self_kl 0 | self_cv 0 | loss 3.298 | nll_loss 0.772 | ppl 1.71 | wps 22481.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 39000 | lr 1.1094e-05 | gnorm 0.995 | train_wall 236 | wall 27315
2021-01-16 23:25:37 | INFO | fairseq.trainer | begin training epoch 105
2021-01-16 23:25:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:25:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:26:43 | INFO | train_inner | epoch 105:    100 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.303, nll_loss=0.772, ppl=1.71, wps=17917, ups=1.15, wpb=15573.7, bsz=561.4, num_updates=39100, lr=1.10798e-05, gnorm=1.005, train_wall=62, wall=27380
2021-01-16 23:27:46 | INFO | train_inner | epoch 105:    200 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.762, ppl=1.7, wps=24961.2, ups=1.58, wpb=15822.6, bsz=543.3, num_updates=39200, lr=1.10657e-05, gnorm=0.985, train_wall=63, wall=27444
2021-01-16 23:28:50 | INFO | train_inner | epoch 105:    300 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.772, ppl=1.71, wps=24626.3, ups=1.58, wpb=15577.8, bsz=567.7, num_updates=39300, lr=1.10516e-05, gnorm=0.998, train_wall=63, wall=27507
2021-01-16 23:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:29:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:29:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:29:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:29:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:29:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:29:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:29:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:29:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:29:56 | INFO | valid | epoch 105 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.06 | ppl 16.68 | bleu 22.44 | wps 5543.6 | wpb 11799.1 | bsz 428.6 | num_updates 39375 | best_bleu 22.62
2021-01-16 23:29:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:29:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:29:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:29:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:29:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:29:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 105 @ 39375 updates, score 22.44) (writing took 3.19426285661757 seconds)
2021-01-16 23:29:59 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2021-01-16 23:29:59 | INFO | train | epoch 105 | symm_kl 0.472 | self_kl 0 | self_cv 0 | loss 3.297 | nll_loss 0.771 | ppl 1.71 | wps 22478.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 39375 | lr 1.1041e-05 | gnorm 0.998 | train_wall 236 | wall 27576
2021-01-16 23:29:59 | INFO | fairseq.trainer | begin training epoch 106
2021-01-16 23:30:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:30:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:30:18 | INFO | train_inner | epoch 106:     25 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.313, nll_loss=0.782, ppl=1.72, wps=17809.1, ups=1.13, wpb=15753.7, bsz=538.2, num_updates=39400, lr=1.10375e-05, gnorm=1.005, train_wall=63, wall=27595
2021-01-16 23:31:21 | INFO | train_inner | epoch 106:    125 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.292, nll_loss=0.767, ppl=1.7, wps=25163, ups=1.58, wpb=15915.2, bsz=556.2, num_updates=39500, lr=1.10236e-05, gnorm=0.992, train_wall=63, wall=27659
2021-01-16 23:32:24 | INFO | train_inner | epoch 106:    225 / 375 symm_kl=0.485, self_kl=0, self_cv=0, loss=3.33, nll_loss=0.785, ppl=1.72, wps=24485.2, ups=1.59, wpb=15420, bsz=541.9, num_updates=39600, lr=1.10096e-05, gnorm=1.022, train_wall=63, wall=27722
2021-01-16 23:33:28 | INFO | train_inner | epoch 106:    325 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.761, ppl=1.69, wps=24827.8, ups=1.57, wpb=15842.4, bsz=576.9, num_updates=39700, lr=1.09958e-05, gnorm=0.971, train_wall=64, wall=27785
2021-01-16 23:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:34:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:34:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:34:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:34:18 | INFO | valid | epoch 106 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.06 | ppl 16.68 | bleu 22.39 | wps 5530.5 | wpb 11799.1 | bsz 428.6 | num_updates 39750 | best_bleu 22.62
2021-01-16 23:34:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:34:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 106 @ 39750 updates, score 22.39) (writing took 3.231314040720463 seconds)
2021-01-16 23:34:21 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2021-01-16 23:34:21 | INFO | train | epoch 106 | symm_kl 0.472 | self_kl 0 | self_cv 0 | loss 3.298 | nll_loss 0.771 | ppl 1.71 | wps 22418.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 39750 | lr 1.09888e-05 | gnorm 0.996 | train_wall 236 | wall 27839
2021-01-16 23:34:21 | INFO | fairseq.trainer | begin training epoch 107
2021-01-16 23:34:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:34:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:34:56 | INFO | train_inner | epoch 107:     50 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.771, ppl=1.71, wps=17702.1, ups=1.14, wpb=15570.2, bsz=537.4, num_updates=39800, lr=1.09819e-05, gnorm=0.998, train_wall=63, wall=27873
2021-01-16 23:35:59 | INFO | train_inner | epoch 107:    150 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.772, ppl=1.71, wps=24997.6, ups=1.6, wpb=15667.3, bsz=545.4, num_updates=39900, lr=1.09682e-05, gnorm=1, train_wall=62, wall=27936
2021-01-16 23:37:02 | INFO | train_inner | epoch 107:    250 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.295, nll_loss=0.77, ppl=1.71, wps=24852.3, ups=1.58, wpb=15720.1, bsz=569.2, num_updates=40000, lr=1.09545e-05, gnorm=0.989, train_wall=63, wall=27999
2021-01-16 23:38:05 | INFO | train_inner | epoch 107:    350 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.295, nll_loss=0.77, ppl=1.7, wps=24928.7, ups=1.58, wpb=15768, bsz=544.7, num_updates=40100, lr=1.09408e-05, gnorm=0.988, train_wall=63, wall=28063
2021-01-16 23:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:38:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:38:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:38:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:38:40 | INFO | valid | epoch 107 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.06 | ppl 16.67 | bleu 22.42 | wps 5411.5 | wpb 11799.1 | bsz 428.6 | num_updates 40125 | best_bleu 22.62
2021-01-16 23:38:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:38:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:38:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:38:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 107 @ 40125 updates, score 22.42) (writing took 3.1027116514742374 seconds)
2021-01-16 23:38:43 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2021-01-16 23:38:43 | INFO | train | epoch 107 | symm_kl 0.472 | self_kl 0 | self_cv 0 | loss 3.297 | nll_loss 0.771 | ppl 1.71 | wps 22495.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 40125 | lr 1.09374e-05 | gnorm 0.992 | train_wall 235 | wall 28100
2021-01-16 23:38:43 | INFO | fairseq.trainer | begin training epoch 108
2021-01-16 23:38:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:38:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:39:34 | INFO | train_inner | epoch 108:     75 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.287, nll_loss=0.766, ppl=1.7, wps=17673.5, ups=1.13, wpb=15607.5, bsz=555, num_updates=40200, lr=1.09272e-05, gnorm=0.986, train_wall=63, wall=28151
2021-01-16 23:40:37 | INFO | train_inner | epoch 108:    175 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.299, nll_loss=0.771, ppl=1.71, wps=25059.3, ups=1.59, wpb=15788.7, bsz=542, num_updates=40300, lr=1.09136e-05, gnorm=0.994, train_wall=63, wall=28214
2021-01-16 23:41:40 | INFO | train_inner | epoch 108:    275 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.773, ppl=1.71, wps=24865.9, ups=1.58, wpb=15741.8, bsz=542.5, num_updates=40400, lr=1.09001e-05, gnorm=1, train_wall=63, wall=28277
2021-01-16 23:42:43 | INFO | train_inner | epoch 108:    375 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.769, ppl=1.7, wps=24435.1, ups=1.58, wpb=15477.6, bsz=573, num_updates=40500, lr=1.08866e-05, gnorm=0.989, train_wall=63, wall=28341
2021-01-16 23:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:42:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:42:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:42:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:42:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:42:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:42:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:42:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:43:01 | INFO | valid | epoch 108 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.06 | ppl 16.68 | bleu 22.45 | wps 5566.6 | wpb 11799.1 | bsz 428.6 | num_updates 40500 | best_bleu 22.62
2021-01-16 23:43:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:43:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:43:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:43:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:43:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:43:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 108 @ 40500 updates, score 22.45) (writing took 3.0936983563005924 seconds)
2021-01-16 23:43:05 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2021-01-16 23:43:05 | INFO | train | epoch 108 | symm_kl 0.471 | self_kl 0 | self_cv 0 | loss 3.296 | nll_loss 0.77 | ppl 1.71 | wps 22467.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 40500 | lr 1.08866e-05 | gnorm 0.994 | train_wall 236 | wall 28362
2021-01-16 23:43:05 | INFO | fairseq.trainer | begin training epoch 109
2021-01-16 23:43:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:43:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:44:11 | INFO | train_inner | epoch 109:    100 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.289, nll_loss=0.77, ppl=1.71, wps=18146.5, ups=1.14, wpb=15852.2, bsz=554.9, num_updates=40600, lr=1.08732e-05, gnorm=0.976, train_wall=62, wall=28428
2021-01-16 23:45:14 | INFO | train_inner | epoch 109:    200 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.769, ppl=1.7, wps=24732.8, ups=1.58, wpb=15635, bsz=566.5, num_updates=40700, lr=1.08598e-05, gnorm=0.995, train_wall=63, wall=28491
2021-01-16 23:46:17 | INFO | train_inner | epoch 109:    300 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.764, ppl=1.7, wps=24937.1, ups=1.58, wpb=15753.8, bsz=544.7, num_updates=40800, lr=1.08465e-05, gnorm=0.993, train_wall=63, wall=28554
2021-01-16 23:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:47:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:47:23 | INFO | valid | epoch 109 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.059 | ppl 16.67 | bleu 22.38 | wps 5355.5 | wpb 11799.1 | bsz 428.6 | num_updates 40875 | best_bleu 22.62
2021-01-16 23:47:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:47:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 109 @ 40875 updates, score 22.38) (writing took 3.161784991621971 seconds)
2021-01-16 23:47:26 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2021-01-16 23:47:26 | INFO | train | epoch 109 | symm_kl 0.47 | self_kl 0 | self_cv 0 | loss 3.294 | nll_loss 0.77 | ppl 1.71 | wps 22481.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 40875 | lr 1.08366e-05 | gnorm 0.991 | train_wall 235 | wall 28623
2021-01-16 23:47:26 | INFO | fairseq.trainer | begin training epoch 110
2021-01-16 23:47:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:47:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:47:45 | INFO | train_inner | epoch 110:     25 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.778, ppl=1.71, wps=17448.1, ups=1.13, wpb=15409, bsz=544.2, num_updates=40900, lr=1.08333e-05, gnorm=1.007, train_wall=63, wall=28643
2021-01-16 23:48:48 | INFO | train_inner | epoch 110:    125 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.763, ppl=1.7, wps=25123.3, ups=1.59, wpb=15815.8, bsz=552.5, num_updates=41000, lr=1.082e-05, gnorm=0.983, train_wall=63, wall=28706
2021-01-16 23:49:51 | INFO | train_inner | epoch 110:    225 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.772, ppl=1.71, wps=24645.8, ups=1.58, wpb=15577, bsz=548.3, num_updates=41100, lr=1.08069e-05, gnorm=1, train_wall=63, wall=28769
2021-01-16 23:50:54 | INFO | train_inner | epoch 110:    325 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.303, nll_loss=0.773, ppl=1.71, wps=24973.5, ups=1.59, wpb=15686.6, bsz=551.8, num_updates=41200, lr=1.07937e-05, gnorm=1.002, train_wall=63, wall=28832
2021-01-16 23:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:51:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:51:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:51:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:51:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:51:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:51:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:51:46 | INFO | valid | epoch 110 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.064 | ppl 16.73 | bleu 22.37 | wps 4890.2 | wpb 11799.1 | bsz 428.6 | num_updates 41250 | best_bleu 22.62
2021-01-16 23:51:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:51:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:51:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:51:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 110 @ 41250 updates, score 22.37) (writing took 2.9992223754525185 seconds)
2021-01-16 23:51:49 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2021-01-16 23:51:49 | INFO | train | epoch 110 | symm_kl 0.471 | self_kl 0 | self_cv 0 | loss 3.294 | nll_loss 0.77 | ppl 1.7 | wps 22412.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 41250 | lr 1.07872e-05 | gnorm 0.996 | train_wall 235 | wall 28886
2021-01-16 23:51:49 | INFO | fairseq.trainer | begin training epoch 111
2021-01-16 23:51:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:51:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:52:23 | INFO | train_inner | epoch 111:     50 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.773, ppl=1.71, wps=17699.8, ups=1.12, wpb=15759.6, bsz=570.7, num_updates=41300, lr=1.07807e-05, gnorm=0.987, train_wall=62, wall=28921
2021-01-16 23:53:27 | INFO | train_inner | epoch 111:    150 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.3, nll_loss=0.772, ppl=1.71, wps=24972.8, ups=1.58, wpb=15819.8, bsz=550.7, num_updates=41400, lr=1.07676e-05, gnorm=0.993, train_wall=63, wall=28984
2021-01-16 23:54:30 | INFO | train_inner | epoch 111:    250 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.768, ppl=1.7, wps=24766, ups=1.57, wpb=15760, bsz=554.7, num_updates=41500, lr=1.07547e-05, gnorm=0.988, train_wall=63, wall=29048
2021-01-16 23:55:33 | INFO | train_inner | epoch 111:    350 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.3, nll_loss=0.77, ppl=1.71, wps=24473.4, ups=1.58, wpb=15465.1, bsz=538.2, num_updates=41600, lr=1.07417e-05, gnorm=1.012, train_wall=63, wall=29111
2021-01-16 23:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-16 23:55:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:55:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:55:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:55:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:55:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:55:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-16 23:56:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-16 23:56:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-16 23:56:08 | INFO | valid | epoch 111 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.065 | ppl 16.74 | bleu 22.47 | wps 5461.7 | wpb 11799.1 | bsz 428.6 | num_updates 41625 | best_bleu 22.62
2021-01-16 23:56:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-16 23:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:56:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:56:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:56:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 111 @ 41625 updates, score 22.47) (writing took 3.0001521334052086 seconds)
2021-01-16 23:56:11 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2021-01-16 23:56:11 | INFO | train | epoch 111 | symm_kl 0.47 | self_kl 0 | self_cv 0 | loss 3.293 | nll_loss 0.769 | ppl 1.7 | wps 22416.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 41625 | lr 1.07385e-05 | gnorm 0.994 | train_wall 236 | wall 29148
2021-01-16 23:56:11 | INFO | fairseq.trainer | begin training epoch 112
2021-01-16 23:56:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-16 23:56:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-16 23:57:02 | INFO | train_inner | epoch 112:     75 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.761, ppl=1.69, wps=17678.6, ups=1.14, wpb=15566.5, bsz=575.6, num_updates=41700, lr=1.07288e-05, gnorm=0.988, train_wall=63, wall=29199
2021-01-16 23:58:05 | INFO | train_inner | epoch 112:    175 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.294, nll_loss=0.769, ppl=1.7, wps=24841, ups=1.57, wpb=15796.6, bsz=545.7, num_updates=41800, lr=1.0716e-05, gnorm=0.986, train_wall=63, wall=29262
2021-01-16 23:59:09 | INFO | train_inner | epoch 112:    275 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.771, ppl=1.71, wps=24652.8, ups=1.57, wpb=15744.1, bsz=552.9, num_updates=41900, lr=1.07032e-05, gnorm=0.986, train_wall=64, wall=29326
2021-01-17 00:00:12 | INFO | train_inner | epoch 112:    375 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.769, ppl=1.7, wps=24772, ups=1.59, wpb=15605.5, bsz=543.5, num_updates=42000, lr=1.06904e-05, gnorm=0.986, train_wall=63, wall=29389
2021-01-17 00:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:00:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:00:30 | INFO | valid | epoch 112 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.062 | ppl 16.71 | bleu 22.4 | wps 5578.8 | wpb 11799.1 | bsz 428.6 | num_updates 42000 | best_bleu 22.62
2021-01-17 00:00:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:00:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:00:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:00:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 112 @ 42000 updates, score 22.4) (writing took 3.0688811354339123 seconds)
2021-01-17 00:00:33 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2021-01-17 00:00:33 | INFO | train | epoch 112 | symm_kl 0.469 | self_kl 0 | self_cv 0 | loss 3.292 | nll_loss 0.769 | ppl 1.7 | wps 22412.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 42000 | lr 1.06904e-05 | gnorm 0.987 | train_wall 237 | wall 29411
2021-01-17 00:00:33 | INFO | fairseq.trainer | begin training epoch 113
2021-01-17 00:00:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:00:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:01:40 | INFO | train_inner | epoch 113:    100 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.769, ppl=1.7, wps=17898.3, ups=1.14, wpb=15672.1, bsz=566.1, num_updates=42100, lr=1.06777e-05, gnorm=0.99, train_wall=62, wall=29477
2021-01-17 00:02:43 | INFO | train_inner | epoch 113:    200 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.768, ppl=1.7, wps=24831.8, ups=1.56, wpb=15882.2, bsz=548.6, num_updates=42200, lr=1.06651e-05, gnorm=0.984, train_wall=64, wall=29541
2021-01-17 00:03:46 | INFO | train_inner | epoch 113:    300 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.31, nll_loss=0.777, ppl=1.71, wps=24798.9, ups=1.59, wpb=15616.8, bsz=549, num_updates=42300, lr=1.06525e-05, gnorm=1.01, train_wall=63, wall=29604
2021-01-17 00:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:04:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:04:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:04:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:04:52 | INFO | valid | epoch 113 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.679 | nll_loss 4.066 | ppl 16.74 | bleu 22.57 | wps 5592.9 | wpb 11799.1 | bsz 428.6 | num_updates 42375 | best_bleu 22.62
2021-01-17 00:04:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:04:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:04:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:04:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 113 @ 42375 updates, score 22.57) (writing took 3.0018783304840326 seconds)
2021-01-17 00:04:55 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2021-01-17 00:04:55 | INFO | train | epoch 113 | symm_kl 0.47 | self_kl 0 | self_cv 0 | loss 3.292 | nll_loss 0.769 | ppl 1.7 | wps 22445.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 42375 | lr 1.0643e-05 | gnorm 0.997 | train_wall 236 | wall 29673
2021-01-17 00:04:55 | INFO | fairseq.trainer | begin training epoch 114
2021-01-17 00:04:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:04:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:05:14 | INFO | train_inner | epoch 114:     25 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.76, ppl=1.69, wps=17778.3, ups=1.14, wpb=15649.4, bsz=557.2, num_updates=42400, lr=1.06399e-05, gnorm=0.996, train_wall=63, wall=29692
2021-01-17 00:06:18 | INFO | train_inner | epoch 114:    125 / 375 symm_kl=0.479, self_kl=0, self_cv=0, loss=3.315, nll_loss=0.776, ppl=1.71, wps=24595.5, ups=1.59, wpb=15499.6, bsz=529.6, num_updates=42500, lr=1.06274e-05, gnorm=1.019, train_wall=63, wall=29755
2021-01-17 00:07:21 | INFO | train_inner | epoch 114:    225 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.304, nll_loss=0.772, ppl=1.71, wps=24987.5, ups=1.58, wpb=15858, bsz=550.9, num_updates=42600, lr=1.06149e-05, gnorm=0.994, train_wall=63, wall=29818
2021-01-17 00:08:25 | INFO | train_inner | epoch 114:    325 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.251, nll_loss=0.751, ppl=1.68, wps=24777.2, ups=1.57, wpb=15762.7, bsz=569, num_updates=42700, lr=1.06025e-05, gnorm=0.968, train_wall=63, wall=29882
2021-01-17 00:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:08:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:08:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:08:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:08:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:08:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:08:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:09:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:09:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:09:14 | INFO | valid | epoch 114 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.68 | nll_loss 4.067 | ppl 16.76 | bleu 22.41 | wps 5475 | wpb 11799.1 | bsz 428.6 | num_updates 42750 | best_bleu 22.62
2021-01-17 00:09:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:09:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:09:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:09:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:09:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:09:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 114 @ 42750 updates, score 22.41) (writing took 3.077235149219632 seconds)
2021-01-17 00:09:17 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2021-01-17 00:09:17 | INFO | train | epoch 114 | symm_kl 0.469 | self_kl 0 | self_cv 0 | loss 3.291 | nll_loss 0.768 | ppl 1.7 | wps 22437.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 42750 | lr 1.05963e-05 | gnorm 0.994 | train_wall 236 | wall 29935
2021-01-17 00:09:17 | INFO | fairseq.trainer | begin training epoch 115
2021-01-17 00:09:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:09:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:09:52 | INFO | train_inner | epoch 115:     50 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.772, ppl=1.71, wps=17713.8, ups=1.14, wpb=15473.2, bsz=544.9, num_updates=42800, lr=1.05901e-05, gnorm=1.003, train_wall=62, wall=29969
2021-01-17 00:10:55 | INFO | train_inner | epoch 115:    150 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.76, ppl=1.69, wps=24971.5, ups=1.59, wpb=15739.8, bsz=562.2, num_updates=42900, lr=1.05777e-05, gnorm=0.985, train_wall=63, wall=30032
2021-01-17 00:11:58 | INFO | train_inner | epoch 115:    250 / 375 symm_kl=0.474, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.772, ppl=1.71, wps=25031.9, ups=1.59, wpb=15781.3, bsz=543, num_updates=43000, lr=1.05654e-05, gnorm=1.001, train_wall=63, wall=30095
2021-01-17 00:13:01 | INFO | train_inner | epoch 115:    350 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.295, nll_loss=0.776, ppl=1.71, wps=24582.9, ups=1.58, wpb=15593.5, bsz=563, num_updates=43100, lr=1.05531e-05, gnorm=0.988, train_wall=63, wall=30159
2021-01-17 00:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:13:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:13:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:13:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:13:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:13:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:13:35 | INFO | valid | epoch 115 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.061 | ppl 16.69 | bleu 22.43 | wps 5784.6 | wpb 11799.1 | bsz 428.6 | num_updates 43125 | best_bleu 22.62
2021-01-17 00:13:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:13:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:13:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 115 @ 43125 updates, score 22.43) (writing took 3.0410256572067738 seconds)
2021-01-17 00:13:38 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2021-01-17 00:13:38 | INFO | train | epoch 115 | symm_kl 0.469 | self_kl 0 | self_cv 0 | loss 3.291 | nll_loss 0.769 | ppl 1.7 | wps 22581 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 43125 | lr 1.05501e-05 | gnorm 0.994 | train_wall 235 | wall 30195
2021-01-17 00:13:38 | INFO | fairseq.trainer | begin training epoch 116
2021-01-17 00:13:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:13:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:14:29 | INFO | train_inner | epoch 116:     75 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.76, ppl=1.69, wps=17997.8, ups=1.14, wpb=15723.7, bsz=555, num_updates=43200, lr=1.05409e-05, gnorm=0.994, train_wall=63, wall=30246
2021-01-17 00:15:32 | INFO | train_inner | epoch 116:    175 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.767, ppl=1.7, wps=24712.5, ups=1.58, wpb=15628.7, bsz=546.4, num_updates=43300, lr=1.05287e-05, gnorm=0.994, train_wall=63, wall=30309
2021-01-17 00:16:36 | INFO | train_inner | epoch 116:    275 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.772, ppl=1.71, wps=24804.1, ups=1.57, wpb=15791.2, bsz=562.2, num_updates=43400, lr=1.05166e-05, gnorm=0.987, train_wall=63, wall=30373
2021-01-17 00:17:39 | INFO | train_inner | epoch 116:    375 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.774, ppl=1.71, wps=24663.8, ups=1.58, wpb=15574.6, bsz=548, num_updates=43500, lr=1.05045e-05, gnorm=1.001, train_wall=63, wall=30436
2021-01-17 00:17:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:17:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:17:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:17:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:17:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:17:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:17:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:17:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:17:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:17:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:17:58 | INFO | valid | epoch 116 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.063 | ppl 16.72 | bleu 22.46 | wps 5413.7 | wpb 11799.1 | bsz 428.6 | num_updates 43500 | best_bleu 22.62
2021-01-17 00:17:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:17:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:17:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:18:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:18:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:18:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 116 @ 43500 updates, score 22.46) (writing took 3.1108924821019173 seconds)
2021-01-17 00:18:01 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2021-01-17 00:18:01 | INFO | train | epoch 116 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.29 | nll_loss 0.768 | ppl 1.7 | wps 22373.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 43500 | lr 1.05045e-05 | gnorm 0.992 | train_wall 236 | wall 30458
2021-01-17 00:18:01 | INFO | fairseq.trainer | begin training epoch 117
2021-01-17 00:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:19:07 | INFO | train_inner | epoch 117:    100 / 375 symm_kl=0.476, self_kl=0, self_cv=0, loss=3.308, nll_loss=0.774, ppl=1.71, wps=17697.6, ups=1.13, wpb=15617, bsz=529.8, num_updates=43600, lr=1.04925e-05, gnorm=1.011, train_wall=62, wall=30524
2021-01-17 00:20:10 | INFO | train_inner | epoch 117:    200 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.764, ppl=1.7, wps=24846.5, ups=1.58, wpb=15679.1, bsz=545.3, num_updates=43700, lr=1.04804e-05, gnorm=0.986, train_wall=63, wall=30588
2021-01-17 00:21:13 | INFO | train_inner | epoch 117:    300 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.282, nll_loss=0.765, ppl=1.7, wps=24759.2, ups=1.58, wpb=15655.8, bsz=577.5, num_updates=43800, lr=1.04685e-05, gnorm=0.986, train_wall=63, wall=30651
2021-01-17 00:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:22:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:22:19 | INFO | valid | epoch 117 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.06 | ppl 16.68 | bleu 22.35 | wps 5436.6 | wpb 11799.1 | bsz 428.6 | num_updates 43875 | best_bleu 22.62
2021-01-17 00:22:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:22:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 117 @ 43875 updates, score 22.35) (writing took 3.1346427649259567 seconds)
2021-01-17 00:22:22 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2021-01-17 00:22:22 | INFO | train | epoch 117 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.29 | nll_loss 0.768 | ppl 1.7 | wps 22496.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 43875 | lr 1.04595e-05 | gnorm 0.991 | train_wall 235 | wall 30720
2021-01-17 00:22:22 | INFO | fairseq.trainer | begin training epoch 118
2021-01-17 00:22:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:22:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:22:42 | INFO | train_inner | epoch 118:     25 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.764, ppl=1.7, wps=17928.5, ups=1.14, wpb=15794.6, bsz=556.9, num_updates=43900, lr=1.04565e-05, gnorm=0.972, train_wall=63, wall=30739
2021-01-17 00:23:44 | INFO | train_inner | epoch 118:    125 / 375 symm_kl=0.475, self_kl=0, self_cv=0, loss=3.309, nll_loss=0.777, ppl=1.71, wps=24973, ups=1.59, wpb=15677.6, bsz=532.4, num_updates=44000, lr=1.04447e-05, gnorm=0.993, train_wall=63, wall=30802
2021-01-17 00:24:47 | INFO | train_inner | epoch 118:    225 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.773, ppl=1.71, wps=25204.4, ups=1.6, wpb=15773, bsz=536.2, num_updates=44100, lr=1.04328e-05, gnorm=0.988, train_wall=62, wall=30864
2021-01-17 00:25:50 | INFO | train_inner | epoch 118:    325 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.763, ppl=1.7, wps=25214.7, ups=1.59, wpb=15879.9, bsz=594.5, num_updates=44200, lr=1.0421e-05, gnorm=0.981, train_wall=63, wall=30927
2021-01-17 00:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:26:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:26:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:26:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:26:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:26:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:26:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:26:39 | INFO | valid | epoch 118 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.063 | ppl 16.72 | bleu 22.41 | wps 5709.5 | wpb 11799.1 | bsz 428.6 | num_updates 44250 | best_bleu 22.62
2021-01-17 00:26:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:26:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:26:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:26:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 118 @ 44250 updates, score 22.41) (writing took 3.3045471776276827 seconds)
2021-01-17 00:26:43 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2021-01-17 00:26:43 | INFO | train | epoch 118 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.289 | nll_loss 0.768 | ppl 1.7 | wps 22588.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 44250 | lr 1.04151e-05 | gnorm 0.991 | train_wall 234 | wall 30980
2021-01-17 00:26:43 | INFO | fairseq.trainer | begin training epoch 119
2021-01-17 00:26:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:26:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:27:17 | INFO | train_inner | epoch 119:     50 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.757, ppl=1.69, wps=17514.6, ups=1.14, wpb=15324.4, bsz=545, num_updates=44300, lr=1.04092e-05, gnorm=1.012, train_wall=62, wall=31015
2021-01-17 00:28:21 | INFO | train_inner | epoch 119:    150 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.768, ppl=1.7, wps=25042.8, ups=1.58, wpb=15841.1, bsz=546.7, num_updates=44400, lr=1.03975e-05, gnorm=0.984, train_wall=63, wall=31078
2021-01-17 00:29:24 | INFO | train_inner | epoch 119:    250 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.767, ppl=1.7, wps=24767.8, ups=1.58, wpb=15711.9, bsz=564.2, num_updates=44500, lr=1.03858e-05, gnorm=0.987, train_wall=63, wall=31141
2021-01-17 00:30:27 | INFO | train_inner | epoch 119:    350 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.772, ppl=1.71, wps=24904.3, ups=1.59, wpb=15710, bsz=553.3, num_updates=44600, lr=1.03742e-05, gnorm=0.998, train_wall=63, wall=31204
2021-01-17 00:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:30:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:30:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:30:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:30:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:30:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:30:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:30:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:30:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:30:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:30:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:31:01 | INFO | valid | epoch 119 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.065 | ppl 16.73 | bleu 22.42 | wps 5528.2 | wpb 11799.1 | bsz 428.6 | num_updates 44625 | best_bleu 22.62
2021-01-17 00:31:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:31:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:31:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:31:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:31:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:31:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 119 @ 44625 updates, score 22.42) (writing took 3.1915481835603714 seconds)
2021-01-17 00:31:05 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2021-01-17 00:31:05 | INFO | train | epoch 119 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.288 | nll_loss 0.767 | ppl 1.7 | wps 22451.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 44625 | lr 1.03713e-05 | gnorm 0.993 | train_wall 236 | wall 31242
2021-01-17 00:31:05 | INFO | fairseq.trainer | begin training epoch 120
2021-01-17 00:31:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:31:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:31:55 | INFO | train_inner | epoch 120:     75 / 375 symm_kl=0.472, self_kl=0, self_cv=0, loss=3.294, nll_loss=0.767, ppl=1.7, wps=17706.8, ups=1.14, wpb=15516.8, bsz=545.4, num_updates=44700, lr=1.03626e-05, gnorm=1.006, train_wall=62, wall=31292
2021-01-17 00:32:58 | INFO | train_inner | epoch 120:    175 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.292, nll_loss=0.767, ppl=1.7, wps=25006.9, ups=1.58, wpb=15839.8, bsz=536.1, num_updates=44800, lr=1.0351e-05, gnorm=0.991, train_wall=63, wall=31355
2021-01-17 00:34:01 | INFO | train_inner | epoch 120:    275 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.762, ppl=1.7, wps=25016.8, ups=1.58, wpb=15817.4, bsz=584.6, num_updates=44900, lr=1.03395e-05, gnorm=0.969, train_wall=63, wall=31419
2021-01-17 00:35:04 | INFO | train_inner | epoch 120:    375 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.774, ppl=1.71, wps=24412.3, ups=1.58, wpb=15408.3, bsz=546.9, num_updates=45000, lr=1.0328e-05, gnorm=1.012, train_wall=63, wall=31482
2021-01-17 00:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:35:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:35:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:35:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:35:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:35:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:35:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:35:23 | INFO | valid | epoch 120 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.061 | ppl 16.69 | bleu 22.43 | wps 5478.5 | wpb 11799.1 | bsz 428.6 | num_updates 45000 | best_bleu 22.62
2021-01-17 00:35:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:35:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:35:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:35:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 120 @ 45000 updates, score 22.43) (writing took 3.1815147679299116 seconds)
2021-01-17 00:35:26 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2021-01-17 00:35:26 | INFO | train | epoch 120 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.288 | nll_loss 0.767 | ppl 1.7 | wps 22486.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 45000 | lr 1.0328e-05 | gnorm 0.993 | train_wall 235 | wall 31503
2021-01-17 00:35:26 | INFO | fairseq.trainer | begin training epoch 121
2021-01-17 00:35:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:35:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:36:33 | INFO | train_inner | epoch 121:    100 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.775, ppl=1.71, wps=17585.1, ups=1.13, wpb=15568, bsz=569, num_updates=45100, lr=1.03165e-05, gnorm=0.987, train_wall=63, wall=31570
2021-01-17 00:37:36 | INFO | train_inner | epoch 121:    200 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.284, nll_loss=0.765, ppl=1.7, wps=25024.6, ups=1.59, wpb=15759.7, bsz=550.1, num_updates=45200, lr=1.03051e-05, gnorm=0.989, train_wall=63, wall=31633
2021-01-17 00:38:40 | INFO | train_inner | epoch 121:    300 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.288, nll_loss=0.765, ppl=1.7, wps=24907.9, ups=1.57, wpb=15833.6, bsz=559.7, num_updates=45300, lr=1.02937e-05, gnorm=0.987, train_wall=63, wall=31697
2021-01-17 00:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:39:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:39:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:39:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:39:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:39:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:39:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:39:45 | INFO | valid | epoch 121 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.066 | ppl 16.74 | bleu 22.35 | wps 5421.5 | wpb 11799.1 | bsz 428.6 | num_updates 45375 | best_bleu 22.62
2021-01-17 00:39:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:39:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 121 @ 45375 updates, score 22.35) (writing took 3.107733791694045 seconds)
2021-01-17 00:39:48 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2021-01-17 00:39:48 | INFO | train | epoch 121 | symm_kl 0.468 | self_kl 0 | self_cv 0 | loss 3.288 | nll_loss 0.767 | ppl 1.7 | wps 22453.2 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 45375 | lr 1.02852e-05 | gnorm 0.99 | train_wall 236 | wall 31765
2021-01-17 00:39:48 | INFO | fairseq.trainer | begin training epoch 122
2021-01-17 00:39:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:39:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:39:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:39:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:40:07 | INFO | train_inner | epoch 122:     25 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.758, ppl=1.69, wps=17871.9, ups=1.14, wpb=15695.6, bsz=538, num_updates=45400, lr=1.02824e-05, gnorm=0.99, train_wall=62, wall=31785
2021-01-17 00:41:10 | INFO | train_inner | epoch 122:    125 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.764, ppl=1.7, wps=25096.4, ups=1.6, wpb=15704.5, bsz=565.8, num_updates=45500, lr=1.02711e-05, gnorm=0.976, train_wall=62, wall=31847
2021-01-17 00:42:13 | INFO | train_inner | epoch 122:    225 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.771, ppl=1.71, wps=24700.9, ups=1.58, wpb=15670.3, bsz=534.2, num_updates=45600, lr=1.02598e-05, gnorm=0.986, train_wall=63, wall=31911
2021-01-17 00:43:16 | INFO | train_inner | epoch 122:    325 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.771, ppl=1.71, wps=25050.4, ups=1.6, wpb=15669.8, bsz=551.7, num_updates=45700, lr=1.02486e-05, gnorm=0.991, train_wall=62, wall=31973
2021-01-17 00:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:43:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:43:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:43:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:43:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:43:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:43:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:43:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:43:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:43:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:43:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:44:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:44:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:44:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:44:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:44:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:44:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:44:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:44:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:44:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:44:06 | INFO | valid | epoch 122 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.065 | ppl 16.74 | bleu 22.4 | wps 5420.1 | wpb 11799.1 | bsz 428.6 | num_updates 45750 | best_bleu 22.62
2021-01-17 00:44:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:44:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:44:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:44:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:44:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:44:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 122 @ 45750 updates, score 22.4) (writing took 3.266100700944662 seconds)
2021-01-17 00:44:09 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2021-01-17 00:44:09 | INFO | train | epoch 122 | symm_kl 0.467 | self_kl 0 | self_cv 0 | loss 3.287 | nll_loss 0.767 | ppl 1.7 | wps 22521.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 45750 | lr 1.0243e-05 | gnorm 0.997 | train_wall 235 | wall 32027
2021-01-17 00:44:09 | INFO | fairseq.trainer | begin training epoch 123
2021-01-17 00:44:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:44:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:44:44 | INFO | train_inner | epoch 123:     50 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.771, ppl=1.71, wps=17629.5, ups=1.14, wpb=15491.9, bsz=544.9, num_updates=45800, lr=1.02374e-05, gnorm=1.044, train_wall=62, wall=32061
2021-01-17 00:45:47 | INFO | train_inner | epoch 123:    150 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.764, ppl=1.7, wps=24962.4, ups=1.59, wpb=15703.6, bsz=546.3, num_updates=45900, lr=1.02262e-05, gnorm=0.999, train_wall=63, wall=32124
2021-01-17 00:46:50 | INFO | train_inner | epoch 123:    250 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.284, nll_loss=0.766, ppl=1.7, wps=25164.6, ups=1.58, wpb=15908.4, bsz=561.7, num_updates=46000, lr=1.02151e-05, gnorm=0.982, train_wall=63, wall=32187
2021-01-17 00:47:53 | INFO | train_inner | epoch 123:    350 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.289, nll_loss=0.77, ppl=1.71, wps=24788.9, ups=1.58, wpb=15658, bsz=568.4, num_updates=46100, lr=1.0204e-05, gnorm=0.988, train_wall=63, wall=32250
2021-01-17 00:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:48:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:48:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:48:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:48:27 | INFO | valid | epoch 123 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.065 | ppl 16.74 | bleu 22.35 | wps 5535.1 | wpb 11799.1 | bsz 428.6 | num_updates 46125 | best_bleu 22.62
2021-01-17 00:48:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:48:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 123 @ 46125 updates, score 22.35) (writing took 3.2058007437735796 seconds)
2021-01-17 00:48:30 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2021-01-17 00:48:30 | INFO | train | epoch 123 | symm_kl 0.467 | self_kl 0 | self_cv 0 | loss 3.286 | nll_loss 0.767 | ppl 1.7 | wps 22517.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 46125 | lr 1.02012e-05 | gnorm 0.994 | train_wall 235 | wall 32288
2021-01-17 00:48:30 | INFO | fairseq.trainer | begin training epoch 124
2021-01-17 00:48:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:48:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:49:21 | INFO | train_inner | epoch 124:     75 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.761, ppl=1.69, wps=17956.8, ups=1.14, wpb=15728.7, bsz=550.4, num_updates=46200, lr=1.01929e-05, gnorm=1.002, train_wall=62, wall=32338
2021-01-17 00:50:24 | INFO | train_inner | epoch 124:    175 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.768, ppl=1.7, wps=24770.3, ups=1.58, wpb=15666.9, bsz=572.5, num_updates=46300, lr=1.01819e-05, gnorm=0.986, train_wall=63, wall=32401
2021-01-17 00:51:27 | INFO | train_inner | epoch 124:    275 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.766, ppl=1.7, wps=24898.9, ups=1.59, wpb=15634.9, bsz=562.5, num_updates=46400, lr=1.0171e-05, gnorm=0.995, train_wall=63, wall=32464
2021-01-17 00:52:30 | INFO | train_inner | epoch 124:    375 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.768, ppl=1.7, wps=24560.3, ups=1.58, wpb=15552.8, bsz=519.8, num_updates=46500, lr=1.016e-05, gnorm=1.006, train_wall=63, wall=32527
2021-01-17 00:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:52:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:52:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:52:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:52:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:52:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:52:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:52:48 | INFO | valid | epoch 124 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.067 | ppl 16.76 | bleu 22.33 | wps 5457.5 | wpb 11799.1 | bsz 428.6 | num_updates 46500 | best_bleu 22.62
2021-01-17 00:52:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:52:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:52:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:52:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 124 @ 46500 updates, score 22.33) (writing took 3.174699457362294 seconds)
2021-01-17 00:52:52 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2021-01-17 00:52:52 | INFO | train | epoch 124 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.285 | nll_loss 0.766 | ppl 1.7 | wps 22510.2 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 46500 | lr 1.016e-05 | gnorm 0.995 | train_wall 235 | wall 32549
2021-01-17 00:52:52 | INFO | fairseq.trainer | begin training epoch 125
2021-01-17 00:52:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:52:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:53:58 | INFO | train_inner | epoch 125:    100 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.767, ppl=1.7, wps=17698, ups=1.14, wpb=15536.7, bsz=556.6, num_updates=46600, lr=1.01491e-05, gnorm=0.997, train_wall=62, wall=32615
2021-01-17 00:55:01 | INFO | train_inner | epoch 125:    200 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.763, ppl=1.7, wps=25225.9, ups=1.59, wpb=15857.9, bsz=536.8, num_updates=46700, lr=1.01382e-05, gnorm=0.985, train_wall=63, wall=32678
2021-01-17 00:56:04 | INFO | train_inner | epoch 125:    300 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.769, ppl=1.7, wps=24863.3, ups=1.59, wpb=15656.6, bsz=549.8, num_updates=46800, lr=1.01274e-05, gnorm=0.998, train_wall=63, wall=32741
2021-01-17 00:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 00:56:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:56:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:56:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:56:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:56:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:56:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 00:57:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 00:57:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 00:57:10 | INFO | valid | epoch 125 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.065 | ppl 16.74 | bleu 22.42 | wps 5385.9 | wpb 11799.1 | bsz 428.6 | num_updates 46875 | best_bleu 22.62
2021-01-17 00:57:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 00:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:57:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:57:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:57:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 125 @ 46875 updates, score 22.42) (writing took 3.0326341036707163 seconds)
2021-01-17 00:57:13 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2021-01-17 00:57:13 | INFO | train | epoch 125 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.285 | nll_loss 0.766 | ppl 1.7 | wps 22519.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 46875 | lr 1.01193e-05 | gnorm 0.994 | train_wall 235 | wall 32810
2021-01-17 00:57:13 | INFO | fairseq.trainer | begin training epoch 126
2021-01-17 00:57:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 00:57:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 00:57:32 | INFO | train_inner | epoch 126:     25 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.281, nll_loss=0.767, ppl=1.7, wps=17764.3, ups=1.13, wpb=15693.5, bsz=573.2, num_updates=46900, lr=1.01166e-05, gnorm=0.998, train_wall=63, wall=32829
2021-01-17 00:58:35 | INFO | train_inner | epoch 126:    125 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.769, ppl=1.7, wps=25024.6, ups=1.59, wpb=15726.5, bsz=552.4, num_updates=47000, lr=1.01058e-05, gnorm=0.985, train_wall=63, wall=32892
2021-01-17 00:59:38 | INFO | train_inner | epoch 126:    225 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.759, ppl=1.69, wps=24618.3, ups=1.58, wpb=15600.8, bsz=537.8, num_updates=47100, lr=1.00951e-05, gnorm=1.001, train_wall=63, wall=32956
2021-01-17 01:00:42 | INFO | train_inner | epoch 126:    325 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.287, nll_loss=0.77, ppl=1.71, wps=24934.4, ups=1.57, wpb=15871.8, bsz=580, num_updates=47200, lr=1.00844e-05, gnorm=0.978, train_wall=63, wall=33019
2021-01-17 01:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:01:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:01:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:01:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:01:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:01:32 | INFO | valid | epoch 126 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.066 | ppl 16.75 | bleu 22.29 | wps 5593.7 | wpb 11799.1 | bsz 428.6 | num_updates 47250 | best_bleu 22.62
2021-01-17 01:01:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:01:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:01:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 126 @ 47250 updates, score 22.29) (writing took 3.0999346654862165 seconds)
2021-01-17 01:01:35 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2021-01-17 01:01:35 | INFO | train | epoch 126 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.285 | nll_loss 0.766 | ppl 1.7 | wps 22447.5 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 47250 | lr 1.00791e-05 | gnorm 0.991 | train_wall 236 | wall 33072
2021-01-17 01:01:35 | INFO | fairseq.trainer | begin training epoch 127
2021-01-17 01:01:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:01:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:02:10 | INFO | train_inner | epoch 127:     50 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.764, ppl=1.7, wps=17547.7, ups=1.14, wpb=15459.7, bsz=526, num_updates=47300, lr=1.00737e-05, gnorm=1.005, train_wall=63, wall=33107
2021-01-17 01:03:13 | INFO | train_inner | epoch 127:    150 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.282, nll_loss=0.764, ppl=1.7, wps=24816.2, ups=1.58, wpb=15742.4, bsz=547.8, num_updates=47400, lr=1.00631e-05, gnorm=0.994, train_wall=63, wall=33171
2021-01-17 01:04:16 | INFO | train_inner | epoch 127:    250 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.279, nll_loss=0.764, ppl=1.7, wps=25109.4, ups=1.59, wpb=15759.4, bsz=562.2, num_updates=47500, lr=1.00525e-05, gnorm=0.981, train_wall=63, wall=33234
2021-01-17 01:05:19 | INFO | train_inner | epoch 127:    350 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.288, nll_loss=0.771, ppl=1.71, wps=25024.6, ups=1.58, wpb=15824.1, bsz=565.2, num_updates=47600, lr=1.00419e-05, gnorm=0.984, train_wall=63, wall=33297
2021-01-17 01:05:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:05:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:05:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:05:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:05:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:05:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:05:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:05:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:05:54 | INFO | valid | epoch 127 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.064 | ppl 16.72 | bleu 22.55 | wps 5319 | wpb 11799.1 | bsz 428.6 | num_updates 47625 | best_bleu 22.62
2021-01-17 01:05:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:05:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:05:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:05:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:05:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:05:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 127 @ 47625 updates, score 22.55) (writing took 3.1845636554062366 seconds)
2021-01-17 01:05:57 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2021-01-17 01:05:57 | INFO | train | epoch 127 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.284 | nll_loss 0.766 | ppl 1.7 | wps 22407.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 47625 | lr 1.00393e-05 | gnorm 0.995 | train_wall 236 | wall 33335
2021-01-17 01:05:57 | INFO | fairseq.trainer | begin training epoch 128
2021-01-17 01:05:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:06:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:06:48 | INFO | train_inner | epoch 128:     75 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.761, ppl=1.69, wps=17644.3, ups=1.13, wpb=15619.2, bsz=549, num_updates=47700, lr=1.00314e-05, gnorm=1.005, train_wall=62, wall=33385
2021-01-17 01:07:51 | INFO | train_inner | epoch 128:    175 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.289, nll_loss=0.767, ppl=1.7, wps=25204, ups=1.59, wpb=15864.5, bsz=539.6, num_updates=47800, lr=1.00209e-05, gnorm=0.989, train_wall=63, wall=33448
2021-01-17 01:08:54 | INFO | train_inner | epoch 128:    275 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.765, ppl=1.7, wps=24969.3, ups=1.59, wpb=15664.5, bsz=568.5, num_updates=47900, lr=1.00104e-05, gnorm=0.975, train_wall=63, wall=33511
2021-01-17 01:09:56 | INFO | train_inner | epoch 128:    375 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.77, ppl=1.71, wps=24504.4, ups=1.59, wpb=15369, bsz=550, num_updates=48000, lr=1e-05, gnorm=1.028, train_wall=63, wall=33574
2021-01-17 01:09:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:09:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:09:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:09:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:09:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:10:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:10:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:10:16 | INFO | valid | epoch 128 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.061 | ppl 16.7 | bleu 22.43 | wps 5087.3 | wpb 11799.1 | bsz 428.6 | num_updates 48000 | best_bleu 22.62
2021-01-17 01:10:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:10:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:10:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:10:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:10:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:10:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 128 @ 48000 updates, score 22.43) (writing took 3.2791073136031628 seconds)
2021-01-17 01:10:19 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2021-01-17 01:10:19 | INFO | train | epoch 128 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.283 | nll_loss 0.766 | ppl 1.7 | wps 22470.6 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 48000 | lr 1e-05 | gnorm 0.994 | train_wall 235 | wall 33596
2021-01-17 01:10:19 | INFO | fairseq.trainer | begin training epoch 129
2021-01-17 01:10:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:10:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:11:25 | INFO | train_inner | epoch 129:    100 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.763, ppl=1.7, wps=17590.1, ups=1.12, wpb=15661, bsz=588.9, num_updates=48100, lr=9.9896e-06, gnorm=0.98, train_wall=62, wall=33663
2021-01-17 01:12:29 | INFO | train_inner | epoch 129:    200 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.763, ppl=1.7, wps=24814.2, ups=1.58, wpb=15743.5, bsz=552.2, num_updates=48200, lr=9.97923e-06, gnorm=0.989, train_wall=63, wall=33726
2021-01-17 01:13:32 | INFO | train_inner | epoch 129:    300 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.292, nll_loss=0.771, ppl=1.71, wps=25112.2, ups=1.59, wpb=15772.4, bsz=551.9, num_updates=48300, lr=9.9689e-06, gnorm=0.994, train_wall=63, wall=33789
2021-01-17 01:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:14:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:14:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:14:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:14:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:14:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:14:38 | INFO | valid | epoch 129 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.062 | ppl 16.7 | bleu 22.39 | wps 5433.7 | wpb 11799.1 | bsz 428.6 | num_updates 48375 | best_bleu 22.62
2021-01-17 01:14:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:14:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:14:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:14:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 129 @ 48375 updates, score 22.39) (writing took 3.1728078927844763 seconds)
2021-01-17 01:14:41 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2021-01-17 01:14:41 | INFO | train | epoch 129 | symm_kl 0.466 | self_kl 0 | self_cv 0 | loss 3.283 | nll_loss 0.765 | ppl 1.7 | wps 22446.3 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 48375 | lr 9.96116e-06 | gnorm 0.993 | train_wall 236 | wall 33858
2021-01-17 01:14:41 | INFO | fairseq.trainer | begin training epoch 130
2021-01-17 01:14:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:14:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:15:00 | INFO | train_inner | epoch 130:     25 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.289, nll_loss=0.766, ppl=1.7, wps=17573.4, ups=1.13, wpb=15543.2, bsz=517.5, num_updates=48400, lr=9.95859e-06, gnorm=1.017, train_wall=63, wall=33877
2021-01-17 01:16:03 | INFO | train_inner | epoch 130:    125 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.282, nll_loss=0.761, ppl=1.69, wps=25024.7, ups=1.59, wpb=15725.2, bsz=555.8, num_updates=48500, lr=9.94832e-06, gnorm=0.988, train_wall=63, wall=33940
2021-01-17 01:17:06 | INFO | train_inner | epoch 130:    225 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.753, ppl=1.69, wps=24925.9, ups=1.58, wpb=15762.9, bsz=549.2, num_updates=48600, lr=9.93808e-06, gnorm=0.983, train_wall=63, wall=34004
2021-01-17 01:18:09 | INFO | train_inner | epoch 130:    325 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.771, ppl=1.71, wps=24645.9, ups=1.58, wpb=15549.6, bsz=564.1, num_updates=48700, lr=9.92787e-06, gnorm=0.99, train_wall=63, wall=34067
2021-01-17 01:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:18:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:18:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:18:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:18:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:18:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:18:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:18:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:18:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:18:59 | INFO | valid | epoch 130 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.061 | ppl 16.69 | bleu 22.34 | wps 5606.2 | wpb 11799.1 | bsz 428.6 | num_updates 48750 | best_bleu 22.62
2021-01-17 01:18:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:19:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:19:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:19:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 130 @ 48750 updates, score 22.34) (writing took 3.056101491674781 seconds)
2021-01-17 01:19:02 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2021-01-17 01:19:02 | INFO | train | epoch 130 | symm_kl 0.465 | self_kl 0 | self_cv 0 | loss 3.283 | nll_loss 0.765 | ppl 1.7 | wps 22527.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 48750 | lr 9.92278e-06 | gnorm 0.992 | train_wall 235 | wall 34119
2021-01-17 01:19:02 | INFO | fairseq.trainer | begin training epoch 131
2021-01-17 01:19:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:19:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:19:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:19:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:19:37 | INFO | train_inner | epoch 131:     50 / 375 symm_kl=0.473, self_kl=0, self_cv=0, loss=3.301, nll_loss=0.772, ppl=1.71, wps=17751.8, ups=1.14, wpb=15539.2, bsz=528.2, num_updates=48800, lr=9.91769e-06, gnorm=1.009, train_wall=62, wall=34154
2021-01-17 01:20:40 | INFO | train_inner | epoch 131:    150 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.764, ppl=1.7, wps=25511.3, ups=1.59, wpb=16034.7, bsz=559.5, num_updates=48900, lr=9.90755e-06, gnorm=0.971, train_wall=63, wall=34217
2021-01-17 01:21:43 | INFO | train_inner | epoch 131:    250 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.764, ppl=1.7, wps=25056.8, ups=1.58, wpb=15852.8, bsz=588.6, num_updates=49000, lr=9.89743e-06, gnorm=0.98, train_wall=63, wall=34280
2021-01-17 01:22:46 | INFO | train_inner | epoch 131:    350 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.766, ppl=1.7, wps=24470.5, ups=1.58, wpb=15452.8, bsz=528.6, num_updates=49100, lr=9.88735e-06, gnorm=1.008, train_wall=63, wall=34343
2021-01-17 01:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:23:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:23:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:23:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:23:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:23:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:23:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:23:20 | INFO | valid | epoch 131 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.065 | ppl 16.74 | bleu 22.36 | wps 5494.7 | wpb 11799.1 | bsz 428.6 | num_updates 49125 | best_bleu 22.62
2021-01-17 01:23:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:23:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:23:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:23:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 131 @ 49125 updates, score 22.36) (writing took 3.1536887250840664 seconds)
2021-01-17 01:23:24 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2021-01-17 01:23:24 | INFO | train | epoch 131 | symm_kl 0.465 | self_kl 0 | self_cv 0 | loss 3.281 | nll_loss 0.764 | ppl 1.7 | wps 22494.9 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 49125 | lr 9.88483e-06 | gnorm 0.992 | train_wall 235 | wall 34381
2021-01-17 01:23:24 | INFO | fairseq.trainer | begin training epoch 132
2021-01-17 01:23:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:23:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:24:14 | INFO | train_inner | epoch 132:     75 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.271, nll_loss=0.76, ppl=1.69, wps=17740.1, ups=1.13, wpb=15632.8, bsz=542, num_updates=49200, lr=9.8773e-06, gnorm=0.986, train_wall=62, wall=34432
2021-01-17 01:25:17 | INFO | train_inner | epoch 132:    175 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.289, nll_loss=0.767, ppl=1.7, wps=24980.7, ups=1.58, wpb=15778.1, bsz=560.3, num_updates=49300, lr=9.86727e-06, gnorm=0.994, train_wall=63, wall=34495
2021-01-17 01:26:21 | INFO | train_inner | epoch 132:    275 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.763, ppl=1.7, wps=24604.8, ups=1.58, wpb=15555.8, bsz=577.7, num_updates=49400, lr=9.85728e-06, gnorm=0.991, train_wall=63, wall=34558
2021-01-17 01:27:24 | INFO | train_inner | epoch 132:    375 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.287, nll_loss=0.765, ppl=1.7, wps=24854.9, ups=1.59, wpb=15642.6, bsz=530.6, num_updates=49500, lr=9.84732e-06, gnorm=1.001, train_wall=63, wall=34621
2021-01-17 01:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:27:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:27:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:27:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:27:42 | INFO | valid | epoch 132 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.064 | ppl 16.73 | bleu 22.37 | wps 5522.8 | wpb 11799.1 | bsz 428.6 | num_updates 49500 | best_bleu 22.62
2021-01-17 01:27:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:27:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:27:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:27:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 132 @ 49500 updates, score 22.37) (writing took 3.186344103887677 seconds)
2021-01-17 01:27:45 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2021-01-17 01:27:45 | INFO | train | epoch 132 | symm_kl 0.465 | self_kl 0 | self_cv 0 | loss 3.281 | nll_loss 0.764 | ppl 1.7 | wps 22495.1 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 49500 | lr 9.84732e-06 | gnorm 0.992 | train_wall 235 | wall 34642
2021-01-17 01:27:45 | INFO | fairseq.trainer | begin training epoch 133
2021-01-17 01:27:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:27:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:28:51 | INFO | train_inner | epoch 133:    100 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.284, nll_loss=0.768, ppl=1.7, wps=18004.4, ups=1.14, wpb=15742.2, bsz=566.5, num_updates=49600, lr=9.83739e-06, gnorm=0.988, train_wall=62, wall=34708
2021-01-17 01:29:53 | INFO | train_inner | epoch 133:    200 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.766, ppl=1.7, wps=24958.4, ups=1.6, wpb=15595.3, bsz=565, num_updates=49700, lr=9.82749e-06, gnorm=1.003, train_wall=62, wall=34771
2021-01-17 01:30:56 | INFO | train_inner | epoch 133:    300 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.764, ppl=1.7, wps=25212.2, ups=1.6, wpb=15739.8, bsz=526.8, num_updates=49800, lr=9.81761e-06, gnorm=0.996, train_wall=62, wall=34833
2021-01-17 01:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:31:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:31:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:31:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:31:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:31:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:31:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:31:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:31:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:31:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:31:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:32:00 | INFO | valid | epoch 133 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.067 | ppl 16.76 | bleu 22.49 | wps 5777.3 | wpb 11799.1 | bsz 428.6 | num_updates 49875 | best_bleu 22.62
2021-01-17 01:32:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:32:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:32:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:32:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 133 @ 49875 updates, score 22.49) (writing took 2.969154193997383 seconds)
2021-01-17 01:32:03 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2021-01-17 01:32:03 | INFO | train | epoch 133 | symm_kl 0.464 | self_kl 0 | self_cv 0 | loss 3.28 | nll_loss 0.764 | ppl 1.7 | wps 22754.2 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 49875 | lr 9.81023e-06 | gnorm 0.995 | train_wall 233 | wall 34901
2021-01-17 01:32:03 | INFO | fairseq.trainer | begin training epoch 134
2021-01-17 01:32:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:32:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:32:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:32:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:32:23 | INFO | train_inner | epoch 134:     25 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.754, ppl=1.69, wps=18175.8, ups=1.15, wpb=15752.6, bsz=559.9, num_updates=49900, lr=9.80777e-06, gnorm=0.988, train_wall=62, wall=34920
2021-01-17 01:33:25 | INFO | train_inner | epoch 134:    125 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.764, ppl=1.7, wps=25253.5, ups=1.61, wpb=15719.6, bsz=540.2, num_updates=50000, lr=9.79796e-06, gnorm=0.993, train_wall=62, wall=34982
2021-01-17 01:34:28 | INFO | train_inner | epoch 134:    225 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.765, ppl=1.7, wps=24837.1, ups=1.59, wpb=15596.4, bsz=544.6, num_updates=50100, lr=9.78818e-06, gnorm=0.983, train_wall=63, wall=35045
2021-01-17 01:35:30 | INFO | train_inner | epoch 134:    325 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.763, ppl=1.7, wps=25272.4, ups=1.6, wpb=15785.3, bsz=567.8, num_updates=50200, lr=9.77842e-06, gnorm=0.974, train_wall=62, wall=35107
2021-01-17 01:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:36:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:36:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:36:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:36:20 | INFO | valid | epoch 134 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.064 | ppl 16.73 | bleu 22.46 | wps 5660.6 | wpb 11799.1 | bsz 428.6 | num_updates 50250 | best_bleu 22.62
2021-01-17 01:36:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:36:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 134 @ 50250 updates, score 22.46) (writing took 2.9809176679700613 seconds)
2021-01-17 01:36:23 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2021-01-17 01:36:23 | INFO | train | epoch 134 | symm_kl 0.464 | self_kl 0 | self_cv 0 | loss 3.279 | nll_loss 0.764 | ppl 1.7 | wps 22700.3 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 50250 | lr 9.77356e-06 | gnorm 0.985 | train_wall 234 | wall 35160
2021-01-17 01:36:23 | INFO | fairseq.trainer | begin training epoch 135
2021-01-17 01:36:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:36:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:36:57 | INFO | train_inner | epoch 135:     50 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.773, ppl=1.71, wps=18129.5, ups=1.15, wpb=15764.1, bsz=554.2, num_updates=50300, lr=9.7687e-06, gnorm=0.99, train_wall=62, wall=35194
2021-01-17 01:38:00 | INFO | train_inner | epoch 135:    150 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.762, ppl=1.7, wps=24921.4, ups=1.59, wpb=15671.8, bsz=561.6, num_updates=50400, lr=9.759e-06, gnorm=0.984, train_wall=63, wall=35257
2021-01-17 01:39:03 | INFO | train_inner | epoch 135:    250 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.769, ppl=1.7, wps=24873.5, ups=1.59, wpb=15611.8, bsz=540, num_updates=50500, lr=9.74933e-06, gnorm=1.003, train_wall=63, wall=35320
2021-01-17 01:40:05 | INFO | train_inner | epoch 135:    350 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.761, ppl=1.69, wps=25149.6, ups=1.6, wpb=15680.8, bsz=564.2, num_updates=50600, lr=9.7397e-06, gnorm=0.979, train_wall=62, wall=35382
2021-01-17 01:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:40:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:40:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:40:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:40:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:40:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:40:39 | INFO | valid | epoch 135 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.067 | ppl 16.76 | bleu 22.35 | wps 5541.5 | wpb 11799.1 | bsz 428.6 | num_updates 50625 | best_bleu 22.62
2021-01-17 01:40:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:40:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:40:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:40:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 135 @ 50625 updates, score 22.35) (writing took 2.9834339171648026 seconds)
2021-01-17 01:40:42 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2021-01-17 01:40:42 | INFO | train | epoch 135 | symm_kl 0.464 | self_kl 0 | self_cv 0 | loss 3.279 | nll_loss 0.764 | ppl 1.7 | wps 22677.4 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 50625 | lr 9.73729e-06 | gnorm 0.989 | train_wall 234 | wall 35419
2021-01-17 01:40:42 | INFO | fairseq.trainer | begin training epoch 136
2021-01-17 01:40:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:40:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:41:32 | INFO | train_inner | epoch 136:     75 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.765, ppl=1.7, wps=17846.2, ups=1.15, wpb=15536.9, bsz=540.5, num_updates=50700, lr=9.73009e-06, gnorm=0.995, train_wall=62, wall=35469
2021-01-17 01:42:35 | INFO | train_inner | epoch 136:    175 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.758, ppl=1.69, wps=25277.5, ups=1.6, wpb=15776.1, bsz=561, num_updates=50800, lr=9.7205e-06, gnorm=0.989, train_wall=62, wall=35532
2021-01-17 01:43:37 | INFO | train_inner | epoch 136:    275 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.764, ppl=1.7, wps=25071.4, ups=1.6, wpb=15706.6, bsz=568.9, num_updates=50900, lr=9.71095e-06, gnorm=0.981, train_wall=62, wall=35594
2021-01-17 01:44:40 | INFO | train_inner | epoch 136:    375 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.764, ppl=1.7, wps=24900.1, ups=1.6, wpb=15567.2, bsz=533.9, num_updates=51000, lr=9.70143e-06, gnorm=1, train_wall=62, wall=35657
2021-01-17 01:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:44:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:44:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:44:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:44:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:44:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:44:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:44:59 | INFO | valid | epoch 136 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.065 | ppl 16.74 | bleu 22.42 | wps 5174.2 | wpb 11799.1 | bsz 428.6 | num_updates 51000 | best_bleu 22.62
2021-01-17 01:44:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:45:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:45:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:45:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:45:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:45:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 136 @ 51000 updates, score 22.42) (writing took 3.0085684526711702 seconds)
2021-01-17 01:45:02 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2021-01-17 01:45:02 | INFO | train | epoch 136 | symm_kl 0.464 | self_kl 0 | self_cv 0 | loss 3.279 | nll_loss 0.764 | ppl 1.7 | wps 22613.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 51000 | lr 9.70143e-06 | gnorm 0.989 | train_wall 233 | wall 35679
2021-01-17 01:45:02 | INFO | fairseq.trainer | begin training epoch 137
2021-01-17 01:45:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:45:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:46:08 | INFO | train_inner | epoch 137:    100 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.756, ppl=1.69, wps=17910.7, ups=1.13, wpb=15803.6, bsz=553.7, num_updates=51100, lr=9.69193e-06, gnorm=0.972, train_wall=62, wall=35745
2021-01-17 01:47:11 | INFO | train_inner | epoch 137:    200 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.761, ppl=1.69, wps=24995.2, ups=1.59, wpb=15701.4, bsz=565.6, num_updates=51200, lr=9.68246e-06, gnorm=0.989, train_wall=63, wall=35808
2021-01-17 01:48:13 | INFO | train_inner | epoch 137:    300 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.286, nll_loss=0.765, ppl=1.7, wps=24789.9, ups=1.6, wpb=15501.3, bsz=549.7, num_updates=51300, lr=9.67302e-06, gnorm=0.999, train_wall=62, wall=35871
2021-01-17 01:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:49:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:49:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:49:19 | INFO | valid | epoch 137 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.063 | ppl 16.72 | bleu 22.47 | wps 5360.4 | wpb 11799.1 | bsz 428.6 | num_updates 51375 | best_bleu 22.62
2021-01-17 01:49:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:49:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 137 @ 51375 updates, score 22.47) (writing took 3.0346650201827288 seconds)
2021-01-17 01:49:22 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2021-01-17 01:49:22 | INFO | train | epoch 137 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.278 | nll_loss 0.764 | ppl 1.7 | wps 22633.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 51375 | lr 9.66595e-06 | gnorm 0.988 | train_wall 234 | wall 35939
2021-01-17 01:49:22 | INFO | fairseq.trainer | begin training epoch 138
2021-01-17 01:49:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:49:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:49:41 | INFO | train_inner | epoch 138:     25 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.767, ppl=1.7, wps=17909.4, ups=1.14, wpb=15659.2, bsz=533.2, num_updates=51400, lr=9.6636e-06, gnorm=0.994, train_wall=62, wall=35958
2021-01-17 01:50:43 | INFO | train_inner | epoch 138:    125 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.76, ppl=1.69, wps=25374.9, ups=1.61, wpb=15808.4, bsz=570.1, num_updates=51500, lr=9.65422e-06, gnorm=0.987, train_wall=62, wall=36020
2021-01-17 01:51:45 | INFO | train_inner | epoch 138:    225 / 375 symm_kl=0.467, self_kl=0, self_cv=0, loss=3.291, nll_loss=0.771, ppl=1.71, wps=25139.4, ups=1.6, wpb=15703.5, bsz=538.2, num_updates=51600, lr=9.64486e-06, gnorm=0.997, train_wall=62, wall=36083
2021-01-17 01:52:48 | INFO | train_inner | epoch 138:    325 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.765, ppl=1.7, wps=25023.6, ups=1.6, wpb=15636.9, bsz=556.4, num_updates=51700, lr=9.63552e-06, gnorm=0.996, train_wall=62, wall=36145
2021-01-17 01:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:53:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:53:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:53:38 | INFO | valid | epoch 138 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.066 | ppl 16.75 | bleu 22.5 | wps 5469.5 | wpb 11799.1 | bsz 428.6 | num_updates 51750 | best_bleu 22.62
2021-01-17 01:53:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:53:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 138 @ 51750 updates, score 22.5) (writing took 3.0638828091323376 seconds)
2021-01-17 01:53:41 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2021-01-17 01:53:41 | INFO | train | epoch 138 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.277 | nll_loss 0.763 | ppl 1.7 | wps 22677.8 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 51750 | lr 9.63087e-06 | gnorm 0.992 | train_wall 233 | wall 36198
2021-01-17 01:53:41 | INFO | fairseq.trainer | begin training epoch 139
2021-01-17 01:53:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:53:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:54:16 | INFO | train_inner | epoch 139:     50 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.766, ppl=1.7, wps=17941.3, ups=1.14, wpb=15715.6, bsz=577.4, num_updates=51800, lr=9.62622e-06, gnorm=0.976, train_wall=62, wall=36233
2021-01-17 01:55:18 | INFO | train_inner | epoch 139:    150 / 375 symm_kl=0.47, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.765, ppl=1.7, wps=24912.2, ups=1.59, wpb=15624.9, bsz=529.1, num_updates=51900, lr=9.61694e-06, gnorm=1, train_wall=62, wall=36296
2021-01-17 01:56:21 | INFO | train_inner | epoch 139:    250 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.763, ppl=1.7, wps=25085.5, ups=1.58, wpb=15857.3, bsz=552, num_updates=52000, lr=9.60769e-06, gnorm=0.977, train_wall=63, wall=36359
2021-01-17 01:57:25 | INFO | train_inner | epoch 139:    350 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.752, ppl=1.68, wps=24777.8, ups=1.59, wpb=15626.6, bsz=556.9, num_updates=52100, lr=9.59846e-06, gnorm=0.986, train_wall=63, wall=36422
2021-01-17 01:57:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 01:57:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:57:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:57:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:57:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:57:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:57:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:57:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 01:57:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 01:57:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 01:57:58 | INFO | valid | epoch 139 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.067 | ppl 16.76 | bleu 22.31 | wps 5543.7 | wpb 11799.1 | bsz 428.6 | num_updates 52125 | best_bleu 22.62
2021-01-17 01:57:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 01:57:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:57:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:58:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:58:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:58:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 139 @ 52125 updates, score 22.31) (writing took 2.9955193772912025 seconds)
2021-01-17 01:58:01 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2021-01-17 01:58:01 | INFO | train | epoch 139 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.276 | nll_loss 0.762 | ppl 1.7 | wps 22611.4 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 52125 | lr 9.59616e-06 | gnorm 0.987 | train_wall 234 | wall 36459
2021-01-17 01:58:01 | INFO | fairseq.trainer | begin training epoch 140
2021-01-17 01:58:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 01:58:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 01:58:52 | INFO | train_inner | epoch 140:     75 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.758, ppl=1.69, wps=17876.5, ups=1.15, wpb=15563.8, bsz=568.1, num_updates=52200, lr=9.58927e-06, gnorm=0.99, train_wall=62, wall=36509
2021-01-17 01:59:54 | INFO | train_inner | epoch 140:    175 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.282, nll_loss=0.765, ppl=1.7, wps=24939.7, ups=1.6, wpb=15599, bsz=571.2, num_updates=52300, lr=9.58009e-06, gnorm=1, train_wall=62, wall=36571
2021-01-17 02:00:57 | INFO | train_inner | epoch 140:    275 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.767, ppl=1.7, wps=25046.9, ups=1.59, wpb=15726.2, bsz=527.4, num_updates=52400, lr=9.57095e-06, gnorm=0.99, train_wall=63, wall=36634
2021-01-17 02:01:59 | INFO | train_inner | epoch 140:    375 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.765, ppl=1.7, wps=25140.6, ups=1.6, wpb=15718.8, bsz=545.8, num_updates=52500, lr=9.56183e-06, gnorm=0.99, train_wall=62, wall=36697
2021-01-17 02:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:02:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:02:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:02:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:02:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:02:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:02:18 | INFO | valid | epoch 140 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.067 | ppl 16.76 | bleu 22.35 | wps 5319.4 | wpb 11799.1 | bsz 428.6 | num_updates 52500 | best_bleu 22.62
2021-01-17 02:02:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:02:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:02:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:02:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 140 @ 52500 updates, score 22.35) (writing took 3.1171593107283115 seconds)
2021-01-17 02:02:21 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2021-01-17 02:02:21 | INFO | train | epoch 140 | symm_kl 0.462 | self_kl 0 | self_cv 0 | loss 3.276 | nll_loss 0.763 | ppl 1.7 | wps 22609.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 52500 | lr 9.56183e-06 | gnorm 0.991 | train_wall 234 | wall 36719
2021-01-17 02:02:21 | INFO | fairseq.trainer | begin training epoch 141
2021-01-17 02:02:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:02:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:03:27 | INFO | train_inner | epoch 141:    100 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.28, nll_loss=0.766, ppl=1.7, wps=17808.8, ups=1.14, wpb=15579.3, bsz=556.7, num_updates=52600, lr=9.55274e-06, gnorm=0.989, train_wall=62, wall=36784
2021-01-17 02:04:30 | INFO | train_inner | epoch 141:    200 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.753, ppl=1.69, wps=25077.2, ups=1.59, wpb=15794.5, bsz=548.5, num_updates=52700, lr=9.54367e-06, gnorm=0.982, train_wall=63, wall=36847
2021-01-17 02:05:33 | INFO | train_inner | epoch 141:    300 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.762, ppl=1.7, wps=25116.4, ups=1.59, wpb=15798.5, bsz=564.8, num_updates=52800, lr=9.53463e-06, gnorm=0.981, train_wall=63, wall=36910
2021-01-17 02:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:06:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:06:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:06:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:06:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:06:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:06:38 | INFO | valid | epoch 141 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.062 | ppl 16.7 | bleu 22.47 | wps 5546.3 | wpb 11799.1 | bsz 428.6 | num_updates 52875 | best_bleu 22.62
2021-01-17 02:06:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:06:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:06:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 141 @ 52875 updates, score 22.47) (writing took 3.07285762950778 seconds)
2021-01-17 02:06:41 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2021-01-17 02:06:41 | INFO | train | epoch 141 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.276 | nll_loss 0.763 | ppl 1.7 | wps 22657.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 52875 | lr 9.52786e-06 | gnorm 0.989 | train_wall 234 | wall 36978
2021-01-17 02:06:41 | INFO | fairseq.trainer | begin training epoch 142
2021-01-17 02:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:07:00 | INFO | train_inner | epoch 142:     25 / 375 symm_kl=0.468, self_kl=0, self_cv=0, loss=3.293, nll_loss=0.773, ppl=1.71, wps=17930.9, ups=1.15, wpb=15616.7, bsz=546.6, num_updates=52900, lr=9.52561e-06, gnorm=1.002, train_wall=62, wall=36997
2021-01-17 02:08:02 | INFO | train_inner | epoch 142:    125 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.761, ppl=1.69, wps=25473.8, ups=1.61, wpb=15802.9, bsz=546.9, num_updates=53000, lr=9.51662e-06, gnorm=0.984, train_wall=62, wall=37059
2021-01-17 02:09:04 | INFO | train_inner | epoch 142:    225 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.284, nll_loss=0.766, ppl=1.7, wps=24984, ups=1.6, wpb=15608.8, bsz=547.1, num_updates=53100, lr=9.50765e-06, gnorm=0.993, train_wall=62, wall=37122
2021-01-17 02:10:07 | INFO | train_inner | epoch 142:    325 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.762, ppl=1.7, wps=25068.4, ups=1.6, wpb=15714.4, bsz=564.5, num_updates=53200, lr=9.49871e-06, gnorm=0.984, train_wall=62, wall=37184
2021-01-17 02:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:10:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:10:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:10:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:10:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:10:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:10:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:10:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:10:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:10:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:10:56 | INFO | valid | epoch 142 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.061 | ppl 16.69 | bleu 22.41 | wps 5540.7 | wpb 11799.1 | bsz 428.6 | num_updates 53250 | best_bleu 22.62
2021-01-17 02:10:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:10:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:10:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:10:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:10:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:10:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 142 @ 53250 updates, score 22.41) (writing took 3.0191333796828985 seconds)
2021-01-17 02:10:59 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2021-01-17 02:10:59 | INFO | train | epoch 142 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.276 | nll_loss 0.763 | ppl 1.7 | wps 22752.4 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 53250 | lr 9.49425e-06 | gnorm 0.989 | train_wall 233 | wall 37237
2021-01-17 02:10:59 | INFO | fairseq.trainer | begin training epoch 143
2021-01-17 02:11:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:11:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:11:34 | INFO | train_inner | epoch 143:     50 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.756, ppl=1.69, wps=18075.3, ups=1.16, wpb=15648, bsz=542.2, num_updates=53300, lr=9.4898e-06, gnorm=0.998, train_wall=62, wall=37271
2021-01-17 02:12:36 | INFO | train_inner | epoch 143:    150 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.765, ppl=1.7, wps=25024.5, ups=1.61, wpb=15577.3, bsz=534.4, num_updates=53400, lr=9.48091e-06, gnorm=1.003, train_wall=62, wall=37333
2021-01-17 02:13:39 | INFO | train_inner | epoch 143:    250 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.752, ppl=1.68, wps=25313.1, ups=1.59, wpb=15927.2, bsz=585.4, num_updates=53500, lr=9.47204e-06, gnorm=0.967, train_wall=63, wall=37396
2021-01-17 02:14:41 | INFO | train_inner | epoch 143:    350 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.77, ppl=1.71, wps=25314.2, ups=1.61, wpb=15724.5, bsz=556.9, num_updates=53600, lr=9.4632e-06, gnorm=0.988, train_wall=62, wall=37458
2021-01-17 02:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:14:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:14:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:14:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:14:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:14:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:14:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:15:14 | INFO | valid | epoch 143 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.065 | ppl 16.73 | bleu 22.4 | wps 5786.7 | wpb 11799.1 | bsz 428.6 | num_updates 53625 | best_bleu 22.62
2021-01-17 02:15:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:15:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:15:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:15:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:15:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:15:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 143 @ 53625 updates, score 22.4) (writing took 3.0843488071113825 seconds)
2021-01-17 02:15:17 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2021-01-17 02:15:17 | INFO | train | epoch 143 | symm_kl 0.463 | self_kl 0 | self_cv 0 | loss 3.276 | nll_loss 0.763 | ppl 1.7 | wps 22790.1 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 53625 | lr 9.461e-06 | gnorm 0.993 | train_wall 233 | wall 37495
2021-01-17 02:15:17 | INFO | fairseq.trainer | begin training epoch 144
2021-01-17 02:15:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:16:08 | INFO | train_inner | epoch 144:     75 / 375 symm_kl=0.469, self_kl=0, self_cv=0, loss=3.296, nll_loss=0.774, ppl=1.71, wps=17746.4, ups=1.16, wpb=15361.4, bsz=534.7, num_updates=53700, lr=9.45439e-06, gnorm=1.007, train_wall=62, wall=37545
2021-01-17 02:17:10 | INFO | train_inner | epoch 144:    175 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.763, ppl=1.7, wps=25168, ups=1.61, wpb=15672.6, bsz=547.8, num_updates=53800, lr=9.4456e-06, gnorm=0.982, train_wall=62, wall=37607
2021-01-17 02:18:12 | INFO | train_inner | epoch 144:    275 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.758, ppl=1.69, wps=25243.1, ups=1.6, wpb=15805.8, bsz=556.6, num_updates=53900, lr=9.43683e-06, gnorm=0.987, train_wall=62, wall=37670
2021-01-17 02:19:15 | INFO | train_inner | epoch 144:    375 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.264, nll_loss=0.757, ppl=1.69, wps=24906.5, ups=1.6, wpb=15614.8, bsz=562, num_updates=54000, lr=9.42809e-06, gnorm=0.987, train_wall=62, wall=37732
2021-01-17 02:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:19:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:19:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:19:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:19:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:19:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:19:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:19:33 | INFO | valid | epoch 144 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.063 | ppl 16.71 | bleu 22.46 | wps 5567.1 | wpb 11799.1 | bsz 428.6 | num_updates 54000 | best_bleu 22.62
2021-01-17 02:19:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:19:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:19:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 144 @ 54000 updates, score 22.46) (writing took 3.1346278320997953 seconds)
2021-01-17 02:19:36 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2021-01-17 02:19:36 | INFO | train | epoch 144 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.273 | nll_loss 0.762 | ppl 1.7 | wps 22719.4 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 54000 | lr 9.42809e-06 | gnorm 0.985 | train_wall 233 | wall 37754
2021-01-17 02:19:36 | INFO | fairseq.trainer | begin training epoch 145
2021-01-17 02:19:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:19:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:20:42 | INFO | train_inner | epoch 145:    100 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.759, ppl=1.69, wps=18291.8, ups=1.15, wpb=15894.5, bsz=549.8, num_updates=54100, lr=9.41937e-06, gnorm=0.978, train_wall=62, wall=37819
2021-01-17 02:21:44 | INFO | train_inner | epoch 145:    200 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.769, ppl=1.7, wps=24945.2, ups=1.6, wpb=15579.4, bsz=568.1, num_updates=54200, lr=9.41068e-06, gnorm=0.994, train_wall=62, wall=37882
2021-01-17 02:22:47 | INFO | train_inner | epoch 145:    300 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.267, nll_loss=0.76, ppl=1.69, wps=25202.1, ups=1.6, wpb=15781, bsz=553.9, num_updates=54300, lr=9.40201e-06, gnorm=0.984, train_wall=62, wall=37944
2021-01-17 02:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:23:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:23:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:23:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:23:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:23:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:23:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:23:52 | INFO | valid | epoch 145 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.063 | ppl 16.72 | bleu 22.41 | wps 5558.1 | wpb 11799.1 | bsz 428.6 | num_updates 54375 | best_bleu 22.62
2021-01-17 02:23:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:23:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:23:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:23:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 145 @ 54375 updates, score 22.41) (writing took 3.1354219559580088 seconds)
2021-01-17 02:23:55 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2021-01-17 02:23:55 | INFO | train | epoch 145 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.274 | nll_loss 0.762 | ppl 1.7 | wps 22716 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 54375 | lr 9.39552e-06 | gnorm 0.989 | train_wall 233 | wall 38013
2021-01-17 02:23:55 | INFO | fairseq.trainer | begin training epoch 146
2021-01-17 02:23:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:23:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:24:14 | INFO | train_inner | epoch 146:     25 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.757, ppl=1.69, wps=17792.7, ups=1.15, wpb=15496.6, bsz=537.9, num_updates=54400, lr=9.39336e-06, gnorm=0.998, train_wall=62, wall=38032
2021-01-17 02:25:16 | INFO | train_inner | epoch 146:    125 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.287, nll_loss=0.771, ppl=1.71, wps=25085.5, ups=1.61, wpb=15586.1, bsz=539.5, num_updates=54500, lr=9.38474e-06, gnorm=0.994, train_wall=62, wall=38094
2021-01-17 02:26:19 | INFO | train_inner | epoch 146:    225 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.759, ppl=1.69, wps=25248.7, ups=1.59, wpb=15849.7, bsz=555.9, num_updates=54600, lr=9.37614e-06, gnorm=0.985, train_wall=63, wall=38156
2021-01-17 02:27:22 | INFO | train_inner | epoch 146:    325 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.759, ppl=1.69, wps=25040.8, ups=1.6, wpb=15657.1, bsz=567.7, num_updates=54700, lr=9.36757e-06, gnorm=0.993, train_wall=62, wall=38219
2021-01-17 02:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:27:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:27:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:27:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:27:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:27:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:27:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:27:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:27:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:27:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:27:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:27:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:27:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:27:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:27:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:27:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:28:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:28:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:28:13 | INFO | valid | epoch 146 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.063 | ppl 16.72 | bleu 22.38 | wps 4986 | wpb 11799.1 | bsz 428.6 | num_updates 54750 | best_bleu 22.62
2021-01-17 02:28:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:28:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:28:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:28:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:28:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:28:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 146 @ 54750 updates, score 22.38) (writing took 3.195009708404541 seconds)
2021-01-17 02:28:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2021-01-17 02:28:16 | INFO | train | epoch 146 | symm_kl 0.462 | self_kl 0 | self_cv 0 | loss 3.274 | nll_loss 0.762 | ppl 1.7 | wps 22558 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 54750 | lr 9.36329e-06 | gnorm 0.99 | train_wall 234 | wall 38273
2021-01-17 02:28:16 | INFO | fairseq.trainer | begin training epoch 147
2021-01-17 02:28:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:28:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:28:51 | INFO | train_inner | epoch 147:     50 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.756, ppl=1.69, wps=17407.9, ups=1.12, wpb=15500.4, bsz=539.7, num_updates=54800, lr=9.35902e-06, gnorm=0.991, train_wall=62, wall=38308
2021-01-17 02:29:53 | INFO | train_inner | epoch 147:    150 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.762, ppl=1.7, wps=24617.4, ups=1.6, wpb=15384.6, bsz=540.6, num_updates=54900, lr=9.35049e-06, gnorm=0.99, train_wall=62, wall=38370
2021-01-17 02:30:57 | INFO | train_inner | epoch 147:    250 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.761, ppl=1.69, wps=24740, ups=1.58, wpb=15686.7, bsz=548.2, num_updates=55000, lr=9.34199e-06, gnorm=0.996, train_wall=63, wall=38434
2021-01-17 02:32:00 | INFO | train_inner | epoch 147:    350 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.765, ppl=1.7, wps=25481.5, ups=1.59, wpb=16072.9, bsz=570.4, num_updates=55100, lr=9.33351e-06, gnorm=0.968, train_wall=63, wall=38497
2021-01-17 02:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:32:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:32:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:32:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:32:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:32:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:32:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:32:34 | INFO | valid | epoch 147 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.061 | ppl 16.69 | bleu 22.41 | wps 5190.2 | wpb 11799.1 | bsz 428.6 | num_updates 55125 | best_bleu 22.62
2021-01-17 02:32:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:32:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:32:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:32:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 147 @ 55125 updates, score 22.41) (writing took 3.1930739004164934 seconds)
2021-01-17 02:32:38 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2021-01-17 02:32:38 | INFO | train | epoch 147 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.273 | nll_loss 0.761 | ppl 1.69 | wps 22470.7 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 55125 | lr 9.33139e-06 | gnorm 0.987 | train_wall 235 | wall 38535
2021-01-17 02:32:38 | INFO | fairseq.trainer | begin training epoch 148
2021-01-17 02:32:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:32:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:33:28 | INFO | train_inner | epoch 148:     75 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.764, ppl=1.7, wps=17966, ups=1.14, wpb=15795.6, bsz=572.2, num_updates=55200, lr=9.32505e-06, gnorm=0.993, train_wall=62, wall=38585
2021-01-17 02:34:30 | INFO | train_inner | epoch 148:    175 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.271, nll_loss=0.758, ppl=1.69, wps=24932.1, ups=1.6, wpb=15626.1, bsz=530.3, num_updates=55300, lr=9.31661e-06, gnorm=0.988, train_wall=62, wall=38648
2021-01-17 02:35:32 | INFO | train_inner | epoch 148:    275 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.761, ppl=1.69, wps=25181.2, ups=1.61, wpb=15662.1, bsz=581.7, num_updates=55400, lr=9.3082e-06, gnorm=0.991, train_wall=62, wall=38710
2021-01-17 02:36:35 | INFO | train_inner | epoch 148:    375 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.765, ppl=1.7, wps=24879.3, ups=1.59, wpb=15673.5, bsz=538.9, num_updates=55500, lr=9.29981e-06, gnorm=0.993, train_wall=63, wall=38773
2021-01-17 02:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:36:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:36:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:36:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:36:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:36:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:36:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:36:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:36:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:36:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:36:54 | INFO | valid | epoch 148 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.063 | ppl 16.72 | bleu 22.42 | wps 5308.4 | wpb 11799.1 | bsz 428.6 | num_updates 55500 | best_bleu 22.62
2021-01-17 02:36:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:36:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:36:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:36:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:36:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:36:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 148 @ 55500 updates, score 22.42) (writing took 3.2279216311872005 seconds)
2021-01-17 02:36:58 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2021-01-17 02:36:58 | INFO | train | epoch 148 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.273 | nll_loss 0.761 | ppl 1.7 | wps 22629 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 55500 | lr 9.29981e-06 | gnorm 0.99 | train_wall 233 | wall 38795
2021-01-17 02:36:58 | INFO | fairseq.trainer | begin training epoch 149
2021-01-17 02:36:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:37:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:38:03 | INFO | train_inner | epoch 149:    100 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.758, ppl=1.69, wps=17909.9, ups=1.14, wpb=15726.9, bsz=542.2, num_updates=55600, lr=9.29144e-06, gnorm=0.982, train_wall=62, wall=38861
2021-01-17 02:39:06 | INFO | train_inner | epoch 149:    200 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.761, ppl=1.69, wps=24602.5, ups=1.59, wpb=15496.9, bsz=541.4, num_updates=55700, lr=9.2831e-06, gnorm=1.005, train_wall=63, wall=38924
2021-01-17 02:40:09 | INFO | train_inner | epoch 149:    300 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.762, ppl=1.7, wps=25133.1, ups=1.59, wpb=15771.9, bsz=545.4, num_updates=55800, lr=9.27478e-06, gnorm=0.989, train_wall=63, wall=38986
2021-01-17 02:40:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:40:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:40:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:40:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:40:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:40:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:40:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:41:16 | INFO | valid | epoch 149 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.066 | ppl 16.75 | bleu 22.43 | wps 4894.9 | wpb 11799.1 | bsz 428.6 | num_updates 55875 | best_bleu 22.62
2021-01-17 02:41:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:41:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:41:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:41:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:41:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:41:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 149 @ 55875 updates, score 22.43) (writing took 3.2052183505147696 seconds)
2021-01-17 02:41:19 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2021-01-17 02:41:19 | INFO | train | epoch 149 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.272 | nll_loss 0.761 | ppl 1.69 | wps 22465.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 55875 | lr 9.26855e-06 | gnorm 0.991 | train_wall 234 | wall 39057
2021-01-17 02:41:19 | INFO | fairseq.trainer | begin training epoch 150
2021-01-17 02:41:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:41:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:41:38 | INFO | train_inner | epoch 150:     25 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.762, ppl=1.7, wps=17570.6, ups=1.12, wpb=15669, bsz=579.6, num_updates=55900, lr=9.26648e-06, gnorm=0.994, train_wall=62, wall=39075
2021-01-17 02:42:41 | INFO | train_inner | epoch 150:    125 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.766, ppl=1.7, wps=24951.8, ups=1.6, wpb=15588.2, bsz=567.2, num_updates=56000, lr=9.2582e-06, gnorm=0.987, train_wall=62, wall=39138
2021-01-17 02:43:43 | INFO | train_inner | epoch 150:    225 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.76, ppl=1.69, wps=24893.9, ups=1.59, wpb=15616, bsz=540.7, num_updates=56100, lr=9.24995e-06, gnorm=0.996, train_wall=63, wall=39201
2021-01-17 02:44:46 | INFO | train_inner | epoch 150:    325 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.759, ppl=1.69, wps=25556.4, ups=1.61, wpb=15905.5, bsz=564.3, num_updates=56200, lr=9.24171e-06, gnorm=0.978, train_wall=62, wall=39263
2021-01-17 02:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:45:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:45:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:45:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:45:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:45:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:45:36 | INFO | valid | epoch 150 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.682 | nll_loss 4.07 | ppl 16.8 | bleu 22.43 | wps 4946.4 | wpb 11799.1 | bsz 428.6 | num_updates 56250 | best_bleu 22.62
2021-01-17 02:45:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:45:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:45:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:45:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 150 @ 56250 updates, score 22.43) (writing took 3.1567935701459646 seconds)
2021-01-17 02:45:40 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2021-01-17 02:45:40 | INFO | train | epoch 150 | symm_kl 0.461 | self_kl 0 | self_cv 0 | loss 3.272 | nll_loss 0.762 | ppl 1.7 | wps 22601.3 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 56250 | lr 9.2376e-06 | gnorm 0.989 | train_wall 233 | wall 39317
2021-01-17 02:45:40 | INFO | fairseq.trainer | begin training epoch 151
2021-01-17 02:45:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:45:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:46:14 | INFO | train_inner | epoch 151:     50 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.761, ppl=1.69, wps=17563, ups=1.13, wpb=15533.8, bsz=527.4, num_updates=56300, lr=9.2335e-06, gnorm=0.992, train_wall=62, wall=39351
2021-01-17 02:47:17 | INFO | train_inner | epoch 151:    150 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.247, nll_loss=0.748, ppl=1.68, wps=25440.1, ups=1.59, wpb=15993.1, bsz=583.8, num_updates=56400, lr=9.22531e-06, gnorm=0.965, train_wall=63, wall=39414
2021-01-17 02:48:19 | INFO | train_inner | epoch 151:    250 / 375 symm_kl=0.471, self_kl=0, self_cv=0, loss=3.298, nll_loss=0.772, ppl=1.71, wps=24685.3, ups=1.6, wpb=15436.5, bsz=526.8, num_updates=56500, lr=9.21714e-06, gnorm=1.018, train_wall=62, wall=39477
2021-01-17 02:49:22 | INFO | train_inner | epoch 151:    350 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.757, ppl=1.69, wps=25278, ups=1.6, wpb=15785.5, bsz=555.4, num_updates=56600, lr=9.209e-06, gnorm=0.985, train_wall=62, wall=39539
2021-01-17 02:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:49:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:49:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:49:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:49:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:49:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:49:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:49:55 | INFO | valid | epoch 151 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.064 | ppl 16.72 | bleu 22.42 | wps 5601.4 | wpb 11799.1 | bsz 428.6 | num_updates 56625 | best_bleu 22.62
2021-01-17 02:49:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:49:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:49:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:49:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:49:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:49:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 151 @ 56625 updates, score 22.42) (writing took 3.0865562111139297 seconds)
2021-01-17 02:49:59 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2021-01-17 02:49:59 | INFO | train | epoch 151 | symm_kl 0.46 | self_kl 0 | self_cv 0 | loss 3.27 | nll_loss 0.76 | ppl 1.69 | wps 22706.6 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 56625 | lr 9.20697e-06 | gnorm 0.99 | train_wall 233 | wall 39576
2021-01-17 02:49:59 | INFO | fairseq.trainer | begin training epoch 152
2021-01-17 02:50:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:50:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:50:49 | INFO | train_inner | epoch 152:     75 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.759, ppl=1.69, wps=18291.3, ups=1.15, wpb=15853.8, bsz=567.3, num_updates=56700, lr=9.20087e-06, gnorm=0.973, train_wall=62, wall=39626
2021-01-17 02:51:51 | INFO | train_inner | epoch 152:    175 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.261, nll_loss=0.755, ppl=1.69, wps=25281.9, ups=1.59, wpb=15873.8, bsz=551.9, num_updates=56800, lr=9.19277e-06, gnorm=0.971, train_wall=63, wall=39689
2021-01-17 02:52:54 | INFO | train_inner | epoch 152:    275 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.772, ppl=1.71, wps=25073.8, ups=1.6, wpb=15679.6, bsz=556.3, num_updates=56900, lr=9.18469e-06, gnorm=0.99, train_wall=62, wall=39751
2021-01-17 02:53:56 | INFO | train_inner | epoch 152:    375 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.76, ppl=1.69, wps=24527.7, ups=1.6, wpb=15316.1, bsz=545.2, num_updates=57000, lr=9.17663e-06, gnorm=0.99, train_wall=62, wall=39814
2021-01-17 02:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:53:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:53:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:53:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:53:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:53:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:53:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:54:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:54:15 | INFO | valid | epoch 152 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.064 | ppl 16.72 | bleu 22.38 | wps 5468.3 | wpb 11799.1 | bsz 428.6 | num_updates 57000 | best_bleu 22.62
2021-01-17 02:54:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:54:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:54:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:54:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:54:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:54:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 152 @ 57000 updates, score 22.38) (writing took 3.1274687126278877 seconds)
2021-01-17 02:54:18 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2021-01-17 02:54:18 | INFO | train | epoch 152 | symm_kl 0.459 | self_kl 0 | self_cv 0 | loss 3.269 | nll_loss 0.76 | ppl 1.69 | wps 22674 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 57000 | lr 9.17663e-06 | gnorm 0.981 | train_wall 233 | wall 39835
2021-01-17 02:54:18 | INFO | fairseq.trainer | begin training epoch 153
2021-01-17 02:54:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:54:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:55:24 | INFO | train_inner | epoch 153:    100 / 375 symm_kl=0.464, self_kl=0, self_cv=0, loss=3.281, nll_loss=0.766, ppl=1.7, wps=17757.6, ups=1.14, wpb=15580.4, bsz=548.2, num_updates=57100, lr=9.16859e-06, gnorm=0.993, train_wall=62, wall=39901
2021-01-17 02:56:27 | INFO | train_inner | epoch 153:    200 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.264, nll_loss=0.757, ppl=1.69, wps=25242.5, ups=1.58, wpb=15962.1, bsz=555.7, num_updates=57200, lr=9.16057e-06, gnorm=0.969, train_wall=63, wall=39965
2021-01-17 02:57:30 | INFO | train_inner | epoch 153:    300 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.756, ppl=1.69, wps=24877.1, ups=1.6, wpb=15569.2, bsz=540.7, num_updates=57300, lr=9.15258e-06, gnorm=0.992, train_wall=62, wall=40027
2021-01-17 02:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 02:58:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 02:58:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 02:58:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 02:58:35 | INFO | valid | epoch 153 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.063 | ppl 16.72 | bleu 22.43 | wps 5487.5 | wpb 11799.1 | bsz 428.6 | num_updates 57375 | best_bleu 22.62
2021-01-17 02:58:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 02:58:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 153 @ 57375 updates, score 22.43) (writing took 3.2026187404990196 seconds)
2021-01-17 02:58:38 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2021-01-17 02:58:38 | INFO | train | epoch 153 | symm_kl 0.46 | self_kl 0 | self_cv 0 | loss 3.271 | nll_loss 0.761 | ppl 1.69 | wps 22604.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 57375 | lr 9.14659e-06 | gnorm 0.986 | train_wall 234 | wall 40095
2021-01-17 02:58:38 | INFO | fairseq.trainer | begin training epoch 154
2021-01-17 02:58:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 02:58:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 02:58:57 | INFO | train_inner | epoch 154:     25 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.765, ppl=1.7, wps=17738.5, ups=1.15, wpb=15478.6, bsz=552.4, num_updates=57400, lr=9.1446e-06, gnorm=0.997, train_wall=62, wall=40114
2021-01-17 03:00:00 | INFO | train_inner | epoch 154:    125 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.753, ppl=1.69, wps=25206.9, ups=1.6, wpb=15766.2, bsz=572.2, num_updates=57500, lr=9.13664e-06, gnorm=0.972, train_wall=62, wall=40177
2021-01-17 03:01:02 | INFO | train_inner | epoch 154:    225 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.76, ppl=1.69, wps=25413.2, ups=1.6, wpb=15919.8, bsz=558.3, num_updates=57600, lr=9.12871e-06, gnorm=0.972, train_wall=62, wall=40240
2021-01-17 03:02:05 | INFO | train_inner | epoch 154:    325 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.285, nll_loss=0.766, ppl=1.7, wps=24779.3, ups=1.59, wpb=15608.8, bsz=542.9, num_updates=57700, lr=9.1208e-06, gnorm=0.992, train_wall=63, wall=40303
2021-01-17 03:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:02:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:02:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:02:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:02:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:02:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:02:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:02:55 | INFO | valid | epoch 154 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.061 | ppl 16.69 | bleu 22.47 | wps 5544.2 | wpb 11799.1 | bsz 428.6 | num_updates 57750 | best_bleu 22.62
2021-01-17 03:02:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:02:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:02:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:02:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:02:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:02:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 154 @ 57750 updates, score 22.47) (writing took 3.190636780112982 seconds)
2021-01-17 03:02:58 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2021-01-17 03:02:58 | INFO | train | epoch 154 | symm_kl 0.459 | self_kl 0 | self_cv 0 | loss 3.269 | nll_loss 0.76 | ppl 1.69 | wps 22626.3 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 57750 | lr 9.11685e-06 | gnorm 0.983 | train_wall 234 | wall 40355
2021-01-17 03:02:58 | INFO | fairseq.trainer | begin training epoch 155
2021-01-17 03:02:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:03:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:03:33 | INFO | train_inner | epoch 155:     50 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.753, ppl=1.69, wps=17933.5, ups=1.14, wpb=15704.2, bsz=554.7, num_updates=57800, lr=9.1129e-06, gnorm=0.982, train_wall=62, wall=40390
2021-01-17 03:04:35 | INFO | train_inner | epoch 155:    150 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.763, ppl=1.7, wps=25084.4, ups=1.61, wpb=15613.5, bsz=556.5, num_updates=57900, lr=9.10503e-06, gnorm=0.993, train_wall=62, wall=40452
2021-01-17 03:05:38 | INFO | train_inner | epoch 155:    250 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.763, ppl=1.7, wps=25191.9, ups=1.6, wpb=15720.3, bsz=535.4, num_updates=58000, lr=9.09718e-06, gnorm=0.987, train_wall=62, wall=40515
2021-01-17 03:06:40 | INFO | train_inner | epoch 155:    350 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.261, nll_loss=0.758, ppl=1.69, wps=25311.3, ups=1.6, wpb=15856.8, bsz=570.2, num_updates=58100, lr=9.08934e-06, gnorm=0.972, train_wall=62, wall=40578
2021-01-17 03:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:06:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:06:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:06:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:06:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:06:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:06:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:07:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:07:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:07:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:07:15 | INFO | valid | epoch 155 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.062 | ppl 16.7 | bleu 22.47 | wps 4952.3 | wpb 11799.1 | bsz 428.6 | num_updates 58125 | best_bleu 22.62
2021-01-17 03:07:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:07:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:07:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:07:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:07:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:07:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 155 @ 58125 updates, score 22.47) (writing took 3.285824842751026 seconds)
2021-01-17 03:07:18 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2021-01-17 03:07:18 | INFO | train | epoch 155 | symm_kl 0.459 | self_kl 0 | self_cv 0 | loss 3.268 | nll_loss 0.76 | ppl 1.69 | wps 22581.4 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 58125 | lr 9.08739e-06 | gnorm 0.986 | train_wall 233 | wall 40616
2021-01-17 03:07:18 | INFO | fairseq.trainer | begin training epoch 156
2021-01-17 03:07:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:07:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:08:09 | INFO | train_inner | epoch 156:     75 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.766, ppl=1.7, wps=17468.3, ups=1.13, wpb=15474.1, bsz=564.3, num_updates=58200, lr=9.08153e-06, gnorm=0.989, train_wall=62, wall=40666
2021-01-17 03:09:11 | INFO | train_inner | epoch 156:    175 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.76, ppl=1.69, wps=24584.9, ups=1.6, wpb=15375.3, bsz=557.5, num_updates=58300, lr=9.07374e-06, gnorm=0.995, train_wall=62, wall=40729
2021-01-17 03:10:14 | INFO | train_inner | epoch 156:    275 / 375 symm_kl=0.465, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.76, ppl=1.69, wps=25085.9, ups=1.59, wpb=15736.3, bsz=517.8, num_updates=58400, lr=9.06597e-06, gnorm=0.996, train_wall=62, wall=40791
2021-01-17 03:11:17 | INFO | train_inner | epoch 156:    375 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.756, ppl=1.69, wps=25089.6, ups=1.58, wpb=15881.1, bsz=568.2, num_updates=58500, lr=9.05822e-06, gnorm=0.973, train_wall=63, wall=40855
2021-01-17 03:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:11:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:11:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:11:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:11:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:11:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:11:36 | INFO | valid | epoch 156 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.065 | ppl 16.74 | bleu 22.45 | wps 5286 | wpb 11799.1 | bsz 428.6 | num_updates 58500 | best_bleu 22.62
2021-01-17 03:11:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:11:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:11:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:11:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 156 @ 58500 updates, score 22.45) (writing took 3.1378971338272095 seconds)
2021-01-17 03:11:39 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2021-01-17 03:11:39 | INFO | train | epoch 156 | symm_kl 0.459 | self_kl 0 | self_cv 0 | loss 3.268 | nll_loss 0.76 | ppl 1.69 | wps 22535.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 58500 | lr 9.05822e-06 | gnorm 0.984 | train_wall 234 | wall 40877
2021-01-17 03:11:39 | INFO | fairseq.trainer | begin training epoch 157
2021-01-17 03:11:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:11:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:12:45 | INFO | train_inner | epoch 157:    100 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.761, ppl=1.69, wps=18023.8, ups=1.14, wpb=15842.3, bsz=569.6, num_updates=58600, lr=9.05048e-06, gnorm=0.979, train_wall=62, wall=40943
2021-01-17 03:13:48 | INFO | train_inner | epoch 157:    200 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.764, ppl=1.7, wps=24523.7, ups=1.59, wpb=15415.8, bsz=558.4, num_updates=58700, lr=9.04277e-06, gnorm=0.999, train_wall=63, wall=41005
2021-01-17 03:14:51 | INFO | train_inner | epoch 157:    300 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.753, ppl=1.69, wps=25333.6, ups=1.6, wpb=15865.9, bsz=537.7, num_updates=58800, lr=9.03508e-06, gnorm=0.972, train_wall=62, wall=41068
2021-01-17 03:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:15:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:15:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:15:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:15:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:15:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:15:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:15:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:15:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:15:56 | INFO | valid | epoch 157 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.065 | ppl 16.74 | bleu 22.52 | wps 5564.2 | wpb 11799.1 | bsz 428.6 | num_updates 58875 | best_bleu 22.62
2021-01-17 03:15:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:15:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:15:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:15:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:15:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 157 @ 58875 updates, score 22.52) (writing took 3.2239878606051207 seconds)
2021-01-17 03:15:59 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2021-01-17 03:15:59 | INFO | train | epoch 157 | symm_kl 0.459 | self_kl 0 | self_cv 0 | loss 3.268 | nll_loss 0.76 | ppl 1.69 | wps 22684.3 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 58875 | lr 9.02932e-06 | gnorm 0.987 | train_wall 234 | wall 41136
2021-01-17 03:15:59 | INFO | fairseq.trainer | begin training epoch 158
2021-01-17 03:16:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:16:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:16:18 | INFO | train_inner | epoch 158:     25 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.765, ppl=1.7, wps=17875.5, ups=1.15, wpb=15527.9, bsz=544, num_updates=58900, lr=9.02741e-06, gnorm=1.004, train_wall=62, wall=41155
2021-01-17 03:17:20 | INFO | train_inner | epoch 158:    125 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.277, nll_loss=0.764, ppl=1.7, wps=25008.4, ups=1.6, wpb=15623.1, bsz=554.2, num_updates=59000, lr=9.01975e-06, gnorm=0.992, train_wall=62, wall=41217
2021-01-17 03:18:23 | INFO | train_inner | epoch 158:    225 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.76, ppl=1.69, wps=24882.5, ups=1.6, wpb=15567.1, bsz=538, num_updates=59100, lr=9.01212e-06, gnorm=0.995, train_wall=62, wall=41280
2021-01-17 03:19:26 | INFO | train_inner | epoch 158:    325 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.755, ppl=1.69, wps=25374, ups=1.59, wpb=15984.5, bsz=566.1, num_updates=59200, lr=9.0045e-06, gnorm=0.969, train_wall=63, wall=41343
2021-01-17 03:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:19:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:19:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:19:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:20:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:20:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:20:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:20:16 | INFO | valid | epoch 158 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.065 | ppl 16.73 | bleu 22.57 | wps 5457.7 | wpb 11799.1 | bsz 428.6 | num_updates 59250 | best_bleu 22.62
2021-01-17 03:20:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:20:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:20:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:20:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 158 @ 59250 updates, score 22.57) (writing took 3.1836934592574835 seconds)
2021-01-17 03:20:19 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2021-01-17 03:20:19 | INFO | train | epoch 158 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.267 | nll_loss 0.759 | ppl 1.69 | wps 22612.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 59250 | lr 9.0007e-06 | gnorm 0.987 | train_wall 234 | wall 41396
2021-01-17 03:20:19 | INFO | fairseq.trainer | begin training epoch 159
2021-01-17 03:20:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:20:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:20:53 | INFO | train_inner | epoch 159:     50 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.753, ppl=1.68, wps=17839.8, ups=1.14, wpb=15641.9, bsz=548.1, num_updates=59300, lr=8.99691e-06, gnorm=0.985, train_wall=62, wall=41431
2021-01-17 03:21:56 | INFO | train_inner | epoch 159:    150 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.755, ppl=1.69, wps=25036.3, ups=1.59, wpb=15730, bsz=536.9, num_updates=59400, lr=8.98933e-06, gnorm=0.98, train_wall=63, wall=41493
2021-01-17 03:22:59 | INFO | train_inner | epoch 159:    250 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.764, ppl=1.7, wps=24926.1, ups=1.59, wpb=15704.3, bsz=553, num_updates=59500, lr=8.98177e-06, gnorm=0.979, train_wall=63, wall=41556
2021-01-17 03:24:02 | INFO | train_inner | epoch 159:    350 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.763, ppl=1.7, wps=25076.1, ups=1.59, wpb=15748.4, bsz=575.2, num_updates=59600, lr=8.97424e-06, gnorm=0.98, train_wall=63, wall=41619
2021-01-17 03:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:24:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:24:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:24:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:24:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:24:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:24:36 | INFO | valid | epoch 159 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.063 | ppl 16.71 | bleu 22.65 | wps 5538 | wpb 11799.1 | bsz 428.6 | num_updates 59625 | best_bleu 22.65
2021-01-17 03:24:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:24:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:24:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:24:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_best.pt (epoch 159 @ 59625 updates, score 22.65) (writing took 5.1844536904245615 seconds)
2021-01-17 03:24:41 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2021-01-17 03:24:41 | INFO | train | epoch 159 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.267 | nll_loss 0.759 | ppl 1.69 | wps 22439.4 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 59625 | lr 8.97235e-06 | gnorm 0.985 | train_wall 234 | wall 41658
2021-01-17 03:24:41 | INFO | fairseq.trainer | begin training epoch 160
2021-01-17 03:24:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:24:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:25:31 | INFO | train_inner | epoch 160:     75 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.253, nll_loss=0.752, ppl=1.68, wps=17873.1, ups=1.12, wpb=15912.4, bsz=574.9, num_updates=59700, lr=8.96672e-06, gnorm=0.98, train_wall=62, wall=41708
2021-01-17 03:26:34 | INFO | train_inner | epoch 160:    175 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.247, nll_loss=0.752, ppl=1.68, wps=25240.4, ups=1.6, wpb=15785.2, bsz=562, num_updates=59800, lr=8.95922e-06, gnorm=0.967, train_wall=62, wall=41771
2021-01-17 03:27:36 | INFO | train_inner | epoch 160:    275 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.765, ppl=1.7, wps=25224.6, ups=1.6, wpb=15726.7, bsz=521.7, num_updates=59900, lr=8.95173e-06, gnorm=0.991, train_wall=62, wall=41833
2021-01-17 03:28:39 | INFO | train_inner | epoch 160:    375 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.283, nll_loss=0.769, ppl=1.7, wps=24119.9, ups=1.59, wpb=15171, bsz=555.2, num_updates=60000, lr=8.94427e-06, gnorm=1.012, train_wall=63, wall=41896
2021-01-17 03:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:28:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:28:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:28:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:28:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:28:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:28:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:28:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:28:59 | INFO | valid | epoch 160 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.063 | ppl 16.71 | bleu 22.48 | wps 4931.6 | wpb 11799.1 | bsz 428.6 | num_updates 60000 | best_bleu 22.65
2021-01-17 03:28:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:29:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:29:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:29:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:29:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:29:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 160 @ 60000 updates, score 22.48) (writing took 3.1722326688468456 seconds)
2021-01-17 03:29:02 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2021-01-17 03:29:02 | INFO | train | epoch 160 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.266 | nll_loss 0.759 | ppl 1.69 | wps 22531.9 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 60000 | lr 8.94427e-06 | gnorm 0.984 | train_wall 234 | wall 41919
2021-01-17 03:29:02 | INFO | fairseq.trainer | begin training epoch 161
2021-01-17 03:29:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:29:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:30:07 | INFO | train_inner | epoch 161:    100 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.763, ppl=1.7, wps=17459.3, ups=1.13, wpb=15458.2, bsz=540.5, num_updates=60100, lr=8.93683e-06, gnorm=0.993, train_wall=62, wall=41985
2021-01-17 03:31:10 | INFO | train_inner | epoch 161:    200 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.267, nll_loss=0.758, ppl=1.69, wps=24935.5, ups=1.59, wpb=15713.7, bsz=559.3, num_updates=60200, lr=8.9294e-06, gnorm=0.989, train_wall=63, wall=42048
2021-01-17 03:32:13 | INFO | train_inner | epoch 161:    300 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.761, ppl=1.69, wps=25121, ups=1.59, wpb=15798.9, bsz=565.2, num_updates=60300, lr=8.92199e-06, gnorm=0.977, train_wall=63, wall=42111
2021-01-17 03:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:33:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:33:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:33:19 | INFO | valid | epoch 161 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.063 | ppl 16.72 | bleu 22.5 | wps 5208.9 | wpb 11799.1 | bsz 428.6 | num_updates 60375 | best_bleu 22.65
2021-01-17 03:33:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:33:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 161 @ 60375 updates, score 22.5) (writing took 3.1666599567979574 seconds)
2021-01-17 03:33:22 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2021-01-17 03:33:22 | INFO | train | epoch 161 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.266 | nll_loss 0.759 | ppl 1.69 | wps 22584 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 60375 | lr 8.91645e-06 | gnorm 0.986 | train_wall 234 | wall 42180
2021-01-17 03:33:22 | INFO | fairseq.trainer | begin training epoch 162
2021-01-17 03:33:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:33:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:33:41 | INFO | train_inner | epoch 162:     25 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.751, ppl=1.68, wps=17856.1, ups=1.13, wpb=15735.7, bsz=546.3, num_updates=60400, lr=8.91461e-06, gnorm=0.981, train_wall=62, wall=42199
2021-01-17 03:34:44 | INFO | train_inner | epoch 162:    125 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.757, ppl=1.69, wps=25353.2, ups=1.61, wpb=15787, bsz=568.5, num_updates=60500, lr=8.90724e-06, gnorm=0.977, train_wall=62, wall=42261
2021-01-17 03:35:46 | INFO | train_inner | epoch 162:    225 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.763, ppl=1.7, wps=25188.3, ups=1.6, wpb=15714.8, bsz=565.3, num_updates=60600, lr=8.89988e-06, gnorm=0.977, train_wall=62, wall=42323
2021-01-17 03:36:49 | INFO | train_inner | epoch 162:    325 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.758, ppl=1.69, wps=25018.4, ups=1.59, wpb=15685.5, bsz=539.5, num_updates=60700, lr=8.89255e-06, gnorm=0.992, train_wall=62, wall=42386
2021-01-17 03:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:37:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:37:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:37:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:37:39 | INFO | valid | epoch 162 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.064 | ppl 16.72 | bleu 22.44 | wps 5173.5 | wpb 11799.1 | bsz 428.6 | num_updates 60750 | best_bleu 22.65
2021-01-17 03:37:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:37:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:37:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:37:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 162 @ 60750 updates, score 22.44) (writing took 3.179437682032585 seconds)
2021-01-17 03:37:42 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2021-01-17 03:37:42 | INFO | train | epoch 162 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.265 | nll_loss 0.759 | ppl 1.69 | wps 22643.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 60750 | lr 8.88889e-06 | gnorm 0.984 | train_wall 233 | wall 42439
2021-01-17 03:37:42 | INFO | fairseq.trainer | begin training epoch 163
2021-01-17 03:37:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:37:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:38:17 | INFO | train_inner | epoch 163:     50 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.758, ppl=1.69, wps=17866.4, ups=1.14, wpb=15725.7, bsz=551, num_updates=60800, lr=8.88523e-06, gnorm=0.98, train_wall=62, wall=42474
2021-01-17 03:39:19 | INFO | train_inner | epoch 163:    150 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.764, ppl=1.7, wps=25288.4, ups=1.6, wpb=15805.6, bsz=562.2, num_updates=60900, lr=8.87794e-06, gnorm=0.983, train_wall=62, wall=42537
2021-01-17 03:40:22 | INFO | train_inner | epoch 163:    250 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.758, ppl=1.69, wps=24535.3, ups=1.59, wpb=15430.1, bsz=547.4, num_updates=61000, lr=8.87066e-06, gnorm=1.007, train_wall=63, wall=42599
2021-01-17 03:41:25 | INFO | train_inner | epoch 163:    350 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.757, ppl=1.69, wps=25170.6, ups=1.6, wpb=15780.3, bsz=529.7, num_updates=61100, lr=8.86339e-06, gnorm=0.99, train_wall=62, wall=42662
2021-01-17 03:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:41:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:41:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:41:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:41:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:41:58 | INFO | valid | epoch 163 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.061 | ppl 16.7 | bleu 22.6 | wps 5764 | wpb 11799.1 | bsz 428.6 | num_updates 61125 | best_bleu 22.65
2021-01-17 03:41:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:42:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:42:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:42:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:42:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:42:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 163 @ 61125 updates, score 22.6) (writing took 3.187498025596142 seconds)
2021-01-17 03:42:02 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2021-01-17 03:42:02 | INFO | train | epoch 163 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.266 | nll_loss 0.759 | ppl 1.69 | wps 22663 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 61125 | lr 8.86158e-06 | gnorm 0.989 | train_wall 234 | wall 42699
2021-01-17 03:42:02 | INFO | fairseq.trainer | begin training epoch 164
2021-01-17 03:42:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:42:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:42:52 | INFO | train_inner | epoch 164:     75 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.76, ppl=1.69, wps=18018.6, ups=1.15, wpb=15721.8, bsz=560.1, num_updates=61200, lr=8.85615e-06, gnorm=1.001, train_wall=63, wall=42749
2021-01-17 03:43:55 | INFO | train_inner | epoch 164:    175 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.762, ppl=1.7, wps=25106, ups=1.6, wpb=15704.1, bsz=537, num_updates=61300, lr=8.84892e-06, gnorm=0.991, train_wall=62, wall=42812
2021-01-17 03:44:57 | INFO | train_inner | epoch 164:    275 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.757, ppl=1.69, wps=24879.8, ups=1.59, wpb=15607.1, bsz=551.5, num_updates=61400, lr=8.84171e-06, gnorm=0.984, train_wall=63, wall=42875
2021-01-17 03:46:00 | INFO | train_inner | epoch 164:    375 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.756, ppl=1.69, wps=24911.2, ups=1.6, wpb=15578.1, bsz=571.5, num_updates=61500, lr=8.83452e-06, gnorm=0.994, train_wall=62, wall=42937
2021-01-17 03:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:46:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:46:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:46:18 | INFO | valid | epoch 164 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.064 | ppl 16.72 | bleu 22.44 | wps 5533.5 | wpb 11799.1 | bsz 428.6 | num_updates 61500 | best_bleu 22.65
2021-01-17 03:46:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:46:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:46:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:46:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 164 @ 61500 updates, score 22.44) (writing took 3.1910366378724575 seconds)
2021-01-17 03:46:21 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2021-01-17 03:46:21 | INFO | train | epoch 164 | symm_kl 0.458 | self_kl 0 | self_cv 0 | loss 3.266 | nll_loss 0.759 | ppl 1.69 | wps 22638.6 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 61500 | lr 8.83452e-06 | gnorm 0.992 | train_wall 234 | wall 42959
2021-01-17 03:46:21 | INFO | fairseq.trainer | begin training epoch 165
2021-01-17 03:46:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:46:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:47:27 | INFO | train_inner | epoch 165:    100 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.763, ppl=1.7, wps=18075.8, ups=1.15, wpb=15742, bsz=543.2, num_updates=61600, lr=8.82735e-06, gnorm=0.979, train_wall=62, wall=43024
2021-01-17 03:48:30 | INFO | train_inner | epoch 165:    200 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.257, nll_loss=0.752, ppl=1.68, wps=24933.3, ups=1.59, wpb=15683.9, bsz=549.5, num_updates=61700, lr=8.82019e-06, gnorm=0.98, train_wall=63, wall=43087
2021-01-17 03:49:32 | INFO | train_inner | epoch 165:    300 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.759, ppl=1.69, wps=24983.8, ups=1.61, wpb=15534.9, bsz=564.6, num_updates=61800, lr=8.81305e-06, gnorm=0.995, train_wall=62, wall=43149
2021-01-17 03:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:50:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:50:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:50:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:50:37 | INFO | valid | epoch 165 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.064 | ppl 16.73 | bleu 22.51 | wps 5691.3 | wpb 11799.1 | bsz 428.6 | num_updates 61875 | best_bleu 22.65
2021-01-17 03:50:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:50:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 165 @ 61875 updates, score 22.51) (writing took 3.1582829635590315 seconds)
2021-01-17 03:50:40 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2021-01-17 03:50:40 | INFO | train | epoch 165 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.264 | nll_loss 0.758 | ppl 1.69 | wps 22726.9 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 61875 | lr 8.80771e-06 | gnorm 0.984 | train_wall 233 | wall 43217
2021-01-17 03:50:40 | INFO | fairseq.trainer | begin training epoch 166
2021-01-17 03:50:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:50:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:50:59 | INFO | train_inner | epoch 166:     25 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.756, ppl=1.69, wps=18130.6, ups=1.15, wpb=15777.1, bsz=567, num_updates=61900, lr=8.80593e-06, gnorm=0.975, train_wall=62, wall=43236
2021-01-17 03:52:01 | INFO | train_inner | epoch 166:    125 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.76, ppl=1.69, wps=24983.6, ups=1.61, wpb=15564.7, bsz=536.2, num_updates=62000, lr=8.79883e-06, gnorm=0.997, train_wall=62, wall=43299
2021-01-17 03:53:04 | INFO | train_inner | epoch 166:    225 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.757, ppl=1.69, wps=24614.7, ups=1.59, wpb=15453.4, bsz=538.5, num_updates=62100, lr=8.79174e-06, gnorm=1, train_wall=63, wall=43362
2021-01-17 03:54:07 | INFO | train_inner | epoch 166:    325 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.249, nll_loss=0.752, ppl=1.68, wps=25567.3, ups=1.6, wpb=15981.6, bsz=569.2, num_updates=62200, lr=8.78467e-06, gnorm=0.972, train_wall=62, wall=43424
2021-01-17 03:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:54:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:54:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:54:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:54:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:54:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:54:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:54:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:54:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:54:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:54:57 | INFO | valid | epoch 166 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.068 | ppl 16.78 | bleu 22.45 | wps 5214 | wpb 11799.1 | bsz 428.6 | num_updates 62250 | best_bleu 22.65
2021-01-17 03:54:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:54:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:54:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:54:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:54:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:55:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 166 @ 62250 updates, score 22.45) (writing took 3.1556277833878994 seconds)
2021-01-17 03:55:00 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2021-01-17 03:55:00 | INFO | train | epoch 166 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.264 | nll_loss 0.758 | ppl 1.69 | wps 22650.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 62250 | lr 8.78114e-06 | gnorm 0.986 | train_wall 233 | wall 43477
2021-01-17 03:55:00 | INFO | fairseq.trainer | begin training epoch 167
2021-01-17 03:55:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:55:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:55:34 | INFO | train_inner | epoch 167:     50 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.765, ppl=1.7, wps=17928.2, ups=1.14, wpb=15679.2, bsz=552.3, num_updates=62300, lr=8.77762e-06, gnorm=0.986, train_wall=62, wall=43511
2021-01-17 03:56:37 | INFO | train_inner | epoch 167:    150 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.762, ppl=1.7, wps=25324.7, ups=1.6, wpb=15818.5, bsz=553.1, num_updates=62400, lr=8.77058e-06, gnorm=0.987, train_wall=62, wall=43574
2021-01-17 03:57:39 | INFO | train_inner | epoch 167:    250 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.241, nll_loss=0.745, ppl=1.68, wps=25116.1, ups=1.59, wpb=15763.1, bsz=554.8, num_updates=62500, lr=8.76356e-06, gnorm=0.976, train_wall=63, wall=43637
2021-01-17 03:58:42 | INFO | train_inner | epoch 167:    350 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.276, nll_loss=0.766, ppl=1.7, wps=24963.2, ups=1.6, wpb=15611.5, bsz=557.7, num_updates=62600, lr=8.75656e-06, gnorm=0.996, train_wall=62, wall=43699
2021-01-17 03:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 03:58:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:58:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:58:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:59:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:59:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:59:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:59:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 03:59:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 03:59:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 03:59:15 | INFO | valid | epoch 167 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.67 | nll_loss 4.061 | ppl 16.7 | bleu 22.56 | wps 5792.1 | wpb 11799.1 | bsz 428.6 | num_updates 62625 | best_bleu 22.65
2021-01-17 03:59:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 03:59:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:59:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:59:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:59:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 03:59:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 167 @ 62625 updates, score 22.56) (writing took 3.184066515415907 seconds)
2021-01-17 03:59:18 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2021-01-17 03:59:18 | INFO | train | epoch 167 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.263 | nll_loss 0.758 | ppl 1.69 | wps 22741.2 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 62625 | lr 8.75481e-06 | gnorm 0.987 | train_wall 233 | wall 43736
2021-01-17 03:59:18 | INFO | fairseq.trainer | begin training epoch 168
2021-01-17 03:59:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 03:59:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:00:08 | INFO | train_inner | epoch 168:     75 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.758, ppl=1.69, wps=18081.9, ups=1.16, wpb=15603.6, bsz=557.1, num_updates=62700, lr=8.74957e-06, gnorm=0.979, train_wall=62, wall=43786
2021-01-17 04:01:11 | INFO | train_inner | epoch 168:    175 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.756, ppl=1.69, wps=24725.9, ups=1.59, wpb=15564.8, bsz=543.6, num_updates=62800, lr=8.7426e-06, gnorm=0.996, train_wall=63, wall=43848
2021-01-17 04:02:14 | INFO | train_inner | epoch 168:    275 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.246, nll_loss=0.752, ppl=1.68, wps=25369.3, ups=1.59, wpb=15983.4, bsz=560.7, num_updates=62900, lr=8.73565e-06, gnorm=0.975, train_wall=63, wall=43911
2021-01-17 04:03:17 | INFO | train_inner | epoch 168:    375 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.281, nll_loss=0.767, ppl=1.7, wps=24796.9, ups=1.6, wpb=15484.8, bsz=547.2, num_updates=63000, lr=8.72872e-06, gnorm=1.002, train_wall=62, wall=43974
2021-01-17 04:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:03:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:03:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:03:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:03:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:03:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:03:36 | INFO | valid | epoch 168 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.063 | ppl 16.72 | bleu 22.53 | wps 5105 | wpb 11799.1 | bsz 428.6 | num_updates 63000 | best_bleu 22.65
2021-01-17 04:03:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:03:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:03:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:03:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 168 @ 63000 updates, score 22.53) (writing took 3.2229655273258686 seconds)
2021-01-17 04:03:39 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2021-01-17 04:03:39 | INFO | train | epoch 168 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.263 | nll_loss 0.758 | ppl 1.69 | wps 22551 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 63000 | lr 8.72872e-06 | gnorm 0.987 | train_wall 234 | wall 43997
2021-01-17 04:03:39 | INFO | fairseq.trainer | begin training epoch 169
2021-01-17 04:03:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:03:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:04:45 | INFO | train_inner | epoch 169:    100 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.753, ppl=1.69, wps=17895.5, ups=1.13, wpb=15798.3, bsz=511.7, num_updates=63100, lr=8.7218e-06, gnorm=0.989, train_wall=62, wall=44062
2021-01-17 04:05:48 | INFO | train_inner | epoch 169:    200 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.759, ppl=1.69, wps=25107.1, ups=1.6, wpb=15721.2, bsz=566, num_updates=63200, lr=8.71489e-06, gnorm=0.984, train_wall=62, wall=44125
2021-01-17 04:06:50 | INFO | train_inner | epoch 169:    300 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.253, nll_loss=0.752, ppl=1.68, wps=25014.2, ups=1.6, wpb=15670.2, bsz=579.4, num_updates=63300, lr=8.70801e-06, gnorm=0.979, train_wall=62, wall=44187
2021-01-17 04:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:07:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:07:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:07:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:07:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:07:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:07:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:07:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:07:55 | INFO | valid | epoch 169 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.063 | ppl 16.71 | bleu 22.53 | wps 5557.8 | wpb 11799.1 | bsz 428.6 | num_updates 63375 | best_bleu 22.65
2021-01-17 04:07:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:07:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:07:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:07:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:07:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:07:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 169 @ 63375 updates, score 22.53) (writing took 3.0580372251570225 seconds)
2021-01-17 04:07:58 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2021-01-17 04:07:58 | INFO | train | epoch 169 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.262 | nll_loss 0.757 | ppl 1.69 | wps 22687.3 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 63375 | lr 8.70285e-06 | gnorm 0.987 | train_wall 234 | wall 44256
2021-01-17 04:07:58 | INFO | fairseq.trainer | begin training epoch 170
2021-01-17 04:07:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:08:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:08:17 | INFO | train_inner | epoch 170:     25 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.282, nll_loss=0.768, ppl=1.7, wps=17723.6, ups=1.15, wpb=15475.7, bsz=548.1, num_updates=63400, lr=8.70114e-06, gnorm=1.002, train_wall=62, wall=44275
2021-01-17 04:09:20 | INFO | train_inner | epoch 170:    125 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.267, nll_loss=0.758, ppl=1.69, wps=25138.9, ups=1.61, wpb=15640.1, bsz=539.7, num_updates=63500, lr=8.69428e-06, gnorm=0.98, train_wall=62, wall=44337
2021-01-17 04:10:22 | INFO | train_inner | epoch 170:    225 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.248, nll_loss=0.752, ppl=1.68, wps=25365.1, ups=1.61, wpb=15782.6, bsz=580.6, num_updates=63600, lr=8.68744e-06, gnorm=0.967, train_wall=62, wall=44399
2021-01-17 04:11:25 | INFO | train_inner | epoch 170:    325 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.758, ppl=1.69, wps=25208.7, ups=1.6, wpb=15792.7, bsz=563.1, num_updates=63700, lr=8.68062e-06, gnorm=0.973, train_wall=62, wall=44462
2021-01-17 04:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:11:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:11:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:11:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:11:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:11:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:11:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:12:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:12:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:12:14 | INFO | valid | epoch 170 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.067 | ppl 16.76 | bleu 22.57 | wps 5618.4 | wpb 11799.1 | bsz 428.6 | num_updates 63750 | best_bleu 22.65
2021-01-17 04:12:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:12:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:12:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:12:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:12:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:12:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 170 @ 63750 updates, score 22.57) (writing took 3.225785693153739 seconds)
2021-01-17 04:12:17 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2021-01-17 04:12:17 | INFO | train | epoch 170 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.262 | nll_loss 0.757 | ppl 1.69 | wps 22747.1 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 63750 | lr 8.67722e-06 | gnorm 0.982 | train_wall 233 | wall 44514
2021-01-17 04:12:17 | INFO | fairseq.trainer | begin training epoch 171
2021-01-17 04:12:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:12:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:12:51 | INFO | train_inner | epoch 171:     50 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.752, ppl=1.68, wps=17996.6, ups=1.15, wpb=15612.4, bsz=537.7, num_updates=63800, lr=8.67382e-06, gnorm=1.002, train_wall=62, wall=44549
2021-01-17 04:13:53 | INFO | train_inner | epoch 171:    150 / 375 symm_kl=0.466, self_kl=0, self_cv=0, loss=3.29, nll_loss=0.771, ppl=1.71, wps=25218.6, ups=1.61, wpb=15681.4, bsz=531.8, num_updates=63900, lr=8.66703e-06, gnorm=0.997, train_wall=62, wall=44611
2021-01-17 04:14:56 | INFO | train_inner | epoch 171:    250 / 375 symm_kl=0.445, self_kl=0, self_cv=0, loss=3.232, nll_loss=0.743, ppl=1.67, wps=25144.6, ups=1.59, wpb=15777.5, bsz=569.6, num_updates=64000, lr=8.66025e-06, gnorm=0.965, train_wall=63, wall=44674
2021-01-17 04:15:59 | INFO | train_inner | epoch 171:    350 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.274, nll_loss=0.764, ppl=1.7, wps=24912.6, ups=1.59, wpb=15701.1, bsz=553.6, num_updates=64100, lr=8.6535e-06, gnorm=0.991, train_wall=63, wall=44737
2021-01-17 04:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:16:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:16:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:16:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:16:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:16:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:16:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:16:33 | INFO | valid | epoch 171 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.067 | ppl 16.76 | bleu 22.45 | wps 5730.3 | wpb 11799.1 | bsz 428.6 | num_updates 64125 | best_bleu 22.65
2021-01-17 04:16:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:16:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:16:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:16:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 171 @ 64125 updates, score 22.45) (writing took 3.1695765908807516 seconds)
2021-01-17 04:16:36 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2021-01-17 04:16:36 | INFO | train | epoch 171 | symm_kl 0.457 | self_kl 0 | self_cv 0 | loss 3.262 | nll_loss 0.757 | ppl 1.69 | wps 22721.9 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 64125 | lr 8.65181e-06 | gnorm 0.988 | train_wall 233 | wall 44773
2021-01-17 04:16:36 | INFO | fairseq.trainer | begin training epoch 172
2021-01-17 04:16:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:16:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:17:26 | INFO | train_inner | epoch 172:     75 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.759, ppl=1.69, wps=17831.3, ups=1.16, wpb=15419.4, bsz=548, num_updates=64200, lr=8.64675e-06, gnorm=0.997, train_wall=62, wall=44823
2021-01-17 04:18:29 | INFO | train_inner | epoch 172:    175 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.753, ppl=1.69, wps=25230, ups=1.59, wpb=15865.9, bsz=558.7, num_updates=64300, lr=8.64003e-06, gnorm=0.978, train_wall=63, wall=44886
2021-01-17 04:19:31 | INFO | train_inner | epoch 172:    275 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.751, ppl=1.68, wps=25389.4, ups=1.6, wpb=15866.2, bsz=561, num_updates=64400, lr=8.63332e-06, gnorm=0.973, train_wall=62, wall=44948
2021-01-17 04:20:34 | INFO | train_inner | epoch 172:    375 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.761, ppl=1.69, wps=24675.6, ups=1.6, wpb=15441.9, bsz=546, num_updates=64500, lr=8.62662e-06, gnorm=1.002, train_wall=62, wall=45011
2021-01-17 04:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:20:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:20:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:20:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:20:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:20:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:20:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:20:52 | INFO | valid | epoch 172 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.064 | ppl 16.72 | bleu 22.51 | wps 5700.6 | wpb 11799.1 | bsz 428.6 | num_updates 64500 | best_bleu 22.65
2021-01-17 04:20:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:20:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:20:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:20:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 172 @ 64500 updates, score 22.51) (writing took 3.1957731042057276 seconds)
2021-01-17 04:20:55 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2021-01-17 04:20:55 | INFO | train | epoch 172 | symm_kl 0.456 | self_kl 0 | self_cv 0 | loss 3.261 | nll_loss 0.757 | ppl 1.69 | wps 22716.3 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 64500 | lr 8.62662e-06 | gnorm 0.985 | train_wall 233 | wall 45032
2021-01-17 04:20:55 | INFO | fairseq.trainer | begin training epoch 173
2021-01-17 04:20:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:20:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:22:00 | INFO | train_inner | epoch 173:    100 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.755, ppl=1.69, wps=18189.5, ups=1.15, wpb=15759.1, bsz=555.6, num_updates=64600, lr=8.61994e-06, gnorm=0.975, train_wall=62, wall=45098
2021-01-17 04:23:03 | INFO | train_inner | epoch 173:    200 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.25, nll_loss=0.752, ppl=1.68, wps=25153.8, ups=1.6, wpb=15720.1, bsz=576, num_updates=64700, lr=8.61328e-06, gnorm=0.976, train_wall=62, wall=45160
2021-01-17 04:24:05 | INFO | train_inner | epoch 173:    300 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.76, ppl=1.69, wps=25287.8, ups=1.61, wpb=15695.4, bsz=545.8, num_updates=64800, lr=8.60663e-06, gnorm=0.99, train_wall=62, wall=45222
2021-01-17 04:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:24:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:24:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:24:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:24:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:24:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:24:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:24:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:24:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:24:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:24:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:25:10 | INFO | valid | epoch 173 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.678 | nll_loss 4.067 | ppl 16.76 | bleu 22.52 | wps 5545.5 | wpb 11799.1 | bsz 428.6 | num_updates 64875 | best_bleu 22.65
2021-01-17 04:25:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:25:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:25:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:25:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:25:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:25:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 173 @ 64875 updates, score 22.52) (writing took 3.172568580135703 seconds)
2021-01-17 04:25:13 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2021-01-17 04:25:13 | INFO | train | epoch 173 | symm_kl 0.456 | self_kl 0 | self_cv 0 | loss 3.261 | nll_loss 0.756 | ppl 1.69 | wps 22758.2 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 64875 | lr 8.60165e-06 | gnorm 0.983 | train_wall 233 | wall 45290
2021-01-17 04:25:13 | INFO | fairseq.trainer | begin training epoch 174
2021-01-17 04:25:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:25:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:25:32 | INFO | train_inner | epoch 174:     25 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.267, nll_loss=0.759, ppl=1.69, wps=17702, ups=1.14, wpb=15462.2, bsz=544.6, num_updates=64900, lr=8.6e-06, gnorm=0.996, train_wall=62, wall=45310
2021-01-17 04:26:34 | INFO | train_inner | epoch 174:    125 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.758, ppl=1.69, wps=25215.5, ups=1.61, wpb=15690.5, bsz=579.9, num_updates=65000, lr=8.59338e-06, gnorm=0.976, train_wall=62, wall=45372
2021-01-17 04:27:38 | INFO | train_inner | epoch 174:    225 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.757, ppl=1.69, wps=24909.3, ups=1.58, wpb=15777.2, bsz=536.6, num_updates=65100, lr=8.58678e-06, gnorm=0.985, train_wall=63, wall=45435
2021-01-17 04:28:41 | INFO | train_inner | epoch 174:    325 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.25, nll_loss=0.752, ppl=1.68, wps=25351.8, ups=1.59, wpb=15906.4, bsz=549.5, num_updates=65200, lr=8.58019e-06, gnorm=0.964, train_wall=63, wall=45498
2021-01-17 04:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:29:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:29:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:29:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:29:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:29:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:29:30 | INFO | valid | epoch 174 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.066 | ppl 16.75 | bleu 22.42 | wps 5511.5 | wpb 11799.1 | bsz 428.6 | num_updates 65250 | best_bleu 22.65
2021-01-17 04:29:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:29:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:29:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:29:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 174 @ 65250 updates, score 22.42) (writing took 3.1828614231199026 seconds)
2021-01-17 04:29:33 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2021-01-17 04:29:33 | INFO | train | epoch 174 | symm_kl 0.456 | self_kl 0 | self_cv 0 | loss 3.261 | nll_loss 0.757 | ppl 1.69 | wps 22590.2 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 65250 | lr 8.5769e-06 | gnorm 0.983 | train_wall 234 | wall 45551
2021-01-17 04:29:33 | INFO | fairseq.trainer | begin training epoch 175
2021-01-17 04:29:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:29:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:30:08 | INFO | train_inner | epoch 175:     50 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.764, ppl=1.7, wps=17547.8, ups=1.14, wpb=15383.1, bsz=534.6, num_updates=65300, lr=8.57362e-06, gnorm=1.008, train_wall=62, wall=45586
2021-01-17 04:31:11 | INFO | train_inner | epoch 175:    150 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.242, nll_loss=0.747, ppl=1.68, wps=25190.5, ups=1.6, wpb=15757.7, bsz=570.6, num_updates=65400, lr=8.56706e-06, gnorm=0.967, train_wall=62, wall=45648
2021-01-17 04:32:13 | INFO | train_inner | epoch 175:    250 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.756, ppl=1.69, wps=25309.3, ups=1.6, wpb=15836.9, bsz=553.5, num_updates=65500, lr=8.56052e-06, gnorm=0.982, train_wall=62, wall=45711
2021-01-17 04:33:16 | INFO | train_inner | epoch 175:    350 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.767, ppl=1.7, wps=24873, ups=1.6, wpb=15556.4, bsz=536.8, num_updates=65600, lr=8.55399e-06, gnorm=0.996, train_wall=62, wall=45773
2021-01-17 04:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:33:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:33:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:33:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:33:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:33:49 | INFO | valid | epoch 175 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.062 | ppl 16.7 | bleu 22.55 | wps 5635.9 | wpb 11799.1 | bsz 428.6 | num_updates 65625 | best_bleu 22.65
2021-01-17 04:33:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:33:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:33:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:33:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 175 @ 65625 updates, score 22.55) (writing took 3.203184150159359 seconds)
2021-01-17 04:33:53 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2021-01-17 04:33:53 | INFO | train | epoch 175 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.26 | nll_loss 0.757 | ppl 1.69 | wps 22691.5 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 65625 | lr 8.55236e-06 | gnorm 0.984 | train_wall 234 | wall 45810
2021-01-17 04:33:53 | INFO | fairseq.trainer | begin training epoch 176
2021-01-17 04:33:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:33:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:34:43 | INFO | train_inner | epoch 176:     75 / 375 symm_kl=0.445, self_kl=0, self_cv=0, loss=3.23, nll_loss=0.741, ppl=1.67, wps=18139.4, ups=1.15, wpb=15827.2, bsz=558.9, num_updates=65700, lr=8.54748e-06, gnorm=0.97, train_wall=62, wall=45860
2021-01-17 04:35:46 | INFO | train_inner | epoch 176:    175 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.756, ppl=1.69, wps=25113.7, ups=1.6, wpb=15717.7, bsz=559.6, num_updates=65800, lr=8.54098e-06, gnorm=0.981, train_wall=62, wall=45923
2021-01-17 04:36:48 | INFO | train_inner | epoch 176:    275 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.269, nll_loss=0.761, ppl=1.69, wps=24599.5, ups=1.6, wpb=15388.3, bsz=551.7, num_updates=65900, lr=8.5345e-06, gnorm=1.005, train_wall=62, wall=45986
2021-01-17 04:37:51 | INFO | train_inner | epoch 176:    375 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.762, ppl=1.7, wps=25268.4, ups=1.6, wpb=15768.4, bsz=541.4, num_updates=66000, lr=8.52803e-06, gnorm=0.981, train_wall=62, wall=46048
2021-01-17 04:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:37:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:37:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:37:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:37:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:37:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:37:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:37:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:37:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:37:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:37:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:37:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:37:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:37:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:37:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:38:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:38:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:38:10 | INFO | valid | epoch 176 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.063 | ppl 16.72 | bleu 22.42 | wps 5105.9 | wpb 11799.1 | bsz 428.6 | num_updates 66000 | best_bleu 22.65
2021-01-17 04:38:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:38:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:38:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:38:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 176 @ 66000 updates, score 22.42) (writing took 3.160194030031562 seconds)
2021-01-17 04:38:13 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2021-01-17 04:38:13 | INFO | train | epoch 176 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.259 | nll_loss 0.756 | ppl 1.69 | wps 22576.4 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 66000 | lr 8.52803e-06 | gnorm 0.984 | train_wall 234 | wall 46070
2021-01-17 04:38:13 | INFO | fairseq.trainer | begin training epoch 177
2021-01-17 04:38:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:38:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:39:19 | INFO | train_inner | epoch 177:    100 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.253, nll_loss=0.754, ppl=1.69, wps=17845.3, ups=1.13, wpb=15804.3, bsz=549.4, num_updates=66100, lr=8.52158e-06, gnorm=0.973, train_wall=62, wall=46137
2021-01-17 04:40:22 | INFO | train_inner | epoch 177:    200 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.244, nll_loss=0.749, ppl=1.68, wps=24996.5, ups=1.59, wpb=15685.1, bsz=555.4, num_updates=66200, lr=8.51514e-06, gnorm=0.986, train_wall=63, wall=46199
2021-01-17 04:41:25 | INFO | train_inner | epoch 177:    300 / 375 symm_kl=0.462, self_kl=0, self_cv=0, loss=3.278, nll_loss=0.765, ppl=1.7, wps=25184, ups=1.6, wpb=15749.9, bsz=543.2, num_updates=66300, lr=8.50871e-06, gnorm=0.993, train_wall=62, wall=46262
2021-01-17 04:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:42:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:42:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:42:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:42:29 | INFO | valid | epoch 177 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.067 | ppl 16.76 | bleu 22.43 | wps 5673.6 | wpb 11799.1 | bsz 428.6 | num_updates 66375 | best_bleu 22.65
2021-01-17 04:42:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:42:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 177 @ 66375 updates, score 22.43) (writing took 3.1947213262319565 seconds)
2021-01-17 04:42:32 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2021-01-17 04:42:32 | INFO | train | epoch 177 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.259 | nll_loss 0.756 | ppl 1.69 | wps 22679.5 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 66375 | lr 8.5039e-06 | gnorm 0.985 | train_wall 234 | wall 46330
2021-01-17 04:42:32 | INFO | fairseq.trainer | begin training epoch 178
2021-01-17 04:42:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:42:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:42:51 | INFO | train_inner | epoch 178:     25 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.754, ppl=1.69, wps=17794.5, ups=1.15, wpb=15467.1, bsz=558.4, num_updates=66400, lr=8.5023e-06, gnorm=0.99, train_wall=62, wall=46349
2021-01-17 04:43:54 | INFO | train_inner | epoch 178:    125 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.754, ppl=1.69, wps=25161, ups=1.6, wpb=15737.9, bsz=560, num_updates=66500, lr=8.49591e-06, gnorm=0.984, train_wall=62, wall=46411
2021-01-17 04:44:56 | INFO | train_inner | epoch 178:    225 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.251, nll_loss=0.758, ppl=1.69, wps=25334.3, ups=1.6, wpb=15790.7, bsz=560.3, num_updates=66600, lr=8.48953e-06, gnorm=0.97, train_wall=62, wall=46474
2021-01-17 04:45:59 | INFO | train_inner | epoch 178:    325 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.272, nll_loss=0.76, ppl=1.69, wps=24899.8, ups=1.59, wpb=15658.8, bsz=549, num_updates=66700, lr=8.48316e-06, gnorm=1.002, train_wall=63, wall=46537
2021-01-17 04:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:46:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:46:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:46:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:46:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:46:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:46:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:46:49 | INFO | valid | epoch 178 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.066 | ppl 16.75 | bleu 22.52 | wps 5399.8 | wpb 11799.1 | bsz 428.6 | num_updates 66750 | best_bleu 22.65
2021-01-17 04:46:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:46:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:46:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:46:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 178 @ 66750 updates, score 22.52) (writing took 3.176211107522249 seconds)
2021-01-17 04:46:52 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2021-01-17 04:46:52 | INFO | train | epoch 178 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.259 | nll_loss 0.757 | ppl 1.69 | wps 22642.8 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 66750 | lr 8.47998e-06 | gnorm 0.985 | train_wall 234 | wall 46590
2021-01-17 04:46:52 | INFO | fairseq.trainer | begin training epoch 179
2021-01-17 04:46:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:46:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:47:27 | INFO | train_inner | epoch 179:     50 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.267, nll_loss=0.758, ppl=1.69, wps=17856.3, ups=1.14, wpb=15627, bsz=540.2, num_updates=66800, lr=8.47681e-06, gnorm=0.99, train_wall=62, wall=46624
2021-01-17 04:48:29 | INFO | train_inner | epoch 179:    150 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.756, ppl=1.69, wps=25209.6, ups=1.59, wpb=15809.3, bsz=552.1, num_updates=66900, lr=8.47047e-06, gnorm=0.99, train_wall=62, wall=46687
2021-01-17 04:49:32 | INFO | train_inner | epoch 179:    250 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.257, nll_loss=0.752, ppl=1.68, wps=25021.7, ups=1.6, wpb=15622.3, bsz=548.1, num_updates=67000, lr=8.46415e-06, gnorm=0.985, train_wall=62, wall=46749
2021-01-17 04:50:35 | INFO | train_inner | epoch 179:    350 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.251, nll_loss=0.756, ppl=1.69, wps=24914.6, ups=1.59, wpb=15709.5, bsz=566.1, num_updates=67100, lr=8.45784e-06, gnorm=0.97, train_wall=63, wall=46812
2021-01-17 04:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:50:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:50:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:50:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:50:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:50:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:50:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:51:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:51:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:51:09 | INFO | valid | epoch 179 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.064 | ppl 16.72 | bleu 22.52 | wps 5232.6 | wpb 11799.1 | bsz 428.6 | num_updates 67125 | best_bleu 22.65
2021-01-17 04:51:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:51:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:51:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:51:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 179 @ 67125 updates, score 22.52) (writing took 3.1802060957998037 seconds)
2021-01-17 04:51:13 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2021-01-17 04:51:13 | INFO | train | epoch 179 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.258 | nll_loss 0.756 | ppl 1.69 | wps 22591.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 67125 | lr 8.45626e-06 | gnorm 0.987 | train_wall 234 | wall 46850
2021-01-17 04:51:13 | INFO | fairseq.trainer | begin training epoch 180
2021-01-17 04:51:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:51:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:51:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:51:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:52:03 | INFO | train_inner | epoch 180:     75 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.27, nll_loss=0.76, ppl=1.69, wps=17675, ups=1.14, wpb=15528.6, bsz=534.8, num_updates=67200, lr=8.45154e-06, gnorm=1.003, train_wall=62, wall=46900
2021-01-17 04:53:06 | INFO | train_inner | epoch 180:    175 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.247, nll_loss=0.753, ppl=1.68, wps=24998.1, ups=1.58, wpb=15836.7, bsz=569.6, num_updates=67300, lr=8.44526e-06, gnorm=0.971, train_wall=63, wall=46963
2021-01-17 04:54:09 | INFO | train_inner | epoch 180:    275 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.261, nll_loss=0.761, ppl=1.69, wps=25040.3, ups=1.6, wpb=15677.3, bsz=566.1, num_updates=67400, lr=8.43899e-06, gnorm=0.983, train_wall=62, wall=47026
2021-01-17 04:55:12 | INFO | train_inner | epoch 180:    375 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.251, nll_loss=0.748, ppl=1.68, wps=24710, ups=1.59, wpb=15542, bsz=542.2, num_updates=67500, lr=8.43274e-06, gnorm=0.993, train_wall=63, wall=47089
2021-01-17 04:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:55:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:55:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:55:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:55:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:55:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:55:30 | INFO | valid | epoch 180 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.067 | ppl 16.76 | bleu 22.53 | wps 5623.1 | wpb 11799.1 | bsz 428.6 | num_updates 67500 | best_bleu 22.65
2021-01-17 04:55:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:55:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:55:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:55:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 180 @ 67500 updates, score 22.53) (writing took 3.2593010030686855 seconds)
2021-01-17 04:55:33 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2021-01-17 04:55:33 | INFO | train | epoch 180 | symm_kl 0.454 | self_kl 0 | self_cv 0 | loss 3.257 | nll_loss 0.755 | ppl 1.69 | wps 22584.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 67500 | lr 8.43274e-06 | gnorm 0.985 | train_wall 235 | wall 47110
2021-01-17 04:55:33 | INFO | fairseq.trainer | begin training epoch 181
2021-01-17 04:55:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:55:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:56:39 | INFO | train_inner | epoch 181:    100 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.754, ppl=1.69, wps=18094.5, ups=1.15, wpb=15724, bsz=539.2, num_updates=67600, lr=8.4265e-06, gnorm=0.988, train_wall=62, wall=47176
2021-01-17 04:57:41 | INFO | train_inner | epoch 181:    200 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.754, ppl=1.69, wps=24532.6, ups=1.6, wpb=15341.8, bsz=541.2, num_updates=67700, lr=8.42028e-06, gnorm=1.004, train_wall=62, wall=47238
2021-01-17 04:58:44 | INFO | train_inner | epoch 181:    300 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.756, ppl=1.69, wps=25569.3, ups=1.59, wpb=16038.2, bsz=564.3, num_updates=67800, lr=8.41406e-06, gnorm=0.96, train_wall=63, wall=47301
2021-01-17 04:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 04:59:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:59:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:59:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:59:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 04:59:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 04:59:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 04:59:50 | INFO | valid | epoch 181 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.671 | nll_loss 4.062 | ppl 16.71 | bleu 22.54 | wps 5452.6 | wpb 11799.1 | bsz 428.6 | num_updates 67875 | best_bleu 22.65
2021-01-17 04:59:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 04:59:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:59:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 04:59:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 181 @ 67875 updates, score 22.54) (writing took 3.1483836248517036 seconds)
2021-01-17 04:59:53 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2021-01-17 04:59:53 | INFO | train | epoch 181 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.257 | nll_loss 0.755 | ppl 1.69 | wps 22610 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 67875 | lr 8.40941e-06 | gnorm 0.985 | train_wall 234 | wall 47370
2021-01-17 04:59:53 | INFO | fairseq.trainer | begin training epoch 182
2021-01-17 04:59:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 04:59:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:00:12 | INFO | train_inner | epoch 182:     25 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.758, ppl=1.69, wps=17789.3, ups=1.13, wpb=15689.3, bsz=566.5, num_updates=67900, lr=8.40787e-06, gnorm=0.987, train_wall=63, wall=47389
2021-01-17 05:01:15 | INFO | train_inner | epoch 182:    125 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.249, nll_loss=0.749, ppl=1.68, wps=24780.5, ups=1.59, wpb=15565.3, bsz=541.2, num_updates=68000, lr=8.40168e-06, gnorm=0.988, train_wall=63, wall=47452
2021-01-17 05:02:18 | INFO | train_inner | epoch 182:    225 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.248, nll_loss=0.753, ppl=1.69, wps=25056.1, ups=1.59, wpb=15724.3, bsz=576.9, num_updates=68100, lr=8.39551e-06, gnorm=0.977, train_wall=63, wall=47515
2021-01-17 05:03:20 | INFO | train_inner | epoch 182:    325 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.761, ppl=1.69, wps=25299, ups=1.6, wpb=15773, bsz=549.1, num_updates=68200, lr=8.38935e-06, gnorm=0.987, train_wall=62, wall=47577
2021-01-17 05:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:03:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:03:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:03:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:03:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:03:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:03:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:03:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:03:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:03:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:03:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:03:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:03:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:03:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:03:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:04:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:04:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:04:08 | INFO | valid | epoch 182 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.064 | ppl 16.72 | bleu 22.62 | wps 6266 | wpb 11799.1 | bsz 428.6 | num_updates 68250 | best_bleu 22.65
2021-01-17 05:04:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:04:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:04:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:04:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:04:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:04:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 182 @ 68250 updates, score 22.62) (writing took 3.2305207289755344 seconds)
2021-01-17 05:04:12 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2021-01-17 05:04:12 | INFO | train | epoch 182 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.258 | nll_loss 0.756 | ppl 1.69 | wps 22750.7 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 68250 | lr 8.38628e-06 | gnorm 0.986 | train_wall 234 | wall 47629
2021-01-17 05:04:12 | INFO | fairseq.trainer | begin training epoch 183
2021-01-17 05:04:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:04:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:04:46 | INFO | train_inner | epoch 183:     50 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.756, ppl=1.69, wps=18124.5, ups=1.16, wpb=15608.7, bsz=550.6, num_updates=68300, lr=8.38321e-06, gnorm=0.991, train_wall=62, wall=47663
2021-01-17 05:05:49 | INFO | train_inner | epoch 183:    150 / 375 symm_kl=0.444, self_kl=0, self_cv=0, loss=3.231, nll_loss=0.746, ppl=1.68, wps=25510.2, ups=1.6, wpb=15941.4, bsz=576.3, num_updates=68400, lr=8.37708e-06, gnorm=0.962, train_wall=62, wall=47726
2021-01-17 05:06:52 | INFO | train_inner | epoch 183:    250 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.261, nll_loss=0.757, ppl=1.69, wps=25025.2, ups=1.59, wpb=15773.4, bsz=540.2, num_updates=68500, lr=8.37096e-06, gnorm=0.979, train_wall=63, wall=47789
2021-01-17 05:07:54 | INFO | train_inner | epoch 183:    350 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.275, nll_loss=0.764, ppl=1.7, wps=24908.5, ups=1.6, wpb=15561.1, bsz=545.6, num_updates=68600, lr=8.36486e-06, gnorm=1, train_wall=62, wall=47851
2021-01-17 05:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:08:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:08:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:08:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:08:28 | INFO | valid | epoch 183 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.066 | ppl 16.75 | bleu 22.58 | wps 5483.4 | wpb 11799.1 | bsz 428.6 | num_updates 68625 | best_bleu 22.65
2021-01-17 05:08:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:08:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:08:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:08:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 183 @ 68625 updates, score 22.58) (writing took 3.036648517474532 seconds)
2021-01-17 05:08:31 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2021-01-17 05:08:31 | INFO | train | epoch 183 | symm_kl 0.455 | self_kl 0 | self_cv 0 | loss 3.258 | nll_loss 0.755 | ppl 1.69 | wps 22679.6 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 68625 | lr 8.36333e-06 | gnorm 0.984 | train_wall 234 | wall 47888
2021-01-17 05:08:31 | INFO | fairseq.trainer | begin training epoch 184
2021-01-17 05:08:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:08:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:09:21 | INFO | train_inner | epoch 184:     75 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.752, ppl=1.68, wps=17899.5, ups=1.15, wpb=15506.1, bsz=555.4, num_updates=68700, lr=8.35877e-06, gnorm=0.987, train_wall=62, wall=47938
2021-01-17 05:10:23 | INFO | train_inner | epoch 184:    175 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.754, ppl=1.69, wps=25156.8, ups=1.61, wpb=15660.2, bsz=575, num_updates=68800, lr=8.35269e-06, gnorm=0.995, train_wall=62, wall=48000
2021-01-17 05:11:25 | INFO | train_inner | epoch 184:    275 / 375 symm_kl=0.459, self_kl=0, self_cv=0, loss=3.271, nll_loss=0.764, ppl=1.7, wps=25358.4, ups=1.61, wpb=15743.9, bsz=541.2, num_updates=68900, lr=8.34663e-06, gnorm=0.981, train_wall=62, wall=48062
2021-01-17 05:12:28 | INFO | train_inner | epoch 184:    375 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.752, ppl=1.68, wps=24917.5, ups=1.6, wpb=15595.8, bsz=532.2, num_updates=69000, lr=8.34058e-06, gnorm=0.982, train_wall=62, wall=48125
2021-01-17 05:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:12:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:12:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:12:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:12:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:12:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:12:47 | INFO | valid | epoch 184 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.066 | ppl 16.75 | bleu 22.55 | wps 5251.6 | wpb 11799.1 | bsz 428.6 | num_updates 69000 | best_bleu 22.65
2021-01-17 05:12:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:12:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:12:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:12:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 184 @ 69000 updates, score 22.55) (writing took 3.0122843496501446 seconds)
2021-01-17 05:12:50 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2021-01-17 05:12:50 | INFO | train | epoch 184 | symm_kl 0.454 | self_kl 0 | self_cv 0 | loss 3.257 | nll_loss 0.755 | ppl 1.69 | wps 22725.6 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 69000 | lr 8.34058e-06 | gnorm 0.984 | train_wall 232 | wall 48147
2021-01-17 05:12:50 | INFO | fairseq.trainer | begin training epoch 185
2021-01-17 05:12:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:12:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:13:55 | INFO | train_inner | epoch 185:    100 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.76, ppl=1.69, wps=17893.6, ups=1.14, wpb=15676.2, bsz=529.2, num_updates=69100, lr=8.33454e-06, gnorm=0.983, train_wall=62, wall=48213
2021-01-17 05:14:58 | INFO | train_inner | epoch 185:    200 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.754, ppl=1.69, wps=24864.7, ups=1.58, wpb=15719.9, bsz=569.4, num_updates=69200, lr=8.32851e-06, gnorm=0.979, train_wall=63, wall=48276
2021-01-17 05:16:01 | INFO | train_inner | epoch 185:    300 / 375 symm_kl=0.447, self_kl=0, self_cv=0, loss=3.24, nll_loss=0.748, ppl=1.68, wps=25044.2, ups=1.59, wpb=15766.8, bsz=565.8, num_updates=69300, lr=8.3225e-06, gnorm=0.971, train_wall=63, wall=48339
2021-01-17 05:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:16:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:16:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:16:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:16:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:16:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:16:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:16:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:16:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:17:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:17:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:17:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:17:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:17:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:17:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:17:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:17:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:17:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:17:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:17:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:17:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:17:08 | INFO | valid | epoch 185 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.068 | ppl 16.77 | bleu 22.59 | wps 5275.3 | wpb 11799.1 | bsz 428.6 | num_updates 69375 | best_bleu 22.65
2021-01-17 05:17:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:17:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:17:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:17:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:17:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:17:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 185 @ 69375 updates, score 22.59) (writing took 3.0681131035089493 seconds)
2021-01-17 05:17:11 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2021-01-17 05:17:11 | INFO | train | epoch 185 | symm_kl 0.454 | self_kl 0 | self_cv 0 | loss 3.256 | nll_loss 0.755 | ppl 1.69 | wps 22520.1 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 69375 | lr 8.318e-06 | gnorm 0.983 | train_wall 235 | wall 48408
2021-01-17 05:17:11 | INFO | fairseq.trainer | begin training epoch 186
2021-01-17 05:17:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:17:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:17:30 | INFO | train_inner | epoch 186:     25 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.268, nll_loss=0.759, ppl=1.69, wps=17678.7, ups=1.13, wpb=15601.2, bsz=540.9, num_updates=69400, lr=8.31651e-06, gnorm=0.998, train_wall=62, wall=48427
2021-01-17 05:18:32 | INFO | train_inner | epoch 186:    125 / 375 symm_kl=0.461, self_kl=0, self_cv=0, loss=3.273, nll_loss=0.761, ppl=1.69, wps=25096.6, ups=1.61, wpb=15580.1, bsz=534.3, num_updates=69500, lr=8.31052e-06, gnorm=0.996, train_wall=62, wall=48489
2021-01-17 05:19:34 | INFO | train_inner | epoch 186:    225 / 375 symm_kl=0.446, self_kl=0, self_cv=0, loss=3.233, nll_loss=0.744, ppl=1.68, wps=24933.9, ups=1.59, wpb=15635.7, bsz=583.7, num_updates=69600, lr=8.30455e-06, gnorm=0.974, train_wall=62, wall=48552
2021-01-17 05:20:38 | INFO | train_inner | epoch 186:    325 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.245, nll_loss=0.75, ppl=1.68, wps=25413.2, ups=1.58, wpb=16042.3, bsz=553.4, num_updates=69700, lr=8.29859e-06, gnorm=0.965, train_wall=63, wall=48615
2021-01-17 05:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:21:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:21:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:21:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:21:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:21:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:21:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:21:27 | INFO | valid | epoch 186 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.065 | ppl 16.74 | bleu 22.41 | wps 5214.4 | wpb 11799.1 | bsz 428.6 | num_updates 69750 | best_bleu 22.65
2021-01-17 05:21:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:21:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:21:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:21:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 186 @ 69750 updates, score 22.41) (writing took 3.028395852074027 seconds)
2021-01-17 05:21:30 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2021-01-17 05:21:30 | INFO | train | epoch 186 | symm_kl 0.454 | self_kl 0 | self_cv 0 | loss 3.256 | nll_loss 0.754 | ppl 1.69 | wps 22652 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 69750 | lr 8.29561e-06 | gnorm 0.984 | train_wall 233 | wall 48668
2021-01-17 05:21:30 | INFO | fairseq.trainer | begin training epoch 187
2021-01-17 05:21:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:21:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:22:05 | INFO | train_inner | epoch 187:     50 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.755, ppl=1.69, wps=17769.2, ups=1.14, wpb=15550.9, bsz=556.8, num_updates=69800, lr=8.29264e-06, gnorm=0.995, train_wall=62, wall=48702
2021-01-17 05:23:08 | INFO | train_inner | epoch 187:    150 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.756, ppl=1.69, wps=24814, ups=1.58, wpb=15664.4, bsz=545.9, num_updates=69900, lr=8.28671e-06, gnorm=0.984, train_wall=63, wall=48766
2021-01-17 05:24:11 | INFO | train_inner | epoch 187:    250 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.257, nll_loss=0.755, ppl=1.69, wps=24921.7, ups=1.59, wpb=15663.5, bsz=545, num_updates=70000, lr=8.28079e-06, gnorm=0.986, train_wall=63, wall=48828
2021-01-17 05:25:14 | INFO | train_inner | epoch 187:    350 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.759, ppl=1.69, wps=24987.9, ups=1.6, wpb=15665.5, bsz=561.3, num_updates=70100, lr=8.27488e-06, gnorm=0.979, train_wall=62, wall=48891
2021-01-17 05:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:25:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:25:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:25:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:25:48 | INFO | valid | epoch 187 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.066 | ppl 16.75 | bleu 22.52 | wps 5514.2 | wpb 11799.1 | bsz 428.6 | num_updates 70125 | best_bleu 22.65
2021-01-17 05:25:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:25:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:25:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:25:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 187 @ 70125 updates, score 22.52) (writing took 3.096251331269741 seconds)
2021-01-17 05:25:51 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2021-01-17 05:25:51 | INFO | train | epoch 187 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.255 | nll_loss 0.754 | ppl 1.69 | wps 22578.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 70125 | lr 8.2734e-06 | gnorm 0.98 | train_wall 235 | wall 48928
2021-01-17 05:25:51 | INFO | fairseq.trainer | begin training epoch 188
2021-01-17 05:25:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:25:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:26:41 | INFO | train_inner | epoch 188:     75 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.755, ppl=1.69, wps=18027, ups=1.15, wpb=15687.2, bsz=554.3, num_updates=70200, lr=8.26898e-06, gnorm=0.976, train_wall=62, wall=48978
2021-01-17 05:27:44 | INFO | train_inner | epoch 188:    175 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.243, nll_loss=0.746, ppl=1.68, wps=24996.9, ups=1.59, wpb=15728.4, bsz=537.5, num_updates=70300, lr=8.2631e-06, gnorm=0.97, train_wall=63, wall=49041
2021-01-17 05:28:46 | INFO | train_inner | epoch 188:    275 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.256, nll_loss=0.761, ppl=1.69, wps=24970.3, ups=1.6, wpb=15572.7, bsz=570.3, num_updates=70400, lr=8.25723e-06, gnorm=0.975, train_wall=62, wall=49103
2021-01-17 05:29:49 | INFO | train_inner | epoch 188:    375 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.755, ppl=1.69, wps=25009.2, ups=1.59, wpb=15691.7, bsz=547.1, num_updates=70500, lr=8.25137e-06, gnorm=0.995, train_wall=63, wall=49166
2021-01-17 05:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:29:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:29:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:29:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:29:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:29:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:29:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:29:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:29:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:29:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:29:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:30:08 | INFO | valid | epoch 188 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.064 | ppl 16.72 | bleu 22.37 | wps 5240.7 | wpb 11799.1 | bsz 428.6 | num_updates 70500 | best_bleu 22.65
2021-01-17 05:30:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:30:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:30:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:30:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:30:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:30:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 188 @ 70500 updates, score 22.37) (writing took 3.0373924542218447 seconds)
2021-01-17 05:30:11 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2021-01-17 05:30:11 | INFO | train | epoch 188 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.254 | nll_loss 0.755 | ppl 1.69 | wps 22605.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 70500 | lr 8.25137e-06 | gnorm 0.979 | train_wall 234 | wall 49188
2021-01-17 05:30:11 | INFO | fairseq.trainer | begin training epoch 189
2021-01-17 05:30:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:30:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:31:17 | INFO | train_inner | epoch 189:    100 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.756, ppl=1.69, wps=17775.7, ups=1.13, wpb=15674.6, bsz=560, num_updates=70600, lr=8.24552e-06, gnorm=0.977, train_wall=62, wall=49254
2021-01-17 05:32:20 | INFO | train_inner | epoch 189:    200 / 375 symm_kl=0.444, self_kl=0, self_cv=0, loss=3.228, nll_loss=0.741, ppl=1.67, wps=25015.2, ups=1.58, wpb=15822.6, bsz=553.5, num_updates=70700, lr=8.23969e-06, gnorm=0.969, train_wall=63, wall=49318
2021-01-17 05:33:23 | INFO | train_inner | epoch 189:    300 / 375 symm_kl=0.463, self_kl=0, self_cv=0, loss=3.284, nll_loss=0.77, ppl=1.71, wps=24706.8, ups=1.59, wpb=15505.8, bsz=558.3, num_updates=70800, lr=8.23387e-06, gnorm=0.994, train_wall=63, wall=49380
2021-01-17 05:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:34:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:34:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:34:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:34:31 | INFO | valid | epoch 189 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.068 | ppl 16.77 | bleu 22.47 | wps 4652 | wpb 11799.1 | bsz 428.6 | num_updates 70875 | best_bleu 22.65
2021-01-17 05:34:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:34:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 189 @ 70875 updates, score 22.47) (writing took 3.0344343781471252 seconds)
2021-01-17 05:34:34 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2021-01-17 05:34:34 | INFO | train | epoch 189 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.254 | nll_loss 0.754 | ppl 1.69 | wps 22351.8 | ups 1.43 | wpb 15683.1 | bsz 553 | num_updates 70875 | lr 8.22951e-06 | gnorm 0.98 | train_wall 235 | wall 49452
2021-01-17 05:34:34 | INFO | fairseq.trainer | begin training epoch 190
2021-01-17 05:34:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:34:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:34:53 | INFO | train_inner | epoch 190:     25 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.246, nll_loss=0.746, ppl=1.68, wps=17360.4, ups=1.11, wpb=15629.3, bsz=548.1, num_updates=70900, lr=8.22806e-06, gnorm=0.981, train_wall=63, wall=49470
2021-01-17 05:35:56 | INFO | train_inner | epoch 190:    125 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.261, nll_loss=0.755, ppl=1.69, wps=24996.5, ups=1.59, wpb=15700.3, bsz=538.4, num_updates=71000, lr=8.22226e-06, gnorm=0.992, train_wall=63, wall=49533
2021-01-17 05:36:58 | INFO | train_inner | epoch 190:    225 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.245, nll_loss=0.749, ppl=1.68, wps=25197.2, ups=1.6, wpb=15705.9, bsz=560.1, num_updates=71100, lr=8.21648e-06, gnorm=0.989, train_wall=62, wall=49595
2021-01-17 05:38:01 | INFO | train_inner | epoch 190:    325 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.757, ppl=1.69, wps=25324, ups=1.6, wpb=15787.9, bsz=569.3, num_updates=71200, lr=8.21071e-06, gnorm=0.982, train_wall=62, wall=49658
2021-01-17 05:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:38:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:38:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:38:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:38:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:38:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:38:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:38:50 | INFO | valid | epoch 190 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.065 | ppl 16.73 | bleu 22.31 | wps 5639 | wpb 11799.1 | bsz 428.6 | num_updates 71250 | best_bleu 22.65
2021-01-17 05:38:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:38:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:38:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:38:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 190 @ 71250 updates, score 22.31) (writing took 3.029446814209223 seconds)
2021-01-17 05:38:53 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2021-01-17 05:38:53 | INFO | train | epoch 190 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.254 | nll_loss 0.754 | ppl 1.69 | wps 22757.8 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 71250 | lr 8.20783e-06 | gnorm 0.991 | train_wall 233 | wall 49710
2021-01-17 05:38:53 | INFO | fairseq.trainer | begin training epoch 191
2021-01-17 05:38:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:38:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:39:27 | INFO | train_inner | epoch 191:     50 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.757, ppl=1.69, wps=18030.6, ups=1.15, wpb=15637.5, bsz=529.5, num_updates=71300, lr=8.20495e-06, gnorm=1.001, train_wall=62, wall=49745
2021-01-17 05:40:30 | INFO | train_inner | epoch 191:    150 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.756, ppl=1.69, wps=25111, ups=1.59, wpb=15748.8, bsz=565.6, num_updates=71400, lr=8.1992e-06, gnorm=0.973, train_wall=63, wall=49807
2021-01-17 05:41:33 | INFO | train_inner | epoch 191:    250 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.246, nll_loss=0.752, ppl=1.68, wps=25389.7, ups=1.59, wpb=15937.7, bsz=555.9, num_updates=71500, lr=8.19346e-06, gnorm=0.964, train_wall=63, wall=49870
2021-01-17 05:42:36 | INFO | train_inner | epoch 191:    350 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.251, nll_loss=0.751, ppl=1.68, wps=24788.3, ups=1.59, wpb=15603.7, bsz=562.3, num_updates=71600, lr=8.18774e-06, gnorm=0.984, train_wall=63, wall=49933
2021-01-17 05:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:42:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:42:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:42:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:42:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:42:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:42:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:43:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:43:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:43:09 | INFO | valid | epoch 191 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.673 | nll_loss 4.063 | ppl 16.71 | bleu 22.56 | wps 5513 | wpb 11799.1 | bsz 428.6 | num_updates 71625 | best_bleu 22.65
2021-01-17 05:43:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:43:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:43:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:43:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:43:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:43:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 191 @ 71625 updates, score 22.56) (writing took 2.996647998690605 seconds)
2021-01-17 05:43:12 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2021-01-17 05:43:12 | INFO | train | epoch 191 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.253 | nll_loss 0.753 | ppl 1.69 | wps 22638.7 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 71625 | lr 8.18631e-06 | gnorm 0.99 | train_wall 234 | wall 49970
2021-01-17 05:43:12 | INFO | fairseq.trainer | begin training epoch 192
2021-01-17 05:43:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:43:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:44:03 | INFO | train_inner | epoch 192:     75 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.257, nll_loss=0.751, ppl=1.68, wps=17838.8, ups=1.15, wpb=15510.4, bsz=549.9, num_updates=71700, lr=8.18203e-06, gnorm=1.03, train_wall=62, wall=50020
2021-01-17 05:45:05 | INFO | train_inner | epoch 192:    175 / 375 symm_kl=0.46, self_kl=0, self_cv=0, loss=3.271, nll_loss=0.762, ppl=1.7, wps=24789.2, ups=1.6, wpb=15478.4, bsz=547, num_updates=71800, lr=8.17633e-06, gnorm=0.997, train_wall=62, wall=50082
2021-01-17 05:46:08 | INFO | train_inner | epoch 192:    275 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.258, nll_loss=0.755, ppl=1.69, wps=25102.4, ups=1.59, wpb=15790.2, bsz=546.5, num_updates=71900, lr=8.17064e-06, gnorm=0.986, train_wall=63, wall=50145
2021-01-17 05:47:10 | INFO | train_inner | epoch 192:    375 / 375 symm_kl=0.446, self_kl=0, self_cv=0, loss=3.239, nll_loss=0.749, ppl=1.68, wps=25215.5, ups=1.6, wpb=15713.6, bsz=550.4, num_updates=72000, lr=8.16497e-06, gnorm=0.97, train_wall=62, wall=50208
2021-01-17 05:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:47:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:47:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:47:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:47:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:47:29 | INFO | valid | epoch 192 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.068 | ppl 16.77 | bleu 22.34 | wps 5523.3 | wpb 11799.1 | bsz 428.6 | num_updates 72000 | best_bleu 22.65
2021-01-17 05:47:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:47:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:47:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:47:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 192 @ 72000 updates, score 22.34) (writing took 3.0125904008746147 seconds)
2021-01-17 05:47:32 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2021-01-17 05:47:32 | INFO | train | epoch 192 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.254 | nll_loss 0.754 | ppl 1.69 | wps 22692.4 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 72000 | lr 8.16497e-06 | gnorm 0.983 | train_wall 233 | wall 50229
2021-01-17 05:47:32 | INFO | fairseq.trainer | begin training epoch 193
2021-01-17 05:47:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:47:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:48:38 | INFO | train_inner | epoch 193:    100 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.259, nll_loss=0.759, ppl=1.69, wps=18063.1, ups=1.14, wpb=15781.7, bsz=564.9, num_updates=72100, lr=8.1593e-06, gnorm=0.97, train_wall=62, wall=50295
2021-01-17 05:49:40 | INFO | train_inner | epoch 193:    200 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.249, nll_loss=0.747, ppl=1.68, wps=24796.4, ups=1.61, wpb=15444.7, bsz=538.6, num_updates=72200, lr=8.15365e-06, gnorm=0.99, train_wall=62, wall=50357
2021-01-17 05:50:42 | INFO | train_inner | epoch 193:    300 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.257, nll_loss=0.76, ppl=1.69, wps=25358.8, ups=1.61, wpb=15793.8, bsz=570.8, num_updates=72300, lr=8.14801e-06, gnorm=0.973, train_wall=62, wall=50420
2021-01-17 05:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:51:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:51:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:51:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:51:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:51:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:51:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:51:49 | INFO | valid | epoch 193 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.674 | nll_loss 4.064 | ppl 16.73 | bleu 22.39 | wps 4998 | wpb 11799.1 | bsz 428.6 | num_updates 72375 | best_bleu 22.65
2021-01-17 05:51:49 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:51:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:51:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:51:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 193 @ 72375 updates, score 22.39) (writing took 3.148942109197378 seconds)
2021-01-17 05:51:52 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2021-01-17 05:51:52 | INFO | train | epoch 193 | symm_kl 0.452 | self_kl 0 | self_cv 0 | loss 3.253 | nll_loss 0.754 | ppl 1.69 | wps 22582.3 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 72375 | lr 8.14379e-06 | gnorm 0.979 | train_wall 233 | wall 50489
2021-01-17 05:51:52 | INFO | fairseq.trainer | begin training epoch 194
2021-01-17 05:51:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:51:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:52:11 | INFO | train_inner | epoch 194:     25 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.247, nll_loss=0.75, ppl=1.68, wps=17749, ups=1.13, wpb=15755.6, bsz=541.6, num_updates=72400, lr=8.14238e-06, gnorm=0.978, train_wall=62, wall=50508
2021-01-17 05:53:14 | INFO | train_inner | epoch 194:    125 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.246, nll_loss=0.747, ppl=1.68, wps=24754.6, ups=1.6, wpb=15472.8, bsz=546.8, num_updates=72500, lr=8.13676e-06, gnorm=0.987, train_wall=62, wall=50571
2021-01-17 05:54:16 | INFO | train_inner | epoch 194:    225 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.254, nll_loss=0.754, ppl=1.69, wps=25171.4, ups=1.59, wpb=15804.4, bsz=542.9, num_updates=72600, lr=8.13116e-06, gnorm=0.992, train_wall=63, wall=50634
2021-01-17 05:55:19 | INFO | train_inner | epoch 194:    325 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.253, nll_loss=0.754, ppl=1.69, wps=25049.2, ups=1.6, wpb=15623.5, bsz=555.7, num_updates=72700, lr=8.12556e-06, gnorm=0.976, train_wall=62, wall=50696
2021-01-17 05:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 05:55:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:55:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:55:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:55:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:55:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:55:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:55:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:55:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:55:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 05:56:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 05:56:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 05:56:09 | INFO | valid | epoch 194 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.069 | ppl 16.79 | bleu 22.37 | wps 5270 | wpb 11799.1 | bsz 428.6 | num_updates 72750 | best_bleu 22.65
2021-01-17 05:56:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 05:56:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:56:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:56:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:56:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:56:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 194 @ 72750 updates, score 22.37) (writing took 3.0694285575300455 seconds)
2021-01-17 05:56:12 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2021-01-17 05:56:12 | INFO | train | epoch 194 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.253 | nll_loss 0.753 | ppl 1.69 | wps 22628.2 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 72750 | lr 8.12277e-06 | gnorm 0.981 | train_wall 234 | wall 50749
2021-01-17 05:56:12 | INFO | fairseq.trainer | begin training epoch 195
2021-01-17 05:56:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 05:56:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 05:56:47 | INFO | train_inner | epoch 195:     50 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.761, ppl=1.69, wps=17927.5, ups=1.14, wpb=15757, bsz=572.3, num_updates=72800, lr=8.11998e-06, gnorm=0.978, train_wall=62, wall=50784
2021-01-17 05:57:49 | INFO | train_inner | epoch 195:    150 / 375 symm_kl=0.458, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.758, ppl=1.69, wps=24919.5, ups=1.6, wpb=15618.5, bsz=535.4, num_updates=72900, lr=8.11441e-06, gnorm=0.993, train_wall=62, wall=50847
2021-01-17 05:58:52 | INFO | train_inner | epoch 195:    250 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.247, nll_loss=0.749, ppl=1.68, wps=25106, ups=1.6, wpb=15717.6, bsz=549, num_updates=73000, lr=8.10885e-06, gnorm=0.984, train_wall=62, wall=50909
2021-01-17 05:59:54 | INFO | train_inner | epoch 195:    350 / 375 symm_kl=0.448, self_kl=0, self_cv=0, loss=3.24, nll_loss=0.747, ppl=1.68, wps=25259.7, ups=1.6, wpb=15782, bsz=563.9, num_updates=73100, lr=8.1033e-06, gnorm=0.973, train_wall=62, wall=50972
2021-01-17 06:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:00:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:00:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:00:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:00:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:00:28 | INFO | valid | epoch 195 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.064 | ppl 16.73 | bleu 22.44 | wps 5474.1 | wpb 11799.1 | bsz 428.6 | num_updates 73125 | best_bleu 22.65
2021-01-17 06:00:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:00:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 195 @ 73125 updates, score 22.44) (writing took 3.040726099163294 seconds)
2021-01-17 06:00:31 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2021-01-17 06:00:31 | INFO | train | epoch 195 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.253 | nll_loss 0.754 | ppl 1.69 | wps 22696.2 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 73125 | lr 8.10191e-06 | gnorm 0.988 | train_wall 233 | wall 51008
2021-01-17 06:00:31 | INFO | fairseq.trainer | begin training epoch 196
2021-01-17 06:00:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:00:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:00:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:00:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:01:21 | INFO | train_inner | epoch 196:     75 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.263, nll_loss=0.759, ppl=1.69, wps=17791.7, ups=1.16, wpb=15373.8, bsz=556, num_updates=73200, lr=8.09776e-06, gnorm=1.014, train_wall=61, wall=51058
2021-01-17 06:02:23 | INFO | train_inner | epoch 196:    175 / 375 symm_kl=0.45, self_kl=0, self_cv=0, loss=3.248, nll_loss=0.754, ppl=1.69, wps=25355.6, ups=1.6, wpb=15831.6, bsz=560.5, num_updates=73300, lr=8.09224e-06, gnorm=0.975, train_wall=62, wall=51120
2021-01-17 06:03:25 | INFO | train_inner | epoch 196:    275 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.244, nll_loss=0.749, ppl=1.68, wps=25266.8, ups=1.61, wpb=15695.8, bsz=560, num_updates=73400, lr=8.08672e-06, gnorm=0.972, train_wall=62, wall=51183
2021-01-17 06:04:28 | INFO | train_inner | epoch 196:    375 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.752, ppl=1.68, wps=25232.9, ups=1.6, wpb=15794, bsz=536.6, num_updates=73500, lr=8.08122e-06, gnorm=1.003, train_wall=62, wall=51245
2021-01-17 06:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:04:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:04:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:04:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:04:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:04:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:04:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:04:47 | INFO | valid | epoch 196 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.672 | nll_loss 4.064 | ppl 16.72 | bleu 22.55 | wps 5254.6 | wpb 11799.1 | bsz 428.6 | num_updates 73500 | best_bleu 22.65
2021-01-17 06:04:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:04:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:04:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:04:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 196 @ 73500 updates, score 22.55) (writing took 3.0111548602581024 seconds)
2021-01-17 06:04:50 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2021-01-17 06:04:50 | INFO | train | epoch 196 | symm_kl 0.452 | self_kl 0 | self_cv 0 | loss 3.252 | nll_loss 0.753 | ppl 1.69 | wps 22740.2 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 73500 | lr 8.08122e-06 | gnorm 0.987 | train_wall 232 | wall 51267
2021-01-17 06:04:50 | INFO | fairseq.trainer | begin training epoch 197
2021-01-17 06:04:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:04:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:05:56 | INFO | train_inner | epoch 197:    100 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.24, nll_loss=0.747, ppl=1.68, wps=17996.9, ups=1.14, wpb=15843.1, bsz=563.6, num_updates=73600, lr=8.07573e-06, gnorm=0.974, train_wall=62, wall=51333
2021-01-17 06:06:59 | INFO | train_inner | epoch 197:    200 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.753, ppl=1.69, wps=24808.3, ups=1.58, wpb=15676.7, bsz=564.5, num_updates=73700, lr=8.07025e-06, gnorm=0.994, train_wall=63, wall=51396
2021-01-17 06:08:01 | INFO | train_inner | epoch 197:    300 / 375 symm_kl=0.457, self_kl=0, self_cv=0, loss=3.266, nll_loss=0.759, ppl=1.69, wps=25216.9, ups=1.61, wpb=15682.9, bsz=538, num_updates=73800, lr=8.06478e-06, gnorm=0.981, train_wall=62, wall=51459
2021-01-17 06:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:08:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:08:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:08:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:08:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:08:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:09:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:09:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:09:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:09:07 | INFO | valid | epoch 197 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.675 | nll_loss 4.067 | ppl 16.76 | bleu 22.45 | wps 5496.2 | wpb 11799.1 | bsz 428.6 | num_updates 73875 | best_bleu 22.65
2021-01-17 06:09:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:09:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:09:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:09:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:09:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:09:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 197 @ 73875 updates, score 22.45) (writing took 3.035441007465124 seconds)
2021-01-17 06:09:10 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2021-01-17 06:09:10 | INFO | train | epoch 197 | symm_kl 0.453 | self_kl 0 | self_cv 0 | loss 3.252 | nll_loss 0.753 | ppl 1.69 | wps 22618.2 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 73875 | lr 8.06068e-06 | gnorm 0.986 | train_wall 234 | wall 51527
2021-01-17 06:09:10 | INFO | fairseq.trainer | begin training epoch 198
2021-01-17 06:09:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:09:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:09:28 | INFO | train_inner | epoch 198:     25 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.248, nll_loss=0.751, ppl=1.68, wps=17754.5, ups=1.15, wpb=15455, bsz=555.4, num_updates=73900, lr=8.05932e-06, gnorm=0.993, train_wall=62, wall=51546
2021-01-17 06:10:30 | INFO | train_inner | epoch 198:    125 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.26, nll_loss=0.754, ppl=1.69, wps=25276.1, ups=1.62, wpb=15605.4, bsz=519.6, num_updates=74000, lr=8.05387e-06, gnorm=1.006, train_wall=62, wall=51607
2021-01-17 06:11:32 | INFO | train_inner | epoch 198:    225 / 375 symm_kl=0.455, self_kl=0, self_cv=0, loss=3.262, nll_loss=0.759, ppl=1.69, wps=25215.3, ups=1.61, wpb=15649.4, bsz=563.4, num_updates=74100, lr=8.04844e-06, gnorm=0.986, train_wall=62, wall=51669
2021-01-17 06:12:35 | INFO | train_inner | epoch 198:    325 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.754, ppl=1.69, wps=25382.9, ups=1.6, wpb=15855.8, bsz=545.5, num_updates=74200, lr=8.04301e-06, gnorm=0.972, train_wall=62, wall=51732
2021-01-17 06:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:13:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:13:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:13:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:13:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:13:25 | INFO | valid | epoch 198 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.677 | nll_loss 4.069 | ppl 16.78 | bleu 22.53 | wps 5180.2 | wpb 11799.1 | bsz 428.6 | num_updates 74250 | best_bleu 22.65
2021-01-17 06:13:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:13:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:13:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:13:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 198 @ 74250 updates, score 22.53) (writing took 2.9935565385967493 seconds)
2021-01-17 06:13:28 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2021-01-17 06:13:28 | INFO | train | epoch 198 | symm_kl 0.452 | self_kl 0 | self_cv 0 | loss 3.252 | nll_loss 0.753 | ppl 1.69 | wps 22765.1 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 74250 | lr 8.0403e-06 | gnorm 0.986 | train_wall 232 | wall 51785
2021-01-17 06:13:28 | INFO | fairseq.trainer | begin training epoch 199
2021-01-17 06:13:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:13:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:14:03 | INFO | train_inner | epoch 199:     50 / 375 symm_kl=0.445, self_kl=0, self_cv=0, loss=3.232, nll_loss=0.744, ppl=1.67, wps=17818.7, ups=1.14, wpb=15680.7, bsz=574.4, num_updates=74300, lr=8.0376e-06, gnorm=0.976, train_wall=62, wall=51820
2021-01-17 06:15:05 | INFO | train_inner | epoch 199:    150 / 375 symm_kl=0.454, self_kl=0, self_cv=0, loss=3.253, nll_loss=0.752, ppl=1.68, wps=25362.2, ups=1.6, wpb=15875.3, bsz=539.3, num_updates=74400, lr=8.03219e-06, gnorm=0.986, train_wall=62, wall=51883
2021-01-17 06:16:08 | INFO | train_inner | epoch 199:    250 / 375 symm_kl=0.452, self_kl=0, self_cv=0, loss=3.252, nll_loss=0.753, ppl=1.69, wps=25202.3, ups=1.6, wpb=15752.2, bsz=559.9, num_updates=74500, lr=8.0268e-06, gnorm=0.98, train_wall=62, wall=51945
2021-01-17 06:17:10 | INFO | train_inner | epoch 199:    350 / 375 symm_kl=0.449, self_kl=0, self_cv=0, loss=3.246, nll_loss=0.751, ppl=1.68, wps=25097.9, ups=1.61, wpb=15586.6, bsz=562.5, num_updates=74600, lr=8.02142e-06, gnorm=0.974, train_wall=62, wall=52007
2021-01-17 06:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:17:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:26 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:17:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:17:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:17:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:17:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:17:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:17:44 | INFO | valid | epoch 199 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.068 | ppl 16.77 | bleu 22.43 | wps 5495.1 | wpb 11799.1 | bsz 428.6 | num_updates 74625 | best_bleu 22.65
2021-01-17 06:17:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:17:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:17:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:17:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 199 @ 74625 updates, score 22.43) (writing took 3.0503522735089064 seconds)
2021-01-17 06:17:47 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2021-01-17 06:17:47 | INFO | train | epoch 199 | symm_kl 0.452 | self_kl 0 | self_cv 0 | loss 3.251 | nll_loss 0.752 | ppl 1.68 | wps 22728 | ups 1.45 | wpb 15683.1 | bsz 553 | num_updates 74625 | lr 8.02008e-06 | gnorm 0.983 | train_wall 233 | wall 52044
2021-01-17 06:17:47 | INFO | fairseq.trainer | begin training epoch 200
2021-01-17 06:17:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:17:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:18:37 | INFO | train_inner | epoch 200:     75 / 375 symm_kl=0.448, self_kl=0, self_cv=0, loss=3.238, nll_loss=0.743, ppl=1.67, wps=17845.6, ups=1.15, wpb=15570.1, bsz=560.3, num_updates=74700, lr=8.01605e-06, gnorm=0.994, train_wall=62, wall=52094
2021-01-17 06:19:40 | INFO | train_inner | epoch 200:    175 / 375 symm_kl=0.451, self_kl=0, self_cv=0, loss=3.249, nll_loss=0.753, ppl=1.68, wps=24936.5, ups=1.58, wpb=15746, bsz=549.5, num_updates=74800, lr=8.01069e-06, gnorm=0.981, train_wall=63, wall=52158
2021-01-17 06:20:43 | INFO | train_inner | epoch 200:    275 / 375 symm_kl=0.456, self_kl=0, self_cv=0, loss=3.265, nll_loss=0.761, ppl=1.69, wps=25315.3, ups=1.6, wpb=15795.5, bsz=546.6, num_updates=74900, lr=8.00534e-06, gnorm=0.979, train_wall=62, wall=52220
2021-01-17 06:21:46 | INFO | train_inner | epoch 200:    375 / 375 symm_kl=0.453, self_kl=0, self_cv=0, loss=3.255, nll_loss=0.754, ppl=1.69, wps=24602.7, ups=1.59, wpb=15471.8, bsz=552.5, num_updates=75000, lr=8e-06, gnorm=1, train_wall=63, wall=52283
2021-01-17 06:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-17 06:21:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:21:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:21:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2021-01-17 06:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:21:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2021-01-17 06:21:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:21:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-01-17 06:21:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-01-17 06:21:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-01-17 06:22:04 | INFO | valid | epoch 200 | valid on 'valid' subset | symm_kl 0 | self_kl 0 | self_cv 0 | loss 5.676 | nll_loss 4.066 | ppl 16.75 | bleu 22.53 | wps 5740.5 | wpb 11799.1 | bsz 428.6 | num_updates 75000 | best_bleu 22.65
2021-01-17 06:22:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-17 06:22:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/entr/bash/../checkpoints/noised_target/checkpoint_last.pt (epoch 200 @ 75000 updates, score 22.53) (writing took 3.0704283956438303 seconds)
2021-01-17 06:22:07 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2021-01-17 06:22:07 | INFO | train | epoch 200 | symm_kl 0.452 | self_kl 0 | self_cv 0 | loss 3.251 | nll_loss 0.752 | ppl 1.68 | wps 22641.3 | ups 1.44 | wpb 15683.1 | bsz 553 | num_updates 75000 | lr 8e-06 | gnorm 0.985 | train_wall 234 | wall 52304
2021-01-17 06:22:07 | INFO | fairseq_cli.train | done training in 52302.9 seconds
examples/entr/bash/kl_train.sh: 72: examples/entr/bash/kl_train.sh: retrained_model: not found
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1200 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
