nohup: ignoring input
2020-12-03 19:33:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:19 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:12166
2020-12-03 19:33:19 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:12166
2020-12-03 19:33:19 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:12166
2020-12-03 19:33:19 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-03 19:33:20 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-03 19:33:20 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-03 19:33:25 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='closer_dropout', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='r3f_closer_dropout_all', cross_self_attention=False, curriculum=0, data='./examples/transformer_enzh/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:12166', distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-05, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3024, max_tokens_valid=3024, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', nprocs_per_node=3, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=0.08, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='./examples/transformer_enzh/bash/../checkpoints/closer_all1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-03 19:33:25 | INFO | fairseq.tasks.translation | [ch] dictionary: 27920 types
2020-12-03 19:33:25 | INFO | fairseq.tasks.translation | [en] dictionary: 19376 types
2020-12-03 19:33:25 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.ch
2020-12-03 19:33:25 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.en
2020-12-03 19:33:25 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin valid ch-en 1664 examples
2020-12-03 19:33:26 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(27920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19376, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19376, bias=False)
  )
)
2020-12-03 19:33:26 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-03 19:33:26 | INFO | fairseq_cli.train | model: closer_dropout (TransformerModel)
2020-12-03 19:33:26 | INFO | fairseq_cli.train | criterion: r3f_closer_dropout_all (R3fCloserDropoutAll)
2020-12-03 19:33:26 | INFO | fairseq_cli.train | num. model params: 78274560 (num. trained: 78274560)
2020-12-03 19:33:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2020-12-03 19:33:27 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-03 19:33:27 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-03 19:33:27 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-03 19:33:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 3 workers***********************
2020-12-03 19:33:27 | INFO | fairseq_cli.train | training on 3 devices (GPUs/TPUs)
2020-12-03 19:33:27 | INFO | fairseq_cli.train | max tokens per GPU = 3024 and max sentences per GPU = None
2020-12-03 19:33:28 | INFO | fairseq.trainer | loaded checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 39 @ 0 updates)
2020-12-03 19:33:28 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-03 19:33:28 | INFO | fairseq.trainer | loading train data for epoch 39
2020-12-03 19:33:28 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.ch
2020-12-03 19:33:28 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.en
2020-12-03 19:33:28 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin train ch-en 200000 examples
111
111
2020-12-03 19:33:28 | INFO | fairseq.trainer | begin training epoch 39
111
2020-12-03 19:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:33:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:34:21 | INFO | train_inner | epoch 039:    100 / 719 loss=4.594, nll_loss=1.762, symm_mse=25.27, ppl=3.39, wps=22140, ups=2.02, wpb=10950.6, bsz=372.1, num_updates=100, lr=1.25975e-05, gnorm=2.515, train_wall=79, wall=0
2020-12-03 19:35:09 | INFO | train_inner | epoch 039:    200 / 719 loss=5.708, nll_loss=2.078, symm_mse=17.835, ppl=4.22, wps=16942.3, ups=2.09, wpb=8122.5, bsz=283.1, num_updates=200, lr=2.5095e-05, gnorm=2.222, train_wall=48, wall=0
2020-12-03 19:35:58 | INFO | train_inner | epoch 039:    300 / 719 loss=5.377, nll_loss=2.196, symm_mse=14.249, ppl=4.58, wps=16414.8, ups=2.01, wpb=8155.4, bsz=280, num_updates=300, lr=3.75925e-05, gnorm=1.617, train_wall=49, wall=0
2020-12-03 19:36:48 | INFO | train_inner | epoch 039:    400 / 719 loss=5.188, nll_loss=2.248, symm_mse=12.199, ppl=4.75, wps=16335.9, ups=2.01, wpb=8144, bsz=299.3, num_updates=400, lr=5.009e-05, gnorm=1.394, train_wall=50, wall=0
2020-12-03 19:37:38 | INFO | train_inner | epoch 039:    500 / 719 loss=5.193, nll_loss=2.33, symm_mse=11.576, ppl=5.03, wps=16519.5, ups=2.01, wpb=8201.9, bsz=255.9, num_updates=500, lr=6.25875e-05, gnorm=1.321, train_wall=49, wall=0
2020-12-03 19:38:28 | INFO | train_inner | epoch 039:    600 / 719 loss=5.02, nll_loss=2.265, symm_mse=10.464, ppl=4.8, wps=16354.5, ups=2, wpb=8197.1, bsz=284.5, num_updates=600, lr=7.5085e-05, gnorm=1.254, train_wall=50, wall=0
2020-12-03 19:39:18 | INFO | train_inner | epoch 039:    700 / 719 loss=5.025, nll_loss=2.329, symm_mse=10.004, ppl=5.03, wps=16356, ups=2, wpb=8175, bsz=285.1, num_updates=700, lr=8.75825e-05, gnorm=1.211, train_wall=50, wall=0
2020-12-03 19:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 19:39:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:39:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:39:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:39:50 | INFO | valid | epoch 039 | valid on 'valid' subset | symm_mse 0 | loss 8.934 | nll_loss 7.986 | ppl 253.52 | bleu 11.7 | wps 3383 | wpb 4629 | bsz 118.9 | num_updates 719
2020-12-03 19:39:50 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 19:39:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:39:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:39:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 39 @ 719 updates, score 11.7) (writing took 4.738556236028671 seconds)
2020-12-03 19:39:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-12-03 19:39:55 | INFO | train | epoch 039 | loss 4.422 | nll_loss 1.949 | symm_mse 14.418 | ppl 3.86 | wps 21896.8 | ups 2.11 | wpb 10365.7 | bsz 353.4 | num_updates 719 | lr 8.9957e-05 | gnorm 1.446 | train_wall 489 | wall 0
111
2020-12-03 19:39:55 | INFO | fairseq.trainer | begin training epoch 40
2020-12-03 19:39:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:39:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:40:38 | INFO | train_inner | epoch 040:     81 / 719 loss=5.035, nll_loss=2.335, symm_mse=10.045, ppl=5.05, wps=10082.2, ups=1.25, wpb=8064.9, bsz=263, num_updates=800, lr=0.00010008, gnorm=1.221, train_wall=49, wall=0
2020-12-03 19:41:27 | INFO | train_inner | epoch 040:    181 / 719 loss=4.974, nll_loss=2.322, symm_mse=9.601, ppl=5, wps=16512.3, ups=2.02, wpb=8178.8, bsz=273.2, num_updates=900, lr=0.000112578, gnorm=1.167, train_wall=49, wall=0
2020-12-03 19:42:17 | INFO | train_inner | epoch 040:    281 / 719 loss=4.921, nll_loss=2.309, symm_mse=9.228, ppl=4.95, wps=16186.4, ups=2, wpb=8108.7, bsz=277.6, num_updates=1000, lr=0.000125075, gnorm=1.152, train_wall=50, wall=0
2020-12-03 19:43:08 | INFO | train_inner | epoch 040:    381 / 719 loss=4.856, nll_loss=2.288, symm_mse=8.807, ppl=4.88, wps=16275.6, ups=1.99, wpb=8162.7, bsz=280.9, num_updates=1100, lr=0.000137573, gnorm=1.121, train_wall=50, wall=0
2020-12-03 19:43:58 | INFO | train_inner | epoch 040:    481 / 719 loss=4.859, nll_loss=2.316, symm_mse=8.613, ppl=4.98, wps=16393.1, ups=2, wpb=8193.6, bsz=282.5, num_updates=1200, lr=0.00015007, gnorm=1.114, train_wall=50, wall=0
2020-12-03 19:44:47 | INFO | train_inner | epoch 040:    581 / 719 loss=4.922, nll_loss=2.384, symm_mse=8.672, ppl=5.22, wps=16382.9, ups=2.01, wpb=8167.5, bsz=273.1, num_updates=1300, lr=0.000162568, gnorm=1.104, train_wall=50, wall=0
2020-12-03 19:45:37 | INFO | train_inner | epoch 040:    681 / 719 loss=4.888, nll_loss=2.383, symm_mse=8.38, ppl=5.22, wps=16436.3, ups=2.02, wpb=8127.1, bsz=287.2, num_updates=1400, lr=0.000175065, gnorm=1.095, train_wall=49, wall=0
2020-12-03 19:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 19:45:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:45:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:45:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:45:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:45:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:46:16 | INFO | valid | epoch 040 | valid on 'valid' subset | symm_mse 0 | loss 8.94 | nll_loss 7.991 | ppl 254.43 | bleu 11.46 | wps 3738 | wpb 4629 | bsz 118.9 | num_updates 1438 | best_bleu 11.7
2020-12-03 19:46:16 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 19:46:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:46:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:46:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:46:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:46:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 40 @ 1438 updates, score 11.46) (writing took 3.662670087069273 seconds)
2020-12-03 19:46:20 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-12-03 19:46:20 | INFO | train | epoch 040 | loss 4.915 | nll_loss 2.336 | symm_mse 8.965 | ppl 5.05 | wps 15233.7 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 1438 | lr 0.000179814 | gnorm 1.132 | train_wall 356 | wall 0
111
2020-12-03 19:46:20 | INFO | fairseq.trainer | begin training epoch 41
2020-12-03 19:46:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:46:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:46:53 | INFO | train_inner | epoch 041:     62 / 719 loss=4.825, nll_loss=2.328, symm_mse=8.227, ppl=5.02, wps=10833.4, ups=1.31, wpb=8292.3, bsz=281.2, num_updates=1500, lr=0.000187563, gnorm=1.072, train_wall=49, wall=0
2020-12-03 19:47:43 | INFO | train_inner | epoch 041:    162 / 719 loss=4.816, nll_loss=2.326, symm_mse=8.159, ppl=5.01, wps=16366.9, ups=2.02, wpb=8117.7, bsz=271.3, num_updates=1600, lr=0.00020006, gnorm=1.075, train_wall=49, wall=0
2020-12-03 19:48:33 | INFO | train_inner | epoch 041:    262 / 719 loss=4.805, nll_loss=2.35, symm_mse=7.876, ppl=5.1, wps=16186, ups=2, wpb=8098.7, bsz=281.1, num_updates=1700, lr=0.000212558, gnorm=1.059, train_wall=50, wall=0
2020-12-03 19:49:23 | INFO | train_inner | epoch 041:    362 / 719 loss=4.807, nll_loss=2.364, symm_mse=7.785, ppl=5.15, wps=16320.7, ups=1.99, wpb=8210, bsz=280.9, num_updates=1800, lr=0.000225055, gnorm=1.066, train_wall=50, wall=0
2020-12-03 19:50:13 | INFO | train_inner | epoch 041:    462 / 719 loss=4.74, nll_loss=2.339, symm_mse=7.376, ppl=5.06, wps=16482.1, ups=2.01, wpb=8191.2, bsz=320.4, num_updates=1900, lr=0.000237553, gnorm=1.034, train_wall=49, wall=0
2020-12-03 19:51:03 | INFO | train_inner | epoch 041:    562 / 719 loss=4.898, nll_loss=2.464, symm_mse=7.85, ppl=5.52, wps=16361.9, ups=2.01, wpb=8138.9, bsz=253.8, num_updates=2000, lr=0.00025005, gnorm=1.082, train_wall=50, wall=0
2020-12-03 19:51:52 | INFO | train_inner | epoch 041:    662 / 719 loss=4.854, nll_loss=2.458, symm_mse=7.517, ppl=5.49, wps=16457.5, ups=2.01, wpb=8170, bsz=284.1, num_updates=2100, lr=0.000262548, gnorm=1.035, train_wall=49, wall=0
2020-12-03 19:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 19:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:52:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:52:44 | INFO | valid | epoch 041 | valid on 'valid' subset | symm_mse 0 | loss 8.841 | nll_loss 7.892 | ppl 237.54 | bleu 11.85 | wps 3261.1 | wpb 4629 | bsz 118.9 | num_updates 2157 | best_bleu 11.85
2020-12-03 19:52:44 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 19:52:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:52:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:52:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 41 @ 2157 updates, score 11.85) (writing took 6.567803464829922 seconds)
2020-12-03 19:52:51 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2020-12-03 19:52:51 | INFO | train | epoch 041 | loss 4.829 | nll_loss 2.388 | symm_mse 7.811 | ppl 5.24 | wps 15010.3 | ups 1.84 | wpb 8159.9 | bsz 278.2 | num_updates 2157 | lr 0.000269671 | gnorm 1.061 | train_wall 356 | wall 0
111
2020-12-03 19:52:51 | INFO | fairseq.trainer | begin training epoch 42
2020-12-03 19:52:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:52:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:53:15 | INFO | train_inner | epoch 042:     43 / 719 loss=4.891, nll_loss=2.473, symm_mse=7.735, ppl=5.55, wps=9811.3, ups=1.22, wpb=8060, bsz=245.5, num_updates=2200, lr=0.000275045, gnorm=1.071, train_wall=49, wall=0
2020-12-03 19:54:05 | INFO | train_inner | epoch 042:    143 / 719 loss=4.816, nll_loss=2.405, symm_mse=7.561, ppl=5.3, wps=16523.5, ups=2, wpb=8269.3, bsz=256, num_updates=2300, lr=0.000287543, gnorm=1.003, train_wall=50, wall=0
2020-12-03 19:54:55 | INFO | train_inner | epoch 042:    243 / 719 loss=4.771, nll_loss=2.412, symm_mse=7.105, ppl=5.32, wps=16208.2, ups=1.99, wpb=8128, bsz=284.4, num_updates=2400, lr=0.00030004, gnorm=0.997, train_wall=50, wall=0
2020-12-03 19:55:45 | INFO | train_inner | epoch 042:    343 / 719 loss=4.793, nll_loss=2.437, symm_mse=7.113, ppl=5.41, wps=16049.5, ups=1.98, wpb=8090.5, bsz=278.2, num_updates=2500, lr=0.000312538, gnorm=0.998, train_wall=50, wall=0
2020-12-03 19:56:36 | INFO | train_inner | epoch 042:    443 / 719 loss=4.839, nll_loss=2.488, symm_mse=7.147, ppl=5.61, wps=16205.5, ups=1.99, wpb=8147.8, bsz=275.5, num_updates=2600, lr=0.000325035, gnorm=1.017, train_wall=50, wall=0
2020-12-03 19:57:26 | INFO | train_inner | epoch 042:    543 / 719 loss=4.813, nll_loss=2.5, symm_mse=6.823, ppl=5.66, wps=16245.8, ups=1.99, wpb=8166.3, bsz=285.6, num_updates=2700, lr=0.000337533, gnorm=1.015, train_wall=50, wall=0
2020-12-03 19:58:16 | INFO | train_inner | epoch 042:    643 / 719 loss=4.879, nll_loss=2.567, symm_mse=6.909, ppl=5.92, wps=16320.1, ups=1.99, wpb=8197.6, bsz=284.4, num_updates=2800, lr=0.00035003, gnorm=1.004, train_wall=50, wall=0
2020-12-03 19:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 19:58:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:58:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:58:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:58:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:58:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:58:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:59:16 | INFO | valid | epoch 042 | valid on 'valid' subset | symm_mse 0 | loss 8.837 | nll_loss 7.888 | ppl 236.81 | bleu 11.28 | wps 3460.4 | wpb 4629 | bsz 118.9 | num_updates 2876 | best_bleu 11.85
2020-12-03 19:59:16 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 19:59:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:59:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:59:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:59:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:59:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 42 @ 2876 updates, score 11.28) (writing took 4.047512233257294 seconds)
2020-12-03 19:59:20 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2020-12-03 19:59:20 | INFO | train | epoch 042 | loss 4.818 | nll_loss 2.471 | symm_mse 7.084 | ppl 5.54 | wps 15066.2 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 2876 | lr 0.000359528 | gnorm 1.008 | train_wall 358 | wall 0
111
2020-12-03 19:59:20 | INFO | fairseq.trainer | begin training epoch 43
2020-12-03 19:59:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 19:59:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 19:59:35 | INFO | train_inner | epoch 043:     24 / 719 loss=4.798, nll_loss=2.507, symm_mse=6.629, ppl=5.69, wps=10358.9, ups=1.26, wpb=8204.8, bsz=287.5, num_updates=2900, lr=0.000362528, gnorm=0.98, train_wall=49, wall=0
2020-12-03 20:00:25 | INFO | train_inner | epoch 043:    124 / 719 loss=4.769, nll_loss=2.437, symm_mse=6.908, ppl=5.41, wps=16583.8, ups=2.03, wpb=8185.5, bsz=276.2, num_updates=3000, lr=0.000375025, gnorm=1, train_wall=49, wall=0
2020-12-03 20:01:15 | INFO | train_inner | epoch 043:    224 / 719 loss=4.774, nll_loss=2.483, symm_mse=6.596, ppl=5.59, wps=16290, ups=2, wpb=8160.5, bsz=285.2, num_updates=3100, lr=0.000387523, gnorm=0.976, train_wall=50, wall=0
2020-12-03 20:02:05 | INFO | train_inner | epoch 043:    324 / 719 loss=4.843, nll_loss=2.538, symm_mse=6.801, ppl=5.81, wps=16379.9, ups=2, wpb=8207.5, bsz=276.1, num_updates=3200, lr=0.00040002, gnorm=0.994, train_wall=50, wall=0
2020-12-03 20:02:55 | INFO | train_inner | epoch 043:    424 / 719 loss=4.804, nll_loss=2.532, symm_mse=6.506, ppl=5.78, wps=16152.1, ups=1.99, wpb=8118.4, bsz=295.4, num_updates=3300, lr=0.000412518, gnorm=1.012, train_wall=50, wall=0
2020-12-03 20:03:45 | INFO | train_inner | epoch 043:    524 / 719 loss=4.846, nll_loss=2.591, symm_mse=6.43, ppl=6.02, wps=16261.9, ups=2, wpb=8112.7, bsz=289.4, num_updates=3400, lr=0.000425015, gnorm=0.996, train_wall=50, wall=0
2020-12-03 20:04:35 | INFO | train_inner | epoch 043:    624 / 719 loss=4.926, nll_loss=2.662, symm_mse=6.615, ppl=6.33, wps=16371.5, ups=2.01, wpb=8163.1, bsz=261.3, num_updates=3500, lr=0.000437513, gnorm=0.966, train_wall=50, wall=0
2020-12-03 20:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:05:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:44 | INFO | valid | epoch 043 | valid on 'valid' subset | symm_mse 0 | loss 8.793 | nll_loss 7.848 | ppl 230.39 | bleu 10.8 | wps 3477.9 | wpb 4629 | bsz 118.9 | num_updates 3595 | best_bleu 11.85
2020-12-03 20:05:44 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 43 @ 3595 updates, score 10.8) (writing took 3.895230596885085 seconds)
2020-12-03 20:05:48 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2020-12-03 20:05:48 | INFO | train | epoch 043 | loss 4.836 | nll_loss 2.555 | symm_mse 6.621 | ppl 5.88 | wps 15137.1 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 3595 | lr 0.000449385 | gnorm 0.99 | train_wall 357 | wall 0
111
2020-12-03 20:05:48 | INFO | fairseq.trainer | begin training epoch 44
2020-12-03 20:05:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:05:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:05:54 | INFO | train_inner | epoch 044:      5 / 719 loss=4.918, nll_loss=2.677, symm_mse=6.432, ppl=6.39, wps=10256.2, ups=1.27, wpb=8080.1, bsz=267, num_updates=3600, lr=0.00045001, gnorm=0.999, train_wall=49, wall=0
2020-12-03 20:06:42 | INFO | train_inner | epoch 044:    105 / 719 loss=4.754, nll_loss=2.496, symm_mse=6.33, ppl=5.64, wps=16643.6, ups=2.05, wpb=8111.1, bsz=298.6, num_updates=3700, lr=0.000462508, gnorm=0.953, train_wall=48, wall=0
2020-12-03 20:07:32 | INFO | train_inner | epoch 044:    205 / 719 loss=4.844, nll_loss=2.581, symm_mse=6.5, ppl=5.98, wps=16365.4, ups=2.02, wpb=8096.6, bsz=273, num_updates=3800, lr=0.000475005, gnorm=0.953, train_wall=49, wall=0
2020-12-03 20:08:22 | INFO | train_inner | epoch 044:    305 / 719 loss=4.913, nll_loss=2.664, symm_mse=6.479, ppl=6.34, wps=16366.9, ups=2, wpb=8183.6, bsz=265.1, num_updates=3900, lr=0.000487503, gnorm=0.963, train_wall=50, wall=0
2020-12-03 20:09:12 | INFO | train_inner | epoch 044:    405 / 719 loss=4.861, nll_loss=2.635, symm_mse=6.227, ppl=6.21, wps=16520.1, ups=2.01, wpb=8211.1, bsz=273.4, num_updates=4000, lr=0.0005, gnorm=0.922, train_wall=49, wall=0
2020-12-03 20:10:02 | INFO | train_inner | epoch 044:    505 / 719 loss=4.871, nll_loss=2.662, symm_mse=6.107, ppl=6.33, wps=16219.9, ups=2, wpb=8129.8, bsz=294.2, num_updates=4100, lr=0.000493865, gnorm=0.934, train_wall=50, wall=0
2020-12-03 20:10:51 | INFO | train_inner | epoch 044:    605 / 719 loss=4.886, nll_loss=2.675, symm_mse=6.163, ppl=6.39, wps=16516, ups=2.01, wpb=8222.9, bsz=264.6, num_updates=4200, lr=0.00048795, gnorm=0.919, train_wall=50, wall=0
2020-12-03 20:11:41 | INFO | train_inner | epoch 044:    705 / 719 loss=4.91, nll_loss=2.712, symm_mse=6.103, ppl=6.55, wps=16496.7, ups=2.01, wpb=8226.3, bsz=268.4, num_updates=4300, lr=0.000482243, gnorm=0.901, train_wall=50, wall=0
2020-12-03 20:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:11:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:11:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:11:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:12:11 | INFO | valid | epoch 044 | valid on 'valid' subset | symm_mse 0 | loss 8.811 | nll_loss 7.871 | ppl 234.09 | bleu 10.82 | wps 3419.2 | wpb 4629 | bsz 118.9 | num_updates 4314 | best_bleu 11.85
2020-12-03 20:12:11 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:12:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:12:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:12:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:12:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:12:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 44 @ 4314 updates, score 10.82) (writing took 4.108618447557092 seconds)
2020-12-03 20:12:15 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2020-12-03 20:12:15 | INFO | train | epoch 044 | loss 4.86 | nll_loss 2.631 | symm_mse 6.254 | ppl 6.2 | wps 15158.4 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 4314 | lr 0.00048146 | gnorm 0.935 | train_wall 355 | wall 0
111
2020-12-03 20:12:15 | INFO | fairseq.trainer | begin training epoch 45
2020-12-03 20:12:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:12:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:13:00 | INFO | train_inner | epoch 045:     86 / 719 loss=4.754, nll_loss=2.542, symm_mse=5.994, ppl=5.82, wps=10158.2, ups=1.27, wpb=8020.6, bsz=289.7, num_updates=4400, lr=0.000476731, gnorm=0.941, train_wall=48, wall=0
2020-12-03 20:13:50 | INFO | train_inner | epoch 045:    186 / 719 loss=4.819, nll_loss=2.599, symm_mse=6.134, ppl=6.06, wps=16366.9, ups=2, wpb=8177.7, bsz=274.6, num_updates=4500, lr=0.000471405, gnorm=0.926, train_wall=50, wall=0
2020-12-03 20:14:40 | INFO | train_inner | epoch 045:    286 / 719 loss=4.764, nll_loss=2.57, symm_mse=5.87, ppl=5.94, wps=16258.9, ups=1.99, wpb=8150.6, bsz=283.1, num_updates=4600, lr=0.000466252, gnorm=0.872, train_wall=50, wall=0
2020-12-03 20:15:30 | INFO | train_inner | epoch 045:    386 / 719 loss=4.786, nll_loss=2.591, symm_mse=5.92, ppl=6.02, wps=16610.2, ups=2.01, wpb=8256, bsz=289.1, num_updates=4700, lr=0.000461266, gnorm=0.894, train_wall=49, wall=0
2020-12-03 20:16:20 | INFO | train_inner | epoch 045:    486 / 719 loss=4.864, nll_loss=2.67, symm_mse=6.012, ppl=6.37, wps=16328, ups=1.99, wpb=8201.7, bsz=262.6, num_updates=4800, lr=0.000456435, gnorm=0.909, train_wall=50, wall=0
2020-12-03 20:17:10 | INFO | train_inner | epoch 045:    586 / 719 loss=4.837, nll_loss=2.654, symm_mse=5.895, ppl=6.3, wps=16431.6, ups=2.01, wpb=8186.8, bsz=274.5, num_updates=4900, lr=0.000451754, gnorm=0.875, train_wall=50, wall=0
2020-12-03 20:18:00 | INFO | train_inner | epoch 045:    686 / 719 loss=4.799, nll_loss=2.636, symm_mse=5.694, ppl=6.22, wps=16338.8, ups=2, wpb=8160.1, bsz=290.1, num_updates=5000, lr=0.000447214, gnorm=0.863, train_wall=50, wall=0
2020-12-03 20:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:18:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:18:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:18:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:18:39 | INFO | valid | epoch 045 | valid on 'valid' subset | symm_mse 0 | loss 8.772 | nll_loss 7.823 | ppl 226.45 | bleu 11.61 | wps 3387.6 | wpb 4629 | bsz 118.9 | num_updates 5033 | best_bleu 11.85
2020-12-03 20:18:39 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:18:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:18:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:18:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 45 @ 5033 updates, score 11.61) (writing took 3.887672133743763 seconds)
2020-12-03 20:18:43 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2020-12-03 20:18:43 | INFO | train | epoch 045 | loss 4.806 | nll_loss 2.612 | symm_mse 5.934 | ppl 6.12 | wps 15124.5 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 5033 | lr 0.000445745 | gnorm 0.894 | train_wall 356 | wall 0
111
2020-12-03 20:18:43 | INFO | fairseq.trainer | begin training epoch 46
2020-12-03 20:18:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:18:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:19:19 | INFO | train_inner | epoch 046:     67 / 719 loss=4.736, nll_loss=2.552, symm_mse=5.771, ppl=5.86, wps=10233.3, ups=1.27, wpb=8043.6, bsz=275, num_updates=5100, lr=0.000442807, gnorm=0.878, train_wall=48, wall=0
2020-12-03 20:20:09 | INFO | train_inner | epoch 046:    167 / 719 loss=4.708, nll_loss=2.511, symm_mse=5.835, ppl=5.7, wps=16496.3, ups=2, wpb=8258.4, bsz=288.6, num_updates=5200, lr=0.000438529, gnorm=0.874, train_wall=50, wall=0
2020-12-03 20:20:59 | INFO | train_inner | epoch 046:    267 / 719 loss=4.74, nll_loss=2.561, symm_mse=5.74, ppl=5.9, wps=16331.2, ups=2, wpb=8174.6, bsz=277.4, num_updates=5300, lr=0.000434372, gnorm=0.885, train_wall=50, wall=0
2020-12-03 20:21:49 | INFO | train_inner | epoch 046:    367 / 719 loss=4.738, nll_loss=2.549, symm_mse=5.823, ppl=5.85, wps=16456.4, ups=2, wpb=8247.7, bsz=258.6, num_updates=5400, lr=0.000430331, gnorm=0.839, train_wall=50, wall=0
2020-12-03 20:22:39 | INFO | train_inner | epoch 046:    467 / 719 loss=4.698, nll_loss=2.536, symm_mse=5.567, ppl=5.8, wps=16382.8, ups=2, wpb=8180.6, bsz=300, num_updates=5500, lr=0.000426401, gnorm=0.846, train_wall=50, wall=0
2020-12-03 20:23:29 | INFO | train_inner | epoch 046:    567 / 719 loss=4.784, nll_loss=2.608, symm_mse=5.781, ppl=6.1, wps=16297.9, ups=2, wpb=8147.7, bsz=271.1, num_updates=5600, lr=0.000422577, gnorm=0.863, train_wall=50, wall=0
2020-12-03 20:24:19 | INFO | train_inner | epoch 046:    667 / 719 loss=4.74, nll_loss=2.59, symm_mse=5.539, ppl=6.02, wps=16130, ups=2.01, wpb=8041.4, bsz=278.7, num_updates=5700, lr=0.000418854, gnorm=0.867, train_wall=50, wall=0
2020-12-03 20:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:24:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:24:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:24:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:24:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:25:07 | INFO | valid | epoch 046 | valid on 'valid' subset | symm_mse 0 | loss 8.695 | nll_loss 7.749 | ppl 215.13 | bleu 11.74 | wps 3365.8 | wpb 4629 | bsz 118.9 | num_updates 5752 | best_bleu 11.85
2020-12-03 20:25:07 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:25:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:25:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:25:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:25:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:25:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 46 @ 5752 updates, score 11.74) (writing took 3.747966067865491 seconds)
2020-12-03 20:25:11 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2020-12-03 20:25:11 | INFO | train | epoch 046 | loss 4.735 | nll_loss 2.559 | symm_mse 5.717 | ppl 5.89 | wps 15119.1 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 5752 | lr 0.000416956 | gnorm 0.866 | train_wall 357 | wall 0
111
2020-12-03 20:25:11 | INFO | fairseq.trainer | begin training epoch 47
2020-12-03 20:25:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:25:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:25:37 | INFO | train_inner | epoch 047:     48 / 719 loss=4.749, nll_loss=2.57, symm_mse=5.757, ppl=5.94, wps=10299.8, ups=1.27, wpb=8106.7, bsz=251.4, num_updates=5800, lr=0.000415227, gnorm=0.879, train_wall=49, wall=0
2020-12-03 20:26:27 | INFO | train_inner | epoch 047:    148 / 719 loss=4.618, nll_loss=2.434, symm_mse=5.629, ppl=5.4, wps=16494.1, ups=2.01, wpb=8214, bsz=289.8, num_updates=5900, lr=0.000411693, gnorm=0.835, train_wall=50, wall=0
2020-12-03 20:27:17 | INFO | train_inner | epoch 047:    248 / 719 loss=4.655, nll_loss=2.472, symm_mse=5.679, ppl=5.55, wps=16539.9, ups=2.02, wpb=8208.1, bsz=271, num_updates=6000, lr=0.000408248, gnorm=0.839, train_wall=49, wall=0
2020-12-03 20:28:07 | INFO | train_inner | epoch 047:    348 / 719 loss=4.695, nll_loss=2.529, symm_mse=5.596, ppl=5.77, wps=16224.3, ups=2.01, wpb=8064.4, bsz=269, num_updates=6100, lr=0.000404888, gnorm=0.875, train_wall=49, wall=0
2020-12-03 20:28:57 | INFO | train_inner | epoch 047:    448 / 719 loss=4.644, nll_loss=2.488, symm_mse=5.459, ppl=5.61, wps=16524.2, ups=2, wpb=8266.1, bsz=283.9, num_updates=6200, lr=0.00040161, gnorm=0.822, train_wall=50, wall=0
2020-12-03 20:29:47 | INFO | train_inner | epoch 047:    548 / 719 loss=4.674, nll_loss=2.518, symm_mse=5.503, ppl=5.73, wps=16188.5, ups=2, wpb=8101, bsz=282.2, num_updates=6300, lr=0.00039841, gnorm=0.857, train_wall=50, wall=0
2020-12-03 20:30:36 | INFO | train_inner | epoch 047:    648 / 719 loss=4.709, nll_loss=2.569, symm_mse=5.419, ppl=5.93, wps=16355.6, ups=2.01, wpb=8154.1, bsz=295.2, num_updates=6400, lr=0.000395285, gnorm=0.852, train_wall=50, wall=0
2020-12-03 20:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:31:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:33 | INFO | valid | epoch 047 | valid on 'valid' subset | symm_mse 0 | loss 8.662 | nll_loss 7.708 | ppl 209.06 | bleu 11.89 | wps 3492 | wpb 4629 | bsz 118.9 | num_updates 6471 | best_bleu 11.89
2020-12-03 20:31:33 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:31:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 47 @ 6471 updates, score 11.89) (writing took 6.331746796146035 seconds)
2020-12-03 20:31:40 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2020-12-03 20:31:40 | INFO | train | epoch 047 | loss 4.668 | nll_loss 2.503 | symm_mse 5.553 | ppl 5.67 | wps 15076.2 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 6471 | lr 0.00039311 | gnorm 0.845 | train_wall 356 | wall 0
111
2020-12-03 20:31:40 | INFO | fairseq.trainer | begin training epoch 48
2020-12-03 20:31:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:31:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:31:57 | INFO | train_inner | epoch 048:     29 / 719 loss=4.633, nll_loss=2.481, symm_mse=5.43, ppl=5.58, wps=10038.4, ups=1.24, wpb=8117.8, bsz=279.5, num_updates=6500, lr=0.000392232, gnorm=0.803, train_wall=49, wall=0
2020-12-03 20:32:46 | INFO | train_inner | epoch 048:    129 / 719 loss=4.538, nll_loss=2.375, symm_mse=5.369, ppl=5.19, wps=16677.5, ups=2.04, wpb=8166.2, bsz=291.9, num_updates=6600, lr=0.000389249, gnorm=0.843, train_wall=49, wall=0
2020-12-03 20:33:36 | INFO | train_inner | epoch 048:    229 / 719 loss=4.635, nll_loss=2.453, symm_mse=5.651, ppl=5.48, wps=16258.4, ups=2, wpb=8119.6, bsz=263, num_updates=6700, lr=0.000386334, gnorm=0.835, train_wall=50, wall=0
2020-12-03 20:34:26 | INFO | train_inner | epoch 048:    329 / 719 loss=4.636, nll_loss=2.467, symm_mse=5.552, ppl=5.53, wps=16488.6, ups=2.01, wpb=8190.2, bsz=274.3, num_updates=6800, lr=0.000383482, gnorm=0.844, train_wall=49, wall=0
2020-12-03 20:35:16 | INFO | train_inner | epoch 048:    429 / 719 loss=4.65, nll_loss=2.486, symm_mse=5.537, ppl=5.6, wps=16549.6, ups=2.01, wpb=8222.6, bsz=256.1, num_updates=6900, lr=0.000380693, gnorm=0.809, train_wall=49, wall=0
2020-12-03 20:36:05 | INFO | train_inner | epoch 048:    529 / 719 loss=4.599, nll_loss=2.456, symm_mse=5.325, ppl=5.49, wps=16387.6, ups=2.01, wpb=8136.7, bsz=292.4, num_updates=7000, lr=0.000377964, gnorm=0.826, train_wall=49, wall=0
2020-12-03 20:36:55 | INFO | train_inner | epoch 048:    629 / 719 loss=4.645, nll_loss=2.5, symm_mse=5.388, ppl=5.66, wps=16292.3, ups=1.99, wpb=8167.7, bsz=273.5, num_updates=7100, lr=0.000375293, gnorm=0.815, train_wall=50, wall=0
2020-12-03 20:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:37:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:37:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:37:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:37:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:37:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:37:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:38:03 | INFO | valid | epoch 048 | valid on 'valid' subset | symm_mse 0 | loss 8.597 | nll_loss 7.633 | ppl 198.53 | bleu 12.32 | wps 3216.7 | wpb 4629 | bsz 118.9 | num_updates 7190 | best_bleu 12.32
2020-12-03 20:38:03 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:38:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:38:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:38:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:38:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:38:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 48 @ 7190 updates, score 12.32) (writing took 6.572266299277544 seconds)
2020-12-03 20:38:10 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2020-12-03 20:38:10 | INFO | train | epoch 048 | loss 4.614 | nll_loss 2.456 | symm_mse 5.442 | ppl 5.49 | wps 15042.2 | ups 1.84 | wpb 8159.9 | bsz 278.2 | num_updates 7190 | lr 0.000372937 | gnorm 0.829 | train_wall 355 | wall 0
111
2020-12-03 20:38:10 | INFO | fairseq.trainer | begin training epoch 49
2020-12-03 20:38:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:38:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:38:18 | INFO | train_inner | epoch 049:     10 / 719 loss=4.609, nll_loss=2.473, symm_mse=5.274, ppl=5.55, wps=9824.8, ups=1.21, wpb=8121.2, bsz=288.3, num_updates=7200, lr=0.000372678, gnorm=0.835, train_wall=49, wall=0
2020-12-03 20:39:07 | INFO | train_inner | epoch 049:    110 / 719 loss=4.5, nll_loss=2.331, symm_mse=5.379, ppl=5.03, wps=16706.8, ups=2.03, wpb=8216.5, bsz=282.3, num_updates=7300, lr=0.000370117, gnorm=0.816, train_wall=49, wall=0
2020-12-03 20:39:57 | INFO | train_inner | epoch 049:    210 / 719 loss=4.537, nll_loss=2.375, symm_mse=5.379, ppl=5.19, wps=16481.5, ups=2.02, wpb=8166.5, bsz=282.5, num_updates=7400, lr=0.000367607, gnorm=0.828, train_wall=49, wall=0
2020-12-03 20:40:46 | INFO | train_inner | epoch 049:    310 / 719 loss=4.567, nll_loss=2.409, symm_mse=5.395, ppl=5.31, wps=16374.8, ups=2.01, wpb=8131.9, bsz=283.5, num_updates=7500, lr=0.000365148, gnorm=0.807, train_wall=49, wall=0
2020-12-03 20:41:37 | INFO | train_inner | epoch 049:    410 / 719 loss=4.574, nll_loss=2.415, symm_mse=5.405, ppl=5.33, wps=16291.9, ups=1.99, wpb=8168.9, bsz=267.7, num_updates=7600, lr=0.000362738, gnorm=0.806, train_wall=50, wall=0
2020-12-03 20:42:27 | INFO | train_inner | epoch 049:    510 / 719 loss=4.57, nll_loss=2.434, symm_mse=5.231, ppl=5.4, wps=16195.2, ups=2, wpb=8098.8, bsz=280.6, num_updates=7700, lr=0.000360375, gnorm=0.801, train_wall=50, wall=0
2020-12-03 20:43:16 | INFO | train_inner | epoch 049:    610 / 719 loss=4.577, nll_loss=2.434, symm_mse=5.301, ppl=5.4, wps=16417.5, ups=2.01, wpb=8186.6, bsz=283.3, num_updates=7800, lr=0.000358057, gnorm=0.805, train_wall=50, wall=0
2020-12-03 20:44:06 | INFO | train_inner | epoch 049:    710 / 719 loss=4.615, nll_loss=2.471, symm_mse=5.367, ppl=5.54, wps=16501.5, ups=2.01, wpb=8214.8, bsz=267.4, num_updates=7900, lr=0.000355784, gnorm=0.816, train_wall=50, wall=0
2020-12-03 20:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:44:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:44:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:44:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:44:32 | INFO | valid | epoch 049 | valid on 'valid' subset | symm_mse 0 | loss 8.659 | nll_loss 7.698 | ppl 207.61 | bleu 11.96 | wps 3610.1 | wpb 4629 | bsz 118.9 | num_updates 7909 | best_bleu 12.32
2020-12-03 20:44:32 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:44:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:44:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:44:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 49 @ 7909 updates, score 11.96) (writing took 3.8828956987708807 seconds)
2020-12-03 20:44:35 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2020-12-03 20:44:35 | INFO | train | epoch 049 | loss 4.563 | nll_loss 2.41 | symm_mse 5.352 | ppl 5.31 | wps 15211.5 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 7909 | lr 0.000355582 | gnorm 0.812 | train_wall 356 | wall 0
111
2020-12-03 20:44:35 | INFO | fairseq.trainer | begin training epoch 50
2020-12-03 20:44:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:44:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:45:23 | INFO | train_inner | epoch 050:     91 / 719 loss=4.49, nll_loss=2.327, symm_mse=5.333, ppl=5.02, wps=10560, ups=1.3, wpb=8113.2, bsz=273.3, num_updates=8000, lr=0.000353553, gnorm=0.819, train_wall=48, wall=0
2020-12-03 20:46:13 | INFO | train_inner | epoch 050:    191 / 719 loss=4.493, nll_loss=2.333, symm_mse=5.311, ppl=5.04, wps=16364.9, ups=2.01, wpb=8146, bsz=281.1, num_updates=8100, lr=0.000351364, gnorm=0.824, train_wall=50, wall=0
2020-12-03 20:47:02 | INFO | train_inner | epoch 050:    291 / 719 loss=4.534, nll_loss=2.373, symm_mse=5.387, ppl=5.18, wps=16558.3, ups=2.02, wpb=8202.2, bsz=256.2, num_updates=8200, lr=0.000349215, gnorm=0.801, train_wall=49, wall=0
2020-12-03 20:47:52 | INFO | train_inner | epoch 050:    391 / 719 loss=4.507, nll_loss=2.364, symm_mse=5.201, ppl=5.15, wps=16232, ups=2.01, wpb=8065.8, bsz=285.7, num_updates=8300, lr=0.000347105, gnorm=0.801, train_wall=49, wall=0
2020-12-03 20:48:42 | INFO | train_inner | epoch 050:    491 / 719 loss=4.53, nll_loss=2.386, symm_mse=5.248, ppl=5.23, wps=16640, ups=2.01, wpb=8275.8, bsz=275.9, num_updates=8400, lr=0.000345033, gnorm=0.798, train_wall=49, wall=0
2020-12-03 20:49:32 | INFO | train_inner | epoch 050:    591 / 719 loss=4.534, nll_loss=2.398, symm_mse=5.197, ppl=5.27, wps=16424.1, ups=2.01, wpb=8174.7, bsz=289.4, num_updates=8500, lr=0.000342997, gnorm=0.812, train_wall=50, wall=0
2020-12-03 20:50:21 | INFO | train_inner | epoch 050:    691 / 719 loss=4.567, nll_loss=2.424, symm_mse=5.299, ppl=5.37, wps=16329, ups=2.01, wpb=8132.3, bsz=278.6, num_updates=8600, lr=0.000340997, gnorm=0.827, train_wall=50, wall=0
2020-12-03 20:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:50:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:50:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:50:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:50:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:50:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:50:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:50:57 | INFO | valid | epoch 050 | valid on 'valid' subset | symm_mse 0 | loss 8.646 | nll_loss 7.687 | ppl 206.03 | bleu 12.12 | wps 3543.9 | wpb 4629 | bsz 118.9 | num_updates 8628 | best_bleu 12.32
2020-12-03 20:50:57 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:50:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:50:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:51:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:51:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:51:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 50 @ 8628 updates, score 12.12) (writing took 3.9405728839337826 seconds)
2020-12-03 20:51:01 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2020-12-03 20:51:01 | INFO | train | epoch 050 | loss 4.521 | nll_loss 2.371 | symm_mse 5.275 | ppl 5.17 | wps 15225.9 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 8628 | lr 0.000340443 | gnorm 0.811 | train_wall 355 | wall 0
111
2020-12-03 20:51:01 | INFO | fairseq.trainer | begin training epoch 51
2020-12-03 20:51:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:51:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:51:39 | INFO | train_inner | epoch 051:     72 / 719 loss=4.508, nll_loss=2.339, symm_mse=5.402, ppl=5.06, wps=10427.2, ups=1.29, wpb=8104.6, bsz=266.6, num_updates=8700, lr=0.000339032, gnorm=0.808, train_wall=48, wall=0
2020-12-03 20:52:29 | INFO | train_inner | epoch 051:    172 / 719 loss=4.429, nll_loss=2.278, symm_mse=5.168, ppl=4.85, wps=16294.6, ups=2.01, wpb=8106.2, bsz=287.8, num_updates=8800, lr=0.0003371, gnorm=0.803, train_wall=50, wall=0
2020-12-03 20:53:19 | INFO | train_inner | epoch 051:    272 / 719 loss=4.465, nll_loss=2.32, symm_mse=5.17, ppl=4.99, wps=16308.8, ups=2.01, wpb=8132.6, bsz=288.4, num_updates=8900, lr=0.000335201, gnorm=0.802, train_wall=50, wall=0
2020-12-03 20:54:08 | INFO | train_inner | epoch 051:    372 / 719 loss=4.483, nll_loss=2.331, symm_mse=5.242, ppl=5.03, wps=16508.3, ups=2.02, wpb=8171.6, bsz=272.2, num_updates=9000, lr=0.000333333, gnorm=0.812, train_wall=49, wall=0
2020-12-03 20:54:58 | INFO | train_inner | epoch 051:    472 / 719 loss=4.431, nll_loss=2.29, symm_mse=5.114, ppl=4.89, wps=16726.2, ups=2.02, wpb=8262.3, bsz=288.9, num_updates=9100, lr=0.000331497, gnorm=0.797, train_wall=49, wall=0
2020-12-03 20:55:47 | INFO | train_inner | epoch 051:    572 / 719 loss=4.525, nll_loss=2.382, symm_mse=5.241, ppl=5.21, wps=16390.5, ups=2.01, wpb=8152.8, bsz=270.4, num_updates=9200, lr=0.00032969, gnorm=0.808, train_wall=50, wall=0
2020-12-03 20:56:37 | INFO | train_inner | epoch 051:    672 / 719 loss=4.492, nll_loss=2.365, symm_mse=5.079, ppl=5.15, wps=16329.3, ups=2, wpb=8167.5, bsz=284.9, num_updates=9300, lr=0.000327913, gnorm=0.774, train_wall=50, wall=0
2020-12-03 20:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 20:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:23 | INFO | valid | epoch 051 | valid on 'valid' subset | symm_mse 0 | loss 8.663 | nll_loss 7.699 | ppl 207.79 | bleu 11.92 | wps 3480.4 | wpb 4629 | bsz 118.9 | num_updates 9347 | best_bleu 12.32
2020-12-03 20:57:23 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 20:57:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 51 @ 9347 updates, score 11.92) (writing took 3.415910229086876 seconds)
2020-12-03 20:57:26 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2020-12-03 20:57:26 | INFO | train | epoch 051 | loss 4.48 | nll_loss 2.333 | symm_mse 5.213 | ppl 5.04 | wps 15233.4 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 9347 | lr 0.000327087 | gnorm 0.803 | train_wall 355 | wall 0
111
2020-12-03 20:57:26 | INFO | fairseq.trainer | begin training epoch 52
2020-12-03 20:57:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 20:57:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 20:57:55 | INFO | train_inner | epoch 052:     53 / 719 loss=4.475, nll_loss=2.327, symm_mse=5.218, ppl=5.02, wps=10472.8, ups=1.29, wpb=8142.1, bsz=275.6, num_updates=9400, lr=0.000326164, gnorm=0.818, train_wall=49, wall=0
2020-12-03 20:58:45 | INFO | train_inner | epoch 052:    153 / 719 loss=4.383, nll_loss=2.232, symm_mse=5.116, ppl=4.7, wps=16645.4, ups=2.02, wpb=8259.2, bsz=276.6, num_updates=9500, lr=0.000324443, gnorm=0.787, train_wall=49, wall=0
2020-12-03 20:59:34 | INFO | train_inner | epoch 052:    253 / 719 loss=4.459, nll_loss=2.3, symm_mse=5.278, ppl=4.92, wps=16343.4, ups=2.02, wpb=8101.3, bsz=272.5, num_updates=9600, lr=0.000322749, gnorm=0.819, train_wall=49, wall=0
2020-12-03 21:00:24 | INFO | train_inner | epoch 052:    353 / 719 loss=4.446, nll_loss=2.284, symm_mse=5.289, ppl=4.87, wps=16439.9, ups=1.99, wpb=8241, bsz=273, num_updates=9700, lr=0.000321081, gnorm=0.801, train_wall=50, wall=0
2020-12-03 21:01:14 | INFO | train_inner | epoch 052:    453 / 719 loss=4.52, nll_loss=2.362, symm_mse=5.357, ppl=5.14, wps=16268.9, ups=2.02, wpb=8036.3, bsz=255.5, num_updates=9800, lr=0.000319438, gnorm=0.817, train_wall=49, wall=0
2020-12-03 21:02:04 | INFO | train_inner | epoch 052:    553 / 719 loss=4.46, nll_loss=2.325, symm_mse=5.109, ppl=5.01, wps=16367, ups=2.01, wpb=8153.2, bsz=279.5, num_updates=9900, lr=0.000317821, gnorm=0.806, train_wall=50, wall=0
2020-12-03 21:02:53 | INFO | train_inner | epoch 052:    653 / 719 loss=4.499, nll_loss=2.358, symm_mse=5.208, ppl=5.13, wps=16304.6, ups=2.02, wpb=8080.9, bsz=280, num_updates=10000, lr=0.000316228, gnorm=0.803, train_wall=49, wall=0
2020-12-03 21:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:03:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:03:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:03:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:03:47 | INFO | valid | epoch 052 | valid on 'valid' subset | symm_mse 0 | loss 8.705 | nll_loss 7.747 | ppl 214.89 | bleu 12.43 | wps 3716.7 | wpb 4629 | bsz 118.9 | num_updates 10066 | best_bleu 12.43
2020-12-03 21:03:47 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:03:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:03:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:03:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 52 @ 10066 updates, score 12.43) (writing took 6.056556599214673 seconds)
2020-12-03 21:03:53 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2020-12-03 21:03:53 | INFO | train | epoch 052 | loss 4.445 | nll_loss 2.3 | symm_mse 5.161 | ppl 4.92 | wps 15158.8 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 10066 | lr 0.000315189 | gnorm 0.801 | train_wall 355 | wall 0
111
2020-12-03 21:03:53 | INFO | fairseq.trainer | begin training epoch 53
2020-12-03 21:03:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:03:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:04:13 | INFO | train_inner | epoch 053:     34 / 719 loss=4.342, nll_loss=2.225, symm_mse=4.814, ppl=4.67, wps=10372.8, ups=1.26, wpb=8260.4, bsz=302.2, num_updates=10100, lr=0.000314658, gnorm=0.767, train_wall=49, wall=0
2020-12-03 21:05:02 | INFO | train_inner | epoch 053:    134 / 719 loss=4.354, nll_loss=2.205, symm_mse=5.078, ppl=4.61, wps=16659, ups=2.02, wpb=8243, bsz=296, num_updates=10200, lr=0.000313112, gnorm=0.787, train_wall=49, wall=0
2020-12-03 21:05:52 | INFO | train_inner | epoch 053:    234 / 719 loss=4.419, nll_loss=2.264, symm_mse=5.2, ppl=4.8, wps=16347.2, ups=2.01, wpb=8133.7, bsz=268.6, num_updates=10300, lr=0.000311588, gnorm=0.803, train_wall=50, wall=0
2020-12-03 21:06:42 | INFO | train_inner | epoch 053:    334 / 719 loss=4.412, nll_loss=2.261, symm_mse=5.168, ppl=4.79, wps=16426, ups=2.01, wpb=8160, bsz=268.9, num_updates=10400, lr=0.000310087, gnorm=0.793, train_wall=49, wall=0
2020-12-03 21:07:32 | INFO | train_inner | epoch 053:    434 / 719 loss=4.429, nll_loss=2.28, symm_mse=5.177, ppl=4.86, wps=16286.6, ups=2.01, wpb=8117.3, bsz=273.8, num_updates=10500, lr=0.000308607, gnorm=0.801, train_wall=50, wall=0
2020-12-03 21:08:21 | INFO | train_inner | epoch 053:    534 / 719 loss=4.409, nll_loss=2.281, symm_mse=4.993, ppl=4.86, wps=16483.1, ups=2.01, wpb=8194.4, bsz=287.5, num_updates=10600, lr=0.000307148, gnorm=0.793, train_wall=49, wall=0
2020-12-03 21:09:11 | INFO | train_inner | epoch 053:    634 / 719 loss=4.421, nll_loss=2.288, symm_mse=5.043, ppl=4.89, wps=16363.4, ups=2.02, wpb=8114.6, bsz=281.4, num_updates=10700, lr=0.000305709, gnorm=0.779, train_wall=49, wall=0
2020-12-03 21:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:09:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:09:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:09:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:09:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:09:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:09:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:10:14 | INFO | valid | epoch 053 | valid on 'valid' subset | symm_mse 0 | loss 8.6 | nll_loss 7.638 | ppl 199.17 | bleu 12.65 | wps 3581.5 | wpb 4629 | bsz 118.9 | num_updates 10785 | best_bleu 12.65
2020-12-03 21:10:14 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:10:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:10:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:10:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:10:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:10:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 53 @ 10785 updates, score 12.65) (writing took 6.302530428394675 seconds)
2020-12-03 21:10:21 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2020-12-03 21:10:21 | INFO | train | epoch 053 | loss 4.413 | nll_loss 2.267 | symm_mse 5.127 | ppl 4.81 | wps 15135.5 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 10785 | lr 0.000304502 | gnorm 0.792 | train_wall 355 | wall 0
111
2020-12-03 21:10:21 | INFO | fairseq.trainer | begin training epoch 54
2020-12-03 21:10:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:10:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:10:31 | INFO | train_inner | epoch 054:     15 / 719 loss=4.472, nll_loss=2.325, symm_mse=5.225, ppl=5.01, wps=10142.7, ups=1.24, wpb=8152.5, bsz=269.9, num_updates=10800, lr=0.00030429, gnorm=0.803, train_wall=49, wall=0
2020-12-03 21:11:20 | INFO | train_inner | epoch 054:    115 / 719 loss=4.363, nll_loss=2.204, symm_mse=5.165, ppl=4.61, wps=16761.5, ups=2.04, wpb=8224, bsz=264.9, num_updates=10900, lr=0.000302891, gnorm=0.777, train_wall=49, wall=0
2020-12-03 21:12:10 | INFO | train_inner | epoch 054:    215 / 719 loss=4.38, nll_loss=2.219, symm_mse=5.205, ppl=4.66, wps=16194, ups=2, wpb=8089.4, bsz=270.7, num_updates=11000, lr=0.000301511, gnorm=0.809, train_wall=50, wall=0
2020-12-03 21:13:00 | INFO | train_inner | epoch 054:    315 / 719 loss=4.315, nll_loss=2.186, symm_mse=4.878, ppl=4.55, wps=16526.9, ups=2.01, wpb=8231.8, bsz=288.7, num_updates=11100, lr=0.00030015, gnorm=0.776, train_wall=50, wall=0
2020-12-03 21:13:50 | INFO | train_inner | epoch 054:    415 / 719 loss=4.39, nll_loss=2.251, symm_mse=5.047, ppl=4.76, wps=16214.1, ups=2.01, wpb=8052.1, bsz=286.2, num_updates=11200, lr=0.000298807, gnorm=0.792, train_wall=49, wall=0
2020-12-03 21:14:39 | INFO | train_inner | epoch 054:    515 / 719 loss=4.369, nll_loss=2.238, symm_mse=4.968, ppl=4.72, wps=16674.7, ups=2.04, wpb=8192.5, bsz=297.9, num_updates=11300, lr=0.000297482, gnorm=0.782, train_wall=49, wall=0
2020-12-03 21:15:28 | INFO | train_inner | epoch 054:    615 / 719 loss=4.457, nll_loss=2.299, symm_mse=5.3, ppl=4.92, wps=16550.4, ups=2.03, wpb=8166.8, bsz=269.5, num_updates=11400, lr=0.000296174, gnorm=0.793, train_wall=49, wall=0
2020-12-03 21:16:18 | INFO | train_inner | epoch 054:    715 / 719 loss=4.388, nll_loss=2.262, symm_mse=4.972, ppl=4.8, wps=16427.1, ups=2.01, wpb=8190.5, bsz=279.8, num_updates=11500, lr=0.000294884, gnorm=0.769, train_wall=50, wall=0
2020-12-03 21:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:16:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:16:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:16:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:16:41 | INFO | valid | epoch 054 | valid on 'valid' subset | symm_mse 0 | loss 8.565 | nll_loss 7.595 | ppl 193.33 | bleu 12.85 | wps 3574.9 | wpb 4629 | bsz 118.9 | num_updates 11504 | best_bleu 12.85
2020-12-03 21:16:41 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:16:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:16:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:16:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 54 @ 11504 updates, score 12.85) (writing took 6.431938236579299 seconds)
2020-12-03 21:16:48 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2020-12-03 21:16:48 | INFO | train | epoch 054 | loss 4.382 | nll_loss 2.237 | symm_mse 5.088 | ppl 4.72 | wps 15154.7 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 11504 | lr 0.000294833 | gnorm 0.787 | train_wall 354 | wall 0
111
2020-12-03 21:16:48 | INFO | fairseq.trainer | begin training epoch 55
2020-12-03 21:16:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:16:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:17:38 | INFO | train_inner | epoch 055:     96 / 719 loss=4.307, nll_loss=2.15, symm_mse=5.079, ppl=4.44, wps=10282.6, ups=1.25, wpb=8214.6, bsz=264.2, num_updates=11600, lr=0.00029361, gnorm=0.804, train_wall=49, wall=0
2020-12-03 21:18:28 | INFO | train_inner | epoch 055:    196 / 719 loss=4.321, nll_loss=2.171, symm_mse=5.058, ppl=4.5, wps=16264.9, ups=2, wpb=8131.3, bsz=284.3, num_updates=11700, lr=0.000292353, gnorm=0.785, train_wall=50, wall=0
2020-12-03 21:19:18 | INFO | train_inner | epoch 055:    296 / 719 loss=4.309, nll_loss=2.166, symm_mse=4.982, ppl=4.49, wps=16485.4, ups=2, wpb=8262.9, bsz=288.2, num_updates=11800, lr=0.000291111, gnorm=0.782, train_wall=50, wall=0
2020-12-03 21:20:08 | INFO | train_inner | epoch 055:    396 / 719 loss=4.349, nll_loss=2.203, symm_mse=5.058, ppl=4.6, wps=16422.5, ups=2.01, wpb=8165.2, bsz=281.5, num_updates=11900, lr=0.000289886, gnorm=0.893, train_wall=49, wall=0
2020-12-03 21:20:58 | INFO | train_inner | epoch 055:    496 / 719 loss=4.415, nll_loss=2.261, symm_mse=5.212, ppl=4.79, wps=16283.1, ups=2, wpb=8125.6, bsz=273, num_updates=12000, lr=0.000288675, gnorm=0.805, train_wall=50, wall=0
2020-12-03 21:21:47 | INFO | train_inner | epoch 055:    596 / 719 loss=4.403, nll_loss=2.265, symm_mse=5.079, ppl=4.81, wps=16394.5, ups=2.02, wpb=8123.7, bsz=272.6, num_updates=12100, lr=0.00028748, gnorm=0.802, train_wall=49, wall=0
2020-12-03 21:22:37 | INFO | train_inner | epoch 055:    696 / 719 loss=4.373, nll_loss=2.248, symm_mse=4.941, ppl=4.75, wps=16326.6, ups=2.02, wpb=8082.7, bsz=282.8, num_updates=12200, lr=0.000286299, gnorm=0.779, train_wall=49, wall=0
2020-12-03 21:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:22:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:22:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:22:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:22:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:22:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:22:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:23:10 | INFO | valid | epoch 055 | valid on 'valid' subset | symm_mse 0 | loss 8.584 | nll_loss 7.616 | ppl 196.17 | bleu 12.53 | wps 3400.7 | wpb 4629 | bsz 118.9 | num_updates 12223 | best_bleu 12.85
2020-12-03 21:23:10 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:23:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:23:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:23:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 55 @ 12223 updates, score 12.53) (writing took 3.9025649446994066 seconds)
2020-12-03 21:23:14 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2020-12-03 21:23:14 | INFO | train | epoch 055 | loss 4.356 | nll_loss 2.211 | symm_mse 5.059 | ppl 4.63 | wps 15179 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 12223 | lr 0.00028603 | gnorm 0.806 | train_wall 355 | wall 0
111
2020-12-03 21:23:14 | INFO | fairseq.trainer | begin training epoch 56
2020-12-03 21:23:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:23:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:23:55 | INFO | train_inner | epoch 056:     77 / 719 loss=4.311, nll_loss=2.162, symm_mse=5.035, ppl=4.47, wps=10347.5, ups=1.27, wpb=8122.3, bsz=276.9, num_updates=12300, lr=0.000285133, gnorm=0.781, train_wall=49, wall=0
2020-12-03 21:24:45 | INFO | train_inner | epoch 056:    177 / 719 loss=4.314, nll_loss=2.166, symm_mse=5.024, ppl=4.49, wps=16241.7, ups=2.01, wpb=8075.2, bsz=274.5, num_updates=12400, lr=0.000283981, gnorm=0.805, train_wall=49, wall=0
2020-12-03 21:25:35 | INFO | train_inner | epoch 056:    277 / 719 loss=4.326, nll_loss=2.171, symm_mse=5.099, ppl=4.5, wps=16510.8, ups=2.02, wpb=8191, bsz=263.2, num_updates=12500, lr=0.000282843, gnorm=0.771, train_wall=49, wall=0
2020-12-03 21:26:24 | INFO | train_inner | epoch 056:    377 / 719 loss=4.319, nll_loss=2.175, symm_mse=5.022, ppl=4.51, wps=16356.3, ups=2.01, wpb=8134.4, bsz=287.2, num_updates=12600, lr=0.000281718, gnorm=0.789, train_wall=49, wall=0
2020-12-03 21:27:15 | INFO | train_inner | epoch 056:    477 / 719 loss=4.322, nll_loss=2.187, symm_mse=4.949, ppl=4.55, wps=16423.1, ups=1.98, wpb=8275.6, bsz=291.6, num_updates=12700, lr=0.000280607, gnorm=0.807, train_wall=50, wall=0
2020-12-03 21:28:05 | INFO | train_inner | epoch 056:    577 / 719 loss=4.32, nll_loss=2.188, symm_mse=4.935, ppl=4.56, wps=16332.1, ups=1.99, wpb=8202.8, bsz=298.6, num_updates=12800, lr=0.000279508, gnorm=0.789, train_wall=50, wall=0
2020-12-03 21:28:55 | INFO | train_inner | epoch 056:    677 / 719 loss=4.418, nll_loss=2.264, symm_mse=5.223, ppl=4.8, wps=16357.8, ups=2.02, wpb=8109.4, bsz=250.8, num_updates=12900, lr=0.000278423, gnorm=0.803, train_wall=49, wall=0
2020-12-03 21:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:29:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:29:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:29:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:29:37 | INFO | valid | epoch 056 | valid on 'valid' subset | symm_mse 0 | loss 8.597 | nll_loss 7.625 | ppl 197.43 | bleu 12.91 | wps 3609.2 | wpb 4629 | bsz 118.9 | num_updates 12942 | best_bleu 12.91
2020-12-03 21:29:37 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:29:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:29:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:29:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 56 @ 12942 updates, score 12.91) (writing took 6.479707267135382 seconds)
2020-12-03 21:29:43 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2020-12-03 21:29:43 | INFO | train | epoch 056 | loss 4.329 | nll_loss 2.186 | symm_mse 5.024 | ppl 4.55 | wps 15092.9 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 12942 | lr 0.000277971 | gnorm 0.79 | train_wall 356 | wall 0
111
2020-12-03 21:29:43 | INFO | fairseq.trainer | begin training epoch 57
2020-12-03 21:29:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:29:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:30:15 | INFO | train_inner | epoch 057:     58 / 719 loss=4.28, nll_loss=2.146, symm_mse=4.881, ppl=4.43, wps=10081.8, ups=1.25, wpb=8080, bsz=286.6, num_updates=13000, lr=0.00027735, gnorm=0.774, train_wall=49, wall=0
2020-12-03 21:31:04 | INFO | train_inner | epoch 057:    158 / 719 loss=4.298, nll_loss=2.142, symm_mse=5.077, ppl=4.41, wps=16477.2, ups=2.02, wpb=8167.6, bsz=272.1, num_updates=13100, lr=0.000276289, gnorm=0.78, train_wall=49, wall=0
2020-12-03 21:31:54 | INFO | train_inner | epoch 057:    258 / 719 loss=4.27, nll_loss=2.123, symm_mse=4.987, ppl=4.35, wps=16483.9, ups=2.03, wpb=8130, bsz=278.5, num_updates=13200, lr=0.000275241, gnorm=0.777, train_wall=49, wall=0
2020-12-03 21:32:44 | INFO | train_inner | epoch 057:    358 / 719 loss=4.284, nll_loss=2.142, symm_mse=4.957, ppl=4.41, wps=16481.8, ups=2, wpb=8230, bsz=275.5, num_updates=13300, lr=0.000274204, gnorm=0.777, train_wall=50, wall=0
2020-12-03 21:33:34 | INFO | train_inner | epoch 057:    458 / 719 loss=4.324, nll_loss=2.177, symm_mse=5.042, ppl=4.52, wps=16064.4, ups=1.99, wpb=8092.3, bsz=270.5, num_updates=13400, lr=0.000273179, gnorm=0.797, train_wall=50, wall=0
2020-12-03 21:34:23 | INFO | train_inner | epoch 057:    558 / 719 loss=4.33, nll_loss=2.186, symm_mse=5.035, ppl=4.55, wps=16603.2, ups=2.02, wpb=8231.6, bsz=276.3, num_updates=13500, lr=0.000272166, gnorm=0.779, train_wall=49, wall=0
2020-12-03 21:35:13 | INFO | train_inner | epoch 057:    658 / 719 loss=4.317, nll_loss=2.191, symm_mse=4.885, ppl=4.57, wps=16418.2, ups=2.01, wpb=8161.6, bsz=291.7, num_updates=13600, lr=0.000271163, gnorm=0.783, train_wall=49, wall=0
2020-12-03 21:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:35:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:35:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:35:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:35:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:35:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:35:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:36:06 | INFO | valid | epoch 057 | valid on 'valid' subset | symm_mse 0 | loss 8.629 | nll_loss 7.665 | ppl 202.95 | bleu 13.03 | wps 3353.9 | wpb 4629 | bsz 118.9 | num_updates 13661 | best_bleu 13.03
2020-12-03 21:36:06 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:36:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:36:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:36:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:36:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:36:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 57 @ 13661 updates, score 13.03) (writing took 6.539542276412249 seconds)
2020-12-03 21:36:13 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2020-12-03 21:36:13 | INFO | train | epoch 057 | loss 4.306 | nll_loss 2.161 | symm_mse 5.003 | ppl 4.47 | wps 15063.3 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 13661 | lr 0.000270557 | gnorm 0.784 | train_wall 355 | wall 0
111
2020-12-03 21:36:13 | INFO | fairseq.trainer | begin training epoch 58
2020-12-03 21:36:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:36:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:36:35 | INFO | train_inner | epoch 058:     39 / 719 loss=4.328, nll_loss=2.182, symm_mse=5.047, ppl=4.54, wps=9933.7, ups=1.22, wpb=8122.7, bsz=277, num_updates=13700, lr=0.000270172, gnorm=0.787, train_wall=49, wall=0
2020-12-03 21:37:24 | INFO | train_inner | epoch 058:    139 / 719 loss=4.273, nll_loss=2.113, symm_mse=5.075, ppl=4.33, wps=16437.7, ups=2.03, wpb=8098, bsz=268.8, num_updates=13800, lr=0.000269191, gnorm=0.789, train_wall=49, wall=0
2020-12-03 21:38:14 | INFO | train_inner | epoch 058:    239 / 719 loss=4.253, nll_loss=2.106, symm_mse=4.961, ppl=4.3, wps=16537.9, ups=2, wpb=8257.5, bsz=278.6, num_updates=13900, lr=0.000268221, gnorm=0.783, train_wall=50, wall=0
2020-12-03 21:39:04 | INFO | train_inner | epoch 058:    339 / 719 loss=4.245, nll_loss=2.104, symm_mse=4.908, ppl=4.3, wps=16445.5, ups=2, wpb=8240.7, bsz=290.6, num_updates=14000, lr=0.000267261, gnorm=0.763, train_wall=50, wall=0
2020-12-03 21:39:54 | INFO | train_inner | epoch 058:    439 / 719 loss=4.303, nll_loss=2.158, symm_mse=5.017, ppl=4.46, wps=16365.2, ups=2.02, wpb=8088.7, bsz=272.9, num_updates=14100, lr=0.000266312, gnorm=0.8, train_wall=49, wall=0
2020-12-03 21:40:44 | INFO | train_inner | epoch 058:    539 / 719 loss=4.276, nll_loss=2.136, symm_mse=4.944, ppl=4.4, wps=16449.1, ups=2, wpb=8211.7, bsz=285, num_updates=14200, lr=0.000265372, gnorm=0.779, train_wall=50, wall=0
2020-12-03 21:41:33 | INFO | train_inner | epoch 058:    639 / 719 loss=4.345, nll_loss=2.2, symm_mse=5.07, ppl=4.6, wps=16317.9, ups=2.01, wpb=8116.2, bsz=270.5, num_updates=14300, lr=0.000264443, gnorm=0.802, train_wall=49, wall=0
2020-12-03 21:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:42:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:33 | INFO | valid | epoch 058 | valid on 'valid' subset | symm_mse 0 | loss 8.586 | nll_loss 7.618 | ppl 196.43 | bleu 12.83 | wps 3815.8 | wpb 4629 | bsz 118.9 | num_updates 14380 | best_bleu 13.03
2020-12-03 21:42:33 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:42:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 58 @ 14380 updates, score 12.83) (writing took 3.7106820177286863 seconds)
2020-12-03 21:42:37 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2020-12-03 21:42:37 | INFO | train | epoch 058 | loss 4.283 | nll_loss 2.139 | symm_mse 4.976 | ppl 4.4 | wps 15262.2 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 14380 | lr 0.000263706 | gnorm 0.783 | train_wall 355 | wall 0
111
2020-12-03 21:42:37 | INFO | fairseq.trainer | begin training epoch 59
2020-12-03 21:42:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:42:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:42:50 | INFO | train_inner | epoch 059:     20 / 719 loss=4.29, nll_loss=2.155, symm_mse=4.925, ppl=4.45, wps=10633, ups=1.31, wpb=8127.6, bsz=275.6, num_updates=14400, lr=0.000263523, gnorm=0.774, train_wall=49, wall=0
2020-12-03 21:43:38 | INFO | train_inner | epoch 059:    120 / 719 loss=4.238, nll_loss=2.079, symm_mse=5.041, ppl=4.22, wps=16720.9, ups=2.06, wpb=8109.9, bsz=277.1, num_updates=14500, lr=0.000262613, gnorm=0.782, train_wall=48, wall=0
2020-12-03 21:44:28 | INFO | train_inner | epoch 059:    220 / 719 loss=4.244, nll_loss=2.088, symm_mse=5.025, ppl=4.25, wps=16327.6, ups=2, wpb=8169.3, bsz=267.9, num_updates=14600, lr=0.000261712, gnorm=0.777, train_wall=50, wall=0
2020-12-03 21:45:18 | INFO | train_inner | epoch 059:    320 / 719 loss=4.249, nll_loss=2.114, symm_mse=4.87, ppl=4.33, wps=16163, ups=2, wpb=8086.4, bsz=284.4, num_updates=14700, lr=0.00026082, gnorm=0.76, train_wall=50, wall=0
2020-12-03 21:46:08 | INFO | train_inner | epoch 059:    420 / 719 loss=4.293, nll_loss=2.135, symm_mse=5.101, ppl=4.39, wps=16398.5, ups=2.01, wpb=8174.5, bsz=260.1, num_updates=14800, lr=0.000259938, gnorm=0.782, train_wall=50, wall=0
2020-12-03 21:46:58 | INFO | train_inner | epoch 059:    520 / 719 loss=4.281, nll_loss=2.141, symm_mse=4.951, ppl=4.41, wps=16410, ups=2, wpb=8205.7, bsz=283.7, num_updates=14900, lr=0.000259064, gnorm=0.776, train_wall=50, wall=0
2020-12-03 21:47:48 | INFO | train_inner | epoch 059:    620 / 719 loss=4.271, nll_loss=2.143, symm_mse=4.855, ppl=4.42, wps=16404.5, ups=2, wpb=8193.1, bsz=289.8, num_updates=15000, lr=0.000258199, gnorm=0.78, train_wall=50, wall=0
2020-12-03 21:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:48:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:48:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:48:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:48:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:48:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:48:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:48:59 | INFO | valid | epoch 059 | valid on 'valid' subset | symm_mse 0 | loss 8.609 | nll_loss 7.642 | ppl 199.77 | bleu 12.66 | wps 3607.8 | wpb 4629 | bsz 118.9 | num_updates 15099 | best_bleu 13.03
2020-12-03 21:48:59 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:49:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:49:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:49:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:49:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:49:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 59 @ 15099 updates, score 12.66) (writing took 3.920772571116686 seconds)
2020-12-03 21:49:02 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2020-12-03 21:49:02 | INFO | train | epoch 059 | loss 4.262 | nll_loss 2.118 | symm_mse 4.958 | ppl 4.34 | wps 15216.4 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 15099 | lr 0.000257351 | gnorm 0.777 | train_wall 355 | wall 0
111
2020-12-03 21:49:02 | INFO | fairseq.trainer | begin training epoch 60
2020-12-03 21:49:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:49:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:49:07 | INFO | train_inner | epoch 060:      1 / 719 loss=4.264, nll_loss=2.139, symm_mse=4.827, ppl=4.4, wps=10458, ups=1.27, wpb=8210.4, bsz=288.2, num_updates=15100, lr=0.000257343, gnorm=0.774, train_wall=49, wall=0
2020-12-03 21:49:55 | INFO | train_inner | epoch 060:    101 / 719 loss=4.13, nll_loss=1.989, symm_mse=4.755, ppl=3.97, wps=16804.4, ups=2.06, wpb=8175.4, bsz=279, num_updates=15200, lr=0.000256495, gnorm=0.748, train_wall=48, wall=0
2020-12-03 21:50:45 | INFO | train_inner | epoch 060:    201 / 719 loss=4.187, nll_loss=2.044, symm_mse=4.851, ppl=4.12, wps=16321.4, ups=1.99, wpb=8184.1, bsz=300.2, num_updates=15300, lr=0.000255655, gnorm=0.793, train_wall=50, wall=0
2020-12-03 21:51:35 | INFO | train_inner | epoch 060:    301 / 719 loss=4.292, nll_loss=2.129, symm_mse=5.152, ppl=4.37, wps=16336, ups=2.01, wpb=8143.4, bsz=272.7, num_updates=15400, lr=0.000254824, gnorm=0.799, train_wall=50, wall=0
2020-12-03 21:52:25 | INFO | train_inner | epoch 060:    401 / 719 loss=4.287, nll_loss=2.138, symm_mse=5.035, ppl=4.4, wps=16227.5, ups=2, wpb=8105.2, bsz=283.8, num_updates=15500, lr=0.000254, gnorm=0.794, train_wall=50, wall=0
2020-12-03 21:53:15 | INFO | train_inner | epoch 060:    501 / 719 loss=4.238, nll_loss=2.099, symm_mse=4.9, ppl=4.29, wps=16223.1, ups=2, wpb=8105.4, bsz=277.8, num_updates=15600, lr=0.000253185, gnorm=0.782, train_wall=50, wall=0
2020-12-03 21:54:05 | INFO | train_inner | epoch 060:    601 / 719 loss=4.271, nll_loss=2.131, symm_mse=4.941, ppl=4.38, wps=16543.5, ups=2, wpb=8265.6, bsz=281.4, num_updates=15700, lr=0.000252377, gnorm=0.789, train_wall=50, wall=0
2020-12-03 21:54:55 | INFO | train_inner | epoch 060:    701 / 719 loss=4.301, nll_loss=2.158, symm_mse=5.013, ppl=4.46, wps=16642.4, ups=2.02, wpb=8219.4, bsz=256.8, num_updates=15800, lr=0.000251577, gnorm=0.794, train_wall=49, wall=0
2020-12-03 21:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 21:55:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:55:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:55:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:55:26 | INFO | valid | epoch 060 | valid on 'valid' subset | symm_mse 0 | loss 8.542 | nll_loss 7.565 | ppl 189.39 | bleu 13.17 | wps 3434.1 | wpb 4629 | bsz 118.9 | num_updates 15818 | best_bleu 13.17
2020-12-03 21:55:26 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 21:55:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:55:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:55:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 60 @ 15818 updates, score 13.17) (writing took 6.584342297166586 seconds)
2020-12-03 21:55:32 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2020-12-03 21:55:32 | INFO | train | epoch 060 | loss 4.244 | nll_loss 2.099 | symm_mse 4.947 | ppl 4.28 | wps 15056.4 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 15818 | lr 0.000251434 | gnorm 0.787 | train_wall 356 | wall 0
111
2020-12-03 21:55:32 | INFO | fairseq.trainer | begin training epoch 61
2020-12-03 21:55:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 21:55:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 21:56:15 | INFO | train_inner | epoch 061:     82 / 719 loss=4.139, nll_loss=2, symm_mse=4.765, ppl=4, wps=10088.1, ups=1.24, wpb=8159.5, bsz=285.9, num_updates=15900, lr=0.000250785, gnorm=0.782, train_wall=48, wall=0
2020-12-03 21:57:06 | INFO | train_inner | epoch 061:    182 / 719 loss=4.234, nll_loss=2.073, symm_mse=5.046, ppl=4.21, wps=16340.6, ups=2, wpb=8181.9, bsz=265.2, num_updates=16000, lr=0.00025, gnorm=0.781, train_wall=50, wall=0
2020-12-03 21:57:56 | INFO | train_inner | epoch 061:    282 / 719 loss=4.187, nll_loss=2.043, symm_mse=4.862, ppl=4.12, wps=16413.7, ups=1.99, wpb=8266.6, bsz=289.9, num_updates=16100, lr=0.000249222, gnorm=0.764, train_wall=50, wall=0
2020-12-03 21:58:46 | INFO | train_inner | epoch 061:    382 / 719 loss=4.21, nll_loss=2.074, symm_mse=4.835, ppl=4.21, wps=16282.2, ups=2.01, wpb=8097.2, bsz=282.7, num_updates=16200, lr=0.000248452, gnorm=0.767, train_wall=49, wall=0
2020-12-03 21:59:35 | INFO | train_inner | epoch 061:    482 / 719 loss=4.26, nll_loss=2.106, symm_mse=5.045, ppl=4.3, wps=16375.3, ups=2.01, wpb=8128.8, bsz=267.7, num_updates=16300, lr=0.000247689, gnorm=0.796, train_wall=49, wall=0
2020-12-03 22:00:25 | INFO | train_inner | epoch 061:    582 / 719 loss=4.266, nll_loss=2.119, symm_mse=4.999, ppl=4.34, wps=16300, ups=2, wpb=8170.2, bsz=270.6, num_updates=16400, lr=0.000246932, gnorm=0.796, train_wall=50, wall=0
2020-12-03 22:01:15 | INFO | train_inner | epoch 061:    682 / 719 loss=4.271, nll_loss=2.131, symm_mse=4.957, ppl=4.38, wps=16158.4, ups=2, wpb=8069.5, bsz=275.4, num_updates=16500, lr=0.000246183, gnorm=0.784, train_wall=50, wall=0
2020-12-03 22:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:01:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:01:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:01:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:01:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:01:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:01:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:01:56 | INFO | valid | epoch 061 | valid on 'valid' subset | symm_mse 0 | loss 8.599 | nll_loss 7.63 | ppl 198.12 | bleu 12.94 | wps 3356.6 | wpb 4629 | bsz 118.9 | num_updates 16537 | best_bleu 13.17
2020-12-03 22:01:56 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:02:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 61 @ 16537 updates, score 12.94) (writing took 3.8693690542131662 seconds)
2020-12-03 22:02:00 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2020-12-03 22:02:00 | INFO | train | epoch 061 | loss 4.224 | nll_loss 2.079 | symm_mse 4.923 | ppl 4.23 | wps 15119.6 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 16537 | lr 0.000245907 | gnorm 0.78 | train_wall 356 | wall 0
111
2020-12-03 22:02:00 | INFO | fairseq.trainer | begin training epoch 62
2020-12-03 22:02:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:02:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:02:34 | INFO | train_inner | epoch 062:     63 / 719 loss=4.165, nll_loss=2.028, symm_mse=4.79, ppl=4.08, wps=10376.4, ups=1.26, wpb=8207.4, bsz=291.7, num_updates=16600, lr=0.00024544, gnorm=0.766, train_wall=49, wall=0
2020-12-03 22:03:24 | INFO | train_inner | epoch 062:    163 / 719 loss=4.16, nll_loss=2.013, symm_mse=4.842, ppl=4.04, wps=16303.7, ups=2.01, wpb=8106.5, bsz=273.5, num_updates=16700, lr=0.000244704, gnorm=0.779, train_wall=49, wall=0
2020-12-03 22:04:14 | INFO | train_inner | epoch 062:    263 / 719 loss=4.191, nll_loss=2.041, symm_mse=4.93, ppl=4.11, wps=16527.5, ups=2.01, wpb=8226.3, bsz=289.3, num_updates=16800, lr=0.000243975, gnorm=0.78, train_wall=50, wall=0
2020-12-03 22:05:04 | INFO | train_inner | epoch 062:    363 / 719 loss=4.22, nll_loss=2.081, symm_mse=4.871, ppl=4.23, wps=16407.3, ups=2.01, wpb=8167.9, bsz=280.1, num_updates=16900, lr=0.000243252, gnorm=0.765, train_wall=50, wall=0
2020-12-03 22:05:54 | INFO | train_inner | epoch 062:    463 / 719 loss=4.242, nll_loss=2.091, symm_mse=5.002, ppl=4.26, wps=16181.5, ups=2, wpb=8087.9, bsz=274.5, num_updates=17000, lr=0.000242536, gnorm=0.802, train_wall=50, wall=0
2020-12-03 22:06:44 | INFO | train_inner | epoch 062:    563 / 719 loss=4.231, nll_loss=2.082, symm_mse=4.98, ppl=4.23, wps=16221.6, ups=2, wpb=8095.7, bsz=272.2, num_updates=17100, lr=0.000241825, gnorm=0.792, train_wall=50, wall=0
2020-12-03 22:07:33 | INFO | train_inner | epoch 062:    663 / 719 loss=4.24, nll_loss=2.097, symm_mse=4.941, ppl=4.28, wps=16612.2, ups=2.01, wpb=8264.2, bsz=270.1, num_updates=17200, lr=0.000241121, gnorm=0.782, train_wall=49, wall=0
2020-12-03 22:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:24 | INFO | valid | epoch 062 | valid on 'valid' subset | symm_mse 0 | loss 8.496 | nll_loss 7.515 | ppl 182.92 | bleu 13.04 | wps 3412.8 | wpb 4629 | bsz 118.9 | num_updates 17256 | best_bleu 13.17
2020-12-03 22:08:24 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:08:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 62 @ 17256 updates, score 13.04) (writing took 3.8593622110784054 seconds)
2020-12-03 22:08:28 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2020-12-03 22:08:28 | INFO | train | epoch 062 | loss 4.206 | nll_loss 2.06 | symm_mse 4.914 | ppl 4.17 | wps 15147.5 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 17256 | lr 0.00024073 | gnorm 0.782 | train_wall 356 | wall 0
111
2020-12-03 22:08:28 | INFO | fairseq.trainer | begin training epoch 63
2020-12-03 22:08:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:08:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:08:52 | INFO | train_inner | epoch 063:     44 / 719 loss=4.182, nll_loss=2.041, symm_mse=4.856, ppl=4.11, wps=10239.6, ups=1.27, wpb=8093.6, bsz=280.4, num_updates=17300, lr=0.000240424, gnorm=0.776, train_wall=49, wall=0
2020-12-03 22:09:42 | INFO | train_inner | epoch 063:    144 / 719 loss=4.156, nll_loss=2.002, symm_mse=4.902, ppl=4, wps=16520.7, ups=2.03, wpb=8136.8, bsz=273.8, num_updates=17400, lr=0.000239732, gnorm=0.778, train_wall=49, wall=0
2020-12-03 22:10:32 | INFO | train_inner | epoch 063:    244 / 719 loss=4.185, nll_loss=2.023, symm_mse=5.01, ppl=4.06, wps=16361.4, ups=2, wpb=8181.3, bsz=263, num_updates=17500, lr=0.000239046, gnorm=0.791, train_wall=50, wall=0
2020-12-03 22:11:22 | INFO | train_inner | epoch 063:    344 / 719 loss=4.178, nll_loss=2.03, symm_mse=4.902, ppl=4.08, wps=16421.4, ups=2, wpb=8215.9, bsz=273.4, num_updates=17600, lr=0.000238366, gnorm=0.773, train_wall=50, wall=0
2020-12-03 22:12:11 | INFO | train_inner | epoch 063:    444 / 719 loss=4.202, nll_loss=2.06, symm_mse=4.879, ppl=4.17, wps=16319.2, ups=2.01, wpb=8126.8, bsz=291, num_updates=17700, lr=0.000237691, gnorm=0.787, train_wall=50, wall=0
2020-12-03 22:13:01 | INFO | train_inner | epoch 063:    544 / 719 loss=4.207, nll_loss=2.063, symm_mse=4.909, ppl=4.18, wps=16492, ups=2.01, wpb=8213.7, bsz=272.6, num_updates=17800, lr=0.000237023, gnorm=0.807, train_wall=50, wall=0
2020-12-03 22:13:51 | INFO | train_inner | epoch 063:    644 / 719 loss=4.238, nll_loss=2.096, symm_mse=4.931, ppl=4.28, wps=16133, ups=1.99, wpb=8086.9, bsz=279.8, num_updates=17900, lr=0.00023636, gnorm=0.789, train_wall=50, wall=0
2020-12-03 22:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:14:52 | INFO | valid | epoch 063 | valid on 'valid' subset | symm_mse 0 | loss 8.556 | nll_loss 7.581 | ppl 191.42 | bleu 13.24 | wps 3352 | wpb 4629 | bsz 118.9 | num_updates 17975 | best_bleu 13.24
2020-12-03 22:14:52 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:14:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:14:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:14:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:14:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:14:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 63 @ 17975 updates, score 13.24) (writing took 6.632097387686372 seconds)
2020-12-03 22:14:58 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2020-12-03 22:14:58 | INFO | train | epoch 063 | loss 4.191 | nll_loss 2.045 | symm_mse 4.898 | ppl 4.13 | wps 15018.3 | ups 1.84 | wpb 8159.9 | bsz 278.2 | num_updates 17975 | lr 0.000235866 | gnorm 0.785 | train_wall 356 | wall 0
111
2020-12-03 22:14:58 | INFO | fairseq.trainer | begin training epoch 64
2020-12-03 22:14:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:15:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:15:14 | INFO | train_inner | epoch 064:     25 / 719 loss=4.186, nll_loss=2.051, symm_mse=4.809, ppl=4.14, wps=9911, ups=1.21, wpb=8160, bsz=284.6, num_updates=18000, lr=0.000235702, gnorm=0.78, train_wall=49, wall=0
2020-12-03 22:16:04 | INFO | train_inner | epoch 064:    125 / 719 loss=4.114, nll_loss=1.969, symm_mse=4.788, ppl=3.91, wps=16395.2, ups=2.01, wpb=8167.9, bsz=285.1, num_updates=18100, lr=0.00023505, gnorm=0.768, train_wall=50, wall=0
2020-12-03 22:16:54 | INFO | train_inner | epoch 064:    225 / 719 loss=4.167, nll_loss=2.009, symm_mse=4.953, ppl=4.03, wps=16265.6, ups=1.99, wpb=8173.7, bsz=275.9, num_updates=18200, lr=0.000234404, gnorm=0.784, train_wall=50, wall=0
2020-12-03 22:17:44 | INFO | train_inner | epoch 064:    325 / 719 loss=4.161, nll_loss=2.016, symm_mse=4.847, ppl=4.04, wps=16262.2, ups=1.97, wpb=8236.5, bsz=277.5, num_updates=18300, lr=0.000233762, gnorm=0.773, train_wall=50, wall=0
2020-12-03 22:18:35 | INFO | train_inner | epoch 064:    425 / 719 loss=4.125, nll_loss=1.988, symm_mse=4.756, ppl=3.97, wps=16337.5, ups=1.99, wpb=8222.9, bsz=295.9, num_updates=18400, lr=0.000233126, gnorm=0.776, train_wall=50, wall=0
2020-12-03 22:19:25 | INFO | train_inner | epoch 064:    525 / 719 loss=4.217, nll_loss=2.069, symm_mse=4.952, ppl=4.2, wps=16068.7, ups=2, wpb=8026.5, bsz=268.3, num_updates=18500, lr=0.000232495, gnorm=0.799, train_wall=50, wall=0
2020-12-03 22:20:15 | INFO | train_inner | epoch 064:    625 / 719 loss=4.265, nll_loss=2.105, symm_mse=5.112, ppl=4.3, wps=16066.8, ups=2.01, wpb=8012.1, bsz=268.2, num_updates=18600, lr=0.000231869, gnorm=0.817, train_wall=50, wall=0
2020-12-03 22:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:21:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:23 | INFO | valid | epoch 064 | valid on 'valid' subset | symm_mse 0 | loss 8.598 | nll_loss 7.628 | ppl 197.86 | bleu 13.17 | wps 3620 | wpb 4629 | bsz 118.9 | num_updates 18694 | best_bleu 13.24
2020-12-03 22:21:23 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:21:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 64 @ 18694 updates, score 13.17) (writing took 3.7903077751398087 seconds)
2020-12-03 22:21:27 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2020-12-03 22:21:27 | INFO | train | epoch 064 | loss 4.175 | nll_loss 2.027 | symm_mse 4.891 | ppl 4.08 | wps 15103.7 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 18694 | lr 0.000231286 | gnorm 0.784 | train_wall 358 | wall 0
111
2020-12-03 22:21:27 | INFO | fairseq.trainer | begin training epoch 65
2020-12-03 22:21:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:21:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:21:33 | INFO | train_inner | epoch 065:      6 / 719 loss=4.186, nll_loss=2.048, symm_mse=4.85, ppl=4.13, wps=10527, ups=1.27, wpb=8273, bsz=280.8, num_updates=18700, lr=0.000231249, gnorm=0.775, train_wall=50, wall=0
2020-12-03 22:22:22 | INFO | train_inner | epoch 065:    106 / 719 loss=4.129, nll_loss=1.974, symm_mse=4.879, ppl=3.93, wps=16837.3, ups=2.05, wpb=8193.9, bsz=272.9, num_updates=18800, lr=0.000230633, gnorm=0.779, train_wall=48, wall=0
2020-12-03 22:23:12 | INFO | train_inner | epoch 065:    206 / 719 loss=4.133, nll_loss=1.985, symm_mse=4.836, ppl=3.96, wps=16435.9, ups=2, wpb=8226.6, bsz=279, num_updates=18900, lr=0.000230022, gnorm=0.769, train_wall=50, wall=0
2020-12-03 22:24:02 | INFO | train_inner | epoch 065:    306 / 719 loss=4.162, nll_loss=2.009, symm_mse=4.926, ppl=4.02, wps=16305.7, ups=2, wpb=8172.8, bsz=285.3, num_updates=19000, lr=0.000229416, gnorm=0.791, train_wall=50, wall=0
2020-12-03 22:24:52 | INFO | train_inner | epoch 065:    406 / 719 loss=4.162, nll_loss=2.012, symm_mse=4.906, ppl=4.03, wps=16305.4, ups=2, wpb=8138.5, bsz=291.1, num_updates=19100, lr=0.000228814, gnorm=0.791, train_wall=50, wall=0
2020-12-03 22:25:42 | INFO | train_inner | epoch 065:    506 / 719 loss=4.161, nll_loss=2.025, symm_mse=4.792, ppl=4.07, wps=16125.2, ups=2, wpb=8082, bsz=285.5, num_updates=19200, lr=0.000228218, gnorm=0.804, train_wall=50, wall=0
2020-12-03 22:26:32 | INFO | train_inner | epoch 065:    606 / 719 loss=4.164, nll_loss=2.021, symm_mse=4.843, ppl=4.06, wps=16412.6, ups=1.99, wpb=8256.5, bsz=274.3, num_updates=19300, lr=0.000227626, gnorm=0.78, train_wall=50, wall=0
2020-12-03 22:27:22 | INFO | train_inner | epoch 065:    706 / 719 loss=4.208, nll_loss=2.059, symm_mse=4.961, ppl=4.17, wps=16108.9, ups=2, wpb=8065, bsz=261, num_updates=19400, lr=0.000227038, gnorm=0.788, train_wall=50, wall=0
2020-12-03 22:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:27:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:27:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:27:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:27:51 | INFO | valid | epoch 065 | valid on 'valid' subset | symm_mse 0 | loss 8.595 | nll_loss 7.623 | ppl 197.1 | bleu 13.22 | wps 3501.6 | wpb 4629 | bsz 118.9 | num_updates 19413 | best_bleu 13.24
2020-12-03 22:27:51 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:27:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:27:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:27:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 65 @ 19413 updates, score 13.22) (writing took 3.9728267658501863 seconds)
2020-12-03 22:27:55 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2020-12-03 22:27:55 | INFO | train | epoch 065 | loss 4.16 | nll_loss 2.013 | symm_mse 4.877 | ppl 4.04 | wps 15125.1 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 19413 | lr 0.000226962 | gnorm 0.786 | train_wall 357 | wall 0
111
2020-12-03 22:27:55 | INFO | fairseq.trainer | begin training epoch 66
2020-12-03 22:27:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:27:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:28:41 | INFO | train_inner | epoch 066:     87 / 719 loss=4.089, nll_loss=1.941, symm_mse=4.793, ppl=3.84, wps=10465.1, ups=1.28, wpb=8168.8, bsz=284.6, num_updates=19500, lr=0.000226455, gnorm=0.771, train_wall=49, wall=0
2020-12-03 22:29:31 | INFO | train_inner | epoch 066:    187 / 719 loss=4.128, nll_loss=1.969, symm_mse=4.923, ppl=3.92, wps=16219, ups=1.99, wpb=8168.1, bsz=279.4, num_updates=19600, lr=0.000225877, gnorm=0.782, train_wall=50, wall=0
2020-12-03 22:30:21 | INFO | train_inner | epoch 066:    287 / 719 loss=4.131, nll_loss=1.977, symm_mse=4.896, ppl=3.94, wps=16190, ups=2.01, wpb=8070.2, bsz=271.4, num_updates=19700, lr=0.000225303, gnorm=0.799, train_wall=50, wall=0
2020-12-03 22:31:11 | INFO | train_inner | epoch 066:    387 / 719 loss=4.157, nll_loss=2.011, symm_mse=4.872, ppl=4.03, wps=16452.5, ups=2, wpb=8205.8, bsz=290.2, num_updates=19800, lr=0.000224733, gnorm=0.777, train_wall=50, wall=0
2020-12-03 22:32:00 | INFO | train_inner | epoch 066:    487 / 719 loss=4.189, nll_loss=2.035, symm_mse=4.964, ppl=4.1, wps=16189.8, ups=2.01, wpb=8074.5, bsz=262.4, num_updates=19900, lr=0.000224168, gnorm=0.793, train_wall=50, wall=0
2020-12-03 22:32:51 | INFO | train_inner | epoch 066:    587 / 719 loss=4.167, nll_loss=2.021, symm_mse=4.887, ppl=4.06, wps=16454.1, ups=1.99, wpb=8270.9, bsz=276.8, num_updates=20000, lr=0.000223607, gnorm=0.775, train_wall=50, wall=0
2020-12-03 22:33:40 | INFO | train_inner | epoch 066:    687 / 719 loss=4.171, nll_loss=2.034, symm_mse=4.816, ppl=4.1, wps=16401.5, ups=2.01, wpb=8160.7, bsz=278.5, num_updates=20100, lr=0.00022305, gnorm=0.778, train_wall=50, wall=0
2020-12-03 22:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:33:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:33:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:33:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:33:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:33:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:33:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:34:19 | INFO | valid | epoch 066 | valid on 'valid' subset | symm_mse 0 | loss 8.635 | nll_loss 7.669 | ppl 203.46 | bleu 13.28 | wps 3272.8 | wpb 4629 | bsz 118.9 | num_updates 20132 | best_bleu 13.28
2020-12-03 22:34:19 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:34:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:34:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:34:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:34:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:34:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 66 @ 20132 updates, score 13.28) (writing took 6.452886870130897 seconds)
2020-12-03 22:34:26 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2020-12-03 22:34:26 | INFO | train | epoch 066 | loss 4.146 | nll_loss 1.998 | symm_mse 4.868 | ppl 3.99 | wps 14999.8 | ups 1.84 | wpb 8159.9 | bsz 278.2 | num_updates 20132 | lr 0.000222873 | gnorm 0.782 | train_wall 357 | wall 0
111
2020-12-03 22:34:26 | INFO | fairseq.trainer | begin training epoch 67
2020-12-03 22:34:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:34:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:35:02 | INFO | train_inner | epoch 067:     68 / 719 loss=4.089, nll_loss=1.948, symm_mse=4.739, ppl=3.86, wps=9970.1, ups=1.22, wpb=8143.8, bsz=276.4, num_updates=20200, lr=0.000222497, gnorm=0.785, train_wall=49, wall=0
2020-12-03 22:35:52 | INFO | train_inner | epoch 067:    168 / 719 loss=4.047, nll_loss=1.904, symm_mse=4.711, ppl=3.74, wps=16360.3, ups=2, wpb=8187.9, bsz=297.9, num_updates=20300, lr=0.000221948, gnorm=0.757, train_wall=50, wall=0
2020-12-03 22:36:42 | INFO | train_inner | epoch 067:    268 / 719 loss=4.096, nll_loss=1.947, symm_mse=4.81, ppl=3.86, wps=16227.3, ups=2.01, wpb=8074.2, bsz=289.8, num_updates=20400, lr=0.000221404, gnorm=0.784, train_wall=50, wall=0
2020-12-03 22:37:32 | INFO | train_inner | epoch 067:    368 / 719 loss=4.131, nll_loss=1.978, symm_mse=4.893, ppl=3.94, wps=16420.3, ups=2.02, wpb=8141.2, bsz=283, num_updates=20500, lr=0.000220863, gnorm=0.793, train_wall=49, wall=0
2020-12-03 22:38:21 | INFO | train_inner | epoch 067:    468 / 719 loss=4.182, nll_loss=2.027, symm_mse=4.972, ppl=4.08, wps=16352.9, ups=2.02, wpb=8103, bsz=262.1, num_updates=20600, lr=0.000220326, gnorm=0.808, train_wall=49, wall=0
2020-12-03 22:39:11 | INFO | train_inner | epoch 067:    568 / 719 loss=4.161, nll_loss=2.016, symm_mse=4.868, ppl=4.04, wps=16355.5, ups=2.01, wpb=8145.4, bsz=272.4, num_updates=20700, lr=0.000219793, gnorm=0.798, train_wall=50, wall=0
2020-12-03 22:40:01 | INFO | train_inner | epoch 067:    668 / 719 loss=4.18, nll_loss=2.032, symm_mse=4.921, ppl=4.09, wps=16529.2, ups=2.01, wpb=8226.4, bsz=273.9, num_updates=20800, lr=0.000219265, gnorm=0.792, train_wall=50, wall=0
2020-12-03 22:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:40:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:40:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:40:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:40:48 | INFO | valid | epoch 067 | valid on 'valid' subset | symm_mse 0 | loss 8.606 | nll_loss 7.634 | ppl 198.69 | bleu 13.24 | wps 3482.2 | wpb 4629 | bsz 118.9 | num_updates 20851 | best_bleu 13.28
2020-12-03 22:40:48 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:40:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:40:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:40:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 67 @ 20851 updates, score 13.24) (writing took 3.9153543058782816 seconds)
2020-12-03 22:40:52 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2020-12-03 22:40:52 | INFO | train | epoch 067 | loss 4.132 | nll_loss 1.983 | symm_mse 4.861 | ppl 3.95 | wps 15197.5 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 20851 | lr 0.000218996 | gnorm 0.787 | train_wall 355 | wall 0
111
2020-12-03 22:40:52 | INFO | fairseq.trainer | begin training epoch 68
2020-12-03 22:40:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:40:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:41:19 | INFO | train_inner | epoch 068:     49 / 719 loss=4.135, nll_loss=1.983, symm_mse=4.884, ppl=3.95, wps=10611.2, ups=1.28, wpb=8263.2, bsz=274.2, num_updates=20900, lr=0.000218739, gnorm=0.768, train_wall=49, wall=0
2020-12-03 22:42:08 | INFO | train_inner | epoch 068:    149 / 719 loss=4.108, nll_loss=1.945, symm_mse=4.931, ppl=3.85, wps=16393.9, ups=2.01, wpb=8144.2, bsz=273.9, num_updates=21000, lr=0.000218218, gnorm=0.785, train_wall=49, wall=0
2020-12-03 22:42:58 | INFO | train_inner | epoch 068:    249 / 719 loss=4.037, nll_loss=1.896, symm_mse=4.692, ppl=3.72, wps=16435.7, ups=2, wpb=8215.2, bsz=301.8, num_updates=21100, lr=0.0002177, gnorm=0.765, train_wall=50, wall=0
2020-12-03 22:43:48 | INFO | train_inner | epoch 068:    349 / 719 loss=4.129, nll_loss=1.974, symm_mse=4.894, ppl=3.93, wps=16655.3, ups=2.03, wpb=8220.1, bsz=265.1, num_updates=21200, lr=0.000217186, gnorm=0.787, train_wall=49, wall=0
2020-12-03 22:44:37 | INFO | train_inner | epoch 068:    449 / 719 loss=4.128, nll_loss=1.988, symm_mse=4.785, ppl=3.97, wps=16399, ups=2.01, wpb=8142.6, bsz=286, num_updates=21300, lr=0.000216676, gnorm=0.781, train_wall=49, wall=0
2020-12-03 22:45:27 | INFO | train_inner | epoch 068:    549 / 719 loss=4.139, nll_loss=1.991, symm_mse=4.87, ppl=3.98, wps=16108.7, ups=1.99, wpb=8082.5, bsz=278.7, num_updates=21400, lr=0.000216169, gnorm=0.795, train_wall=50, wall=0
2020-12-03 22:46:17 | INFO | train_inner | epoch 068:    649 / 719 loss=4.15, nll_loss=2.007, symm_mse=4.847, ppl=4.02, wps=16370.1, ups=2, wpb=8178.6, bsz=280.6, num_updates=21500, lr=0.000215666, gnorm=0.806, train_wall=50, wall=0
2020-12-03 22:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:46:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:46:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:46:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:46:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:46:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:46:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:47:14 | INFO | valid | epoch 068 | valid on 'valid' subset | symm_mse 0 | loss 8.669 | nll_loss 7.704 | ppl 208.47 | bleu 12.8 | wps 3621.6 | wpb 4629 | bsz 118.9 | num_updates 21570 | best_bleu 13.28
2020-12-03 22:47:14 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:47:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:47:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:47:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:47:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:47:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 68 @ 21570 updates, score 12.8) (writing took 3.889171840623021 seconds)
2020-12-03 22:47:18 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2020-12-03 22:47:18 | INFO | train | epoch 068 | loss 4.119 | nll_loss 1.969 | symm_mse 4.853 | ppl 3.92 | wps 15206.6 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 21570 | lr 0.000215315 | gnorm 0.787 | train_wall 355 | wall 0
111
2020-12-03 22:47:18 | INFO | fairseq.trainer | begin training epoch 69
2020-12-03 22:47:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:47:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:47:35 | INFO | train_inner | epoch 069:     30 / 719 loss=4.123, nll_loss=1.971, symm_mse=4.872, ppl=3.92, wps=10466.5, ups=1.28, wpb=8167.7, bsz=260.7, num_updates=21600, lr=0.000215166, gnorm=0.797, train_wall=49, wall=0
2020-12-03 22:48:24 | INFO | train_inner | epoch 069:    130 / 719 loss=4.079, nll_loss=1.913, symm_mse=4.919, ppl=3.77, wps=16608.5, ups=2.05, wpb=8093.8, bsz=263.3, num_updates=21700, lr=0.000214669, gnorm=0.805, train_wall=49, wall=0
2020-12-03 22:49:14 | INFO | train_inner | epoch 069:    230 / 719 loss=4.099, nll_loss=1.941, symm_mse=4.889, ppl=3.84, wps=16518.5, ups=2.01, wpb=8217, bsz=272.2, num_updates=21800, lr=0.000214176, gnorm=0.774, train_wall=50, wall=0
2020-12-03 22:50:03 | INFO | train_inner | epoch 069:    330 / 719 loss=4.086, nll_loss=1.947, symm_mse=4.732, ppl=3.85, wps=16460.6, ups=2.02, wpb=8149.9, bsz=291.6, num_updates=21900, lr=0.000213687, gnorm=0.784, train_wall=49, wall=0
2020-12-03 22:50:53 | INFO | train_inner | epoch 069:    430 / 719 loss=4.1, nll_loss=1.956, symm_mse=4.79, ppl=3.88, wps=16397.6, ups=2.01, wpb=8170.4, bsz=293.5, num_updates=22000, lr=0.000213201, gnorm=0.799, train_wall=50, wall=0
2020-12-03 22:51:43 | INFO | train_inner | epoch 069:    530 / 719 loss=4.114, nll_loss=1.968, symm_mse=4.827, ppl=3.91, wps=16350.9, ups=2.01, wpb=8130.8, bsz=284.2, num_updates=22100, lr=0.000212718, gnorm=0.787, train_wall=50, wall=0
2020-12-03 22:52:33 | INFO | train_inner | epoch 069:    630 / 719 loss=4.16, nll_loss=2.008, symm_mse=4.932, ppl=4.02, wps=16305.1, ups=2, wpb=8162.6, bsz=274.2, num_updates=22200, lr=0.000212238, gnorm=0.794, train_wall=50, wall=0
2020-12-03 22:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:53:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:38 | INFO | valid | epoch 069 | valid on 'valid' subset | symm_mse 0 | loss 8.613 | nll_loss 7.64 | ppl 199.51 | bleu 13.33 | wps 3573.9 | wpb 4629 | bsz 118.9 | num_updates 22289 | best_bleu 13.33
2020-12-03 22:53:38 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 22:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 69 @ 22289 updates, score 13.33) (writing took 6.692117623984814 seconds)
2020-12-03 22:53:45 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2020-12-03 22:53:45 | INFO | train | epoch 069 | loss 4.106 | nll_loss 1.955 | symm_mse 4.845 | ppl 3.88 | wps 15144 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 22289 | lr 0.000211814 | gnorm 0.79 | train_wall 354 | wall 0
111
2020-12-03 22:53:45 | INFO | fairseq.trainer | begin training epoch 70
2020-12-03 22:53:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:53:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:53:54 | INFO | train_inner | epoch 070:     11 / 719 loss=4.14, nll_loss=1.985, symm_mse=4.934, ppl=3.96, wps=10089.2, ups=1.24, wpb=8139.1, bsz=261.7, num_updates=22300, lr=0.000211762, gnorm=0.79, train_wall=49, wall=0
2020-12-03 22:54:43 | INFO | train_inner | epoch 070:    111 / 719 loss=4.04, nll_loss=1.89, symm_mse=4.751, ppl=3.71, wps=16572.3, ups=2.03, wpb=8145.2, bsz=287.4, num_updates=22400, lr=0.000211289, gnorm=0.805, train_wall=49, wall=0
2020-12-03 22:55:33 | INFO | train_inner | epoch 070:    211 / 719 loss=4.05, nll_loss=1.9, symm_mse=4.762, ppl=3.73, wps=16459.3, ups=2, wpb=8234.5, bsz=273.4, num_updates=22500, lr=0.000210819, gnorm=0.773, train_wall=50, wall=0
2020-12-03 22:56:22 | INFO | train_inner | epoch 070:    311 / 719 loss=4.109, nll_loss=1.949, symm_mse=4.917, ppl=3.86, wps=16502.5, ups=2.03, wpb=8137.6, bsz=269.7, num_updates=22600, lr=0.000210352, gnorm=0.804, train_wall=49, wall=0
2020-12-03 22:57:12 | INFO | train_inner | epoch 070:    411 / 719 loss=4.12, nll_loss=1.956, symm_mse=4.977, ppl=3.88, wps=16419, ups=2.01, wpb=8184.4, bsz=271.8, num_updates=22700, lr=0.000209888, gnorm=0.805, train_wall=50, wall=0
2020-12-03 22:58:01 | INFO | train_inner | epoch 070:    511 / 719 loss=4.163, nll_loss=1.999, symm_mse=5.03, ppl=4, wps=16270.8, ups=2.03, wpb=8025.4, bsz=259.2, num_updates=22800, lr=0.000209427, gnorm=0.833, train_wall=49, wall=0
2020-12-03 22:58:51 | INFO | train_inner | epoch 070:    611 / 719 loss=4.061, nll_loss=1.931, symm_mse=4.636, ppl=3.81, wps=16473.4, ups=2, wpb=8236.7, bsz=304, num_updates=22900, lr=0.000208969, gnorm=0.776, train_wall=50, wall=0
2020-12-03 22:59:42 | INFO | train_inner | epoch 070:    711 / 719 loss=4.116, nll_loss=1.979, symm_mse=4.77, ppl=3.94, wps=16211.2, ups=1.99, wpb=8147.6, bsz=288.6, num_updates=23000, lr=0.000208514, gnorm=0.791, train_wall=50, wall=0
2020-12-03 22:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 22:59:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:59:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:59:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 22:59:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:59:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 22:59:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:00:07 | INFO | valid | epoch 070 | valid on 'valid' subset | symm_mse 0 | loss 8.633 | nll_loss 7.671 | ppl 203.83 | bleu 13.17 | wps 3540.1 | wpb 4629 | bsz 118.9 | num_updates 23008 | best_bleu 13.33
2020-12-03 23:00:07 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:00:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:00:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:00:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:00:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:00:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 70 @ 23008 updates, score 13.17) (writing took 3.8847556319087744 seconds)
2020-12-03 23:00:11 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2020-12-03 23:00:11 | INFO | train | epoch 070 | loss 4.095 | nll_loss 1.944 | symm_mse 4.841 | ppl 3.85 | wps 15199.4 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 23008 | lr 0.000208478 | gnorm 0.798 | train_wall 356 | wall 0
111
2020-12-03 23:00:11 | INFO | fairseq.trainer | begin training epoch 71
2020-12-03 23:00:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:00:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:00:59 | INFO | train_inner | epoch 071:     92 / 719 loss=4.047, nll_loss=1.891, symm_mse=4.805, ppl=3.71, wps=10458.8, ups=1.29, wpb=8123.1, bsz=276.1, num_updates=23100, lr=0.000208063, gnorm=0.795, train_wall=48, wall=0
2020-12-03 23:01:49 | INFO | train_inner | epoch 071:    192 / 719 loss=4.062, nll_loss=1.904, symm_mse=4.845, ppl=3.74, wps=16421.1, ups=2.01, wpb=8178.3, bsz=261, num_updates=23200, lr=0.000207614, gnorm=0.776, train_wall=50, wall=0
2020-12-03 23:02:39 | INFO | train_inner | epoch 071:    292 / 719 loss=4.071, nll_loss=1.909, symm_mse=4.889, ppl=3.76, wps=16478, ups=2.02, wpb=8161.5, bsz=275.3, num_updates=23300, lr=0.000207168, gnorm=0.794, train_wall=49, wall=0
2020-12-03 23:03:28 | INFO | train_inner | epoch 071:    392 / 719 loss=4.064, nll_loss=1.922, symm_mse=4.725, ppl=3.79, wps=16489.7, ups=2.01, wpb=8201, bsz=293.5, num_updates=23400, lr=0.000206725, gnorm=0.789, train_wall=50, wall=0
2020-12-03 23:04:18 | INFO | train_inner | epoch 071:    492 / 719 loss=4.098, nll_loss=1.946, symm_mse=4.849, ppl=3.85, wps=16497, ups=2.02, wpb=8172.4, bsz=283.4, num_updates=23500, lr=0.000206284, gnorm=0.79, train_wall=49, wall=0
2020-12-03 23:05:08 | INFO | train_inner | epoch 071:    592 / 719 loss=4.106, nll_loss=1.955, symm_mse=4.867, ppl=3.88, wps=16253.7, ups=2, wpb=8135.2, bsz=274.9, num_updates=23600, lr=0.000205847, gnorm=0.794, train_wall=50, wall=0
2020-12-03 23:05:58 | INFO | train_inner | epoch 071:    692 / 719 loss=4.128, nll_loss=1.977, symm_mse=4.889, ppl=3.94, wps=16363.9, ups=2.01, wpb=8147.5, bsz=285.4, num_updates=23700, lr=0.000205412, gnorm=0.813, train_wall=50, wall=0
2020-12-03 23:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:06:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:06:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:06:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:06:33 | INFO | valid | epoch 071 | valid on 'valid' subset | symm_mse 0 | loss 8.682 | nll_loss 7.717 | ppl 210.42 | bleu 13.48 | wps 3483.3 | wpb 4629 | bsz 118.9 | num_updates 23727 | best_bleu 13.48
2020-12-03 23:06:33 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:06:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:06:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:06:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 71 @ 23727 updates, score 13.48) (writing took 6.760323921218514 seconds)
2020-12-03 23:06:40 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2020-12-03 23:06:40 | INFO | train | epoch 071 | loss 4.083 | nll_loss 1.931 | symm_mse 4.84 | ppl 3.81 | wps 15082.9 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 23727 | lr 0.000205295 | gnorm 0.794 | train_wall 355 | wall 0
111
2020-12-03 23:06:40 | INFO | fairseq.trainer | begin training epoch 72
2020-12-03 23:06:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:06:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:07:19 | INFO | train_inner | epoch 072:     73 / 719 loss=4.085, nll_loss=1.912, symm_mse=4.99, ppl=3.76, wps=10054.3, ups=1.24, wpb=8128.6, bsz=262.8, num_updates=23800, lr=0.00020498, gnorm=0.82, train_wall=49, wall=0
2020-12-03 23:08:08 | INFO | train_inner | epoch 072:    173 / 719 loss=4.033, nll_loss=1.874, symm_mse=4.832, ppl=3.66, wps=16466.9, ups=2.03, wpb=8122, bsz=281.3, num_updates=23900, lr=0.000204551, gnorm=0.795, train_wall=49, wall=0
2020-12-03 23:08:58 | INFO | train_inner | epoch 072:    273 / 719 loss=4.034, nll_loss=1.888, symm_mse=4.723, ppl=3.7, wps=16563.4, ups=2.01, wpb=8238.4, bsz=288.4, num_updates=24000, lr=0.000204124, gnorm=0.788, train_wall=49, wall=0
2020-12-03 23:09:48 | INFO | train_inner | epoch 072:    373 / 719 loss=4.056, nll_loss=1.909, symm_mse=4.767, ppl=3.75, wps=16238.1, ups=2, wpb=8108.3, bsz=280.6, num_updates=24100, lr=0.0002037, gnorm=0.79, train_wall=50, wall=0
2020-12-03 23:10:38 | INFO | train_inner | epoch 072:    473 / 719 loss=4.097, nll_loss=1.941, symm_mse=4.881, ppl=3.84, wps=16428.8, ups=2, wpb=8206.1, bsz=259.7, num_updates=24200, lr=0.000203279, gnorm=0.804, train_wall=50, wall=0
2020-12-03 23:11:27 | INFO | train_inner | epoch 072:    573 / 719 loss=4.1, nll_loss=1.955, symm_mse=4.806, ppl=3.88, wps=16450.2, ups=2.02, wpb=8163.6, bsz=303.8, num_updates=24300, lr=0.00020286, gnorm=0.806, train_wall=49, wall=0
2020-12-03 23:12:17 | INFO | train_inner | epoch 072:    673 / 719 loss=4.088, nll_loss=1.949, symm_mse=4.74, ppl=3.86, wps=16297.3, ups=1.99, wpb=8181.1, bsz=281.4, num_updates=24400, lr=0.000202444, gnorm=0.787, train_wall=50, wall=0
2020-12-03 23:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:12:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:12:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:12:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:12:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:12:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:12:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:13:02 | INFO | valid | epoch 072 | valid on 'valid' subset | symm_mse 0 | loss 8.617 | nll_loss 7.652 | ppl 201.14 | bleu 13.21 | wps 3490.9 | wpb 4629 | bsz 118.9 | num_updates 24446 | best_bleu 13.48
2020-12-03 23:13:02 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:13:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:13:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:13:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:13:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:13:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 72 @ 24446 updates, score 13.21) (writing took 4.015497544780374 seconds)
2020-12-03 23:13:06 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2020-12-03 23:13:06 | INFO | train | epoch 072 | loss 4.074 | nll_loss 1.921 | symm_mse 4.829 | ppl 3.79 | wps 15196.7 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 24446 | lr 0.000202254 | gnorm 0.798 | train_wall 355 | wall 0
111
2020-12-03 23:13:06 | INFO | fairseq.trainer | begin training epoch 73
2020-12-03 23:13:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:13:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:13:36 | INFO | train_inner | epoch 073:     54 / 719 loss=4.11, nll_loss=1.939, symm_mse=5.016, ppl=3.83, wps=10423.7, ups=1.27, wpb=8184.9, bsz=250, num_updates=24500, lr=0.000202031, gnorm=0.807, train_wall=49, wall=0
2020-12-03 23:14:26 | INFO | train_inner | epoch 073:    154 / 719 loss=4.024, nll_loss=1.865, symm_mse=4.809, ppl=3.64, wps=16516.8, ups=2.01, wpb=8202.4, bsz=278.3, num_updates=24600, lr=0.000201619, gnorm=0.787, train_wall=49, wall=0
2020-12-03 23:15:15 | INFO | train_inner | epoch 073:    254 / 719 loss=4.022, nll_loss=1.875, symm_mse=4.72, ppl=3.67, wps=16414.5, ups=2, wpb=8192, bsz=287.4, num_updates=24700, lr=0.000201211, gnorm=0.784, train_wall=50, wall=0
2020-12-03 23:16:05 | INFO | train_inner | epoch 073:    354 / 719 loss=4.027, nll_loss=1.87, symm_mse=4.81, ppl=3.65, wps=16644.9, ups=2.03, wpb=8218.6, bsz=271.7, num_updates=24800, lr=0.000200805, gnorm=0.795, train_wall=49, wall=0
2020-12-03 23:16:55 | INFO | train_inner | epoch 073:    454 / 719 loss=4.081, nll_loss=1.928, symm_mse=4.85, ppl=3.81, wps=16154.8, ups=2.01, wpb=8033.8, bsz=288.6, num_updates=24900, lr=0.000200401, gnorm=0.799, train_wall=50, wall=0
2020-12-03 23:17:44 | INFO | train_inner | epoch 073:    554 / 719 loss=4.121, nll_loss=1.96, symm_mse=4.964, ppl=3.89, wps=16317.3, ups=2.02, wpb=8076.8, bsz=269.8, num_updates=25000, lr=0.0002, gnorm=0.811, train_wall=49, wall=0
2020-12-03 23:18:34 | INFO | train_inner | epoch 073:    654 / 719 loss=4.072, nll_loss=1.938, symm_mse=4.694, ppl=3.83, wps=16480.2, ups=2.01, wpb=8194.6, bsz=295.6, num_updates=25100, lr=0.000199601, gnorm=0.802, train_wall=49, wall=0
2020-12-03 23:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:19:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:27 | INFO | valid | epoch 073 | valid on 'valid' subset | symm_mse 0 | loss 8.687 | nll_loss 7.722 | ppl 211.16 | bleu 13.31 | wps 3640.6 | wpb 4629 | bsz 118.9 | num_updates 25165 | best_bleu 13.48
2020-12-03 23:19:27 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:19:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 73 @ 25165 updates, score 13.31) (writing took 3.960219368338585 seconds)
2020-12-03 23:19:31 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2020-12-03 23:19:31 | INFO | train | epoch 073 | loss 4.061 | nll_loss 1.907 | symm_mse 4.821 | ppl 3.75 | wps 15245.1 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 25165 | lr 0.000199343 | gnorm 0.796 | train_wall 355 | wall 0
111
2020-12-03 23:19:31 | INFO | fairseq.trainer | begin training epoch 74
2020-12-03 23:19:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:19:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:19:51 | INFO | train_inner | epoch 074:     35 / 719 loss=4.06, nll_loss=1.907, symm_mse=4.822, ppl=3.75, wps=10540.2, ups=1.29, wpb=8164.6, bsz=268.9, num_updates=25200, lr=0.000199205, gnorm=0.777, train_wall=49, wall=0
2020-12-03 23:20:41 | INFO | train_inner | epoch 074:    135 / 719 loss=4.002, nll_loss=1.853, symm_mse=4.702, ppl=3.61, wps=16450.2, ups=2.03, wpb=8110.9, bsz=290.6, num_updates=25300, lr=0.000198811, gnorm=0.778, train_wall=49, wall=0
2020-12-03 23:21:31 | INFO | train_inner | epoch 074:    235 / 719 loss=4.016, nll_loss=1.854, symm_mse=4.83, ppl=3.62, wps=16275.3, ups=2, wpb=8139.7, bsz=282.4, num_updates=25400, lr=0.000198419, gnorm=0.79, train_wall=50, wall=0
2020-12-03 23:22:20 | INFO | train_inner | epoch 074:    335 / 719 loss=4.042, nll_loss=1.891, symm_mse=4.774, ppl=3.71, wps=16300.7, ups=2.01, wpb=8124.7, bsz=276.3, num_updates=25500, lr=0.00019803, gnorm=0.798, train_wall=50, wall=0
2020-12-03 23:23:10 | INFO | train_inner | epoch 074:    435 / 719 loss=4.048, nll_loss=1.893, symm_mse=4.817, ppl=3.71, wps=16665.5, ups=2.02, wpb=8262.6, bsz=277.4, num_updates=25600, lr=0.000197642, gnorm=0.793, train_wall=49, wall=0
2020-12-03 23:24:00 | INFO | train_inner | epoch 074:    535 / 719 loss=4.078, nll_loss=1.92, symm_mse=4.883, ppl=3.79, wps=16567.6, ups=2.01, wpb=8251.5, bsz=270.2, num_updates=25700, lr=0.000197257, gnorm=0.816, train_wall=50, wall=0
2020-12-03 23:24:49 | INFO | train_inner | epoch 074:    635 / 719 loss=4.118, nll_loss=1.955, symm_mse=4.973, ppl=3.88, wps=16308.5, ups=2.01, wpb=8096.8, bsz=268, num_updates=25800, lr=0.000196875, gnorm=0.816, train_wall=49, wall=0
2020-12-03 23:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:25:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:25:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:25:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:25:52 | INFO | valid | epoch 074 | valid on 'valid' subset | symm_mse 0 | loss 8.658 | nll_loss 7.691 | ppl 206.67 | bleu 13.24 | wps 3653.5 | wpb 4629 | bsz 118.9 | num_updates 25884 | best_bleu 13.48
2020-12-03 23:25:52 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:25:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 74 @ 25884 updates, score 13.24) (writing took 3.791036084294319 seconds)
2020-12-03 23:25:56 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2020-12-03 23:25:56 | INFO | train | epoch 074 | loss 4.051 | nll_loss 1.896 | symm_mse 4.821 | ppl 3.72 | wps 15234.7 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 25884 | lr 0.000196555 | gnorm 0.797 | train_wall 355 | wall 0
111
2020-12-03 23:25:56 | INFO | fairseq.trainer | begin training epoch 75
2020-12-03 23:25:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:25:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:25:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:25:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:26:07 | INFO | train_inner | epoch 075:     16 / 719 loss=4.064, nll_loss=1.918, symm_mse=4.776, ppl=3.78, wps=10455.9, ups=1.29, wpb=8116.8, bsz=278.7, num_updates=25900, lr=0.000196494, gnorm=0.799, train_wall=49, wall=0
2020-12-03 23:26:56 | INFO | train_inner | epoch 075:    116 / 719 loss=3.961, nll_loss=1.814, symm_mse=4.643, ppl=3.52, wps=16668.3, ups=2.05, wpb=8129.3, bsz=295.5, num_updates=26000, lr=0.000196116, gnorm=0.798, train_wall=49, wall=0
2020-12-03 23:27:45 | INFO | train_inner | epoch 075:    216 / 719 loss=4.033, nll_loss=1.863, symm_mse=4.922, ppl=3.64, wps=16606.9, ups=2.04, wpb=8157.1, bsz=273.1, num_updates=26100, lr=0.00019574, gnorm=0.808, train_wall=49, wall=0
2020-12-03 23:28:34 | INFO | train_inner | epoch 075:    316 / 719 loss=4.043, nll_loss=1.881, symm_mse=4.868, ppl=3.68, wps=16357.7, ups=2.02, wpb=8089.9, bsz=275.1, num_updates=26200, lr=0.000195366, gnorm=0.81, train_wall=49, wall=0
2020-12-03 23:29:24 | INFO | train_inner | epoch 075:    416 / 719 loss=4.068, nll_loss=1.909, symm_mse=4.876, ppl=3.76, wps=16445, ups=2.01, wpb=8162.9, bsz=273.5, num_updates=26300, lr=0.000194994, gnorm=0.809, train_wall=49, wall=0
2020-12-03 23:30:14 | INFO | train_inner | epoch 075:    516 / 719 loss=4.072, nll_loss=1.909, symm_mse=4.912, ppl=3.76, wps=16532.1, ups=2, wpb=8274, bsz=265.8, num_updates=26400, lr=0.000194625, gnorm=0.79, train_wall=50, wall=0
2020-12-03 23:31:04 | INFO | train_inner | epoch 075:    616 / 719 loss=4.066, nll_loss=1.917, symm_mse=4.805, ppl=3.78, wps=16476.1, ups=2.01, wpb=8189.3, bsz=278.7, num_updates=26500, lr=0.000194257, gnorm=0.804, train_wall=49, wall=0
2020-12-03 23:31:54 | INFO | train_inner | epoch 075:    716 / 719 loss=4.043, nll_loss=1.906, symm_mse=4.679, ppl=3.75, wps=16331, ups=2, wpb=8179.2, bsz=292.9, num_updates=26600, lr=0.000193892, gnorm=0.793, train_wall=50, wall=0
2020-12-03 23:31:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:31:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:31:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:31:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:31:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:31:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:31:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:32:18 | INFO | valid | epoch 075 | valid on 'valid' subset | symm_mse 0 | loss 8.663 | nll_loss 7.701 | ppl 208.08 | bleu 13.36 | wps 3413.8 | wpb 4629 | bsz 118.9 | num_updates 26603 | best_bleu 13.48
2020-12-03 23:32:18 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:32:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:32:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:32:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:32:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:32:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 75 @ 26603 updates, score 13.36) (writing took 3.9812298994511366 seconds)
2020-12-03 23:32:21 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2020-12-03 23:32:22 | INFO | train | epoch 075 | loss 4.041 | nll_loss 1.886 | symm_mse 4.819 | ppl 3.7 | wps 15217.1 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 26603 | lr 0.000193881 | gnorm 0.802 | train_wall 354 | wall 0
111
2020-12-03 23:32:22 | INFO | fairseq.trainer | begin training epoch 76
2020-12-03 23:32:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:32:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:33:12 | INFO | train_inner | epoch 076:     97 / 719 loss=3.972, nll_loss=1.814, symm_mse=4.741, ppl=3.52, wps=10463.4, ups=1.27, wpb=8222.9, bsz=273.9, num_updates=26700, lr=0.000193528, gnorm=0.785, train_wall=49, wall=0
2020-12-03 23:34:02 | INFO | train_inner | epoch 076:    197 / 719 loss=3.974, nll_loss=1.828, symm_mse=4.66, ppl=3.55, wps=16505.7, ups=2.01, wpb=8209, bsz=287.7, num_updates=26800, lr=0.000193167, gnorm=0.791, train_wall=50, wall=0
2020-12-03 23:34:52 | INFO | train_inner | epoch 076:    297 / 719 loss=4.025, nll_loss=1.864, symm_mse=4.836, ppl=3.64, wps=16414.8, ups=2.02, wpb=8137.1, bsz=274.9, num_updates=26900, lr=0.000192807, gnorm=0.805, train_wall=49, wall=0
2020-12-03 23:35:42 | INFO | train_inner | epoch 076:    397 / 719 loss=4.021, nll_loss=1.866, symm_mse=4.8, ppl=3.64, wps=16287.2, ups=2.01, wpb=8101.1, bsz=285.8, num_updates=27000, lr=0.00019245, gnorm=0.801, train_wall=50, wall=0
2020-12-03 23:36:32 | INFO | train_inner | epoch 076:    497 / 719 loss=4.075, nll_loss=1.911, symm_mse=4.934, ppl=3.76, wps=16251.5, ups=2, wpb=8128, bsz=278.3, num_updates=27100, lr=0.000192095, gnorm=0.827, train_wall=50, wall=0
2020-12-03 23:37:21 | INFO | train_inner | epoch 076:    597 / 719 loss=4.125, nll_loss=1.951, symm_mse=5.073, ppl=3.87, wps=16356.4, ups=2.02, wpb=8094.6, bsz=254.3, num_updates=27200, lr=0.000191741, gnorm=0.821, train_wall=49, wall=0
2020-12-03 23:38:11 | INFO | train_inner | epoch 076:    697 / 719 loss=4.039, nll_loss=1.896, symm_mse=4.72, ppl=3.72, wps=16542.9, ups=2.02, wpb=8204.3, bsz=288.2, num_updates=27300, lr=0.00019139, gnorm=0.789, train_wall=49, wall=0
2020-12-03 23:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:22 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:38:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:38:41 | INFO | valid | epoch 076 | valid on 'valid' subset | symm_mse 0 | loss 8.683 | nll_loss 7.728 | ppl 212.08 | bleu 12.99 | wps 3931.4 | wpb 4629 | bsz 118.9 | num_updates 27322 | best_bleu 13.48
2020-12-03 23:38:41 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:38:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:38:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:38:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 76 @ 27322 updates, score 12.99) (writing took 3.7268297858536243 seconds)
2020-12-03 23:38:45 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2020-12-03 23:38:45 | INFO | train | epoch 076 | loss 4.032 | nll_loss 1.875 | symm_mse 4.816 | ppl 3.67 | wps 15314 | ups 1.88 | wpb 8159.9 | bsz 278.2 | num_updates 27322 | lr 0.000191313 | gnorm 0.803 | train_wall 355 | wall 0
111
2020-12-03 23:38:45 | INFO | fairseq.trainer | begin training epoch 77
2020-12-03 23:38:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:38:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:39:26 | INFO | train_inner | epoch 077:     78 / 719 loss=4.015, nll_loss=1.852, symm_mse=4.839, ppl=3.61, wps=10814.4, ups=1.33, wpb=8105.9, bsz=270, num_updates=27400, lr=0.00019104, gnorm=0.818, train_wall=48, wall=0
2020-12-03 23:40:15 | INFO | train_inner | epoch 077:    178 / 719 loss=4.004, nll_loss=1.836, symm_mse=4.855, ppl=3.57, wps=16512.1, ups=2.01, wpb=8235.2, bsz=268.1, num_updates=27500, lr=0.000190693, gnorm=0.797, train_wall=50, wall=0
2020-12-03 23:41:05 | INFO | train_inner | epoch 077:    278 / 719 loss=3.972, nll_loss=1.829, symm_mse=4.642, ppl=3.55, wps=16229.7, ups=2, wpb=8108.7, bsz=300.2, num_updates=27600, lr=0.000190347, gnorm=0.804, train_wall=50, wall=0
2020-12-03 23:41:55 | INFO | train_inner | epoch 077:    378 / 719 loss=4.053, nll_loss=1.889, symm_mse=4.914, ppl=3.7, wps=16293.2, ups=2.02, wpb=8057, bsz=262.4, num_updates=27700, lr=0.000190003, gnorm=0.806, train_wall=49, wall=0
2020-12-03 23:42:45 | INFO | train_inner | epoch 077:    478 / 719 loss=3.984, nll_loss=1.839, symm_mse=4.673, ppl=3.58, wps=16677.7, ups=2.01, wpb=8279.2, bsz=290.5, num_updates=27800, lr=0.000189661, gnorm=0.786, train_wall=49, wall=0
2020-12-03 23:43:34 | INFO | train_inner | epoch 077:    578 / 719 loss=4.053, nll_loss=1.893, symm_mse=4.871, ppl=3.71, wps=16384.2, ups=2.01, wpb=8167.3, bsz=278.3, num_updates=27900, lr=0.000189321, gnorm=0.815, train_wall=50, wall=0
2020-12-03 23:44:24 | INFO | train_inner | epoch 077:    678 / 719 loss=4.068, nll_loss=1.911, symm_mse=4.871, ppl=3.76, wps=16501.1, ups=2.02, wpb=8178.6, bsz=281.4, num_updates=28000, lr=0.000188982, gnorm=0.818, train_wall=49, wall=0
2020-12-03 23:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:44:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:44:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:44:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:44:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:44:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:44:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:45:06 | INFO | valid | epoch 077 | valid on 'valid' subset | symm_mse 0 | loss 8.726 | nll_loss 7.768 | ppl 218.04 | bleu 13.22 | wps 3550.5 | wpb 4629 | bsz 118.9 | num_updates 28041 | best_bleu 13.48
2020-12-03 23:45:06 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:45:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:45:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:45:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:45:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:45:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 77 @ 28041 updates, score 13.22) (writing took 3.7895195614546537 seconds)
2020-12-03 23:45:09 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2020-12-03 23:45:09 | INFO | train | epoch 077 | loss 4.023 | nll_loss 1.866 | symm_mse 4.815 | ppl 3.64 | wps 15246.6 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 28041 | lr 0.000188844 | gnorm 0.806 | train_wall 355 | wall 0
111
2020-12-03 23:45:09 | INFO | fairseq.trainer | begin training epoch 78
2020-12-03 23:45:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:45:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:45:42 | INFO | train_inner | epoch 078:     59 / 719 loss=4.001, nll_loss=1.847, symm_mse=4.755, ppl=3.6, wps=10425.1, ups=1.29, wpb=8096.2, bsz=285.1, num_updates=28100, lr=0.000188646, gnorm=0.792, train_wall=49, wall=0
2020-12-03 23:46:31 | INFO | train_inner | epoch 078:    159 / 719 loss=4.008, nll_loss=1.839, symm_mse=4.88, ppl=3.58, wps=16548.4, ups=2.03, wpb=8154.9, bsz=265.5, num_updates=28200, lr=0.000188311, gnorm=0.802, train_wall=49, wall=0
2020-12-03 23:47:20 | INFO | train_inner | epoch 078:    259 / 719 loss=3.973, nll_loss=1.817, symm_mse=4.749, ppl=3.52, wps=16505.2, ups=2.02, wpb=8189.9, bsz=293.3, num_updates=28300, lr=0.000187978, gnorm=0.8, train_wall=49, wall=0
2020-12-03 23:48:10 | INFO | train_inner | epoch 078:    359 / 719 loss=4.043, nll_loss=1.875, symm_mse=4.929, ppl=3.67, wps=16435.3, ups=2.02, wpb=8150.9, bsz=270.2, num_updates=28400, lr=0.000187647, gnorm=0.802, train_wall=49, wall=0
2020-12-03 23:49:00 | INFO | train_inner | epoch 078:    459 / 719 loss=4.039, nll_loss=1.876, symm_mse=4.874, ppl=3.67, wps=16211.5, ups=2, wpb=8097.6, bsz=269.4, num_updates=28500, lr=0.000187317, gnorm=0.819, train_wall=50, wall=0
2020-12-03 23:49:50 | INFO | train_inner | epoch 078:    559 / 719 loss=3.998, nll_loss=1.853, symm_mse=4.698, ppl=3.61, wps=16328.6, ups=2.02, wpb=8101.9, bsz=282.4, num_updates=28600, lr=0.000186989, gnorm=0.792, train_wall=49, wall=0
2020-12-03 23:50:39 | INFO | train_inner | epoch 078:    659 / 719 loss=4.055, nll_loss=1.9, symm_mse=4.848, ppl=3.73, wps=16446.9, ups=2.01, wpb=8200.5, bsz=272.1, num_updates=28700, lr=0.000186663, gnorm=0.818, train_wall=50, wall=0
2020-12-03 23:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:51:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:31 | INFO | valid | epoch 078 | valid on 'valid' subset | symm_mse 0 | loss 8.663 | nll_loss 7.696 | ppl 207.42 | bleu 13.12 | wps 3544.1 | wpb 4629 | bsz 118.9 | num_updates 28760 | best_bleu 13.48
2020-12-03 23:51:31 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:51:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 78 @ 28760 updates, score 13.12) (writing took 3.974052892997861 seconds)
2020-12-03 23:51:35 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2020-12-03 23:51:35 | INFO | train | epoch 078 | loss 4.013 | nll_loss 1.856 | symm_mse 4.805 | ppl 3.62 | wps 15233.5 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 28760 | lr 0.000186469 | gnorm 0.801 | train_wall 355 | wall 0
111
2020-12-03 23:51:35 | INFO | fairseq.trainer | begin training epoch 79
2020-12-03 23:51:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:51:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:51:57 | INFO | train_inner | epoch 079:     40 / 719 loss=3.97, nll_loss=1.827, symm_mse=4.637, ppl=3.55, wps=10600.1, ups=1.28, wpb=8265.9, bsz=301.4, num_updates=28800, lr=0.000186339, gnorm=0.781, train_wall=49, wall=0
2020-12-03 23:52:47 | INFO | train_inner | epoch 079:    140 / 719 loss=4.007, nll_loss=1.831, symm_mse=4.929, ppl=3.56, wps=16711.5, ups=2.04, wpb=8199.6, bsz=263.9, num_updates=28900, lr=0.000186016, gnorm=0.818, train_wall=49, wall=0
2020-12-03 23:53:36 | INFO | train_inner | epoch 079:    240 / 719 loss=4.002, nll_loss=1.831, symm_mse=4.895, ppl=3.56, wps=16226.2, ups=2.01, wpb=8078.9, bsz=276.6, num_updates=29000, lr=0.000185695, gnorm=0.824, train_wall=50, wall=0
2020-12-03 23:54:26 | INFO | train_inner | epoch 079:    340 / 719 loss=3.969, nll_loss=1.816, symm_mse=4.716, ppl=3.52, wps=16671.7, ups=2.02, wpb=8271.4, bsz=284.2, num_updates=29100, lr=0.000185376, gnorm=0.789, train_wall=49, wall=0
2020-12-03 23:55:16 | INFO | train_inner | epoch 079:    440 / 719 loss=4.009, nll_loss=1.857, symm_mse=4.762, ppl=3.62, wps=16361.6, ups=2.01, wpb=8159.1, bsz=281.8, num_updates=29200, lr=0.000185058, gnorm=0.829, train_wall=50, wall=0
2020-12-03 23:56:05 | INFO | train_inner | epoch 079:    540 / 719 loss=4.046, nll_loss=1.882, symm_mse=4.899, ppl=3.68, wps=16251.9, ups=2.02, wpb=8064.2, bsz=264.1, num_updates=29300, lr=0.000184742, gnorm=0.821, train_wall=49, wall=0
2020-12-03 23:56:55 | INFO | train_inner | epoch 079:    640 / 719 loss=4.022, nll_loss=1.873, symm_mse=4.766, ppl=3.66, wps=16455, ups=2.02, wpb=8164.3, bsz=279, num_updates=29400, lr=0.000184428, gnorm=0.794, train_wall=49, wall=0
2020-12-03 23:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-03 23:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:57:57 | INFO | valid | epoch 079 | valid on 'valid' subset | symm_mse 0 | loss 8.678 | nll_loss 7.714 | ppl 209.89 | bleu 13.3 | wps 3395.7 | wpb 4629 | bsz 118.9 | num_updates 29479 | best_bleu 13.48
2020-12-03 23:57:57 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-03 23:57:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:57:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:58:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:58:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:58:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 79 @ 29479 updates, score 13.3) (writing took 3.92331038787961 seconds)
2020-12-03 23:58:01 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2020-12-03 23:58:01 | INFO | train | epoch 079 | loss 4.005 | nll_loss 1.847 | symm_mse 4.806 | ppl 3.6 | wps 15201.5 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 29479 | lr 0.00018418 | gnorm 0.81 | train_wall 354 | wall 0
111
2020-12-03 23:58:01 | INFO | fairseq.trainer | begin training epoch 80
2020-12-03 23:58:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-03 23:58:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-03 23:58:14 | INFO | train_inner | epoch 080:     21 / 719 loss=4.024, nll_loss=1.866, symm_mse=4.827, ppl=3.65, wps=10351.6, ups=1.27, wpb=8154.1, bsz=272.2, num_updates=29500, lr=0.000184115, gnorm=0.808, train_wall=49, wall=0
2020-12-03 23:59:03 | INFO | train_inner | epoch 080:    121 / 719 loss=3.907, nll_loss=1.761, symm_mse=4.577, ppl=3.39, wps=16742.9, ups=2.03, wpb=8255.3, bsz=289.8, num_updates=29600, lr=0.000183804, gnorm=0.778, train_wall=49, wall=0
2020-12-03 23:59:53 | INFO | train_inner | epoch 080:    221 / 719 loss=3.998, nll_loss=1.831, symm_mse=4.86, ppl=3.56, wps=16270.7, ups=2.02, wpb=8069.7, bsz=281, num_updates=29700, lr=0.000183494, gnorm=0.812, train_wall=49, wall=0
2020-12-04 00:00:43 | INFO | train_inner | epoch 080:    321 / 719 loss=3.996, nll_loss=1.834, symm_mse=4.818, ppl=3.56, wps=16362.7, ups=2, wpb=8196.8, bsz=275.7, num_updates=29800, lr=0.000183186, gnorm=0.807, train_wall=50, wall=0
2020-12-04 00:01:32 | INFO | train_inner | epoch 080:    421 / 719 loss=4.002, nll_loss=1.845, symm_mse=4.798, ppl=3.59, wps=16395.1, ups=2.01, wpb=8141.6, bsz=273.6, num_updates=29900, lr=0.000182879, gnorm=0.807, train_wall=49, wall=0
2020-12-04 00:02:22 | INFO | train_inner | epoch 080:    521 / 719 loss=3.996, nll_loss=1.838, symm_mse=4.8, ppl=3.57, wps=16451.6, ups=2.02, wpb=8163.6, bsz=285.2, num_updates=30000, lr=0.000182574, gnorm=0.819, train_wall=49, wall=0
2020-12-04 00:03:11 | INFO | train_inner | epoch 080:    621 / 719 loss=4.051, nll_loss=1.885, symm_mse=4.938, ppl=3.69, wps=16470.7, ups=2.03, wpb=8128.1, bsz=269.5, num_updates=30100, lr=0.000182271, gnorm=0.828, train_wall=49, wall=0
2020-12-04 00:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:04:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:22 | INFO | valid | epoch 080 | valid on 'valid' subset | symm_mse 0 | loss 8.658 | nll_loss 7.69 | ppl 206.56 | bleu 13.33 | wps 3491.5 | wpb 4629 | bsz 118.9 | num_updates 30198 | best_bleu 13.48
2020-12-04 00:04:22 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:04:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:24 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 80 @ 30198 updates, score 13.33) (writing took 3.9076614920049906 seconds)
2020-12-04 00:04:26 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2020-12-04 00:04:26 | INFO | train | epoch 080 | loss 3.997 | nll_loss 1.837 | symm_mse 4.806 | ppl 3.57 | wps 15227.6 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 30198 | lr 0.000181975 | gnorm 0.809 | train_wall 355 | wall 0
111
2020-12-04 00:04:26 | INFO | fairseq.trainer | begin training epoch 81
2020-12-04 00:04:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:04:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:04:30 | INFO | train_inner | epoch 081:      2 / 719 loss=4.017, nll_loss=1.867, symm_mse=4.765, ppl=3.65, wps=10344, ups=1.27, wpb=8172.8, bsz=281.6, num_updates=30200, lr=0.000181969, gnorm=0.81, train_wall=49, wall=0
2020-12-04 00:05:19 | INFO | train_inner | epoch 081:    102 / 719 loss=3.944, nll_loss=1.78, symm_mse=4.765, ppl=3.43, wps=16933.6, ups=2.05, wpb=8245.8, bsz=274.3, num_updates=30300, lr=0.000181668, gnorm=0.808, train_wall=48, wall=0
2020-12-04 00:06:08 | INFO | train_inner | epoch 081:    202 / 719 loss=3.972, nll_loss=1.801, symm_mse=4.857, ppl=3.49, wps=16560.6, ups=2.03, wpb=8144.7, bsz=269.8, num_updates=30400, lr=0.000181369, gnorm=0.814, train_wall=49, wall=0
2020-12-04 00:06:58 | INFO | train_inner | epoch 081:    302 / 719 loss=3.965, nll_loss=1.815, symm_mse=4.694, ppl=3.52, wps=16315.9, ups=2.01, wpb=8123.9, bsz=290.7, num_updates=30500, lr=0.000181071, gnorm=0.804, train_wall=50, wall=0
2020-12-04 00:07:48 | INFO | train_inner | epoch 081:    402 / 719 loss=3.99, nll_loss=1.835, symm_mse=4.761, ppl=3.57, wps=16243.8, ups=2, wpb=8117.9, bsz=283.2, num_updates=30600, lr=0.000180775, gnorm=0.802, train_wall=50, wall=0
2020-12-04 00:08:38 | INFO | train_inner | epoch 081:    502 / 719 loss=4.015, nll_loss=1.856, symm_mse=4.829, ppl=3.62, wps=16333.9, ups=2.01, wpb=8124.4, bsz=278.2, num_updates=30700, lr=0.000180481, gnorm=0.811, train_wall=50, wall=0
2020-12-04 00:09:28 | INFO | train_inner | epoch 081:    602 / 719 loss=4.005, nll_loss=1.848, symm_mse=4.817, ppl=3.6, wps=16411.2, ups=2.01, wpb=8175.3, bsz=279.4, num_updates=30800, lr=0.000180187, gnorm=0.822, train_wall=50, wall=0
2020-12-04 00:10:17 | INFO | train_inner | epoch 081:    702 / 719 loss=4.019, nll_loss=1.858, symm_mse=4.854, ppl=3.63, wps=16644.2, ups=2.02, wpb=8248.3, bsz=274.2, num_updates=30900, lr=0.000179896, gnorm=0.804, train_wall=49, wall=0
2020-12-04 00:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:10:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:10:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:10:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:10:48 | INFO | valid | epoch 081 | valid on 'valid' subset | symm_mse 0 | loss 8.671 | nll_loss 7.709 | ppl 209.19 | bleu 13.4 | wps 3438.3 | wpb 4629 | bsz 118.9 | num_updates 30917 | best_bleu 13.48
2020-12-04 00:10:48 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:10:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:10:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:10:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 81 @ 30917 updates, score 13.4) (writing took 3.944237444549799 seconds)
2020-12-04 00:10:51 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2020-12-04 00:10:51 | INFO | train | epoch 081 | loss 3.989 | nll_loss 1.829 | symm_mse 4.801 | ppl 3.55 | wps 15211.6 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 30917 | lr 0.000179846 | gnorm 0.81 | train_wall 355 | wall 0
111
2020-12-04 00:10:51 | INFO | fairseq.trainer | begin training epoch 82
2020-12-04 00:10:52 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:10:54 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:11:35 | INFO | train_inner | epoch 082:     83 / 719 loss=3.945, nll_loss=1.774, symm_mse=4.832, ppl=3.42, wps=10359.7, ups=1.28, wpb=8102.3, bsz=274.6, num_updates=31000, lr=0.000179605, gnorm=0.819, train_wall=49, wall=0
2020-12-04 00:12:25 | INFO | train_inner | epoch 082:    183 / 719 loss=3.928, nll_loss=1.777, symm_mse=4.656, ppl=3.43, wps=16508.4, ups=2.03, wpb=8142.6, bsz=286.1, num_updates=31100, lr=0.000179316, gnorm=0.792, train_wall=49, wall=0
2020-12-04 00:13:14 | INFO | train_inner | epoch 082:    283 / 719 loss=3.981, nll_loss=1.808, symm_mse=4.902, ppl=3.5, wps=16565.9, ups=2.02, wpb=8211.9, bsz=275.8, num_updates=31200, lr=0.000179029, gnorm=0.812, train_wall=49, wall=0
2020-12-04 00:14:04 | INFO | train_inner | epoch 082:    383 / 719 loss=3.991, nll_loss=1.833, symm_mse=4.786, ppl=3.56, wps=16220.3, ups=2, wpb=8103.2, bsz=274.1, num_updates=31300, lr=0.000178743, gnorm=0.812, train_wall=50, wall=0
2020-12-04 00:14:54 | INFO | train_inner | epoch 082:    483 / 719 loss=4.028, nll_loss=1.862, symm_mse=4.907, ppl=3.63, wps=16283.3, ups=2.01, wpb=8102.4, bsz=272, num_updates=31400, lr=0.000178458, gnorm=0.829, train_wall=50, wall=0
2020-12-04 00:15:44 | INFO | train_inner | epoch 082:    583 / 719 loss=4.001, nll_loss=1.842, symm_mse=4.814, ppl=3.59, wps=16466.1, ups=2, wpb=8233.9, bsz=283.4, num_updates=31500, lr=0.000178174, gnorm=0.849, train_wall=50, wall=0
2020-12-04 00:16:34 | INFO | train_inner | epoch 082:    683 / 719 loss=4.003, nll_loss=1.853, symm_mse=4.748, ppl=3.61, wps=16434.7, ups=2.01, wpb=8173.2, bsz=283.1, num_updates=31600, lr=0.000177892, gnorm=0.812, train_wall=49, wall=0
2020-12-04 00:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:16:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:16:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:17:14 | INFO | valid | epoch 082 | valid on 'valid' subset | symm_mse 0 | loss 8.648 | nll_loss 7.685 | ppl 205.73 | bleu 13.49 | wps 3445.6 | wpb 4629 | bsz 118.9 | num_updates 31636 | best_bleu 13.49
2020-12-04 00:17:14 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:17:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:17:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:17:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:17:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 82 @ 31636 updates, score 13.49) (writing took 6.619715141132474 seconds)
2020-12-04 00:17:20 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2020-12-04 00:17:20 | INFO | train | epoch 082 | loss 3.982 | nll_loss 1.821 | symm_mse 4.801 | ppl 3.53 | wps 15088.6 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 31636 | lr 0.000177791 | gnorm 0.818 | train_wall 355 | wall 0
111
2020-12-04 00:17:20 | INFO | fairseq.trainer | begin training epoch 83
2020-12-04 00:17:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:17:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:17:55 | INFO | train_inner | epoch 083:     64 / 719 loss=3.985, nll_loss=1.812, symm_mse=4.891, ppl=3.51, wps=10049.7, ups=1.24, wpb=8112.9, bsz=258.2, num_updates=31700, lr=0.000177611, gnorm=0.836, train_wall=48, wall=0
2020-12-04 00:18:44 | INFO | train_inner | epoch 083:    164 / 719 loss=3.933, nll_loss=1.769, symm_mse=4.762, ppl=3.41, wps=16445.2, ups=2.03, wpb=8119.3, bsz=277.8, num_updates=31800, lr=0.000177332, gnorm=0.8, train_wall=49, wall=0
2020-12-04 00:19:33 | INFO | train_inner | epoch 083:    264 / 719 loss=3.955, nll_loss=1.79, symm_mse=4.791, ppl=3.46, wps=16519.2, ups=2.02, wpb=8160.3, bsz=278.6, num_updates=31900, lr=0.000177054, gnorm=0.816, train_wall=49, wall=0
2020-12-04 00:20:23 | INFO | train_inner | epoch 083:    364 / 719 loss=3.974, nll_loss=1.808, symm_mse=4.83, ppl=3.5, wps=16453.1, ups=2.02, wpb=8139.9, bsz=274.2, num_updates=32000, lr=0.000176777, gnorm=0.815, train_wall=49, wall=0
2020-12-04 00:21:12 | INFO | train_inner | epoch 083:    464 / 719 loss=3.974, nll_loss=1.818, symm_mse=4.759, ppl=3.53, wps=16579.9, ups=2.02, wpb=8194.3, bsz=288.9, num_updates=32100, lr=0.000176501, gnorm=0.83, train_wall=49, wall=0
2020-12-04 00:22:02 | INFO | train_inner | epoch 083:    564 / 719 loss=3.987, nll_loss=1.83, symm_mse=4.783, ppl=3.55, wps=16304.8, ups=2, wpb=8162.4, bsz=281.7, num_updates=32200, lr=0.000176227, gnorm=0.81, train_wall=50, wall=0
2020-12-04 00:22:52 | INFO | train_inner | epoch 083:    664 / 719 loss=4.007, nll_loss=1.851, symm_mse=4.805, ppl=3.61, wps=16612, ups=2.02, wpb=8237.7, bsz=280.4, num_updates=32300, lr=0.000175954, gnorm=0.807, train_wall=49, wall=0
2020-12-04 00:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:23:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:23:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:23:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:23:41 | INFO | valid | epoch 083 | valid on 'valid' subset | symm_mse 0 | loss 8.686 | nll_loss 7.721 | ppl 211.02 | bleu 13.52 | wps 3498.9 | wpb 4629 | bsz 118.9 | num_updates 32355 | best_bleu 13.52
2020-12-04 00:23:41 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:23:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:23:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 83 @ 32355 updates, score 13.52) (writing took 6.650673920288682 seconds)
2020-12-04 00:23:47 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2020-12-04 00:23:47 | INFO | train | epoch 083 | loss 3.973 | nll_loss 1.812 | symm_mse 4.793 | ppl 3.51 | wps 15154.5 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 32355 | lr 0.000175804 | gnorm 0.815 | train_wall 353 | wall 0
111
2020-12-04 00:23:47 | INFO | fairseq.trainer | begin training epoch 84
2020-12-04 00:23:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:23:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:24:13 | INFO | train_inner | epoch 084:     45 / 719 loss=3.97, nll_loss=1.814, symm_mse=4.752, ppl=3.52, wps=10068.7, ups=1.24, wpb=8146.6, bsz=278.2, num_updates=32400, lr=0.000175682, gnorm=0.803, train_wall=49, wall=0
2020-12-04 00:25:02 | INFO | train_inner | epoch 084:    145 / 719 loss=3.933, nll_loss=1.761, symm_mse=4.814, ppl=3.39, wps=16761.1, ups=2.04, wpb=8225.4, bsz=275.6, num_updates=32500, lr=0.000175412, gnorm=0.815, train_wall=49, wall=0
2020-12-04 00:25:51 | INFO | train_inner | epoch 084:    245 / 719 loss=3.921, nll_loss=1.765, symm_mse=4.691, ppl=3.4, wps=16490.7, ups=2.02, wpb=8183.7, bsz=300.2, num_updates=32600, lr=0.000175142, gnorm=0.806, train_wall=49, wall=0
2020-12-04 00:26:41 | INFO | train_inner | epoch 084:    345 / 719 loss=3.94, nll_loss=1.781, symm_mse=4.734, ppl=3.44, wps=16521.4, ups=2.02, wpb=8195.1, bsz=277.2, num_updates=32700, lr=0.000174874, gnorm=0.804, train_wall=49, wall=0
2020-12-04 00:27:31 | INFO | train_inner | epoch 084:    445 / 719 loss=3.987, nll_loss=1.815, symm_mse=4.894, ppl=3.52, wps=16489.4, ups=2.01, wpb=8196.6, bsz=270.9, num_updates=32800, lr=0.000174608, gnorm=0.833, train_wall=49, wall=0
2020-12-04 00:28:20 | INFO | train_inner | epoch 084:    545 / 719 loss=3.979, nll_loss=1.828, symm_mse=4.723, ppl=3.55, wps=16337.2, ups=2.02, wpb=8072, bsz=280.9, num_updates=32900, lr=0.000174342, gnorm=0.835, train_wall=49, wall=0
2020-12-04 00:29:10 | INFO | train_inner | epoch 084:    645 / 719 loss=4.022, nll_loss=1.854, symm_mse=4.905, ppl=3.62, wps=16294.8, ups=2.01, wpb=8111.8, bsz=265.5, num_updates=33000, lr=0.000174078, gnorm=0.833, train_wall=50, wall=0
2020-12-04 00:29:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:29:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:29:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:29:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:29:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:29:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:29:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:30:09 | INFO | valid | epoch 084 | valid on 'valid' subset | symm_mse 0 | loss 8.648 | nll_loss 7.681 | ppl 205.26 | bleu 13.57 | wps 3322.6 | wpb 4629 | bsz 118.9 | num_updates 33074 | best_bleu 13.57
2020-12-04 00:30:09 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:30:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:30:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:30:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:30:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:30:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 84 @ 33074 updates, score 13.57) (writing took 6.274181883782148 seconds)
2020-12-04 00:30:15 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2020-12-04 00:30:15 | INFO | train | epoch 084 | loss 3.965 | nll_loss 1.803 | symm_mse 4.794 | ppl 3.49 | wps 15124.6 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 33074 | lr 0.000173883 | gnorm 0.82 | train_wall 354 | wall 0
111
2020-12-04 00:30:15 | INFO | fairseq.trainer | begin training epoch 85
2020-12-04 00:30:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:30:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:30:31 | INFO | train_inner | epoch 085:     26 / 719 loss=3.956, nll_loss=1.807, symm_mse=4.686, ppl=3.5, wps=9988.9, ups=1.23, wpb=8139.5, bsz=281.6, num_updates=33100, lr=0.000173814, gnorm=0.808, train_wall=49, wall=0
2020-12-04 00:31:21 | INFO | train_inner | epoch 085:    126 / 719 loss=3.926, nll_loss=1.756, symm_mse=4.795, ppl=3.38, wps=16579.4, ups=2.03, wpb=8158.8, bsz=280, num_updates=33200, lr=0.000173553, gnorm=0.81, train_wall=49, wall=0
2020-12-04 00:32:10 | INFO | train_inner | epoch 085:    226 / 719 loss=3.893, nll_loss=1.743, symm_mse=4.611, ppl=3.35, wps=16464.9, ups=2.01, wpb=8203.9, bsz=307.2, num_updates=33300, lr=0.000173292, gnorm=0.807, train_wall=50, wall=0
2020-12-04 00:33:00 | INFO | train_inner | epoch 085:    326 / 719 loss=3.964, nll_loss=1.795, symm_mse=4.844, ppl=3.47, wps=16381.7, ups=2.02, wpb=8096.2, bsz=274.1, num_updates=33400, lr=0.000173032, gnorm=0.831, train_wall=49, wall=0
2020-12-04 00:33:49 | INFO | train_inner | epoch 085:    426 / 719 loss=3.967, nll_loss=1.802, symm_mse=4.819, ppl=3.49, wps=16406, ups=2.02, wpb=8123.4, bsz=273.1, num_updates=33500, lr=0.000172774, gnorm=0.831, train_wall=49, wall=0
2020-12-04 00:34:39 | INFO | train_inner | epoch 085:    526 / 719 loss=3.98, nll_loss=1.811, symm_mse=4.874, ppl=3.51, wps=16351.8, ups=2, wpb=8168.1, bsz=270.5, num_updates=33600, lr=0.000172516, gnorm=0.823, train_wall=50, wall=0
2020-12-04 00:35:29 | INFO | train_inner | epoch 085:    626 / 719 loss=3.988, nll_loss=1.822, symm_mse=4.859, ppl=3.54, wps=16334.9, ups=2, wpb=8152.8, bsz=277.7, num_updates=33700, lr=0.00017226, gnorm=0.829, train_wall=50, wall=0
2020-12-04 00:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:36:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:37 | INFO | valid | epoch 085 | valid on 'valid' subset | symm_mse 0 | loss 8.664 | nll_loss 7.701 | ppl 208.02 | bleu 13.57 | wps 3623.4 | wpb 4629 | bsz 118.9 | num_updates 33793 | best_bleu 13.57
2020-12-04 00:36:37 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:36:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 85 @ 33793 updates, score 13.57) (writing took 6.453069195151329 seconds)
2020-12-04 00:36:43 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2020-12-04 00:36:43 | INFO | train | epoch 085 | loss 3.959 | nll_loss 1.795 | symm_mse 4.8 | ppl 3.47 | wps 15130.1 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 33793 | lr 0.000172023 | gnorm 0.821 | train_wall 355 | wall 0
111
2020-12-04 00:36:43 | INFO | fairseq.trainer | begin training epoch 86
2020-12-04 00:36:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:36:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:36:50 | INFO | train_inner | epoch 086:      7 / 719 loss=4.017, nll_loss=1.852, symm_mse=4.885, ppl=3.61, wps=10141.8, ups=1.24, wpb=8197, bsz=260.2, num_updates=33800, lr=0.000172005, gnorm=0.823, train_wall=49, wall=0
2020-12-04 00:37:39 | INFO | train_inner | epoch 086:    107 / 719 loss=3.966, nll_loss=1.78, symm_mse=4.962, ppl=3.43, wps=16681.7, ups=2.06, wpb=8095.2, bsz=254.8, num_updates=33900, lr=0.000171751, gnorm=0.827, train_wall=48, wall=0
2020-12-04 00:38:28 | INFO | train_inner | epoch 086:    207 / 719 loss=3.951, nll_loss=1.781, symm_mse=4.828, ppl=3.44, wps=16531.6, ups=2.03, wpb=8154.4, bsz=267, num_updates=34000, lr=0.000171499, gnorm=0.833, train_wall=49, wall=0
2020-12-04 00:39:18 | INFO | train_inner | epoch 086:    307 / 719 loss=3.917, nll_loss=1.765, symm_mse=4.66, ppl=3.4, wps=16385.1, ups=2, wpb=8182.1, bsz=288.2, num_updates=34100, lr=0.000171247, gnorm=0.817, train_wall=50, wall=0
2020-12-04 00:40:08 | INFO | train_inner | epoch 086:    407 / 719 loss=3.946, nll_loss=1.787, symm_mse=4.743, ppl=3.45, wps=16528.5, ups=2.01, wpb=8203.6, bsz=290.7, num_updates=34200, lr=0.000170996, gnorm=0.812, train_wall=49, wall=0
2020-12-04 00:40:57 | INFO | train_inner | epoch 086:    507 / 719 loss=3.965, nll_loss=1.797, symm_mse=4.839, ppl=3.48, wps=16447.4, ups=2.02, wpb=8150.4, bsz=271.2, num_updates=34300, lr=0.000170747, gnorm=0.826, train_wall=49, wall=0
2020-12-04 00:41:47 | INFO | train_inner | epoch 086:    607 / 719 loss=3.954, nll_loss=1.796, symm_mse=4.753, ppl=3.47, wps=16439.4, ups=2.01, wpb=8194.6, bsz=288.4, num_updates=34400, lr=0.000170499, gnorm=0.832, train_wall=50, wall=0
2020-12-04 00:42:36 | INFO | train_inner | epoch 086:    707 / 719 loss=3.952, nll_loss=1.796, symm_mse=4.74, ppl=3.47, wps=16481.4, ups=2.02, wpb=8169.1, bsz=294.6, num_updates=34500, lr=0.000170251, gnorm=0.822, train_wall=49, wall=0
2020-12-04 00:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:42:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:42:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:42:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:42:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:42:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:42:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:43:04 | INFO | valid | epoch 086 | valid on 'valid' subset | symm_mse 0 | loss 8.671 | nll_loss 7.709 | ppl 209.22 | bleu 13.2 | wps 3521.2 | wpb 4629 | bsz 118.9 | num_updates 34512 | best_bleu 13.57
2020-12-04 00:43:04 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:43:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:43:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:43:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:43:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:43:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 86 @ 34512 updates, score 13.2) (writing took 3.95161797106266 seconds)
2020-12-04 00:43:08 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2020-12-04 00:43:08 | INFO | train | epoch 086 | loss 3.951 | nll_loss 1.788 | symm_mse 4.791 | ppl 3.45 | wps 15244.1 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 34512 | lr 0.000170222 | gnorm 0.824 | train_wall 354 | wall 0
111
2020-12-04 00:43:08 | INFO | fairseq.trainer | begin training epoch 87
2020-12-04 00:43:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:43:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:43:54 | INFO | train_inner | epoch 087:     88 / 719 loss=3.957, nll_loss=1.778, symm_mse=4.913, ppl=3.43, wps=10398.8, ups=1.28, wpb=8094.2, bsz=259.3, num_updates=34600, lr=0.000170005, gnorm=0.845, train_wall=49, wall=0
2020-12-04 00:44:44 | INFO | train_inner | epoch 087:    188 / 719 loss=3.906, nll_loss=1.736, symm_mse=4.775, ppl=3.33, wps=16580.9, ups=2.02, wpb=8189, bsz=279.4, num_updates=34700, lr=0.00016976, gnorm=0.82, train_wall=49, wall=0
2020-12-04 00:45:33 | INFO | train_inner | epoch 087:    288 / 719 loss=3.943, nll_loss=1.775, symm_mse=4.812, ppl=3.42, wps=16253.9, ups=2.02, wpb=8056.6, bsz=280.8, num_updates=34800, lr=0.000169516, gnorm=0.829, train_wall=49, wall=0
2020-12-04 00:46:23 | INFO | train_inner | epoch 087:    388 / 719 loss=3.96, nll_loss=1.792, symm_mse=4.844, ppl=3.46, wps=16595.3, ups=2.01, wpb=8270.1, bsz=270.7, num_updates=34900, lr=0.000169273, gnorm=0.812, train_wall=50, wall=0
2020-12-04 00:47:13 | INFO | train_inner | epoch 087:    488 / 719 loss=3.954, nll_loss=1.79, symm_mse=4.797, ppl=3.46, wps=16568.5, ups=2.02, wpb=8182.9, bsz=284.1, num_updates=35000, lr=0.000169031, gnorm=0.831, train_wall=49, wall=0
2020-12-04 00:48:03 | INFO | train_inner | epoch 087:    588 / 719 loss=3.951, nll_loss=1.797, symm_mse=4.73, ppl=3.47, wps=16257.3, ups=2, wpb=8132.1, bsz=275.9, num_updates=35100, lr=0.00016879, gnorm=0.809, train_wall=50, wall=0
2020-12-04 00:48:52 | INFO | train_inner | epoch 087:    688 / 719 loss=3.954, nll_loss=1.797, symm_mse=4.763, ppl=3.47, wps=16336.7, ups=2.01, wpb=8133.4, bsz=285.5, num_updates=35200, lr=0.00016855, gnorm=0.83, train_wall=50, wall=0
2020-12-04 00:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:49:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:49:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:49:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:49:30 | INFO | valid | epoch 087 | valid on 'valid' subset | symm_mse 0 | loss 8.7 | nll_loss 7.738 | ppl 213.42 | bleu 13.47 | wps 3414.2 | wpb 4629 | bsz 118.9 | num_updates 35231 | best_bleu 13.57
2020-12-04 00:49:30 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:31 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:49:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:49:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 87 @ 35231 updates, score 13.47) (writing took 3.8320323955267668 seconds)
2020-12-04 00:49:34 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2020-12-04 00:49:34 | INFO | train | epoch 087 | loss 3.945 | nll_loss 1.78 | symm_mse 4.796 | ppl 3.43 | wps 15208.2 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 35231 | lr 0.000168476 | gnorm 0.824 | train_wall 355 | wall 0
111
2020-12-04 00:49:34 | INFO | fairseq.trainer | begin training epoch 88
2020-12-04 00:49:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:49:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:50:11 | INFO | train_inner | epoch 088:     69 / 719 loss=3.918, nll_loss=1.755, symm_mse=4.737, ppl=3.38, wps=10509.9, ups=1.27, wpb=8249.6, bsz=283.2, num_updates=35300, lr=0.000168311, gnorm=0.808, train_wall=49, wall=0
2020-12-04 00:51:00 | INFO | train_inner | epoch 088:    169 / 719 loss=3.898, nll_loss=1.738, symm_mse=4.685, ppl=3.34, wps=16480.5, ups=2.01, wpb=8181, bsz=279.9, num_updates=35400, lr=0.000168073, gnorm=0.81, train_wall=49, wall=0
2020-12-04 00:51:50 | INFO | train_inner | epoch 088:    269 / 719 loss=3.936, nll_loss=1.761, symm_mse=4.87, ppl=3.39, wps=16431.5, ups=2.01, wpb=8176.7, bsz=284.4, num_updates=35500, lr=0.000167836, gnorm=0.83, train_wall=50, wall=0
2020-12-04 00:52:40 | INFO | train_inner | epoch 088:    369 / 719 loss=3.937, nll_loss=1.775, symm_mse=4.757, ppl=3.42, wps=16402.6, ups=2.02, wpb=8123.8, bsz=283.5, num_updates=35600, lr=0.0001676, gnorm=0.814, train_wall=49, wall=0
2020-12-04 00:53:29 | INFO | train_inner | epoch 088:    469 / 719 loss=3.909, nll_loss=1.752, symm_mse=4.697, ppl=3.37, wps=16513.7, ups=2.01, wpb=8198.3, bsz=288.1, num_updates=35700, lr=0.000167365, gnorm=0.812, train_wall=49, wall=0
2020-12-04 00:54:19 | INFO | train_inner | epoch 088:    569 / 719 loss=3.992, nll_loss=1.814, symm_mse=4.97, ppl=3.52, wps=16340.5, ups=2.01, wpb=8142, bsz=263, num_updates=35800, lr=0.000167132, gnorm=0.853, train_wall=50, wall=0
2020-12-04 00:55:09 | INFO | train_inner | epoch 088:    669 / 719 loss=3.963, nll_loss=1.798, symm_mse=4.82, ppl=3.48, wps=16383.6, ups=2.01, wpb=8133, bsz=273.9, num_updates=35900, lr=0.000166899, gnorm=0.82, train_wall=49, wall=0
2020-12-04 00:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 00:55:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:55:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:55:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:55:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:55:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:55:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:55:56 | INFO | valid | epoch 088 | valid on 'valid' subset | symm_mse 0 | loss 8.65 | nll_loss 7.68 | ppl 205.08 | bleu 13.35 | wps 3467.8 | wpb 4629 | bsz 118.9 | num_updates 35950 | best_bleu 13.57
2020-12-04 00:55:56 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 00:55:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:55:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:55:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:55:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:55:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 88 @ 35950 updates, score 13.35) (writing took 3.7199121806770563 seconds)
2020-12-04 00:55:59 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2020-12-04 00:55:59 | INFO | train | epoch 088 | loss 3.938 | nll_loss 1.772 | symm_mse 4.794 | ppl 3.41 | wps 15217.9 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 35950 | lr 0.000166783 | gnorm 0.822 | train_wall 355 | wall 0
111
2020-12-04 00:55:59 | INFO | fairseq.trainer | begin training epoch 89
2020-12-04 00:56:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 00:56:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 00:56:27 | INFO | train_inner | epoch 089:     50 / 719 loss=3.936, nll_loss=1.77, symm_mse=4.786, ppl=3.41, wps=10411.6, ups=1.28, wpb=8156.9, bsz=270.6, num_updates=36000, lr=0.000166667, gnorm=0.81, train_wall=49, wall=0
2020-12-04 00:57:17 | INFO | train_inner | epoch 089:    150 / 719 loss=3.9, nll_loss=1.73, symm_mse=4.775, ppl=3.32, wps=16587.5, ups=2.02, wpb=8231.4, bsz=272, num_updates=36100, lr=0.000166436, gnorm=0.817, train_wall=49, wall=0
2020-12-04 00:58:06 | INFO | train_inner | epoch 089:    250 / 719 loss=3.922, nll_loss=1.754, symm_mse=4.787, ppl=3.37, wps=16375.6, ups=2.02, wpb=8109.4, bsz=278.7, num_updates=36200, lr=0.000166206, gnorm=0.838, train_wall=49, wall=0
2020-12-04 00:58:56 | INFO | train_inner | epoch 089:    350 / 719 loss=3.926, nll_loss=1.761, symm_mse=4.776, ppl=3.39, wps=16472.4, ups=2.03, wpb=8128.6, bsz=292.2, num_updates=36300, lr=0.000165977, gnorm=0.83, train_wall=49, wall=0
2020-12-04 00:59:46 | INFO | train_inner | epoch 089:    450 / 719 loss=3.917, nll_loss=1.758, symm_mse=4.72, ppl=3.38, wps=16538.3, ups=2.01, wpb=8246.6, bsz=282.6, num_updates=36400, lr=0.000165748, gnorm=0.806, train_wall=50, wall=0
2020-12-04 01:00:35 | INFO | train_inner | epoch 089:    550 / 719 loss=3.962, nll_loss=1.793, symm_mse=4.857, ppl=3.46, wps=16466.4, ups=2.02, wpb=8134.2, bsz=262.4, num_updates=36500, lr=0.000165521, gnorm=0.831, train_wall=49, wall=0
2020-12-04 01:01:25 | INFO | train_inner | epoch 089:    650 / 719 loss=3.963, nll_loss=1.792, symm_mse=4.879, ppl=3.46, wps=16277.6, ups=2.01, wpb=8087.9, bsz=266, num_updates=36600, lr=0.000165295, gnorm=0.834, train_wall=49, wall=0
2020-12-04 01:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:20 | INFO | valid | epoch 089 | valid on 'valid' subset | symm_mse 0 | loss 8.637 | nll_loss 7.674 | ppl 204.24 | bleu 13.48 | wps 3476.1 | wpb 4629 | bsz 118.9 | num_updates 36669 | best_bleu 13.57
2020-12-04 01:02:20 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:02:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 89 @ 36669 updates, score 13.48) (writing took 3.9043138828128576 seconds)
2020-12-04 01:02:24 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2020-12-04 01:02:24 | INFO | train | epoch 089 | loss 3.932 | nll_loss 1.765 | symm_mse 4.792 | ppl 3.4 | wps 15236.8 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 36669 | lr 0.000165139 | gnorm 0.825 | train_wall 354 | wall 0
111
2020-12-04 01:02:24 | INFO | fairseq.trainer | begin training epoch 90
2020-12-04 01:02:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:02:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:02:43 | INFO | train_inner | epoch 090:     31 / 719 loss=3.945, nll_loss=1.782, symm_mse=4.781, ppl=3.44, wps=10379.8, ups=1.28, wpb=8102.3, bsz=289.9, num_updates=36700, lr=0.00016507, gnorm=0.83, train_wall=49, wall=0
2020-12-04 01:03:32 | INFO | train_inner | epoch 090:    131 / 719 loss=3.929, nll_loss=1.741, symm_mse=4.949, ppl=3.34, wps=16627.1, ups=2.05, wpb=8117.8, bsz=262.2, num_updates=36800, lr=0.000164845, gnorm=0.839, train_wall=49, wall=0
2020-12-04 01:04:22 | INFO | train_inner | epoch 090:    231 / 719 loss=3.903, nll_loss=1.732, symm_mse=4.792, ppl=3.32, wps=16297, ups=2, wpb=8166.7, bsz=295.7, num_updates=36900, lr=0.000164622, gnorm=0.828, train_wall=50, wall=0
2020-12-04 01:05:12 | INFO | train_inner | epoch 090:    331 / 719 loss=3.907, nll_loss=1.744, symm_mse=4.732, ppl=3.35, wps=16453.4, ups=2, wpb=8215.3, bsz=270.1, num_updates=37000, lr=0.000164399, gnorm=0.813, train_wall=50, wall=0
2020-12-04 01:06:01 | INFO | train_inner | epoch 090:    431 / 719 loss=3.924, nll_loss=1.762, symm_mse=4.752, ppl=3.39, wps=16293.9, ups=2.01, wpb=8099.9, bsz=279, num_updates=37100, lr=0.000164177, gnorm=0.816, train_wall=49, wall=0
2020-12-04 01:06:51 | INFO | train_inner | epoch 090:    531 / 719 loss=3.939, nll_loss=1.777, symm_mse=4.778, ppl=3.43, wps=16611.6, ups=2.02, wpb=8227.7, bsz=286.1, num_updates=37200, lr=0.000163956, gnorm=0.833, train_wall=49, wall=0
2020-12-04 01:07:41 | INFO | train_inner | epoch 090:    631 / 719 loss=3.951, nll_loss=1.793, symm_mse=4.756, ppl=3.47, wps=16330.4, ups=2.01, wpb=8143.8, bsz=276.7, num_updates=37300, lr=0.000163737, gnorm=0.834, train_wall=50, wall=0
2020-12-04 01:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:08:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:08:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:08:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:08:46 | INFO | valid | epoch 090 | valid on 'valid' subset | symm_mse 0 | loss 8.657 | nll_loss 7.691 | ppl 206.7 | bleu 13.62 | wps 3491.1 | wpb 4629 | bsz 118.9 | num_updates 37388 | best_bleu 13.62
2020-12-04 01:08:46 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:08:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:08:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:08:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 90 @ 37388 updates, score 13.62) (writing took 6.290193697437644 seconds)
2020-12-04 01:08:52 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2020-12-04 01:08:52 | INFO | train | epoch 090 | loss 3.925 | nll_loss 1.759 | symm_mse 4.783 | ppl 3.38 | wps 15131.6 | ups 1.85 | wpb 8159.9 | bsz 278.2 | num_updates 37388 | lr 0.000163544 | gnorm 0.826 | train_wall 355 | wall 0
111
2020-12-04 01:08:52 | INFO | fairseq.trainer | begin training epoch 91
2020-12-04 01:08:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:08:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:09:01 | INFO | train_inner | epoch 091:     12 / 719 loss=3.905, nll_loss=1.758, symm_mse=4.619, ppl=3.38, wps=10144.1, ups=1.24, wpb=8181.3, bsz=290.9, num_updates=37400, lr=0.000163517, gnorm=0.814, train_wall=49, wall=0
2020-12-04 01:09:50 | INFO | train_inner | epoch 091:    112 / 719 loss=3.883, nll_loss=1.709, symm_mse=4.791, ppl=3.27, wps=16821.5, ups=2.05, wpb=8195.6, bsz=270.6, num_updates=37500, lr=0.000163299, gnorm=0.82, train_wall=48, wall=0
2020-12-04 01:10:40 | INFO | train_inner | epoch 091:    212 / 719 loss=3.872, nll_loss=1.716, symm_mse=4.632, ppl=3.28, wps=16365.1, ups=1.99, wpb=8239.8, bsz=290.6, num_updates=37600, lr=0.000163082, gnorm=0.819, train_wall=50, wall=0
2020-12-04 01:11:30 | INFO | train_inner | epoch 091:    312 / 719 loss=3.943, nll_loss=1.762, symm_mse=4.914, ppl=3.39, wps=16662.9, ups=2.03, wpb=8222.1, bsz=270.9, num_updates=37700, lr=0.000162866, gnorm=0.835, train_wall=49, wall=0
2020-12-04 01:12:20 | INFO | train_inner | epoch 091:    412 / 719 loss=3.897, nll_loss=1.738, symm_mse=4.693, ppl=3.33, wps=16415.1, ups=2, wpb=8207.6, bsz=303.6, num_updates=37800, lr=0.00016265, gnorm=0.834, train_wall=50, wall=0
2020-12-04 01:13:10 | INFO | train_inner | epoch 091:    512 / 719 loss=3.947, nll_loss=1.775, symm_mse=4.861, ppl=3.42, wps=16262.8, ups=2.01, wpb=8109.7, bsz=257.3, num_updates=37900, lr=0.000162435, gnorm=0.832, train_wall=50, wall=0
2020-12-04 01:14:00 | INFO | train_inner | epoch 091:    612 / 719 loss=3.981, nll_loss=1.8, symm_mse=4.963, ppl=3.48, wps=16201.6, ups=2, wpb=8101.6, bsz=261, num_updates=38000, lr=0.000162221, gnorm=0.862, train_wall=50, wall=0
2020-12-04 01:14:49 | INFO | train_inner | epoch 091:    712 / 719 loss=3.94, nll_loss=1.778, symm_mse=4.784, ppl=3.43, wps=16373.1, ups=2.03, wpb=8073.5, bsz=284.4, num_updates=38100, lr=0.000162008, gnorm=0.836, train_wall=49, wall=0
2020-12-04 01:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:14:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:14:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:14:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:14:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:14:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:14:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:15:14 | INFO | valid | epoch 091 | valid on 'valid' subset | symm_mse 0 | loss 8.745 | nll_loss 7.784 | ppl 220.44 | bleu 13.54 | wps 3542.4 | wpb 4629 | bsz 118.9 | num_updates 38107 | best_bleu 13.62
2020-12-04 01:15:14 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:15:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:15:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:15:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:15:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:15:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 91 @ 38107 updates, score 13.54) (writing took 3.8576706927269697 seconds)
2020-12-04 01:15:18 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2020-12-04 01:15:18 | INFO | train | epoch 091 | loss 3.919 | nll_loss 1.751 | symm_mse 4.792 | ppl 3.37 | wps 15213.3 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 38107 | lr 0.000161994 | gnorm 0.833 | train_wall 355 | wall 0
111
2020-12-04 01:15:18 | INFO | fairseq.trainer | begin training epoch 92
2020-12-04 01:15:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:15:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:16:06 | INFO | train_inner | epoch 092:     93 / 719 loss=3.865, nll_loss=1.696, symm_mse=4.727, ppl=3.24, wps=10574.4, ups=1.29, wpb=8199.3, bsz=274.8, num_updates=38200, lr=0.000161796, gnorm=0.817, train_wall=49, wall=0
2020-12-04 01:16:56 | INFO | train_inner | epoch 092:    193 / 719 loss=3.907, nll_loss=1.734, symm_mse=4.82, ppl=3.33, wps=16482.9, ups=2.03, wpb=8120.3, bsz=285.7, num_updates=38300, lr=0.000161585, gnorm=0.841, train_wall=49, wall=0
2020-12-04 01:17:46 | INFO | train_inner | epoch 092:    293 / 719 loss=3.891, nll_loss=1.727, symm_mse=4.725, ppl=3.31, wps=16265.4, ups=2, wpb=8116.5, bsz=283.6, num_updates=38400, lr=0.000161374, gnorm=0.819, train_wall=50, wall=0
2020-12-04 01:18:35 | INFO | train_inner | epoch 092:    393 / 719 loss=3.925, nll_loss=1.75, symm_mse=4.84, ppl=3.36, wps=16492, ups=2.01, wpb=8208.5, bsz=272.1, num_updates=38500, lr=0.000161165, gnorm=0.835, train_wall=50, wall=0
2020-12-04 01:19:25 | INFO | train_inner | epoch 092:    493 / 719 loss=3.919, nll_loss=1.748, symm_mse=4.816, ppl=3.36, wps=16478.8, ups=2.03, wpb=8120.8, bsz=271.9, num_updates=38600, lr=0.000160956, gnorm=0.849, train_wall=49, wall=0
2020-12-04 01:20:14 | INFO | train_inner | epoch 092:    593 / 719 loss=3.937, nll_loss=1.769, symm_mse=4.827, ppl=3.41, wps=16545.2, ups=2.02, wpb=8202.5, bsz=272.3, num_updates=38700, lr=0.000160748, gnorm=0.83, train_wall=49, wall=0
2020-12-04 01:21:04 | INFO | train_inner | epoch 092:    693 / 719 loss=3.942, nll_loss=1.784, symm_mse=4.756, ppl=3.44, wps=16582.4, ups=2.03, wpb=8166.3, bsz=285.4, num_updates=38800, lr=0.00016054, gnorm=0.836, train_wall=49, wall=0
2020-12-04 01:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:21:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:21:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:21:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:21:38 | INFO | valid | epoch 092 | valid on 'valid' subset | symm_mse 0 | loss 8.697 | nll_loss 7.736 | ppl 213.22 | bleu 13.53 | wps 3580.8 | wpb 4629 | bsz 118.9 | num_updates 38826 | best_bleu 13.62
2020-12-04 01:21:38 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:21:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:21:41 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:21:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 92 @ 38826 updates, score 13.53) (writing took 4.143170913681388 seconds)
2020-12-04 01:21:42 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2020-12-04 01:21:42 | INFO | train | epoch 092 | loss 3.913 | nll_loss 1.745 | symm_mse 4.787 | ppl 3.35 | wps 15277.7 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 38826 | lr 0.000160487 | gnorm 0.833 | train_wall 354 | wall 0
111
2020-12-04 01:21:42 | INFO | fairseq.trainer | begin training epoch 93
2020-12-04 01:21:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:21:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:22:21 | INFO | train_inner | epoch 093:     74 / 719 loss=3.86, nll_loss=1.687, symm_mse=4.756, ppl=3.22, wps=10575.2, ups=1.29, wpb=8226.6, bsz=273.8, num_updates=38900, lr=0.000160334, gnorm=0.824, train_wall=49, wall=0
2020-12-04 01:23:11 | INFO | train_inner | epoch 093:    174 / 719 loss=3.87, nll_loss=1.711, symm_mse=4.658, ppl=3.27, wps=16439.1, ups=2.01, wpb=8192.5, bsz=286.1, num_updates=39000, lr=0.000160128, gnorm=0.815, train_wall=50, wall=0
2020-12-04 01:24:01 | INFO | train_inner | epoch 093:    274 / 719 loss=3.906, nll_loss=1.729, symm_mse=4.84, ppl=3.32, wps=16243, ups=2.01, wpb=8078.4, bsz=268, num_updates=39100, lr=0.000159923, gnorm=0.843, train_wall=50, wall=0
2020-12-04 01:24:51 | INFO | train_inner | epoch 093:    374 / 719 loss=3.905, nll_loss=1.736, symm_mse=4.784, ppl=3.33, wps=16522.9, ups=2.01, wpb=8236.8, bsz=270.5, num_updates=39200, lr=0.000159719, gnorm=0.82, train_wall=50, wall=0
2020-12-04 01:25:40 | INFO | train_inner | epoch 093:    474 / 719 loss=3.912, nll_loss=1.745, symm_mse=4.788, ppl=3.35, wps=16368.3, ups=2.04, wpb=8040, bsz=303, num_updates=39300, lr=0.000159516, gnorm=0.861, train_wall=49, wall=0
2020-12-04 01:26:29 | INFO | train_inner | epoch 093:    574 / 719 loss=3.943, nll_loss=1.77, symm_mse=4.87, ppl=3.41, wps=16681.1, ups=2.03, wpb=8214.3, bsz=262.5, num_updates=39400, lr=0.000159313, gnorm=0.842, train_wall=49, wall=0
2020-12-04 01:27:19 | INFO | train_inner | epoch 093:    674 / 719 loss=3.918, nll_loss=1.761, symm_mse=4.717, ppl=3.39, wps=16459.5, ups=2.02, wpb=8158.1, bsz=286.8, num_updates=39500, lr=0.000159111, gnorm=0.845, train_wall=49, wall=0
2020-12-04 01:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:27:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:27:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:27:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:27:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:27:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:27:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:28:03 | INFO | valid | epoch 093 | valid on 'valid' subset | symm_mse 0 | loss 8.689 | nll_loss 7.725 | ppl 211.55 | bleu 13.36 | wps 3442 | wpb 4629 | bsz 118.9 | num_updates 39545 | best_bleu 13.62
2020-12-04 01:28:03 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:28:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:28:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:28:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:28:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 93 @ 39545 updates, score 13.36) (writing took 3.792889792472124 seconds)
2020-12-04 01:28:07 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2020-12-04 01:28:07 | INFO | train | epoch 093 | loss 3.907 | nll_loss 1.738 | symm_mse 4.788 | ppl 3.34 | wps 15239.6 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 39545 | lr 0.000159021 | gnorm 0.838 | train_wall 354 | wall 0
111
2020-12-04 01:28:07 | INFO | fairseq.trainer | begin training epoch 94
2020-12-04 01:28:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:28:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:28:37 | INFO | train_inner | epoch 094:     55 / 719 loss=3.934, nll_loss=1.754, symm_mse=4.906, ppl=3.37, wps=10324.4, ups=1.28, wpb=8056, bsz=266.2, num_updates=39600, lr=0.00015891, gnorm=0.85, train_wall=48, wall=0
2020-12-04 01:29:26 | INFO | train_inner | epoch 094:    155 / 719 loss=3.865, nll_loss=1.698, symm_mse=4.717, ppl=3.24, wps=16424.6, ups=2.03, wpb=8087.3, bsz=284.3, num_updates=39700, lr=0.00015871, gnorm=0.831, train_wall=49, wall=0
2020-12-04 01:30:16 | INFO | train_inner | epoch 094:    255 / 719 loss=3.893, nll_loss=1.717, symm_mse=4.82, ppl=3.29, wps=16513.9, ups=2.01, wpb=8197.6, bsz=278.5, num_updates=39800, lr=0.000158511, gnorm=0.85, train_wall=49, wall=0
2020-12-04 01:31:05 | INFO | train_inner | epoch 094:    355 / 719 loss=3.885, nll_loss=1.72, symm_mse=4.73, ppl=3.29, wps=16569.6, ups=2.01, wpb=8243.7, bsz=274.8, num_updates=39900, lr=0.000158312, gnorm=0.832, train_wall=50, wall=0
2020-12-04 01:31:55 | INFO | train_inner | epoch 094:    455 / 719 loss=3.905, nll_loss=1.734, symm_mse=4.798, ppl=3.33, wps=16631.4, ups=2.01, wpb=8276, bsz=280.3, num_updates=40000, lr=0.000158114, gnorm=0.834, train_wall=50, wall=0
2020-12-04 01:32:45 | INFO | train_inner | epoch 094:    555 / 719 loss=3.912, nll_loss=1.748, symm_mse=4.767, ppl=3.36, wps=16523.5, ups=2.01, wpb=8232.4, bsz=286, num_updates=40100, lr=0.000157917, gnorm=0.836, train_wall=50, wall=0
2020-12-04 01:33:34 | INFO | train_inner | epoch 094:    655 / 719 loss=3.944, nll_loss=1.772, symm_mse=4.864, ppl=3.42, wps=16372.2, ups=2.04, wpb=8027.1, bsz=275.2, num_updates=40200, lr=0.00015772, gnorm=0.854, train_wall=49, wall=0
2020-12-04 01:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:34:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:27 | INFO | valid | epoch 094 | valid on 'valid' subset | symm_mse 0 | loss 8.631 | nll_loss 7.666 | ppl 203.13 | bleu 13.6 | wps 3473.1 | wpb 4629 | bsz 118.9 | num_updates 40264 | best_bleu 13.62
2020-12-04 01:34:27 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:34:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 94 @ 40264 updates, score 13.6) (writing took 3.6630935445427895 seconds)
2020-12-04 01:34:31 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2020-12-04 01:34:31 | INFO | train | epoch 094 | loss 3.901 | nll_loss 1.732 | symm_mse 4.784 | ppl 3.32 | wps 15283.7 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 40264 | lr 0.000157595 | gnorm 0.838 | train_wall 353 | wall 0
111
2020-12-04 01:34:31 | INFO | fairseq.trainer | begin training epoch 95
2020-12-04 01:34:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:34:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:34:51 | INFO | train_inner | epoch 095:     36 / 719 loss=3.921, nll_loss=1.747, symm_mse=4.847, ppl=3.36, wps=10497.1, ups=1.3, wpb=8085.7, bsz=267.5, num_updates=40300, lr=0.000157524, gnorm=0.845, train_wall=48, wall=0
2020-12-04 01:35:40 | INFO | train_inner | epoch 095:    136 / 719 loss=3.866, nll_loss=1.689, symm_mse=4.799, ppl=3.22, wps=16592.1, ups=2.04, wpb=8150, bsz=277.2, num_updates=40400, lr=0.000157329, gnorm=0.834, train_wall=49, wall=0
2020-12-04 01:36:30 | INFO | train_inner | epoch 095:    236 / 719 loss=3.895, nll_loss=1.716, symm_mse=4.849, ppl=3.29, wps=16417.7, ups=2, wpb=8203.3, bsz=270.1, num_updates=40500, lr=0.000157135, gnorm=0.848, train_wall=50, wall=0
2020-12-04 01:37:20 | INFO | train_inner | epoch 095:    336 / 719 loss=3.847, nll_loss=1.686, symm_mse=4.658, ppl=3.22, wps=16337.8, ups=2, wpb=8163.8, bsz=306.3, num_updates=40600, lr=0.000156941, gnorm=0.836, train_wall=50, wall=0
2020-12-04 01:38:09 | INFO | train_inner | epoch 095:    436 / 719 loss=3.902, nll_loss=1.73, symm_mse=4.809, ppl=3.32, wps=16451.5, ups=2.02, wpb=8128.7, bsz=275.8, num_updates=40700, lr=0.000156748, gnorm=0.847, train_wall=49, wall=0
2020-12-04 01:38:59 | INFO | train_inner | epoch 095:    536 / 719 loss=3.918, nll_loss=1.75, symm_mse=4.796, ppl=3.36, wps=16455.3, ups=2.01, wpb=8175, bsz=270.6, num_updates=40800, lr=0.000156556, gnorm=0.844, train_wall=49, wall=0
2020-12-04 01:39:49 | INFO | train_inner | epoch 095:    636 / 719 loss=3.911, nll_loss=1.752, symm_mse=4.728, ppl=3.37, wps=16605.4, ups=2.02, wpb=8229.2, bsz=279.4, num_updates=40900, lr=0.000156365, gnorm=0.823, train_wall=49, wall=0
2020-12-04 01:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:40:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:40:50 | INFO | valid | epoch 095 | valid on 'valid' subset | symm_mse 0 | loss 8.689 | nll_loss 7.728 | ppl 211.98 | bleu 13.71 | wps 3616.2 | wpb 4629 | bsz 118.9 | num_updates 40983 | best_bleu 13.71
2020-12-04 01:40:50 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:40:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:40:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:40:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 95 @ 40983 updates, score 13.71) (writing took 6.280621647834778 seconds)
2020-12-04 01:40:57 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2020-12-04 01:40:57 | INFO | train | epoch 095 | loss 3.896 | nll_loss 1.726 | symm_mse 4.786 | ppl 3.31 | wps 15200.2 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 40983 | lr 0.000156206 | gnorm 0.842 | train_wall 354 | wall 0
111
2020-12-04 01:40:57 | INFO | fairseq.trainer | begin training epoch 96
2020-12-04 01:40:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:40:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:41:08 | INFO | train_inner | epoch 096:     17 / 719 loss=3.911, nll_loss=1.749, symm_mse=4.74, ppl=3.36, wps=10184.4, ups=1.26, wpb=8094.6, bsz=278.6, num_updates=41000, lr=0.000156174, gnorm=0.846, train_wall=49, wall=0
2020-12-04 01:41:57 | INFO | train_inner | epoch 096:    117 / 719 loss=3.89, nll_loss=1.702, symm_mse=4.905, ppl=3.25, wps=16575.1, ups=2.06, wpb=8062.4, bsz=257.8, num_updates=41100, lr=0.000155984, gnorm=0.863, train_wall=48, wall=0
2020-12-04 01:42:47 | INFO | train_inner | epoch 096:    217 / 719 loss=3.882, nll_loss=1.711, symm_mse=4.772, ppl=3.27, wps=16290.1, ups=2.01, wpb=8098, bsz=282.2, num_updates=41200, lr=0.000155794, gnorm=0.846, train_wall=49, wall=0
2020-12-04 01:43:36 | INFO | train_inner | epoch 096:    317 / 719 loss=3.862, nll_loss=1.697, symm_mse=4.709, ppl=3.24, wps=16504.7, ups=2.02, wpb=8180.8, bsz=290.2, num_updates=41300, lr=0.000155606, gnorm=0.837, train_wall=49, wall=0
2020-12-04 01:44:26 | INFO | train_inner | epoch 096:    417 / 719 loss=3.884, nll_loss=1.72, symm_mse=4.72, ppl=3.29, wps=16370.8, ups=2.01, wpb=8146.7, bsz=280.5, num_updates=41400, lr=0.000155417, gnorm=0.846, train_wall=50, wall=0
2020-12-04 01:45:15 | INFO | train_inner | epoch 096:    517 / 719 loss=3.89, nll_loss=1.721, symm_mse=4.779, ppl=3.3, wps=16651.4, ups=2.02, wpb=8232.6, bsz=293.1, num_updates=41500, lr=0.00015523, gnorm=0.829, train_wall=49, wall=0
2020-12-04 01:46:05 | INFO | train_inner | epoch 096:    617 / 719 loss=3.909, nll_loss=1.741, symm_mse=4.79, ppl=3.34, wps=16539.4, ups=2.01, wpb=8214.3, bsz=273.8, num_updates=41600, lr=0.000155043, gnorm=0.851, train_wall=49, wall=0
2020-12-04 01:46:55 | INFO | train_inner | epoch 096:    717 / 719 loss=3.923, nll_loss=1.749, symm_mse=4.857, ppl=3.36, wps=16524.8, ups=2.01, wpb=8206, bsz=273.6, num_updates=41700, lr=0.000154857, gnorm=0.84, train_wall=49, wall=0
2020-12-04 01:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:46:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:46:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:46:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:46:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:46:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:46:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:47:18 | INFO | valid | epoch 096 | valid on 'valid' subset | symm_mse 0 | loss 8.657 | nll_loss 7.691 | ppl 206.62 | bleu 13.78 | wps 3456.7 | wpb 4629 | bsz 118.9 | num_updates 41702 | best_bleu 13.78
2020-12-04 01:47:18 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:47:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:47:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:47:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:47:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:47:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 96 @ 41702 updates, score 13.78) (writing took 6.529233368113637 seconds)
2020-12-04 01:47:24 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2020-12-04 01:47:24 | INFO | train | epoch 096 | loss 3.891 | nll_loss 1.72 | symm_mse 4.789 | ppl 3.29 | wps 15143 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 41702 | lr 0.000154854 | gnorm 0.845 | train_wall 354 | wall 0
111
2020-12-04 01:47:24 | INFO | fairseq.trainer | begin training epoch 97
2020-12-04 01:47:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:47:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:48:15 | INFO | train_inner | epoch 097:     98 / 719 loss=3.854, nll_loss=1.677, symm_mse=4.775, ppl=3.2, wps=9995.5, ups=1.24, wpb=8051.7, bsz=264, num_updates=41800, lr=0.000154672, gnorm=0.854, train_wall=48, wall=0
2020-12-04 01:49:05 | INFO | train_inner | epoch 097:    198 / 719 loss=3.834, nll_loss=1.671, symm_mse=4.656, ppl=3.18, wps=16583.9, ups=2.02, wpb=8194.8, bsz=282.2, num_updates=41900, lr=0.000154487, gnorm=0.829, train_wall=49, wall=0
2020-12-04 01:49:54 | INFO | train_inner | epoch 097:    298 / 719 loss=3.859, nll_loss=1.692, symm_mse=4.721, ppl=3.23, wps=16454.6, ups=2.01, wpb=8184.2, bsz=291.8, num_updates=42000, lr=0.000154303, gnorm=0.83, train_wall=50, wall=0
2020-12-04 01:50:44 | INFO | train_inner | epoch 097:    398 / 719 loss=3.95, nll_loss=1.757, symm_mse=5.031, ppl=3.38, wps=16240.9, ups=2.01, wpb=8077.4, bsz=251.1, num_updates=42100, lr=0.00015412, gnorm=0.871, train_wall=50, wall=0
2020-12-04 01:51:34 | INFO | train_inner | epoch 097:    498 / 719 loss=3.889, nll_loss=1.724, symm_mse=4.74, ppl=3.3, wps=16607.7, ups=2.01, wpb=8244.9, bsz=277.8, num_updates=42200, lr=0.000153937, gnorm=0.82, train_wall=49, wall=0
2020-12-04 01:52:24 | INFO | train_inner | epoch 097:    598 / 719 loss=3.913, nll_loss=1.742, symm_mse=4.823, ppl=3.35, wps=16395.8, ups=2, wpb=8187.9, bsz=283.5, num_updates=42300, lr=0.000153755, gnorm=0.844, train_wall=50, wall=0
2020-12-04 01:53:14 | INFO | train_inner | epoch 097:    698 / 719 loss=3.892, nll_loss=1.726, symm_mse=4.757, ppl=3.31, wps=16332.4, ups=2, wpb=8150, bsz=290.4, num_updates=42400, lr=0.000153574, gnorm=0.843, train_wall=50, wall=0
2020-12-04 01:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:53:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:53:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:53:45 | INFO | valid | epoch 097 | valid on 'valid' subset | symm_mse 0 | loss 8.651 | nll_loss 7.687 | ppl 206.01 | bleu 13.75 | wps 3606 | wpb 4629 | bsz 118.9 | num_updates 42421 | best_bleu 13.78
2020-12-04 01:53:45 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 01:53:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:53:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:53:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 97 @ 42421 updates, score 13.75) (writing took 3.9217180404812098 seconds)
2020-12-04 01:53:49 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2020-12-04 01:53:49 | INFO | train | epoch 097 | loss 3.885 | nll_loss 1.714 | symm_mse 4.784 | ppl 3.28 | wps 15252.9 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 42421 | lr 0.000153536 | gnorm 0.841 | train_wall 354 | wall 0
111
2020-12-04 01:53:49 | INFO | fairseq.trainer | begin training epoch 98
2020-12-04 01:53:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:53:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:54:30 | INFO | train_inner | epoch 098:     79 / 719 loss=3.839, nll_loss=1.677, symm_mse=4.654, ppl=3.2, wps=10657, ups=1.3, wpb=8191.6, bsz=297.8, num_updates=42500, lr=0.000153393, gnorm=0.825, train_wall=48, wall=0
2020-12-04 01:55:20 | INFO | train_inner | epoch 098:    179 / 719 loss=3.832, nll_loss=1.661, symm_mse=4.716, ppl=3.16, wps=16325.8, ups=2, wpb=8151.1, bsz=288.2, num_updates=42600, lr=0.000153213, gnorm=0.833, train_wall=50, wall=0
2020-12-04 01:56:10 | INFO | train_inner | epoch 098:    279 / 719 loss=3.917, nll_loss=1.723, symm_mse=4.992, ppl=3.3, wps=16476.4, ups=2.03, wpb=8112, bsz=253.3, num_updates=42700, lr=0.000153033, gnorm=0.871, train_wall=49, wall=0
2020-12-04 01:56:59 | INFO | train_inner | epoch 098:    379 / 719 loss=3.864, nll_loss=1.691, symm_mse=4.78, ppl=3.23, wps=16577.2, ups=2.02, wpb=8204.1, bsz=281.6, num_updates=42800, lr=0.000152854, gnorm=0.849, train_wall=49, wall=0
2020-12-04 01:57:49 | INFO | train_inner | epoch 098:    479 / 719 loss=3.909, nll_loss=1.736, symm_mse=4.831, ppl=3.33, wps=16330.9, ups=2, wpb=8147.7, bsz=266.2, num_updates=42900, lr=0.000152676, gnorm=0.857, train_wall=50, wall=0
2020-12-04 01:58:39 | INFO | train_inner | epoch 098:    579 / 719 loss=3.904, nll_loss=1.738, symm_mse=4.772, ppl=3.34, wps=16238.4, ups=2.01, wpb=8083.7, bsz=282.1, num_updates=43000, lr=0.000152499, gnorm=0.853, train_wall=50, wall=0
2020-12-04 01:59:29 | INFO | train_inner | epoch 098:    679 / 719 loss=3.896, nll_loss=1.731, symm_mse=4.757, ppl=3.32, wps=16507, ups=2, wpb=8248.3, bsz=280.4, num_updates=43100, lr=0.000152322, gnorm=0.843, train_wall=50, wall=0
2020-12-04 01:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 01:59:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:59:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:59:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 01:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 01:59:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:00:10 | INFO | valid | epoch 098 | valid on 'valid' subset | symm_mse 0 | loss 8.595 | nll_loss 7.624 | ppl 197.25 | bleu 13.57 | wps 3448.6 | wpb 4629 | bsz 118.9 | num_updates 43140 | best_bleu 13.78
2020-12-04 02:00:10 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 02:00:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:00:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:00:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:00:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:00:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 98 @ 43140 updates, score 13.57) (writing took 3.9286867529153824 seconds)
2020-12-04 02:00:14 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2020-12-04 02:00:14 | INFO | train | epoch 098 | loss 3.88 | nll_loss 1.708 | symm_mse 4.788 | ppl 3.27 | wps 15218.9 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 43140 | lr 0.000152251 | gnorm 0.847 | train_wall 355 | wall 0
111
2020-12-04 02:00:14 | INFO | fairseq.trainer | begin training epoch 99
2020-12-04 02:00:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:00:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:00:47 | INFO | train_inner | epoch 099:     60 / 719 loss=3.872, nll_loss=1.699, symm_mse=4.776, ppl=3.25, wps=10291.7, ups=1.28, wpb=8041.4, bsz=276.6, num_updates=43200, lr=0.000152145, gnorm=0.85, train_wall=48, wall=0
2020-12-04 02:01:36 | INFO | train_inner | epoch 099:    160 / 719 loss=3.844, nll_loss=1.665, symm_mse=4.789, ppl=3.17, wps=16521.4, ups=2.03, wpb=8126.5, bsz=272.7, num_updates=43300, lr=0.000151969, gnorm=0.842, train_wall=49, wall=0
2020-12-04 02:02:26 | INFO | train_inner | epoch 099:    260 / 719 loss=3.803, nll_loss=1.649, symm_mse=4.559, ppl=3.14, wps=16505.4, ups=2, wpb=8257.9, bsz=298.2, num_updates=43400, lr=0.000151794, gnorm=0.814, train_wall=50, wall=0
2020-12-04 02:03:16 | INFO | train_inner | epoch 099:    360 / 719 loss=3.864, nll_loss=1.684, symm_mse=4.829, ppl=3.21, wps=16422.9, ups=2, wpb=8220.4, bsz=275.6, num_updates=43500, lr=0.00015162, gnorm=0.852, train_wall=50, wall=0
2020-12-04 02:04:06 | INFO | train_inner | epoch 099:    460 / 719 loss=3.914, nll_loss=1.734, symm_mse=4.888, ppl=3.33, wps=16429.1, ups=2.01, wpb=8181.4, bsz=264.2, num_updates=43600, lr=0.000151446, gnorm=0.851, train_wall=50, wall=0
2020-12-04 02:04:56 | INFO | train_inner | epoch 099:    560 / 719 loss=3.901, nll_loss=1.727, symm_mse=4.832, ppl=3.31, wps=16332.2, ups=2, wpb=8147.3, bsz=287.1, num_updates=43700, lr=0.000151272, gnorm=0.85, train_wall=50, wall=0
2020-12-04 02:05:46 | INFO | train_inner | epoch 099:    660 / 719 loss=3.91, nll_loss=1.743, symm_mse=4.801, ppl=3.35, wps=16459.1, ups=2.01, wpb=8204.5, bsz=274.4, num_updates=43800, lr=0.000151099, gnorm=0.85, train_wall=50, wall=0
2020-12-04 02:06:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 02:06:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:06:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:06:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:06:37 | INFO | valid | epoch 099 | valid on 'valid' subset | symm_mse 0 | loss 8.698 | nll_loss 7.739 | ppl 213.6 | bleu 13.68 | wps 3401 | wpb 4629 | bsz 118.9 | num_updates 43859 | best_bleu 13.78
2020-12-04 02:06:37 | INFO | fairseq_cli.train | begin save checkpoint
111
111
2020-12-04 02:06:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:06:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:06:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 99 @ 43859 updates, score 13.68) (writing took 3.7377852611243725 seconds)
2020-12-04 02:06:41 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2020-12-04 02:06:41 | INFO | train | epoch 099 | loss 3.875 | nll_loss 1.702 | symm_mse 4.787 | ppl 3.25 | wps 15182.1 | ups 1.86 | wpb 8159.9 | bsz 278.2 | num_updates 43859 | lr 0.000150998 | gnorm 0.846 | train_wall 355 | wall 0
111
2020-12-04 02:06:41 | INFO | fairseq.trainer | begin training epoch 100
2020-12-04 02:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:06:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:07:04 | INFO | train_inner | epoch 100:     41 / 719 loss=3.868, nll_loss=1.695, symm_mse=4.784, ppl=3.24, wps=10289.2, ups=1.28, wpb=8064, bsz=279.2, num_updates=43900, lr=0.000150927, gnorm=0.847, train_wall=49, wall=0
2020-12-04 02:07:53 | INFO | train_inner | epoch 100:    141 / 719 loss=3.844, nll_loss=1.668, symm_mse=4.764, ppl=3.18, wps=16485.8, ups=2.03, wpb=8134.4, bsz=270.9, num_updates=44000, lr=0.000150756, gnorm=0.844, train_wall=49, wall=0
2020-12-04 02:08:43 | INFO | train_inner | epoch 100:    241 / 719 loss=3.854, nll_loss=1.685, symm_mse=4.725, ppl=3.22, wps=16387.2, ups=2.01, wpb=8153.3, bsz=291.8, num_updates=44100, lr=0.000150585, gnorm=0.838, train_wall=50, wall=0
2020-12-04 02:09:33 | INFO | train_inner | epoch 100:    341 / 719 loss=3.87, nll_loss=1.692, symm_mse=4.815, ppl=3.23, wps=16437.2, ups=2.02, wpb=8139.9, bsz=279, num_updates=44200, lr=0.000150414, gnorm=0.856, train_wall=49, wall=0
2020-12-04 02:10:22 | INFO | train_inner | epoch 100:    441 / 719 loss=3.907, nll_loss=1.722, symm_mse=4.916, ppl=3.3, wps=16253.9, ups=2.01, wpb=8095.7, bsz=267.9, num_updates=44300, lr=0.000150244, gnorm=0.867, train_wall=50, wall=0
2020-12-04 02:11:12 | INFO | train_inner | epoch 100:    541 / 719 loss=3.887, nll_loss=1.716, symm_mse=4.793, ppl=3.29, wps=16478.9, ups=2.02, wpb=8176.6, bsz=282, num_updates=44400, lr=0.000150075, gnorm=0.847, train_wall=49, wall=0
2020-12-04 02:12:02 | INFO | train_inner | epoch 100:    641 / 719 loss=3.873, nll_loss=1.703, symm_mse=4.771, ppl=3.26, wps=16455.3, ups=1.99, wpb=8251.1, bsz=276.6, num_updates=44500, lr=0.000149906, gnorm=0.839, train_wall=50, wall=0
2020-12-04 02:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 02:12:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:12:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:12:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 02:12:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:12:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:12:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 02:13:02 | INFO | valid | epoch 100 | valid on 'valid' subset | symm_mse 0 | loss 8.694 | nll_loss 7.732 | ppl 212.58 | bleu 13.33 | wps 3560.7 | wpb 4629 | bsz 118.9 | num_updates 44578 | best_bleu 13.78
2020-12-04 02:13:02 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 02:13:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 100 @ 44578 updates, score 13.33) (writing took 3.874535383656621 seconds)
2020-12-04 02:13:06 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2020-12-04 02:13:06 | INFO | train | epoch 100 | loss 3.87 | nll_loss 1.696 | symm_mse 4.788 | ppl 3.24 | wps 15220.4 | ups 1.87 | wpb 8159.9 | bsz 278.2 | num_updates 44578 | lr 0.000149775 | gnorm 0.847 | train_wall 355 | wall 0
2020-12-04 02:13:06 | INFO | fairseq_cli.train | done training in 23978.0 seconds
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 372 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
nohup: ignoring input
2020-12-04 10:47:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:47:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:48:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:14951
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:14951
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:14951
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:14951
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-04 10:48:01 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-04 10:48:05 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='closer_dropout', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='r3f_closer_dropout_all', cross_self_attention=False, curriculum=0, data='./examples/transformer_enzh/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:14951', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-05, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=130, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3024, max_tokens_valid=3024, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=0.08, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/transformer_enzh/bash/../checkpoints/closer_all1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-04 10:48:05 | INFO | fairseq.tasks.translation | [ch] dictionary: 27920 types
2020-12-04 10:48:05 | INFO | fairseq.tasks.translation | [en] dictionary: 19376 types
2020-12-04 10:48:05 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.ch
2020-12-04 10:48:05 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.en
2020-12-04 10:48:05 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin valid ch-en 1664 examples
2020-12-04 10:48:06 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(27920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19376, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19376, bias=False)
  )
)
2020-12-04 10:48:06 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-04 10:48:06 | INFO | fairseq_cli.train | model: closer_dropout (TransformerModel)
2020-12-04 10:48:06 | INFO | fairseq_cli.train | criterion: r3f_closer_dropout_all (R3fCloserDropoutAll)
2020-12-04 10:48:06 | INFO | fairseq_cli.train | num. model params: 78274560 (num. trained: 78274560)
2020-12-04 10:48:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-04 10:48:06 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 10:48:06 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 10:48:06 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 10:48:06 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 10:48:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-04 10:48:06 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2020-12-04 10:48:06 | INFO | fairseq_cli.train | max tokens per GPU = 3024 and max sentences per GPU = None
2020-12-04 10:48:07 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-04 10:48:08 | INFO | fairseq.trainer | loaded checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 101 @ 44578 updates)
2020-12-04 10:48:08 | INFO | fairseq.trainer | loading train data for epoch 101
2020-12-04 10:48:08 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.ch
2020-12-04 10:48:08 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.en
2020-12-04 10:48:08 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin train ch-en 200000 examples
2020-12-04 10:48:08 | INFO | fairseq.trainer | begin training epoch 101
2020-12-04 10:48:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:48:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:48:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:48:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:48:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:48:22 | INFO | train_inner | epoch 101:     22 / 539 loss=3.875, nll_loss=1.704, symm_mse=4.783, ppl=3.26, wps=11832.1, ups=1.34, wpb=8808.9, bsz=300.2, num_updates=44600, lr=0.000149738, gnorm=0.83, train_wall=49, wall=0
2020-12-04 10:49:08 | INFO | train_inner | epoch 101:    122 / 539 loss=3.796, nll_loss=1.631, symm_mse=4.61, ppl=3.1, wps=23613.5, ups=2.17, wpb=10896.4, bsz=384.2, num_updates=44700, lr=0.000149571, gnorm=0.719, train_wall=46, wall=0
2020-12-04 10:49:55 | INFO | train_inner | epoch 101:    222 / 539 loss=3.84, nll_loss=1.665, symm_mse=4.754, ppl=3.17, wps=23241.8, ups=2.15, wpb=10788.8, bsz=370.3, num_updates=44800, lr=0.000149404, gnorm=0.741, train_wall=46, wall=0
2020-12-04 10:50:42 | INFO | train_inner | epoch 101:    322 / 539 loss=3.832, nll_loss=1.663, symm_mse=4.691, ppl=3.17, wps=22981.5, ups=2.12, wpb=10825.8, bsz=373, num_updates=44900, lr=0.000149237, gnorm=0.726, train_wall=47, wall=0
2020-12-04 10:51:30 | INFO | train_inner | epoch 101:    422 / 539 loss=3.876, nll_loss=1.692, symm_mse=4.873, ppl=3.23, wps=22854.2, ups=2.1, wpb=10908.6, bsz=365.4, num_updates=45000, lr=0.000149071, gnorm=0.753, train_wall=48, wall=0
2020-12-04 10:52:18 | INFO | train_inner | epoch 101:    522 / 539 loss=3.888, nll_loss=1.71, symm_mse=4.838, ppl=3.27, wps=22679.7, ups=2.07, wpb=10932.9, bsz=360.3, num_updates=45100, lr=0.000148906, gnorm=0.739, train_wall=48, wall=0
2020-12-04 10:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 10:52:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:28 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 10:52:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 10:52:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 10:52:44 | INFO | valid | epoch 101 | valid on 'valid' subset | symm_mse 0 | loss 8.693 | nll_loss 7.731 | ppl 212.45 | bleu 13.4 | wps 4255.6 | wpb 5891.5 | bsz 151.3 | num_updates 45117 | best_bleu 13.78
2020-12-04 10:52:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 10:52:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:52:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 101 @ 45117 updates, score 13.4) (writing took 3.6061079893261194 seconds)
2020-12-04 10:52:48 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2020-12-04 10:52:48 | INFO | train | epoch 101 | loss 3.858 | nll_loss 1.685 | symm_mse 4.773 | ppl 3.21 | wps 17743.7 | ups 1.9 | wpb 9327.5 | bsz 318 | num_updates 45117 | lr 0.000148878 | gnorm 0.799 | train_wall 608 | wall 0
2020-12-04 10:52:48 | INFO | fairseq.trainer | begin training epoch 102
2020-12-04 10:52:48 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:52:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:53:30 | INFO | train_inner | epoch 102:     83 / 539 loss=3.789, nll_loss=1.618, symm_mse=4.652, ppl=3.07, wps=15093.2, ups=1.38, wpb=10901.1, bsz=375.4, num_updates=45200, lr=0.000148741, gnorm=0.723, train_wall=47, wall=0
2020-12-04 10:54:18 | INFO | train_inner | epoch 102:    183 / 539 loss=3.843, nll_loss=1.659, symm_mse=4.816, ppl=3.16, wps=22763.9, ups=2.09, wpb=10866.7, bsz=356.1, num_updates=45300, lr=0.000148577, gnorm=0.737, train_wall=48, wall=0
2020-12-04 10:55:06 | INFO | train_inner | epoch 102:    283 / 539 loss=3.832, nll_loss=1.651, symm_mse=4.773, ppl=3.14, wps=22579.9, ups=2.07, wpb=10902, bsz=385.5, num_updates=45400, lr=0.000148413, gnorm=0.731, train_wall=48, wall=0
2020-12-04 10:55:54 | INFO | train_inner | epoch 102:    383 / 539 loss=3.842, nll_loss=1.671, symm_mse=4.713, ppl=3.18, wps=22475.7, ups=2.07, wpb=10872.7, bsz=366, num_updates=45500, lr=0.00014825, gnorm=0.74, train_wall=48, wall=0
2020-12-04 10:56:43 | INFO | train_inner | epoch 102:    483 / 539 loss=3.848, nll_loss=1.678, symm_mse=4.724, ppl=3.2, wps=22584, ups=2.06, wpb=10943.4, bsz=389.7, num_updates=45600, lr=0.000148087, gnorm=0.729, train_wall=48, wall=0
2020-12-04 10:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 10:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 10:57:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 10:57:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 10:57:29 | INFO | valid | epoch 102 | valid on 'valid' subset | symm_mse 0 | loss 8.684 | nll_loss 7.717 | ppl 210.41 | bleu 13.7 | wps 3810.3 | wpb 5891.5 | bsz 151.3 | num_updates 45656 | best_bleu 13.78
2020-12-04 10:57:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 10:57:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 102 @ 45656 updates, score 13.7) (writing took 3.494825255125761 seconds)
2020-12-04 10:57:33 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2020-12-04 10:57:33 | INFO | train | epoch 102 | loss 3.836 | nll_loss 1.661 | symm_mse 4.746 | ppl 3.16 | wps 20567.6 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 45656 | lr 0.000147996 | gnorm 0.734 | train_wall 258 | wall 0
2020-12-04 10:57:33 | INFO | fairseq.trainer | begin training epoch 103
2020-12-04 10:57:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 10:57:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 10:57:56 | INFO | train_inner | epoch 103:     44 / 539 loss=3.859, nll_loss=1.677, symm_mse=4.815, ppl=3.2, wps=14816.2, ups=1.36, wpb=10895.4, bsz=345.9, num_updates=45700, lr=0.000147925, gnorm=0.736, train_wall=47, wall=0
2020-12-04 10:58:45 | INFO | train_inner | epoch 103:    144 / 539 loss=3.78, nll_loss=1.607, symm_mse=4.649, ppl=3.05, wps=22782.8, ups=2.08, wpb=10955.2, bsz=377, num_updates=45800, lr=0.000147764, gnorm=0.724, train_wall=48, wall=0
2020-12-04 10:59:33 | INFO | train_inner | epoch 103:    244 / 539 loss=3.822, nll_loss=1.639, symm_mse=4.773, ppl=3.11, wps=22540.5, ups=2.06, wpb=10962.4, bsz=375.9, num_updates=45900, lr=0.000147602, gnorm=0.732, train_wall=48, wall=0
2020-12-04 11:00:22 | INFO | train_inner | epoch 103:    344 / 539 loss=3.846, nll_loss=1.667, symm_mse=4.769, ppl=3.18, wps=22218.1, ups=2.05, wpb=10818.4, bsz=361, num_updates=46000, lr=0.000147442, gnorm=0.736, train_wall=49, wall=0
2020-12-04 11:01:11 | INFO | train_inner | epoch 103:    444 / 539 loss=3.848, nll_loss=1.672, symm_mse=4.755, ppl=3.19, wps=22259.4, ups=2.06, wpb=10827.7, bsz=384.8, num_updates=46100, lr=0.000147282, gnorm=0.74, train_wall=48, wall=0
2020-12-04 11:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:01:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:01:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:02:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:02:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:02:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:02:14 | INFO | valid | epoch 103 | valid on 'valid' subset | symm_mse 0 | loss 8.678 | nll_loss 7.711 | ppl 209.54 | bleu 13.51 | wps 4537.7 | wpb 5891.5 | bsz 151.3 | num_updates 46195 | best_bleu 13.78
2020-12-04 11:02:14 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:02:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:02:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:02:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:02:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:02:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:02:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:02:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 103 @ 46195 updates, score 13.51) (writing took 3.554683843627572 seconds)
2020-12-04 11:02:17 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2020-12-04 11:02:17 | INFO | train | epoch 103 | loss 3.829 | nll_loss 1.651 | symm_mse 4.745 | ppl 3.14 | wps 20634.3 | ups 1.9 | wpb 10884.9 | bsz 371.1 | num_updates 46195 | lr 0.00014713 | gnorm 0.733 | train_wall 260 | wall 0
2020-12-04 11:02:17 | INFO | fairseq.trainer | begin training epoch 104
2020-12-04 11:02:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:02:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:02:23 | INFO | train_inner | epoch 104:      5 / 539 loss=3.849, nll_loss=1.676, symm_mse=4.749, ppl=3.19, wps=15028.2, ups=1.39, wpb=10840.2, bsz=370, num_updates=46200, lr=0.000147122, gnorm=0.735, train_wall=48, wall=0
2020-12-04 11:03:10 | INFO | train_inner | epoch 104:    105 / 539 loss=3.785, nll_loss=1.604, symm_mse=4.707, ppl=3.04, wps=22789.4, ups=2.1, wpb=10866.6, bsz=375.2, num_updates=46300, lr=0.000146964, gnorm=0.737, train_wall=48, wall=0
2020-12-04 11:03:59 | INFO | train_inner | epoch 104:    205 / 539 loss=3.82, nll_loss=1.636, symm_mse=4.777, ppl=3.11, wps=22072.3, ups=2.05, wpb=10758.7, bsz=366.9, num_updates=46400, lr=0.000146805, gnorm=0.748, train_wall=49, wall=0
2020-12-04 11:04:48 | INFO | train_inner | epoch 104:    305 / 539 loss=3.779, nll_loss=1.614, symm_mse=4.577, ppl=3.06, wps=22583, ups=2.06, wpb=10972.2, bsz=389.8, num_updates=46500, lr=0.000146647, gnorm=0.722, train_wall=48, wall=0
2020-12-04 11:05:36 | INFO | train_inner | epoch 104:    405 / 539 loss=3.878, nll_loss=1.685, symm_mse=4.917, ppl=3.22, wps=22540.7, ups=2.07, wpb=10907, bsz=349.4, num_updates=46600, lr=0.00014649, gnorm=0.761, train_wall=48, wall=0
2020-12-04 11:06:25 | INFO | train_inner | epoch 104:    505 / 539 loss=3.844, nll_loss=1.666, symm_mse=4.757, ppl=3.17, wps=22500.9, ups=2.06, wpb=10938.3, bsz=369, num_updates=46700, lr=0.000146333, gnorm=0.748, train_wall=48, wall=0
2020-12-04 11:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:06:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:06:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:06:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:06:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:06:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:07:00 | INFO | valid | epoch 104 | valid on 'valid' subset | symm_mse 0 | loss 8.7 | nll_loss 7.733 | ppl 212.81 | bleu 13.5 | wps 3891.5 | wpb 5891.5 | bsz 151.3 | num_updates 46734 | best_bleu 13.78
2020-12-04 11:07:00 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:07:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:07:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:07:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:07:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 104 @ 46734 updates, score 13.5) (writing took 3.466370841488242 seconds)
2020-12-04 11:07:04 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2020-12-04 11:07:04 | INFO | train | epoch 104 | loss 3.822 | nll_loss 1.643 | symm_mse 4.747 | ppl 3.12 | wps 20479.5 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 46734 | lr 0.00014628 | gnorm 0.743 | train_wall 260 | wall 0
2020-12-04 11:07:04 | INFO | fairseq.trainer | begin training epoch 105
2020-12-04 11:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:07:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:07:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:07:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:07:38 | INFO | train_inner | epoch 105:     66 / 539 loss=3.796, nll_loss=1.616, symm_mse=4.713, ppl=3.07, wps=14855.1, ups=1.36, wpb=10894.7, bsz=378.3, num_updates=46800, lr=0.000146176, gnorm=0.729, train_wall=47, wall=0
2020-12-04 11:08:27 | INFO | train_inner | epoch 105:    166 / 539 loss=3.782, nll_loss=1.602, symm_mse=4.684, ppl=3.04, wps=22571.5, ups=2.06, wpb=10940, bsz=371.3, num_updates=46900, lr=0.00014602, gnorm=0.74, train_wall=48, wall=0
2020-12-04 11:09:16 | INFO | train_inner | epoch 105:    266 / 539 loss=3.815, nll_loss=1.633, symm_mse=4.758, ppl=3.1, wps=22212.4, ups=2.04, wpb=10902.7, bsz=382.2, num_updates=47000, lr=0.000145865, gnorm=0.738, train_wall=49, wall=0
2020-12-04 11:10:05 | INFO | train_inner | epoch 105:    366 / 539 loss=3.833, nll_loss=1.649, symm_mse=4.797, ppl=3.14, wps=22109.1, ups=2.04, wpb=10820, bsz=370.2, num_updates=47100, lr=0.00014571, gnorm=0.751, train_wall=49, wall=0
2020-12-04 11:10:53 | INFO | train_inner | epoch 105:    466 / 539 loss=3.847, nll_loss=1.667, symm_mse=4.785, ppl=3.18, wps=22214.6, ups=2.05, wpb=10854, bsz=359.8, num_updates=47200, lr=0.000145556, gnorm=0.752, train_wall=49, wall=0
2020-12-04 11:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:11:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:11:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:11:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:11:45 | INFO | valid | epoch 105 | valid on 'valid' subset | symm_mse 0 | loss 8.779 | nll_loss 7.822 | ppl 226.29 | bleu 13.48 | wps 4632.3 | wpb 5891.5 | bsz 151.3 | num_updates 47273 | best_bleu 13.78
2020-12-04 11:11:45 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:11:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:11:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 105 @ 47273 updates, score 13.48) (writing took 3.484329219907522 seconds)
2020-12-04 11:11:49 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2020-12-04 11:11:49 | INFO | train | epoch 105 | loss 3.817 | nll_loss 1.636 | symm_mse 4.749 | ppl 3.11 | wps 20562.2 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 47273 | lr 0.000145443 | gnorm 0.743 | train_wall 261 | wall 0
2020-12-04 11:11:49 | INFO | fairseq.trainer | begin training epoch 106
2020-12-04 11:11:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:11:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:12:05 | INFO | train_inner | epoch 106:     27 / 539 loss=3.844, nll_loss=1.658, symm_mse=4.822, ppl=3.16, wps=15172, ups=1.4, wpb=10819.5, bsz=353.2, num_updates=47300, lr=0.000145402, gnorm=0.748, train_wall=48, wall=0
2020-12-04 11:12:52 | INFO | train_inner | epoch 106:    127 / 539 loss=3.781, nll_loss=1.598, symm_mse=4.715, ppl=3.03, wps=22856.9, ups=2.09, wpb=10924.6, bsz=362.6, num_updates=47400, lr=0.000145248, gnorm=0.742, train_wall=48, wall=0
2020-12-04 11:13:41 | INFO | train_inner | epoch 106:    227 / 539 loss=3.804, nll_loss=1.614, symm_mse=4.794, ppl=3.06, wps=22494.3, ups=2.06, wpb=10933.4, bsz=362.4, num_updates=47500, lr=0.000145095, gnorm=0.758, train_wall=48, wall=0
2020-12-04 11:14:30 | INFO | train_inner | epoch 106:    327 / 539 loss=3.786, nll_loss=1.62, symm_mse=4.592, ppl=3.07, wps=22376.8, ups=2.04, wpb=10971.9, bsz=400.7, num_updates=47600, lr=0.000144943, gnorm=0.735, train_wall=49, wall=0
2020-12-04 11:15:19 | INFO | train_inner | epoch 106:    427 / 539 loss=3.839, nll_loss=1.657, symm_mse=4.785, ppl=3.15, wps=22119.8, ups=2.06, wpb=10763.8, bsz=369.2, num_updates=47700, lr=0.000144791, gnorm=0.755, train_wall=48, wall=0
2020-12-04 11:16:08 | INFO | train_inner | epoch 106:    527 / 539 loss=3.838, nll_loss=1.651, symm_mse=4.822, ppl=3.14, wps=22231.4, ups=2.05, wpb=10854, bsz=374.9, num_updates=47800, lr=0.000144639, gnorm=0.751, train_wall=49, wall=0
2020-12-04 11:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:16:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:16:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:16:31 | INFO | valid | epoch 106 | valid on 'valid' subset | symm_mse 0 | loss 8.718 | nll_loss 7.749 | ppl 215.19 | bleu 13.71 | wps 4222.5 | wpb 5891.5 | bsz 151.3 | num_updates 47812 | best_bleu 13.78
2020-12-04 11:16:31 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 106 @ 47812 updates, score 13.71) (writing took 3.518047148361802 seconds)
2020-12-04 11:16:35 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2020-12-04 11:16:35 | INFO | train | epoch 106 | loss 3.811 | nll_loss 1.629 | symm_mse 4.751 | ppl 3.09 | wps 20520.1 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 47812 | lr 0.000144621 | gnorm 0.747 | train_wall 260 | wall 0
2020-12-04 11:16:35 | INFO | fairseq.trainer | begin training epoch 107
2020-12-04 11:16:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:16:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:16:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:17:20 | INFO | train_inner | epoch 107:     88 / 539 loss=3.779, nll_loss=1.596, symm_mse=4.716, ppl=3.02, wps=15101.4, ups=1.39, wpb=10856.2, bsz=371.2, num_updates=47900, lr=0.000144488, gnorm=0.734, train_wall=47, wall=0
2020-12-04 11:18:08 | INFO | train_inner | epoch 107:    188 / 539 loss=3.819, nll_loss=1.624, symm_mse=4.857, ppl=3.08, wps=22373.1, ups=2.06, wpb=10875, bsz=347.4, num_updates=48000, lr=0.000144338, gnorm=0.746, train_wall=48, wall=0
2020-12-04 11:18:57 | INFO | train_inner | epoch 107:    288 / 539 loss=3.812, nll_loss=1.628, symm_mse=4.769, ppl=3.09, wps=22326.5, ups=2.06, wpb=10856.2, bsz=374.6, num_updates=48100, lr=0.000144187, gnorm=0.757, train_wall=48, wall=0
2020-12-04 11:19:45 | INFO | train_inner | epoch 107:    388 / 539 loss=3.802, nll_loss=1.622, symm_mse=4.723, ppl=3.08, wps=22399, ups=2.06, wpb=10864.4, bsz=383, num_updates=48200, lr=0.000144038, gnorm=0.75, train_wall=48, wall=0
2020-12-04 11:20:34 | INFO | train_inner | epoch 107:    488 / 539 loss=3.833, nll_loss=1.653, symm_mse=4.757, ppl=3.15, wps=22254.5, ups=2.04, wpb=10919.6, bsz=367.7, num_updates=48300, lr=0.000143889, gnorm=0.744, train_wall=49, wall=0
2020-12-04 11:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:21:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:21:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:21:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:21:17 | INFO | valid | epoch 107 | valid on 'valid' subset | symm_mse 0 | loss 8.653 | nll_loss 7.679 | ppl 204.93 | bleu 13.77 | wps 4304.7 | wpb 5891.5 | bsz 151.3 | num_updates 48351 | best_bleu 13.78
2020-12-04 11:21:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:21:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 107 @ 48351 updates, score 13.77) (writing took 3.501087721437216 seconds)
2020-12-04 11:21:21 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2020-12-04 11:21:21 | INFO | train | epoch 107 | loss 3.806 | nll_loss 1.623 | symm_mse 4.751 | ppl 3.08 | wps 20537.7 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 48351 | lr 0.000143813 | gnorm 0.745 | train_wall 260 | wall 0
2020-12-04 11:21:21 | INFO | fairseq.trainer | begin training epoch 108
2020-12-04 11:21:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:21:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:21:47 | INFO | train_inner | epoch 108:     49 / 539 loss=3.775, nll_loss=1.601, symm_mse=4.644, ppl=3.03, wps=15178.4, ups=1.37, wpb=11040.7, bsz=379.8, num_updates=48400, lr=0.00014374, gnorm=0.736, train_wall=48, wall=0
2020-12-04 11:22:35 | INFO | train_inner | epoch 108:    149 / 539 loss=3.757, nll_loss=1.574, symm_mse=4.677, ppl=2.98, wps=22502.6, ups=2.07, wpb=10881.4, bsz=378.6, num_updates=48500, lr=0.000143592, gnorm=0.734, train_wall=48, wall=0
2020-12-04 11:23:24 | INFO | train_inner | epoch 108:    249 / 539 loss=3.803, nll_loss=1.613, symm_mse=4.787, ppl=3.06, wps=22202.5, ups=2.05, wpb=10836.7, bsz=359.1, num_updates=48600, lr=0.000143444, gnorm=0.741, train_wall=49, wall=0
2020-12-04 11:24:13 | INFO | train_inner | epoch 108:    349 / 539 loss=3.815, nll_loss=1.631, symm_mse=4.775, ppl=3.1, wps=22223.5, ups=2.04, wpb=10870.9, bsz=380.1, num_updates=48700, lr=0.000143296, gnorm=0.749, train_wall=49, wall=0
2020-12-04 11:25:02 | INFO | train_inner | epoch 108:    449 / 539 loss=3.83, nll_loss=1.645, symm_mse=4.792, ppl=3.13, wps=22331, ups=2.05, wpb=10889.4, bsz=355.4, num_updates=48800, lr=0.00014315, gnorm=0.761, train_wall=49, wall=0
2020-12-04 11:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:25:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:25:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:25:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:25:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:25:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:25:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:25:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:25:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:26:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:26:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:26:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:26:04 | INFO | valid | epoch 108 | valid on 'valid' subset | symm_mse 0 | loss 8.701 | nll_loss 7.729 | ppl 212.19 | bleu 13.69 | wps 4211.3 | wpb 5891.5 | bsz 151.3 | num_updates 48890 | best_bleu 13.78
2020-12-04 11:26:04 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:26:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:26:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:26:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:26:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:26:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:26:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:26:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 108 @ 48890 updates, score 13.69) (writing took 3.58969203568995 seconds)
2020-12-04 11:26:08 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2020-12-04 11:26:08 | INFO | train | epoch 108 | loss 3.801 | nll_loss 1.617 | symm_mse 4.753 | ppl 3.07 | wps 20444.7 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 48890 | lr 0.000143018 | gnorm 0.747 | train_wall 261 | wall 0
2020-12-04 11:26:08 | INFO | fairseq.trainer | begin training epoch 109
2020-12-04 11:26:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:26:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:26:15 | INFO | train_inner | epoch 109:     10 / 539 loss=3.829, nll_loss=1.643, symm_mse=4.802, ppl=3.12, wps=14765.1, ups=1.36, wpb=10828.3, bsz=378.9, num_updates=48900, lr=0.000143003, gnorm=0.758, train_wall=48, wall=0
2020-12-04 11:27:03 | INFO | train_inner | epoch 109:    110 / 539 loss=3.776, nll_loss=1.586, symm_mse=4.757, ppl=3, wps=22640.9, ups=2.09, wpb=10853.9, bsz=372.9, num_updates=49000, lr=0.000142857, gnorm=0.736, train_wall=48, wall=0
2020-12-04 11:27:52 | INFO | train_inner | epoch 109:    210 / 539 loss=3.751, nll_loss=1.573, symm_mse=4.643, ppl=2.97, wps=22567.2, ups=2.06, wpb=10946.9, bsz=393.5, num_updates=49100, lr=0.000142712, gnorm=0.732, train_wall=48, wall=0
2020-12-04 11:28:40 | INFO | train_inner | epoch 109:    310 / 539 loss=3.786, nll_loss=1.606, symm_mse=4.695, ppl=3.04, wps=22264.5, ups=2.06, wpb=10808.4, bsz=369.8, num_updates=49200, lr=0.000142566, gnorm=0.741, train_wall=48, wall=0
2020-12-04 11:29:29 | INFO | train_inner | epoch 109:    410 / 539 loss=3.821, nll_loss=1.631, symm_mse=4.823, ppl=3.1, wps=22501.9, ups=2.06, wpb=10923.3, bsz=370.4, num_updates=49300, lr=0.000142422, gnorm=0.76, train_wall=48, wall=0
2020-12-04 11:30:18 | INFO | train_inner | epoch 109:    510 / 539 loss=3.833, nll_loss=1.647, symm_mse=4.803, ppl=3.13, wps=22315.6, ups=2.05, wpb=10891.9, bsz=361.8, num_updates=49400, lr=0.000142278, gnorm=0.753, train_wall=49, wall=0
2020-12-04 11:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:30:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:30:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:30:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:30:49 | INFO | valid | epoch 109 | valid on 'valid' subset | symm_mse 0 | loss 8.673 | nll_loss 7.698 | ppl 207.66 | bleu 13.81 | wps 4248.7 | wpb 5891.5 | bsz 151.3 | num_updates 49429 | best_bleu 13.81
2020-12-04 11:30:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:30:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:30:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 109 @ 49429 updates, score 13.81) (writing took 5.989258326590061 seconds)
2020-12-04 11:30:55 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2020-12-04 11:30:55 | INFO | train | epoch 109 | loss 3.797 | nll_loss 1.611 | symm_mse 4.753 | ppl 3.06 | wps 20378.5 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 49429 | lr 0.000142236 | gnorm 0.745 | train_wall 260 | wall 0
2020-12-04 11:30:55 | INFO | fairseq.trainer | begin training epoch 110
2020-12-04 11:30:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:30:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:31:32 | INFO | train_inner | epoch 110:     71 / 539 loss=3.811, nll_loss=1.613, symm_mse=4.854, ppl=3.06, wps=14616.5, ups=1.34, wpb=10883.5, bsz=341, num_updates=49500, lr=0.000142134, gnorm=0.763, train_wall=47, wall=0
2020-12-04 11:32:21 | INFO | train_inner | epoch 110:    171 / 539 loss=3.751, nll_loss=1.571, symm_mse=4.661, ppl=2.97, wps=22423.8, ups=2.06, wpb=10879.6, bsz=373.9, num_updates=49600, lr=0.00014199, gnorm=0.733, train_wall=48, wall=0
2020-12-04 11:33:09 | INFO | train_inner | epoch 110:    271 / 539 loss=3.825, nll_loss=1.628, symm_mse=4.877, ppl=3.09, wps=22300.4, ups=2.06, wpb=10850.8, bsz=348.4, num_updates=49700, lr=0.000141848, gnorm=0.76, train_wall=48, wall=0
2020-12-04 11:33:58 | INFO | train_inner | epoch 110:    371 / 539 loss=3.792, nll_loss=1.606, symm_mse=4.757, ppl=3.04, wps=22300.1, ups=2.04, wpb=10919.7, bsz=385, num_updates=49800, lr=0.000141705, gnorm=0.753, train_wall=49, wall=0
2020-12-04 11:34:48 | INFO | train_inner | epoch 110:    471 / 539 loss=3.77, nll_loss=1.6, symm_mse=4.61, ppl=3.03, wps=22216, ups=2.03, wpb=10960.9, bsz=406.2, num_updates=49900, lr=0.000141563, gnorm=0.74, train_wall=49, wall=0
2020-12-04 11:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:35:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:35:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:35:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:35:37 | INFO | valid | epoch 110 | valid on 'valid' subset | symm_mse 0 | loss 8.742 | nll_loss 7.775 | ppl 219.07 | bleu 13.36 | wps 4656.5 | wpb 5891.5 | bsz 151.3 | num_updates 49968 | best_bleu 13.81
2020-12-04 11:35:37 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:35:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 110 @ 49968 updates, score 13.36) (writing took 3.4632005728781223 seconds)
2020-12-04 11:35:41 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2020-12-04 11:35:41 | INFO | train | epoch 110 | loss 3.792 | nll_loss 1.606 | symm_mse 4.753 | ppl 3.04 | wps 20576.2 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 49968 | lr 0.000141467 | gnorm 0.751 | train_wall 261 | wall 0
2020-12-04 11:35:41 | INFO | fairseq.trainer | begin training epoch 111
2020-12-04 11:35:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:35:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:35:59 | INFO | train_inner | epoch 111:     32 / 539 loss=3.815, nll_loss=1.626, symm_mse=4.803, ppl=3.09, wps=15285.2, ups=1.41, wpb=10869.1, bsz=351.9, num_updates=50000, lr=0.000141421, gnorm=0.748, train_wall=48, wall=0
2020-12-04 11:36:47 | INFO | train_inner | epoch 111:    132 / 539 loss=3.738, nll_loss=1.554, symm_mse=4.673, ppl=2.94, wps=22430.5, ups=2.07, wpb=10856.2, bsz=379.8, num_updates=50100, lr=0.00014128, gnorm=0.74, train_wall=48, wall=0
2020-12-04 11:37:36 | INFO | train_inner | epoch 111:    232 / 539 loss=3.784, nll_loss=1.589, symm_mse=4.805, ppl=3.01, wps=22339.3, ups=2.05, wpb=10898.3, bsz=369.9, num_updates=50200, lr=0.000141139, gnorm=0.766, train_wall=49, wall=0
2020-12-04 11:38:24 | INFO | train_inner | epoch 111:    332 / 539 loss=3.806, nll_loss=1.612, symm_mse=4.828, ppl=3.06, wps=22302.1, ups=2.06, wpb=10830.1, bsz=354.3, num_updates=50300, lr=0.000140999, gnorm=0.757, train_wall=48, wall=0
2020-12-04 11:39:14 | INFO | train_inner | epoch 111:    432 / 539 loss=3.804, nll_loss=1.626, symm_mse=4.702, ppl=3.09, wps=22098.8, ups=2.03, wpb=10880.8, bsz=380.9, num_updates=50400, lr=0.000140859, gnorm=0.751, train_wall=49, wall=0
2020-12-04 11:40:02 | INFO | train_inner | epoch 111:    532 / 539 loss=3.814, nll_loss=1.629, symm_mse=4.778, ppl=3.09, wps=22423.3, ups=2.05, wpb=10942.2, bsz=376.5, num_updates=50500, lr=0.00014072, gnorm=0.751, train_wall=49, wall=0
2020-12-04 11:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:40:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:40:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:40:23 | INFO | valid | epoch 111 | valid on 'valid' subset | symm_mse 0 | loss 8.768 | nll_loss 7.804 | ppl 223.45 | bleu 13.47 | wps 4583.4 | wpb 5891.5 | bsz 151.3 | num_updates 50507 | best_bleu 13.81
2020-12-04 11:40:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:40:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:40:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 111 @ 50507 updates, score 13.47) (writing took 3.530704941600561 seconds)
2020-12-04 11:40:26 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2020-12-04 11:40:26 | INFO | train | epoch 111 | loss 3.788 | nll_loss 1.601 | symm_mse 4.756 | ppl 3.03 | wps 20536.9 | ups 1.89 | wpb 10884.9 | bsz 371.1 | num_updates 50507 | lr 0.00014071 | gnorm 0.752 | train_wall 261 | wall 0
2020-12-04 11:40:26 | INFO | fairseq.trainer | begin training epoch 112
2020-12-04 11:40:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:40:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:41:14 | INFO | train_inner | epoch 112:     93 / 539 loss=3.749, nll_loss=1.563, symm_mse=4.698, ppl=2.95, wps=15278.5, ups=1.4, wpb=10875, bsz=387.8, num_updates=50600, lr=0.00014058, gnorm=0.749, train_wall=48, wall=0
2020-12-04 11:42:03 | INFO | train_inner | epoch 112:    193 / 539 loss=3.782, nll_loss=1.588, symm_mse=4.789, ppl=3.01, wps=22165.7, ups=2.04, wpb=10883.4, bsz=368.7, num_updates=50700, lr=0.000140442, gnorm=0.756, train_wall=49, wall=0
2020-12-04 11:42:51 | INFO | train_inner | epoch 112:    293 / 539 loss=3.773, nll_loss=1.585, symm_mse=4.746, ppl=3, wps=22483.8, ups=2.05, wpb=10962.7, bsz=379.8, num_updates=50800, lr=0.000140303, gnorm=0.76, train_wall=49, wall=0
2020-12-04 11:43:40 | INFO | train_inner | epoch 112:    393 / 539 loss=3.838, nll_loss=1.637, symm_mse=4.911, ppl=3.11, wps=22091.4, ups=2.05, wpb=10796.1, bsz=334.8, num_updates=50900, lr=0.000140165, gnorm=0.768, train_wall=49, wall=0
2020-12-04 11:44:30 | INFO | train_inner | epoch 112:    493 / 539 loss=3.76, nll_loss=1.588, symm_mse=4.605, ppl=3.01, wps=22150.9, ups=2.03, wpb=10913.3, bsz=390.7, num_updates=51000, lr=0.000140028, gnorm=0.764, train_wall=49, wall=0
2020-12-04 11:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:44:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:44:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:45:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:45:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:45:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:45:09 | INFO | valid | epoch 112 | valid on 'valid' subset | symm_mse 0 | loss 8.749 | nll_loss 7.782 | ppl 220.15 | bleu 13.58 | wps 4596.6 | wpb 5891.5 | bsz 151.3 | num_updates 51046 | best_bleu 13.81
2020-12-04 11:45:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:45:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:45:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:45:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:45:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:45:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:45:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 112 @ 51046 updates, score 13.58) (writing took 3.493422668427229 seconds)
2020-12-04 11:45:12 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2020-12-04 11:45:12 | INFO | train | epoch 112 | loss 3.783 | nll_loss 1.595 | symm_mse 4.754 | ppl 3.02 | wps 20497.7 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 51046 | lr 0.000139965 | gnorm 0.759 | train_wall 262 | wall 0
2020-12-04 11:45:12 | INFO | fairseq.trainer | begin training epoch 113
2020-12-04 11:45:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:45:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:45:41 | INFO | train_inner | epoch 113:     54 / 539 loss=3.769, nll_loss=1.588, symm_mse=4.679, ppl=3.01, wps=15105.8, ups=1.4, wpb=10781.1, bsz=365.8, num_updates=51100, lr=0.000139891, gnorm=0.747, train_wall=48, wall=0
2020-12-04 11:46:29 | INFO | train_inner | epoch 113:    154 / 539 loss=3.786, nll_loss=1.587, symm_mse=4.839, ppl=3, wps=22445.7, ups=2.07, wpb=10868.4, bsz=370, num_updates=51200, lr=0.000139754, gnorm=0.764, train_wall=48, wall=0
2020-12-04 11:47:19 | INFO | train_inner | epoch 113:    254 / 539 loss=3.78, nll_loss=1.58, symm_mse=4.845, ppl=2.99, wps=22319.5, ups=2.03, wpb=10968.1, bsz=362, num_updates=51300, lr=0.000139618, gnorm=0.76, train_wall=49, wall=0
2020-12-04 11:48:08 | INFO | train_inner | epoch 113:    354 / 539 loss=3.738, nll_loss=1.564, symm_mse=4.591, ppl=2.96, wps=22401.4, ups=2.04, wpb=10993.6, bsz=398.7, num_updates=51400, lr=0.000139482, gnorm=0.73, train_wall=49, wall=0
2020-12-04 11:48:56 | INFO | train_inner | epoch 113:    454 / 539 loss=3.818, nll_loss=1.627, symm_mse=4.827, ppl=3.09, wps=22402.9, ups=2.05, wpb=10951.3, bsz=363.5, num_updates=51500, lr=0.000139347, gnorm=0.765, train_wall=49, wall=0
2020-12-04 11:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:49:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:49:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:49:56 | INFO | valid | epoch 113 | valid on 'valid' subset | symm_mse 0 | loss 8.709 | nll_loss 7.74 | ppl 213.71 | bleu 13.72 | wps 4157.3 | wpb 5891.5 | bsz 151.3 | num_updates 51585 | best_bleu 13.81
2020-12-04 11:49:56 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:49:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:49:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:49:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:50:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 113 @ 51585 updates, score 13.72) (writing took 3.489689316600561 seconds)
2020-12-04 11:50:00 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2020-12-04 11:50:00 | INFO | train | epoch 113 | loss 3.78 | nll_loss 1.591 | symm_mse 4.757 | ppl 3.01 | wps 20438.2 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 51585 | lr 0.000139232 | gnorm 0.757 | train_wall 261 | wall 0
2020-12-04 11:50:00 | INFO | fairseq.trainer | begin training epoch 114
2020-12-04 11:50:00 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:50:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:50:10 | INFO | train_inner | epoch 114:     15 / 539 loss=3.796, nll_loss=1.611, symm_mse=4.753, ppl=3.05, wps=14688.6, ups=1.37, wpb=10733.2, bsz=360.1, num_updates=51600, lr=0.000139212, gnorm=0.77, train_wall=48, wall=0
2020-12-04 11:50:58 | INFO | train_inner | epoch 114:    115 / 539 loss=3.763, nll_loss=1.561, symm_mse=4.821, ppl=2.95, wps=22508.4, ups=2.07, wpb=10862.5, bsz=363, num_updates=51700, lr=0.000139077, gnorm=0.754, train_wall=48, wall=0
2020-12-04 11:51:47 | INFO | train_inner | epoch 114:    215 / 539 loss=3.759, nll_loss=1.567, symm_mse=4.757, ppl=2.96, wps=22244.5, ups=2.03, wpb=10934.1, bsz=366, num_updates=51800, lr=0.000138943, gnorm=0.741, train_wall=49, wall=0
2020-12-04 11:52:36 | INFO | train_inner | epoch 114:    315 / 539 loss=3.744, nll_loss=1.566, symm_mse=4.634, ppl=2.96, wps=22145.3, ups=2.04, wpb=10868.9, bsz=390.7, num_updates=51900, lr=0.000138809, gnorm=0.738, train_wall=49, wall=0
2020-12-04 11:53:25 | INFO | train_inner | epoch 114:    415 / 539 loss=3.826, nll_loss=1.627, symm_mse=4.906, ppl=3.09, wps=22056, ups=2.03, wpb=10879.3, bsz=350.3, num_updates=52000, lr=0.000138675, gnorm=0.781, train_wall=49, wall=0
2020-12-04 11:54:14 | INFO | train_inner | epoch 114:    515 / 539 loss=3.793, nll_loss=1.614, symm_mse=4.705, ppl=3.06, wps=22177.9, ups=2.04, wpb=10851.2, bsz=380, num_updates=52100, lr=0.000138542, gnorm=0.756, train_wall=49, wall=0
2020-12-04 11:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:54:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:54:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:54:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:54:43 | INFO | valid | epoch 114 | valid on 'valid' subset | symm_mse 0 | loss 8.806 | nll_loss 7.843 | ppl 229.67 | bleu 13.78 | wps 4588.4 | wpb 5891.5 | bsz 151.3 | num_updates 52124 | best_bleu 13.81
2020-12-04 11:54:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:54:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:54:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 114 @ 52124 updates, score 13.78) (writing took 3.5033736508339643 seconds)
2020-12-04 11:54:47 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2020-12-04 11:54:47 | INFO | train | epoch 114 | loss 3.776 | nll_loss 1.586 | symm_mse 4.757 | ppl 3 | wps 20432.9 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 52124 | lr 0.00013851 | gnorm 0.753 | train_wall 263 | wall 0
2020-12-04 11:54:47 | INFO | fairseq.trainer | begin training epoch 115
2020-12-04 11:54:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:54:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:55:26 | INFO | train_inner | epoch 115:     76 / 539 loss=3.756, nll_loss=1.567, symm_mse=4.721, ppl=2.96, wps=15060.5, ups=1.4, wpb=10773, bsz=386.8, num_updates=52200, lr=0.000138409, gnorm=0.763, train_wall=48, wall=0
2020-12-04 11:56:15 | INFO | train_inner | epoch 115:    176 / 539 loss=3.733, nll_loss=1.545, symm_mse=4.681, ppl=2.92, wps=22254.8, ups=2.03, wpb=10955.7, bsz=370.6, num_updates=52300, lr=0.000138277, gnorm=0.751, train_wall=49, wall=0
2020-12-04 11:57:04 | INFO | train_inner | epoch 115:    276 / 539 loss=3.79, nll_loss=1.591, symm_mse=4.85, ppl=3.01, wps=22251, ups=2.05, wpb=10869.8, bsz=356.4, num_updates=52400, lr=0.000138145, gnorm=0.762, train_wall=49, wall=0
2020-12-04 11:57:53 | INFO | train_inner | epoch 115:    376 / 539 loss=3.783, nll_loss=1.59, symm_mse=4.795, ppl=3.01, wps=22232, ups=2.04, wpb=10874.9, bsz=368, num_updates=52500, lr=0.000138013, gnorm=0.769, train_wall=49, wall=0
2020-12-04 11:58:42 | INFO | train_inner | epoch 115:    476 / 539 loss=3.788, nll_loss=1.603, symm_mse=4.742, ppl=3.04, wps=22255.4, ups=2.03, wpb=10954.6, bsz=382.3, num_updates=52600, lr=0.000137882, gnorm=0.768, train_wall=49, wall=0
2020-12-04 11:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 11:59:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 11:59:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 11:59:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 11:59:29 | INFO | valid | epoch 115 | valid on 'valid' subset | symm_mse 0 | loss 8.725 | nll_loss 7.756 | ppl 216.14 | bleu 13.87 | wps 4619.9 | wpb 5891.5 | bsz 151.3 | num_updates 52663 | best_bleu 13.87
2020-12-04 11:59:29 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 11:59:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 115 @ 52663 updates, score 13.87) (writing took 5.838303940370679 seconds)
2020-12-04 11:59:35 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2020-12-04 11:59:35 | INFO | train | epoch 115 | loss 3.772 | nll_loss 1.581 | symm_mse 4.763 | ppl 2.99 | wps 20333.1 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 52663 | lr 0.000137799 | gnorm 0.762 | train_wall 262 | wall 0
2020-12-04 11:59:35 | INFO | fairseq.trainer | begin training epoch 116
2020-12-04 11:59:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 11:59:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 11:59:56 | INFO | train_inner | epoch 116:     37 / 539 loss=3.783, nll_loss=1.588, symm_mse=4.817, ppl=3.01, wps=14807, ups=1.36, wpb=10921.9, bsz=369.4, num_updates=52700, lr=0.000137751, gnorm=0.759, train_wall=48, wall=0
2020-12-04 12:00:44 | INFO | train_inner | epoch 116:    137 / 539 loss=3.709, nll_loss=1.528, symm_mse=4.612, ppl=2.88, wps=22623.5, ups=2.06, wpb=10969.4, bsz=379.4, num_updates=52800, lr=0.00013762, gnorm=0.741, train_wall=48, wall=0
2020-12-04 12:01:33 | INFO | train_inner | epoch 116:    237 / 539 loss=3.751, nll_loss=1.567, symm_mse=4.68, ppl=2.96, wps=22188.4, ups=2.04, wpb=10869, bsz=377.3, num_updates=52900, lr=0.00013749, gnorm=0.757, train_wall=49, wall=0
2020-12-04 12:02:22 | INFO | train_inner | epoch 116:    337 / 539 loss=3.768, nll_loss=1.578, symm_mse=4.75, ppl=2.99, wps=22135.2, ups=2.05, wpb=10810.8, bsz=367.2, num_updates=53000, lr=0.000137361, gnorm=0.758, train_wall=49, wall=0
2020-12-04 12:03:11 | INFO | train_inner | epoch 116:    437 / 539 loss=3.806, nll_loss=1.606, symm_mse=4.879, ppl=3.04, wps=22404.6, ups=2.05, wpb=10941.8, bsz=359.4, num_updates=53100, lr=0.000137231, gnorm=0.767, train_wall=49, wall=0
2020-12-04 12:04:00 | INFO | train_inner | epoch 116:    537 / 539 loss=3.805, nll_loss=1.612, symm_mse=4.832, ppl=3.06, wps=22050.3, ups=2.03, wpb=10837.7, bsz=373.4, num_updates=53200, lr=0.000137102, gnorm=0.775, train_wall=49, wall=0
2020-12-04 12:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:04:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:04:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:04:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:04:19 | INFO | valid | epoch 116 | valid on 'valid' subset | symm_mse 0 | loss 8.781 | nll_loss 7.815 | ppl 225.18 | bleu 13.72 | wps 4179.8 | wpb 5891.5 | bsz 151.3 | num_updates 53202 | best_bleu 13.87
2020-12-04 12:04:19 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:04:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:04:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 116 @ 53202 updates, score 13.72) (writing took 3.5046676695346832 seconds)
2020-12-04 12:04:23 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2020-12-04 12:04:23 | INFO | train | epoch 116 | loss 3.769 | nll_loss 1.578 | symm_mse 4.764 | ppl 2.98 | wps 20409.9 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 53202 | lr 0.0001371 | gnorm 0.76 | train_wall 262 | wall 0
2020-12-04 12:04:23 | INFO | fairseq.trainer | begin training epoch 117
2020-12-04 12:04:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:04:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:05:13 | INFO | train_inner | epoch 117:     98 / 539 loss=3.733, nll_loss=1.538, symm_mse=4.738, ppl=2.9, wps=15032.8, ups=1.38, wpb=10920.5, bsz=378.1, num_updates=53300, lr=0.000136973, gnorm=0.76, train_wall=48, wall=0
2020-12-04 12:06:02 | INFO | train_inner | epoch 117:    198 / 539 loss=3.707, nll_loss=1.527, symm_mse=4.595, ppl=2.88, wps=22447, ups=2.04, wpb=11028.5, bsz=386.6, num_updates=53400, lr=0.000136845, gnorm=0.738, train_wall=49, wall=0
2020-12-04 12:06:51 | INFO | train_inner | epoch 117:    298 / 539 loss=3.789, nll_loss=1.59, symm_mse=4.842, ppl=3.01, wps=22082.6, ups=2.04, wpb=10846.6, bsz=356.2, num_updates=53500, lr=0.000136717, gnorm=0.762, train_wall=49, wall=0
2020-12-04 12:07:40 | INFO | train_inner | epoch 117:    398 / 539 loss=3.811, nll_loss=1.606, symm_mse=4.921, ppl=3.04, wps=22117, ups=2.04, wpb=10826.2, bsz=351.7, num_updates=53600, lr=0.00013659, gnorm=0.778, train_wall=49, wall=0
2020-12-04 12:08:29 | INFO | train_inner | epoch 117:    498 / 539 loss=3.772, nll_loss=1.589, symm_mse=4.699, ppl=3.01, wps=22067.8, ups=2.04, wpb=10826.9, bsz=380.2, num_updates=53700, lr=0.000136462, gnorm=0.764, train_wall=49, wall=0
2020-12-04 12:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:08:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:08:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:08:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:08:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:08:51 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:09:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:09:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:09:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:09:06 | INFO | valid | epoch 117 | valid on 'valid' subset | symm_mse 0 | loss 8.711 | nll_loss 7.743 | ppl 214.21 | bleu 13.71 | wps 4574.5 | wpb 5891.5 | bsz 151.3 | num_updates 53741 | best_bleu 13.87
2020-12-04 12:09:06 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:09:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:09:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:09:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:09:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:09:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 117 @ 53741 updates, score 13.71) (writing took 3.445175239816308 seconds)
2020-12-04 12:09:09 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2020-12-04 12:09:09 | INFO | train | epoch 117 | loss 3.764 | nll_loss 1.572 | symm_mse 4.757 | ppl 2.97 | wps 20463.8 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 53741 | lr 0.00013641 | gnorm 0.761 | train_wall 262 | wall 0
2020-12-04 12:09:09 | INFO | fairseq.trainer | begin training epoch 118
2020-12-04 12:09:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:09:12 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:09:41 | INFO | train_inner | epoch 118:     59 / 539 loss=3.746, nll_loss=1.56, symm_mse=4.69, ppl=2.95, wps=15219.9, ups=1.4, wpb=10895.9, bsz=376.1, num_updates=53800, lr=0.000136335, gnorm=0.765, train_wall=48, wall=0
2020-12-04 12:10:30 | INFO | train_inner | epoch 118:    159 / 539 loss=3.731, nll_loss=1.539, symm_mse=4.72, ppl=2.91, wps=22264.3, ups=2.05, wpb=10882.4, bsz=368.9, num_updates=53900, lr=0.000136209, gnorm=0.761, train_wall=49, wall=0
2020-12-04 12:11:19 | INFO | train_inner | epoch 118:    259 / 539 loss=3.78, nll_loss=1.574, symm_mse=4.878, ppl=2.98, wps=22157.6, ups=2.03, wpb=10906.8, bsz=355.1, num_updates=54000, lr=0.000136083, gnorm=0.773, train_wall=49, wall=0
2020-12-04 12:12:08 | INFO | train_inner | epoch 118:    359 / 539 loss=3.789, nll_loss=1.59, symm_mse=4.849, ppl=3.01, wps=22289.1, ups=2.05, wpb=10891.5, bsz=361.2, num_updates=54100, lr=0.000135957, gnorm=0.769, train_wall=49, wall=0
2020-12-04 12:12:57 | INFO | train_inner | epoch 118:    459 / 539 loss=3.774, nll_loss=1.586, symm_mse=4.75, ppl=3, wps=22307.9, ups=2.04, wpb=10948.4, bsz=379.4, num_updates=54200, lr=0.000135831, gnorm=0.761, train_wall=49, wall=0
2020-12-04 12:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:13:53 | INFO | valid | epoch 118 | valid on 'valid' subset | symm_mse 0 | loss 8.721 | nll_loss 7.752 | ppl 215.62 | bleu 13.83 | wps 4603.3 | wpb 5891.5 | bsz 151.3 | num_updates 54280 | best_bleu 13.87
2020-12-04 12:13:53 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:13:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:13:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 118 @ 54280 updates, score 13.83) (writing took 3.451655263081193 seconds)
2020-12-04 12:13:56 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2020-12-04 12:13:56 | INFO | train | epoch 118 | loss 3.761 | nll_loss 1.568 | symm_mse 4.764 | ppl 2.96 | wps 20460.9 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 54280 | lr 0.000135731 | gnorm 0.765 | train_wall 262 | wall 0
2020-12-04 12:13:56 | INFO | fairseq.trainer | begin training epoch 119
2020-12-04 12:13:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:13:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:14:08 | INFO | train_inner | epoch 119:     20 / 539 loss=3.772, nll_loss=1.581, symm_mse=4.768, ppl=2.99, wps=14941.6, ups=1.39, wpb=10730.9, bsz=374, num_updates=54300, lr=0.000135706, gnorm=0.767, train_wall=48, wall=0
2020-12-04 12:14:57 | INFO | train_inner | epoch 119:    120 / 539 loss=3.717, nll_loss=1.528, symm_mse=4.674, ppl=2.88, wps=22514.7, ups=2.05, wpb=10968.5, bsz=370.2, num_updates=54400, lr=0.000135582, gnorm=0.737, train_wall=49, wall=0
2020-12-04 12:15:46 | INFO | train_inner | epoch 119:    220 / 539 loss=3.753, nll_loss=1.552, symm_mse=4.813, ppl=2.93, wps=22315.4, ups=2.05, wpb=10888.4, bsz=365.8, num_updates=54500, lr=0.000135457, gnorm=0.78, train_wall=49, wall=0
2020-12-04 12:16:35 | INFO | train_inner | epoch 119:    320 / 539 loss=3.769, nll_loss=1.57, symm_mse=4.817, ppl=2.97, wps=22150.9, ups=2.03, wpb=10892.6, bsz=365.5, num_updates=54600, lr=0.000135333, gnorm=0.767, train_wall=49, wall=0
2020-12-04 12:17:24 | INFO | train_inner | epoch 119:    420 / 539 loss=3.758, nll_loss=1.57, symm_mse=4.734, ppl=2.97, wps=22363.6, ups=2.06, wpb=10879.7, bsz=381.9, num_updates=54700, lr=0.000135209, gnorm=0.772, train_wall=48, wall=0
2020-12-04 12:18:13 | INFO | train_inner | epoch 119:    520 / 539 loss=3.774, nll_loss=1.588, symm_mse=4.734, ppl=3.01, wps=21896.3, ups=2.03, wpb=10792.4, bsz=381.8, num_updates=54800, lr=0.000135086, gnorm=0.766, train_wall=49, wall=0
2020-12-04 12:18:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:18:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:18:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:18:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:18:39 | INFO | valid | epoch 119 | valid on 'valid' subset | symm_mse 0 | loss 8.747 | nll_loss 7.783 | ppl 220.18 | bleu 13.58 | wps 4648.5 | wpb 5891.5 | bsz 151.3 | num_updates 54819 | best_bleu 13.87
2020-12-04 12:18:39 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:18:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:18:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 119 @ 54819 updates, score 13.58) (writing took 3.461531350389123 seconds)
2020-12-04 12:18:43 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2020-12-04 12:18:43 | INFO | train | epoch 119 | loss 3.757 | nll_loss 1.564 | symm_mse 4.764 | ppl 2.96 | wps 20481.5 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 54819 | lr 0.000135062 | gnorm 0.765 | train_wall 262 | wall 0
2020-12-04 12:18:43 | INFO | fairseq.trainer | begin training epoch 120
2020-12-04 12:18:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:18:45 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:19:24 | INFO | train_inner | epoch 120:     81 / 539 loss=3.709, nll_loss=1.521, symm_mse=4.658, ppl=2.87, wps=15346.8, ups=1.4, wpb=10952.2, bsz=379.4, num_updates=54900, lr=0.000134963, gnorm=0.754, train_wall=48, wall=0
2020-12-04 12:20:13 | INFO | train_inner | epoch 120:    181 / 539 loss=3.769, nll_loss=1.56, symm_mse=4.898, ppl=2.95, wps=21985.7, ups=2.05, wpb=10731.8, bsz=345.3, num_updates=55000, lr=0.00013484, gnorm=0.779, train_wall=49, wall=0
2020-12-04 12:21:03 | INFO | train_inner | epoch 120:    281 / 539 loss=3.756, nll_loss=1.561, symm_mse=4.775, ppl=2.95, wps=22206.8, ups=2.03, wpb=10944.4, bsz=366.1, num_updates=55100, lr=0.000134718, gnorm=0.796, train_wall=49, wall=0
2020-12-04 12:21:52 | INFO | train_inner | epoch 120:    381 / 539 loss=3.771, nll_loss=1.574, symm_mse=4.805, ppl=2.98, wps=22098.2, ups=2.04, wpb=10856.3, bsz=369.2, num_updates=55200, lr=0.000134595, gnorm=0.771, train_wall=49, wall=0
2020-12-04 12:22:41 | INFO | train_inner | epoch 120:    481 / 539 loss=3.744, nll_loss=1.564, symm_mse=4.656, ppl=2.96, wps=22315.2, ups=2.04, wpb=10959, bsz=405.8, num_updates=55300, lr=0.000134474, gnorm=0.756, train_wall=49, wall=0
2020-12-04 12:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:23:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:10 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:11 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:23:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:23:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:23:26 | INFO | valid | epoch 120 | valid on 'valid' subset | symm_mse 0 | loss 8.755 | nll_loss 7.793 | ppl 221.75 | bleu 13.85 | wps 4491.6 | wpb 5891.5 | bsz 151.3 | num_updates 55358 | best_bleu 13.87
2020-12-04 12:23:26 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:23:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 120 @ 55358 updates, score 13.85) (writing took 3.496237253770232 seconds)
2020-12-04 12:23:30 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2020-12-04 12:23:30 | INFO | train | epoch 120 | loss 3.754 | nll_loss 1.56 | symm_mse 4.767 | ppl 2.95 | wps 20437.9 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 55358 | lr 0.000134403 | gnorm 0.771 | train_wall 262 | wall 0
2020-12-04 12:23:30 | INFO | fairseq.trainer | begin training epoch 121
2020-12-04 12:23:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:23:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:23:52 | INFO | train_inner | epoch 121:     42 / 539 loss=3.761, nll_loss=1.566, symm_mse=4.779, ppl=2.96, wps=15190.2, ups=1.4, wpb=10883.2, bsz=363, num_updates=55400, lr=0.000134352, gnorm=0.763, train_wall=48, wall=0
2020-12-04 12:24:41 | INFO | train_inner | epoch 121:    142 / 539 loss=3.719, nll_loss=1.523, symm_mse=4.727, ppl=2.87, wps=22440.6, ups=2.05, wpb=10931.8, bsz=369.9, num_updates=55500, lr=0.000134231, gnorm=0.771, train_wall=49, wall=0
2020-12-04 12:25:30 | INFO | train_inner | epoch 121:    242 / 539 loss=3.756, nll_loss=1.557, symm_mse=4.797, ppl=2.94, wps=22057.4, ups=2.04, wpb=10828, bsz=383.2, num_updates=55600, lr=0.00013411, gnorm=0.778, train_wall=49, wall=0
2020-12-04 12:26:19 | INFO | train_inner | epoch 121:    342 / 539 loss=3.759, nll_loss=1.561, symm_mse=4.797, ppl=2.95, wps=22307.4, ups=2.04, wpb=10930.2, bsz=365.4, num_updates=55700, lr=0.00013399, gnorm=0.762, train_wall=49, wall=0
2020-12-04 12:27:09 | INFO | train_inner | epoch 121:    442 / 539 loss=3.763, nll_loss=1.574, symm_mse=4.743, ppl=2.98, wps=22035.6, ups=2.03, wpb=10867.9, bsz=379, num_updates=55800, lr=0.00013387, gnorm=0.773, train_wall=49, wall=0
2020-12-04 12:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:27:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:27:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:28:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:28:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:28:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:28:13 | INFO | valid | epoch 121 | valid on 'valid' subset | symm_mse 0 | loss 8.759 | nll_loss 7.789 | ppl 221.13 | bleu 13.88 | wps 4575.7 | wpb 5891.5 | bsz 151.3 | num_updates 55897 | best_bleu 13.88
2020-12-04 12:28:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:28:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:28:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:28:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:28:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:28:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:28:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:28:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 121 @ 55897 updates, score 13.88) (writing took 5.83958319760859 seconds)
2020-12-04 12:28:19 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2020-12-04 12:28:19 | INFO | train | epoch 121 | loss 3.751 | nll_loss 1.556 | symm_mse 4.769 | ppl 2.94 | wps 20267.9 | ups 1.86 | wpb 10884.9 | bsz 371.1 | num_updates 55897 | lr 0.000133754 | gnorm 0.772 | train_wall 263 | wall 0
2020-12-04 12:28:19 | INFO | fairseq.trainer | begin training epoch 122
2020-12-04 12:28:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:28:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:28:24 | INFO | train_inner | epoch 122:      3 / 539 loss=3.769, nll_loss=1.575, symm_mse=4.787, ppl=2.98, wps=14479.6, ups=1.33, wpb=10865.8, bsz=359.3, num_updates=55900, lr=0.00013375, gnorm=0.781, train_wall=49, wall=0
2020-12-04 12:29:12 | INFO | train_inner | epoch 122:    103 / 539 loss=3.737, nll_loss=1.536, symm_mse=4.785, ppl=2.9, wps=22612.2, ups=2.07, wpb=10913.3, bsz=365.5, num_updates=56000, lr=0.000133631, gnorm=0.773, train_wall=48, wall=0
2020-12-04 12:30:01 | INFO | train_inner | epoch 122:    203 / 539 loss=3.738, nll_loss=1.538, symm_mse=4.786, ppl=2.9, wps=22225.8, ups=2.03, wpb=10965.8, bsz=371, num_updates=56100, lr=0.000133511, gnorm=0.773, train_wall=49, wall=0
2020-12-04 12:30:50 | INFO | train_inner | epoch 122:    303 / 539 loss=3.723, nll_loss=1.532, symm_mse=4.705, ppl=2.89, wps=22195.9, ups=2.04, wpb=10858.6, bsz=379, num_updates=56200, lr=0.000133393, gnorm=0.764, train_wall=49, wall=0
2020-12-04 12:31:39 | INFO | train_inner | epoch 122:    403 / 539 loss=3.761, nll_loss=1.566, symm_mse=4.786, ppl=2.96, wps=21977.5, ups=2.04, wpb=10763.5, bsz=366.6, num_updates=56300, lr=0.000133274, gnorm=0.777, train_wall=49, wall=0
2020-12-04 12:32:28 | INFO | train_inner | epoch 122:    503 / 539 loss=3.782, nll_loss=1.587, symm_mse=4.805, ppl=3, wps=22390.7, ups=2.05, wpb=10912.5, bsz=364.3, num_updates=56400, lr=0.000133156, gnorm=0.78, train_wall=49, wall=0
2020-12-04 12:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:32:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:32:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:32:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:32:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:32:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:33:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:33:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:33:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:33:03 | INFO | valid | epoch 122 | valid on 'valid' subset | symm_mse 0 | loss 8.796 | nll_loss 7.834 | ppl 228.15 | bleu 13.66 | wps 4308.2 | wpb 5891.5 | bsz 151.3 | num_updates 56436 | best_bleu 13.88
2020-12-04 12:33:03 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:33:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:33:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:33:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:33:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:33:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:33:06 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:33:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 122 @ 56436 updates, score 13.66) (writing took 3.4958332367241383 seconds)
2020-12-04 12:33:07 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2020-12-04 12:33:07 | INFO | train | epoch 122 | loss 3.748 | nll_loss 1.552 | symm_mse 4.771 | ppl 2.93 | wps 20389.4 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 56436 | lr 0.000133113 | gnorm 0.774 | train_wall 263 | wall 0
2020-12-04 12:33:07 | INFO | fairseq.trainer | begin training epoch 123
2020-12-04 12:33:08 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:33:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:33:40 | INFO | train_inner | epoch 123:     64 / 539 loss=3.711, nll_loss=1.519, symm_mse=4.697, ppl=2.87, wps=14973.5, ups=1.38, wpb=10846.9, bsz=385, num_updates=56500, lr=0.000133038, gnorm=0.786, train_wall=48, wall=0
2020-12-04 12:34:29 | INFO | train_inner | epoch 123:    164 / 539 loss=3.724, nll_loss=1.525, symm_mse=4.759, ppl=2.88, wps=22551.2, ups=2.05, wpb=10993.8, bsz=371.8, num_updates=56600, lr=0.00013292, gnorm=0.764, train_wall=49, wall=0
2020-12-04 12:35:18 | INFO | train_inner | epoch 123:    264 / 539 loss=3.731, nll_loss=1.54, symm_mse=4.708, ppl=2.91, wps=22443.6, ups=2.04, wpb=11001, bsz=374.5, num_updates=56700, lr=0.000132803, gnorm=0.766, train_wall=49, wall=0
2020-12-04 12:36:07 | INFO | train_inner | epoch 123:    364 / 539 loss=3.768, nll_loss=1.567, symm_mse=4.84, ppl=2.96, wps=22116.3, ups=2.04, wpb=10857.9, bsz=365.3, num_updates=56800, lr=0.000132686, gnorm=0.787, train_wall=49, wall=0
2020-12-04 12:36:56 | INFO | train_inner | epoch 123:    464 / 539 loss=3.759, nll_loss=1.563, symm_mse=4.789, ppl=2.96, wps=22234, ups=2.04, wpb=10872.7, bsz=375.8, num_updates=56900, lr=0.00013257, gnorm=0.776, train_wall=49, wall=0
2020-12-04 12:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:37:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:33 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:34 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:35 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:37:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:37:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:37:50 | INFO | valid | epoch 123 | valid on 'valid' subset | symm_mse 0 | loss 8.763 | nll_loss 7.797 | ppl 222.38 | bleu 13.81 | wps 4593.5 | wpb 5891.5 | bsz 151.3 | num_updates 56975 | best_bleu 13.88
2020-12-04 12:37:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:37:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 123 @ 56975 updates, score 13.81) (writing took 3.4495729133486748 seconds)
2020-12-04 12:37:53 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2020-12-04 12:37:53 | INFO | train | epoch 123 | loss 3.744 | nll_loss 1.548 | symm_mse 4.768 | ppl 2.92 | wps 20502.4 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 56975 | lr 0.000132482 | gnorm 0.779 | train_wall 262 | wall 0
2020-12-04 12:37:53 | INFO | fairseq.trainer | begin training epoch 124
2020-12-04 12:37:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:37:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:38:08 | INFO | train_inner | epoch 124:     25 / 539 loss=3.777, nll_loss=1.577, symm_mse=4.836, ppl=2.98, wps=14926.6, ups=1.39, wpb=10707.9, bsz=360.9, num_updates=57000, lr=0.000132453, gnorm=0.795, train_wall=48, wall=0
2020-12-04 12:38:56 | INFO | train_inner | epoch 124:    125 / 539 loss=3.696, nll_loss=1.5, symm_mse=4.699, ppl=2.83, wps=22629.7, ups=2.06, wpb=10966.3, bsz=372.1, num_updates=57100, lr=0.000132337, gnorm=0.756, train_wall=48, wall=0
2020-12-04 12:39:45 | INFO | train_inner | epoch 124:    225 / 539 loss=3.734, nll_loss=1.537, symm_mse=4.76, ppl=2.9, wps=22131.9, ups=2.04, wpb=10829.8, bsz=359, num_updates=57200, lr=0.000132221, gnorm=0.763, train_wall=49, wall=0
2020-12-04 12:40:34 | INFO | train_inner | epoch 124:    325 / 539 loss=3.707, nll_loss=1.522, symm_mse=4.642, ppl=2.87, wps=22435.9, ups=2.05, wpb=10953.8, bsz=396.6, num_updates=57300, lr=0.000132106, gnorm=0.76, train_wall=49, wall=0
2020-12-04 12:41:23 | INFO | train_inner | epoch 124:    425 / 539 loss=3.755, nll_loss=1.559, symm_mse=4.782, ppl=2.95, wps=22309.8, ups=2.03, wpb=10970.9, bsz=371.8, num_updates=57400, lr=0.000131991, gnorm=0.782, train_wall=49, wall=0
2020-12-04 12:42:12 | INFO | train_inner | epoch 124:    525 / 539 loss=3.794, nll_loss=1.589, symm_mse=4.91, ppl=3.01, wps=22010.9, ups=2.04, wpb=10770.4, bsz=366.9, num_updates=57500, lr=0.000131876, gnorm=0.793, train_wall=49, wall=0
2020-12-04 12:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:42:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:42:37 | INFO | valid | epoch 124 | valid on 'valid' subset | symm_mse 0 | loss 8.767 | nll_loss 7.803 | ppl 223.38 | bleu 13.76 | wps 4302.2 | wpb 5891.5 | bsz 151.3 | num_updates 57514 | best_bleu 13.88
2020-12-04 12:42:37 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:42:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:37 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:39 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:42:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 124 @ 57514 updates, score 13.76) (writing took 3.498688977211714 seconds)
2020-12-04 12:42:40 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2020-12-04 12:42:40 | INFO | train | epoch 124 | loss 3.741 | nll_loss 1.544 | symm_mse 4.772 | ppl 2.92 | wps 20441.4 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 57514 | lr 0.00013186 | gnorm 0.773 | train_wall 262 | wall 0
2020-12-04 12:42:40 | INFO | fairseq.trainer | begin training epoch 125
2020-12-04 12:42:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:42:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:43:24 | INFO | train_inner | epoch 125:     86 / 539 loss=3.742, nll_loss=1.536, symm_mse=4.831, ppl=2.9, wps=15107.4, ups=1.39, wpb=10856.7, bsz=361.9, num_updates=57600, lr=0.000131762, gnorm=0.777, train_wall=47, wall=0
2020-12-04 12:44:13 | INFO | train_inner | epoch 125:    186 / 539 loss=3.713, nll_loss=1.515, symm_mse=4.743, ppl=2.86, wps=22444.2, ups=2.04, wpb=10989.1, bsz=369.4, num_updates=57700, lr=0.000131647, gnorm=0.771, train_wall=49, wall=0
2020-12-04 12:45:02 | INFO | train_inner | epoch 125:    286 / 539 loss=3.726, nll_loss=1.532, symm_mse=4.73, ppl=2.89, wps=22150.5, ups=2.04, wpb=10857.1, bsz=381.8, num_updates=57800, lr=0.000131533, gnorm=0.77, train_wall=49, wall=0
2020-12-04 12:45:51 | INFO | train_inner | epoch 125:    386 / 539 loss=3.749, nll_loss=1.554, symm_mse=4.767, ppl=2.94, wps=22121.1, ups=2.04, wpb=10822.8, bsz=373.9, num_updates=57900, lr=0.00013142, gnorm=0.786, train_wall=49, wall=0
2020-12-04 12:46:40 | INFO | train_inner | epoch 125:    486 / 539 loss=3.779, nll_loss=1.574, symm_mse=4.881, ppl=2.98, wps=22103.3, ups=2.05, wpb=10799.7, bsz=352.7, num_updates=58000, lr=0.000131306, gnorm=0.807, train_wall=49, wall=0
2020-12-04 12:47:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:47:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:47:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:47:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:47:23 | INFO | valid | epoch 125 | valid on 'valid' subset | symm_mse 0 | loss 8.774 | nll_loss 7.81 | ppl 224.47 | bleu 13.87 | wps 4411.7 | wpb 5891.5 | bsz 151.3 | num_updates 58053 | best_bleu 13.88
2020-12-04 12:47:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:47:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 125 @ 58053 updates, score 13.87) (writing took 3.4374844282865524 seconds)
2020-12-04 12:47:27 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2020-12-04 12:47:27 | INFO | train | epoch 125 | loss 3.738 | nll_loss 1.541 | symm_mse 4.769 | ppl 2.91 | wps 20477.5 | ups 1.88 | wpb 10884.9 | bsz 371.1 | num_updates 58053 | lr 0.000131246 | gnorm 0.779 | train_wall 262 | wall 0
2020-12-04 12:47:27 | INFO | fairseq.trainer | begin training epoch 126
2020-12-04 12:47:27 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:47:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:47:52 | INFO | train_inner | epoch 126:     47 / 539 loss=3.719, nll_loss=1.532, symm_mse=4.674, ppl=2.89, wps=15345, ups=1.39, wpb=11060.6, bsz=375.8, num_updates=58100, lr=0.000131193, gnorm=0.752, train_wall=48, wall=0
2020-12-04 12:48:40 | INFO | train_inner | epoch 126:    147 / 539 loss=3.73, nll_loss=1.525, symm_mse=4.81, ppl=2.88, wps=22321.1, ups=2.07, wpb=10803.3, bsz=356.7, num_updates=58200, lr=0.000131081, gnorm=0.779, train_wall=48, wall=0
2020-12-04 12:49:29 | INFO | train_inner | epoch 126:    247 / 539 loss=3.747, nll_loss=1.54, symm_mse=4.853, ppl=2.91, wps=22010.9, ups=2.03, wpb=10834.7, bsz=364.3, num_updates=58300, lr=0.000130968, gnorm=0.785, train_wall=49, wall=0
2020-12-04 12:50:19 | INFO | train_inner | epoch 126:    347 / 539 loss=3.725, nll_loss=1.528, symm_mse=4.752, ppl=2.88, wps=21964.9, ups=2.02, wpb=10891.1, bsz=378.2, num_updates=58400, lr=0.000130856, gnorm=0.769, train_wall=49, wall=0
2020-12-04 12:51:08 | INFO | train_inner | epoch 126:    447 / 539 loss=3.745, nll_loss=1.548, symm_mse=4.786, ppl=2.92, wps=21917.8, ups=2.03, wpb=10786, bsz=385.3, num_updates=58500, lr=0.000130744, gnorm=0.788, train_wall=49, wall=0
2020-12-04 12:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:51:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:51:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:51:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:51:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:51:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:52:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:52:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:52:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:52:12 | INFO | valid | epoch 126 | valid on 'valid' subset | symm_mse 0 | loss 8.775 | nll_loss 7.81 | ppl 224.49 | bleu 13.58 | wps 4255.8 | wpb 5891.5 | bsz 151.3 | num_updates 58592 | best_bleu 13.88
2020-12-04 12:52:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:52:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:52:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:52:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:52:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:52:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:52:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:52:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 126 @ 58592 updates, score 13.58) (writing took 3.4389650486409664 seconds)
2020-12-04 12:52:15 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2020-12-04 12:52:15 | INFO | train | epoch 126 | loss 3.734 | nll_loss 1.536 | symm_mse 4.77 | ppl 2.9 | wps 20325.2 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 58592 | lr 0.000130641 | gnorm 0.777 | train_wall 263 | wall 0
2020-12-04 12:52:15 | INFO | fairseq.trainer | begin training epoch 127
2020-12-04 12:52:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:52:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:52:22 | INFO | train_inner | epoch 127:      8 / 539 loss=3.732, nll_loss=1.549, symm_mse=4.658, ppl=2.93, wps=14968.7, ups=1.36, wpb=11033.5, bsz=375.2, num_updates=58600, lr=0.000130632, gnorm=0.774, train_wall=49, wall=0
2020-12-04 12:53:10 | INFO | train_inner | epoch 127:    108 / 539 loss=3.715, nll_loss=1.509, symm_mse=4.792, ppl=2.85, wps=22632.9, ups=2.07, wpb=10938.6, bsz=357.8, num_updates=58700, lr=0.000130521, gnorm=0.773, train_wall=48, wall=0
2020-12-04 12:54:00 | INFO | train_inner | epoch 127:    208 / 539 loss=3.725, nll_loss=1.522, symm_mse=4.798, ppl=2.87, wps=22067.3, ups=2.03, wpb=10882.1, bsz=367, num_updates=58800, lr=0.00013041, gnorm=0.777, train_wall=49, wall=0
2020-12-04 12:54:49 | INFO | train_inner | epoch 127:    308 / 539 loss=3.745, nll_loss=1.54, symm_mse=4.839, ppl=2.91, wps=22186.5, ups=2.05, wpb=10848.8, bsz=379.5, num_updates=58900, lr=0.000130299, gnorm=0.802, train_wall=49, wall=0
2020-12-04 12:55:37 | INFO | train_inner | epoch 127:    408 / 539 loss=3.737, nll_loss=1.545, symm_mse=4.728, ppl=2.92, wps=22040.6, ups=2.04, wpb=10786.9, bsz=386.3, num_updates=59000, lr=0.000130189, gnorm=0.788, train_wall=49, wall=0
2020-12-04 12:56:26 | INFO | train_inner | epoch 127:    508 / 539 loss=3.748, nll_loss=1.553, symm_mse=4.78, ppl=2.93, wps=22327.3, ups=2.04, wpb=10927.9, bsz=362.2, num_updates=59100, lr=0.000130079, gnorm=0.773, train_wall=49, wall=0
2020-12-04 12:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 12:56:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:56:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:56:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:56:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:56:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:56:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:56:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:56:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 12:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 12:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 12:57:01 | INFO | valid | epoch 127 | valid on 'valid' subset | symm_mse 0 | loss 8.768 | nll_loss 7.805 | ppl 223.59 | bleu 13.81 | wps 3913.8 | wpb 5891.5 | bsz 151.3 | num_updates 59131 | best_bleu 13.88
2020-12-04 12:57:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 12:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:57:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:57:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:57:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:57:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:57:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 127 @ 59131 updates, score 13.81) (writing took 3.4603645987808704 seconds)
2020-12-04 12:57:04 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2020-12-04 12:57:04 | INFO | train | epoch 127 | loss 3.732 | nll_loss 1.534 | symm_mse 4.776 | ppl 2.89 | wps 20292.6 | ups 1.86 | wpb 10884.9 | bsz 371.1 | num_updates 59131 | lr 0.000130045 | gnorm 0.781 | train_wall 263 | wall 0
2020-12-04 12:57:04 | INFO | fairseq.trainer | begin training epoch 128
2020-12-04 12:57:05 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 12:57:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 12:57:40 | INFO | train_inner | epoch 128:     69 / 539 loss=3.696, nll_loss=1.504, symm_mse=4.676, ppl=2.84, wps=14754.6, ups=1.35, wpb=10912.1, bsz=377.8, num_updates=59200, lr=0.000129969, gnorm=0.766, train_wall=48, wall=0
2020-12-04 12:58:29 | INFO | train_inner | epoch 128:    169 / 539 loss=3.727, nll_loss=1.522, symm_mse=4.81, ppl=2.87, wps=22223.2, ups=2.05, wpb=10865.4, bsz=353, num_updates=59300, lr=0.000129859, gnorm=0.791, train_wall=49, wall=0
2020-12-04 12:59:18 | INFO | train_inner | epoch 128:    269 / 539 loss=3.743, nll_loss=1.536, symm_mse=4.854, ppl=2.9, wps=22175.3, ups=2.04, wpb=10846.6, bsz=368.4, num_updates=59400, lr=0.00012975, gnorm=0.787, train_wall=49, wall=0
2020-12-04 13:00:08 | INFO | train_inner | epoch 128:    369 / 539 loss=3.714, nll_loss=1.521, symm_mse=4.705, ppl=2.87, wps=22182.7, ups=2.03, wpb=10942.4, bsz=388.4, num_updates=59500, lr=0.000129641, gnorm=0.78, train_wall=49, wall=0
2020-12-04 13:00:56 | INFO | train_inner | epoch 128:    469 / 539 loss=3.744, nll_loss=1.548, symm_mse=4.773, ppl=2.92, wps=22310.5, ups=2.04, wpb=10917.4, bsz=374.5, num_updates=59600, lr=0.000129532, gnorm=0.775, train_wall=49, wall=0
2020-12-04 13:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 13:01:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 13:01:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 13:01:50 | INFO | valid | epoch 128 | valid on 'valid' subset | symm_mse 0 | loss 8.758 | nll_loss 7.794 | ppl 221.9 | bleu 13.77 | wps 3837.3 | wpb 5891.5 | bsz 151.3 | num_updates 59670 | best_bleu 13.88
2020-12-04 13:01:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:01:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:01:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 128 @ 59670 updates, score 13.77) (writing took 3.459643069654703 seconds)
2020-12-04 13:01:54 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2020-12-04 13:01:54 | INFO | train | epoch 128 | loss 3.728 | nll_loss 1.529 | symm_mse 4.771 | ppl 2.89 | wps 20262.6 | ups 1.86 | wpb 10884.9 | bsz 371.1 | num_updates 59670 | lr 0.000129456 | gnorm 0.781 | train_wall 263 | wall 0
2020-12-04 13:01:54 | INFO | fairseq.trainer | begin training epoch 129
2020-12-04 13:01:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:01:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:02:11 | INFO | train_inner | epoch 129:     30 / 539 loss=3.719, nll_loss=1.53, symm_mse=4.689, ppl=2.89, wps=14502.8, ups=1.34, wpb=10842.6, bsz=379, num_updates=59700, lr=0.000129423, gnorm=0.769, train_wall=49, wall=0
2020-12-04 13:03:00 | INFO | train_inner | epoch 129:    130 / 539 loss=3.687, nll_loss=1.493, symm_mse=4.676, ppl=2.82, wps=22555.8, ups=2.06, wpb=10939.6, bsz=380, num_updates=59800, lr=0.000129315, gnorm=0.771, train_wall=48, wall=0
2020-12-04 13:03:49 | INFO | train_inner | epoch 129:    230 / 539 loss=3.739, nll_loss=1.528, symm_mse=4.876, ppl=2.88, wps=22057.5, ups=2.04, wpb=10834, bsz=366.8, num_updates=59900, lr=0.000129207, gnorm=0.792, train_wall=49, wall=0
2020-12-04 13:04:38 | INFO | train_inner | epoch 129:    330 / 539 loss=3.729, nll_loss=1.527, symm_mse=4.806, ppl=2.88, wps=22145.7, ups=2.05, wpb=10825.3, bsz=380.6, num_updates=60000, lr=0.000129099, gnorm=0.805, train_wall=49, wall=0
2020-12-04 13:05:27 | INFO | train_inner | epoch 129:    430 / 539 loss=3.755, nll_loss=1.547, symm_mse=4.871, ppl=2.92, wps=22337, ups=2.03, wpb=10976.4, bsz=349.7, num_updates=60100, lr=0.000128992, gnorm=0.801, train_wall=49, wall=0
2020-12-04 13:06:16 | INFO | train_inner | epoch 129:    530 / 539 loss=3.743, nll_loss=1.552, symm_mse=4.728, ppl=2.93, wps=22130.5, ups=2.04, wpb=10845.8, bsz=369.1, num_updates=60200, lr=0.000128885, gnorm=0.781, train_wall=49, wall=0
2020-12-04 13:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:23 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 13:06:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 13:06:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 13:06:38 | INFO | valid | epoch 129 | valid on 'valid' subset | symm_mse 0 | loss 8.781 | nll_loss 7.816 | ppl 225.28 | bleu 13.91 | wps 4357.8 | wpb 5891.5 | bsz 151.3 | num_updates 60209 | best_bleu 13.91
2020-12-04 13:06:38 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:39 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:06:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 129 @ 60209 updates, score 13.91) (writing took 5.858788246288896 seconds)
2020-12-04 13:06:44 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2020-12-04 13:06:44 | INFO | train | epoch 129 | loss 3.726 | nll_loss 1.526 | symm_mse 4.776 | ppl 2.88 | wps 20242.6 | ups 1.86 | wpb 10884.9 | bsz 371.1 | num_updates 60209 | lr 0.000128875 | gnorm 0.787 | train_wall 262 | wall 0
2020-12-04 13:06:44 | INFO | fairseq.trainer | begin training epoch 130
2020-12-04 13:06:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:06:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:07:30 | INFO | train_inner | epoch 130:     91 / 539 loss=3.693, nll_loss=1.494, symm_mse=4.724, ppl=2.82, wps=14682, ups=1.35, wpb=10904.6, bsz=367.7, num_updates=60300, lr=0.000128778, gnorm=0.771, train_wall=48, wall=0
2020-12-04 13:08:19 | INFO | train_inner | epoch 130:    191 / 539 loss=3.696, nll_loss=1.497, symm_mse=4.729, ppl=2.82, wps=22155.9, ups=2.04, wpb=10883.5, bsz=364.4, num_updates=60400, lr=0.000128671, gnorm=0.798, train_wall=49, wall=0
2020-12-04 13:09:08 | INFO | train_inner | epoch 130:    291 / 539 loss=3.748, nll_loss=1.54, symm_mse=4.867, ppl=2.91, wps=22337.2, ups=2.04, wpb=10947.6, bsz=372.3, num_updates=60500, lr=0.000128565, gnorm=0.786, train_wall=49, wall=0
2020-12-04 13:09:58 | INFO | train_inner | epoch 130:    391 / 539 loss=3.739, nll_loss=1.539, symm_mse=4.787, ppl=2.91, wps=21967.5, ups=2.03, wpb=10820.5, bsz=362.6, num_updates=60600, lr=0.000128459, gnorm=0.79, train_wall=49, wall=0
2020-12-04 13:10:47 | INFO | train_inner | epoch 130:    491 / 539 loss=3.744, nll_loss=1.544, symm_mse=4.813, ppl=2.92, wps=22024.6, ups=2.02, wpb=10889.3, bsz=372.7, num_updates=60700, lr=0.000128353, gnorm=0.81, train_wall=49, wall=0
2020-12-04 13:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:11:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:11:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:11:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:11:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:11:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:11:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:11:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:11:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:11:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2020-12-04 13:11:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2020-12-04 13:11:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2020-12-04 13:11:28 | INFO | valid | epoch 130 | valid on 'valid' subset | symm_mse 0 | loss 8.794 | nll_loss 7.834 | ppl 228.17 | bleu 13.72 | wps 4428.2 | wpb 5891.5 | bsz 151.3 | num_updates 60748 | best_bleu 13.91
2020-12-04 13:11:28 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:11:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 130 @ 60748 updates, score 13.72) (writing took 3.496030980721116 seconds)
2020-12-04 13:11:31 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2020-12-04 13:11:31 | INFO | train | epoch 130 | loss 3.723 | nll_loss 1.522 | symm_mse 4.776 | ppl 2.87 | wps 20394.8 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 60748 | lr 0.000128302 | gnorm 0.792 | train_wall 263 | wall 0
2020-12-04 13:11:31 | INFO | fairseq_cli.train | done training in 8603.2 seconds
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 240 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
nohup: ignoring input
2020-12-04 13:14:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:18 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:21 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:11758
2020-12-04 13:14:21 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:11758
2020-12-04 13:14:21 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:11758
2020-12-04 13:14:21 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:11758
2020-12-04 13:14:21 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 2
2020-12-04 13:14:22 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 1
2020-12-04 13:14:22 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 3
2020-12-04 13:14:22 | INFO | fairseq.distributed_utils | initialized host inspur129 as rank 0
2020-12-04 13:14:26 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='closer_dropout', attention_dropout=0.0, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='r3f_closer_dropout_all', cross_self_attention=False, curriculum=0, data='./examples/transformer_enzh/bash/../data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:11758', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eps=1e-05, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3024, max_tokens_valid=3024, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, no_token_positional_embeddings=False, noise_type='normal', nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, r3f_lambda=0.08, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./examples/transformer_enzh/bash/../checkpoints/closer_all1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ch', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-12-04 13:14:26 | INFO | fairseq.tasks.translation | [ch] dictionary: 27920 types
2020-12-04 13:14:26 | INFO | fairseq.tasks.translation | [en] dictionary: 19376 types
2020-12-04 13:14:26 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.ch
2020-12-04 13:14:26 | INFO | fairseq.data.data_utils | loaded 1664 examples from: ./examples/transformer_enzh/bash/../data-bin/valid.ch-en.en
2020-12-04 13:14:26 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin valid ch-en 1664 examples
2020-12-04 13:14:28 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(27920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(19376, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=19376, bias=False)
  )
)
2020-12-04 13:14:28 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2020-12-04 13:14:28 | INFO | fairseq_cli.train | model: closer_dropout (TransformerModel)
2020-12-04 13:14:28 | INFO | fairseq_cli.train | criterion: r3f_closer_dropout_all (R3fCloserDropoutAll)
2020-12-04 13:14:28 | INFO | fairseq_cli.train | num. model params: 78274560 (num. trained: 78274560)
2020-12-04 13:14:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-04 13:14:28 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 13:14:28 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 13:14:28 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 13:14:28 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     
2020-12-04 13:14:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2020-12-04 13:14:28 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2020-12-04 13:14:28 | INFO | fairseq_cli.train | max tokens per GPU = 3024 and max sentences per GPU = None
2020-12-04 13:14:29 | INFO | fairseq.optim.adam | using FusedAdam
2020-12-04 13:14:29 | INFO | fairseq.trainer | loaded checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 131 @ 60748 updates)
2020-12-04 13:14:29 | INFO | fairseq.trainer | loading train data for epoch 131
2020-12-04 13:14:29 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.ch
2020-12-04 13:14:29 | INFO | fairseq.data.data_utils | loaded 200000 examples from: ./examples/transformer_enzh/bash/../data-bin/train.ch-en.en
2020-12-04 13:14:29 | INFO | fairseq.tasks.translation | ./examples/transformer_enzh/bash/../data-bin train ch-en 200000 examples
2020-12-04 13:14:30 | INFO | fairseq.trainer | begin training epoch 131
2020-12-04 13:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:30 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:32 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:14:58 | INFO | train_inner | epoch 131:     52 / 539 loss=3.715, nll_loss=1.51, symm_mse=4.81, ppl=2.85, wps=15521.5, ups=1.43, wpb=10849.7, bsz=381.5, num_updates=60800, lr=0.000128247, gnorm=0.795, train_wall=49, wall=0
2020-12-04 13:15:46 | INFO | train_inner | epoch 131:    152 / 539 loss=3.685, nll_loss=1.487, symm_mse=4.705, ppl=2.8, wps=22680.2, ups=2.09, wpb=10859.6, bsz=371.7, num_updates=60900, lr=0.000128142, gnorm=0.783, train_wall=48, wall=0
2020-12-04 13:16:36 | INFO | train_inner | epoch 131:    252 / 539 loss=3.728, nll_loss=1.527, symm_mse=4.788, ppl=2.88, wps=21675, ups=2, wpb=10823.6, bsz=381.3, num_updates=61000, lr=0.000128037, gnorm=0.796, train_wall=50, wall=0
2020-12-04 13:17:26 | INFO | train_inner | epoch 131:    352 / 539 loss=3.712, nll_loss=1.514, symm_mse=4.748, ppl=2.86, wps=21768.7, ups=1.99, wpb=10939.3, bsz=378, num_updates=61100, lr=0.000127932, gnorm=0.787, train_wall=50, wall=0
2020-12-04 13:18:17 | INFO | train_inner | epoch 131:    452 / 539 loss=3.725, nll_loss=1.529, symm_mse=4.752, ppl=2.89, wps=21903.2, ups=2, wpb=10972.4, bsz=375, num_updates=61200, lr=0.000127827, gnorm=0.776, train_wall=50, wall=0
2020-12-04 13:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:19:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:03 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:19 | INFO | valid | epoch 131 | valid on 'valid' subset | symm_mse 0 | loss 8.816 | nll_loss 7.854 | ppl 231.34 | bleu 13.79 | wps 4169.3 | wpb 5891.5 | bsz 151.3 | num_updates 61287 | best_bleu 13.91
2020-12-04 13:19:19 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:19:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:20 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 131 @ 61287 updates, score 13.79) (writing took 3.5704690739512444 seconds)
2020-12-04 13:19:23 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2020-12-04 13:19:23 | INFO | train | epoch 131 | loss 3.721 | nll_loss 1.52 | symm_mse 4.777 | ppl 2.87 | wps 20320.7 | ups 1.87 | wpb 10884.9 | bsz 371.1 | num_updates 61287 | lr 0.000127737 | gnorm 0.79 | train_wall 530 | wall 0
2020-12-04 13:19:23 | INFO | fairseq.trainer | begin training epoch 132
2020-12-04 13:19:23 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:19:25 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:19:32 | INFO | train_inner | epoch 132:     13 / 539 loss=3.742, nll_loss=1.538, symm_mse=4.83, ppl=2.9, wps=14422.1, ups=1.33, wpb=10874.1, bsz=347.5, num_updates=61300, lr=0.000127723, gnorm=0.791, train_wall=50, wall=0
2020-12-04 13:20:21 | INFO | train_inner | epoch 132:    113 / 539 loss=3.705, nll_loss=1.5, symm_mse=4.785, ppl=2.83, wps=21983.4, ups=2.02, wpb=10860.3, bsz=361.3, num_updates=61400, lr=0.000127619, gnorm=0.784, train_wall=49, wall=0
2020-12-04 13:21:11 | INFO | train_inner | epoch 132:    213 / 539 loss=3.708, nll_loss=1.502, symm_mse=4.792, ppl=2.83, wps=21822.8, ups=2, wpb=10918.1, bsz=360.7, num_updates=61500, lr=0.000127515, gnorm=0.786, train_wall=50, wall=0
2020-12-04 13:22:01 | INFO | train_inner | epoch 132:    313 / 539 loss=3.72, nll_loss=1.52, symm_mse=4.776, ppl=2.87, wps=21607.2, ups=2, wpb=10824.6, bsz=367.6, num_updates=61600, lr=0.000127412, gnorm=0.786, train_wall=50, wall=0
2020-12-04 13:22:52 | INFO | train_inner | epoch 132:    413 / 539 loss=3.721, nll_loss=1.522, symm_mse=4.765, ppl=2.87, wps=21702.1, ups=1.99, wpb=10886, bsz=370, num_updates=61700, lr=0.000127309, gnorm=0.786, train_wall=50, wall=0
2020-12-04 13:23:42 | INFO | train_inner | epoch 132:    513 / 539 loss=3.722, nll_loss=1.53, symm_mse=4.722, ppl=2.89, wps=21538.8, ups=1.98, wpb=10886.5, bsz=393.6, num_updates=61800, lr=0.000127205, gnorm=0.789, train_wall=50, wall=0
2020-12-04 13:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:23:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:23:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:23:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:23:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:23:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:23:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:23:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:23:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:24:13 | INFO | valid | epoch 132 | valid on 'valid' subset | symm_mse 0 | loss 8.747 | nll_loss 7.782 | ppl 220.07 | bleu 13.77 | wps 4222.8 | wpb 5891.5 | bsz 151.3 | num_updates 61826 | best_bleu 13.91
2020-12-04 13:24:13 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:24:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:24:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:24:14 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:24:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:24:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:24:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:24:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 132 @ 61826 updates, score 13.77) (writing took 3.54038567841053 seconds)
2020-12-04 13:24:17 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2020-12-04 13:24:17 | INFO | train | epoch 132 | loss 3.716 | nll_loss 1.515 | symm_mse 4.774 | ppl 2.86 | wps 19943.3 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 61826 | lr 0.000127179 | gnorm 0.787 | train_wall 269 | wall 0
2020-12-04 13:24:17 | INFO | fairseq.trainer | begin training epoch 133
2020-12-04 13:24:18 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:24:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:24:56 | INFO | train_inner | epoch 133:     74 / 539 loss=3.702, nll_loss=1.501, symm_mse=4.756, ppl=2.83, wps=14669.3, ups=1.35, wpb=10864.7, bsz=374.2, num_updates=61900, lr=0.000127103, gnorm=0.795, train_wall=49, wall=0
2020-12-04 13:25:47 | INFO | train_inner | epoch 133:    174 / 539 loss=3.702, nll_loss=1.492, symm_mse=4.815, ppl=2.81, wps=21664.7, ups=1.98, wpb=10963.1, bsz=371.7, num_updates=62000, lr=0.000127, gnorm=0.791, train_wall=50, wall=0
2020-12-04 13:26:37 | INFO | train_inner | epoch 133:    274 / 539 loss=3.702, nll_loss=1.502, symm_mse=4.758, ppl=2.83, wps=21660.4, ups=1.99, wpb=10881.5, bsz=379.7, num_updates=62100, lr=0.000126898, gnorm=0.786, train_wall=50, wall=0
2020-12-04 13:27:27 | INFO | train_inner | epoch 133:    374 / 539 loss=3.689, nll_loss=1.498, symm_mse=4.66, ppl=2.83, wps=21798.3, ups=1.99, wpb=10965, bsz=388.2, num_updates=62200, lr=0.000126796, gnorm=0.785, train_wall=50, wall=0
2020-12-04 13:28:17 | INFO | train_inner | epoch 133:    474 / 539 loss=3.768, nll_loss=1.558, symm_mse=4.901, ppl=2.95, wps=21677.9, ups=2.01, wpb=10759.4, bsz=346.3, num_updates=62300, lr=0.000126694, gnorm=0.805, train_wall=49, wall=0
2020-12-04 13:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:28:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:28:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:29:08 | INFO | valid | epoch 133 | valid on 'valid' subset | symm_mse 0 | loss 8.771 | nll_loss 7.806 | ppl 223.76 | bleu 13.73 | wps 4287.8 | wpb 5891.5 | bsz 151.3 | num_updates 62365 | best_bleu 13.91
2020-12-04 13:29:08 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:29:09 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:29:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:29:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:29:10 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:29:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 133 @ 62365 updates, score 13.73) (writing took 3.5394821856170893 seconds)
2020-12-04 13:29:11 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2020-12-04 13:29:11 | INFO | train | epoch 133 | loss 3.714 | nll_loss 1.512 | symm_mse 4.774 | ppl 2.85 | wps 19924.2 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 62365 | lr 0.000126628 | gnorm 0.79 | train_wall 269 | wall 0
2020-12-04 13:29:11 | INFO | fairseq.trainer | begin training epoch 134
2020-12-04 13:29:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:29:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:29:31 | INFO | train_inner | epoch 134:     35 / 539 loss=3.724, nll_loss=1.524, symm_mse=4.784, ppl=2.88, wps=14627.9, ups=1.34, wpb=10885, bsz=367.6, num_updates=62400, lr=0.000126592, gnorm=0.785, train_wall=50, wall=0
2020-12-04 13:30:22 | INFO | train_inner | epoch 134:    135 / 539 loss=3.683, nll_loss=1.479, symm_mse=4.742, ppl=2.79, wps=21617.8, ups=1.98, wpb=10933.3, bsz=370.8, num_updates=62500, lr=0.000126491, gnorm=0.776, train_wall=50, wall=0
2020-12-04 13:31:12 | INFO | train_inner | epoch 134:    235 / 539 loss=3.692, nll_loss=1.491, symm_mse=4.743, ppl=2.81, wps=21678.8, ups=1.99, wpb=10912.1, bsz=377.6, num_updates=62600, lr=0.00012639, gnorm=0.79, train_wall=50, wall=0
2020-12-04 13:32:03 | INFO | train_inner | epoch 134:    335 / 539 loss=3.699, nll_loss=1.5, symm_mse=4.74, ppl=2.83, wps=21533.3, ups=1.99, wpb=10832.2, bsz=377, num_updates=62700, lr=0.000126289, gnorm=0.797, train_wall=50, wall=0
2020-12-04 13:32:53 | INFO | train_inner | epoch 134:    435 / 539 loss=3.749, nll_loss=1.538, symm_mse=4.888, ppl=2.9, wps=21599.8, ups=1.98, wpb=10894.8, bsz=356.6, num_updates=62800, lr=0.000126189, gnorm=0.805, train_wall=50, wall=0
2020-12-04 13:33:44 | INFO | train_inner | epoch 134:    535 / 539 loss=3.737, nll_loss=1.536, symm_mse=4.806, ppl=2.9, wps=21435.9, ups=1.97, wpb=10885.2, bsz=377, num_updates=62900, lr=0.000126088, gnorm=0.803, train_wall=51, wall=0
2020-12-04 13:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:33:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:33:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:33:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:33:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:33:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:33:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:33:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:33:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:34:03 | INFO | valid | epoch 134 | valid on 'valid' subset | symm_mse 0 | loss 8.78 | nll_loss 7.818 | ppl 225.59 | bleu 13.89 | wps 4572.7 | wpb 5891.5 | bsz 151.3 | num_updates 62904 | best_bleu 13.91
2020-12-04 13:34:03 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:34:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:34:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:34:04 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:34:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:34:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:34:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:34:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 134 @ 62904 updates, score 13.89) (writing took 3.1590240728110075 seconds)
2020-12-04 13:34:06 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2020-12-04 13:34:06 | INFO | train | epoch 134 | loss 3.711 | nll_loss 1.508 | symm_mse 4.783 | ppl 2.84 | wps 19910.7 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 62904 | lr 0.000126084 | gnorm 0.793 | train_wall 270 | wall 0
2020-12-04 13:34:06 | INFO | fairseq.trainer | begin training epoch 135
2020-12-04 13:34:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:34:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:34:56 | INFO | train_inner | epoch 135:     96 / 539 loss=3.699, nll_loss=1.492, symm_mse=4.791, ppl=2.81, wps=14848.9, ups=1.38, wpb=10774.9, bsz=373, num_updates=63000, lr=0.000125988, gnorm=0.8, train_wall=49, wall=0
2020-12-04 13:35:47 | INFO | train_inner | epoch 135:    196 / 539 loss=3.664, nll_loss=1.469, symm_mse=4.663, ppl=2.77, wps=21794.1, ups=1.99, wpb=10960.2, bsz=393.2, num_updates=63100, lr=0.000125888, gnorm=0.785, train_wall=50, wall=0
2020-12-04 13:36:37 | INFO | train_inner | epoch 135:    296 / 539 loss=3.711, nll_loss=1.509, symm_mse=4.776, ppl=2.85, wps=21599, ups=1.99, wpb=10847.9, bsz=365.9, num_updates=63200, lr=0.000125789, gnorm=0.81, train_wall=50, wall=0
2020-12-04 13:37:27 | INFO | train_inner | epoch 135:    396 / 539 loss=3.749, nll_loss=1.535, symm_mse=4.908, ppl=2.9, wps=21482.7, ups=1.98, wpb=10841.8, bsz=346.3, num_updates=63300, lr=0.000125689, gnorm=0.793, train_wall=50, wall=0
2020-12-04 13:38:18 | INFO | train_inner | epoch 135:    496 / 539 loss=3.701, nll_loss=1.509, symm_mse=4.701, ppl=2.85, wps=21865.6, ups=1.98, wpb=11044.3, bsz=386.7, num_updates=63400, lr=0.00012559, gnorm=0.788, train_wall=50, wall=0
2020-12-04 13:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:38:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:40 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:56 | INFO | valid | epoch 135 | valid on 'valid' subset | symm_mse 0 | loss 8.864 | nll_loss 7.905 | ppl 239.77 | bleu 13.73 | wps 4633 | wpb 5891.5 | bsz 151.3 | num_updates 63443 | best_bleu 13.91
2020-12-04 13:38:56 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:38:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:38:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:38:59 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:39:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 135 @ 63443 updates, score 13.73) (writing took 3.691382884979248 seconds)
2020-12-04 13:39:00 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2020-12-04 13:39:00 | INFO | train | epoch 135 | loss 3.71 | nll_loss 1.507 | symm_mse 4.782 | ppl 2.84 | wps 19957.9 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 63443 | lr 0.000125548 | gnorm 0.797 | train_wall 269 | wall 0
2020-12-04 13:39:00 | INFO | fairseq.trainer | begin training epoch 136
2020-12-04 13:39:01 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:39:02 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:39:31 | INFO | train_inner | epoch 136:     57 / 539 loss=3.716, nll_loss=1.508, symm_mse=4.823, ppl=2.84, wps=14848.1, ups=1.37, wpb=10854.1, bsz=362.2, num_updates=63500, lr=0.000125491, gnorm=0.797, train_wall=49, wall=0
2020-12-04 13:40:21 | INFO | train_inner | epoch 136:    157 / 539 loss=3.668, nll_loss=1.472, symm_mse=4.671, ppl=2.77, wps=21666, ups=1.98, wpb=10920.9, bsz=396.2, num_updates=63600, lr=0.000125392, gnorm=0.785, train_wall=50, wall=0
2020-12-04 13:41:12 | INFO | train_inner | epoch 136:    257 / 539 loss=3.728, nll_loss=1.51, symm_mse=4.915, ppl=2.85, wps=21344, ups=1.98, wpb=10772.8, bsz=346.2, num_updates=63700, lr=0.000125294, gnorm=0.807, train_wall=50, wall=0
2020-12-04 13:42:02 | INFO | train_inner | epoch 136:    357 / 539 loss=3.689, nll_loss=1.491, symm_mse=4.71, ppl=2.81, wps=21754.7, ups=1.99, wpb=10904.9, bsz=372, num_updates=63800, lr=0.000125196, gnorm=0.777, train_wall=50, wall=0
2020-12-04 13:42:53 | INFO | train_inner | epoch 136:    457 / 539 loss=3.729, nll_loss=1.523, symm_mse=4.834, ppl=2.87, wps=21483, ups=1.98, wpb=10873.3, bsz=375.8, num_updates=63900, lr=0.000125098, gnorm=0.806, train_wall=50, wall=0
2020-12-04 13:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:43:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:36 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:50 | INFO | valid | epoch 136 | valid on 'valid' subset | symm_mse 0 | loss 8.814 | nll_loss 7.854 | ppl 231.41 | bleu 13.72 | wps 4674.6 | wpb 5891.5 | bsz 151.3 | num_updates 63982 | best_bleu 13.91
2020-12-04 13:43:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:43:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:43:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 136 @ 63982 updates, score 13.72) (writing took 3.612567711621523 seconds)
2020-12-04 13:43:54 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2020-12-04 13:43:54 | INFO | train | epoch 136 | loss 3.705 | nll_loss 1.502 | symm_mse 4.778 | ppl 2.83 | wps 19952 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 63982 | lr 0.000125018 | gnorm 0.793 | train_wall 270 | wall 0
2020-12-04 13:43:54 | INFO | fairseq.trainer | begin training epoch 137
2020-12-04 13:43:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:43:56 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:44:06 | INFO | train_inner | epoch 137:     18 / 539 loss=3.731, nll_loss=1.53, symm_mse=4.794, ppl=2.89, wps=14959.5, ups=1.37, wpb=10944.5, bsz=362.1, num_updates=64000, lr=0.000125, gnorm=0.798, train_wall=50, wall=0
2020-12-04 13:44:55 | INFO | train_inner | epoch 137:    118 / 539 loss=3.648, nll_loss=1.455, symm_mse=4.628, ppl=2.74, wps=21844.9, ups=2.01, wpb=10844.6, bsz=384, num_updates=64100, lr=0.000124902, gnorm=0.787, train_wall=49, wall=0
2020-12-04 13:45:46 | INFO | train_inner | epoch 137:    218 / 539 loss=3.724, nll_loss=1.508, symm_mse=4.902, ppl=2.84, wps=21360.7, ups=1.96, wpb=10874.1, bsz=349.8, num_updates=64200, lr=0.000124805, gnorm=0.807, train_wall=51, wall=0
2020-12-04 13:46:37 | INFO | train_inner | epoch 137:    318 / 539 loss=3.69, nll_loss=1.489, symm_mse=4.736, ppl=2.81, wps=21677.2, ups=1.98, wpb=10944.1, bsz=383, num_updates=64300, lr=0.000124708, gnorm=0.798, train_wall=50, wall=0
2020-12-04 13:47:27 | INFO | train_inner | epoch 137:    418 / 539 loss=3.709, nll_loss=1.508, symm_mse=4.772, ppl=2.84, wps=21412.8, ups=1.99, wpb=10747.2, bsz=376.6, num_updates=64400, lr=0.000124611, gnorm=0.802, train_wall=50, wall=0
2020-12-04 13:48:17 | INFO | train_inner | epoch 137:    518 / 539 loss=3.756, nll_loss=1.543, symm_mse=4.918, ppl=2.91, wps=21983.8, ups=2, wpb=10966.1, bsz=360.6, num_updates=64500, lr=0.000124515, gnorm=0.805, train_wall=50, wall=0
2020-12-04 13:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:44 | INFO | valid | epoch 137 | valid on 'valid' subset | symm_mse 0 | loss 8.813 | nll_loss 7.853 | ppl 231.23 | bleu 13.92 | wps 4658.2 | wpb 5891.5 | bsz 151.3 | num_updates 64521 | best_bleu 13.92
2020-12-04 13:48:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:48:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:45 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:48:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 137 @ 64521 updates, score 13.92) (writing took 6.073581842705607 seconds)
2020-12-04 13:48:50 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2020-12-04 13:48:50 | INFO | train | epoch 137 | loss 3.704 | nll_loss 1.5 | symm_mse 4.784 | ppl 2.83 | wps 19807.6 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 64521 | lr 0.000124494 | gnorm 0.799 | train_wall 269 | wall 0
2020-12-04 13:48:50 | INFO | fairseq.trainer | begin training epoch 138
2020-12-04 13:48:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:48:53 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:49:32 | INFO | train_inner | epoch 138:     79 / 539 loss=3.666, nll_loss=1.469, symm_mse=4.674, ppl=2.77, wps=14495.5, ups=1.33, wpb=10906.7, bsz=385.1, num_updates=64600, lr=0.000124418, gnorm=0.779, train_wall=49, wall=0
2020-12-04 13:50:22 | INFO | train_inner | epoch 138:    179 / 539 loss=3.694, nll_loss=1.485, symm_mse=4.801, ppl=2.8, wps=21635.4, ups=2, wpb=10804.5, bsz=360.1, num_updates=64700, lr=0.000124322, gnorm=0.796, train_wall=50, wall=0
2020-12-04 13:51:12 | INFO | train_inner | epoch 138:    279 / 539 loss=3.692, nll_loss=1.488, symm_mse=4.759, ppl=2.8, wps=21725.2, ups=1.99, wpb=10902.4, bsz=360.2, num_updates=64800, lr=0.000124226, gnorm=0.795, train_wall=50, wall=0
2020-12-04 13:52:03 | INFO | train_inner | epoch 138:    379 / 539 loss=3.718, nll_loss=1.508, symm_mse=4.851, ppl=2.84, wps=21544.4, ups=1.97, wpb=10910.2, bsz=382.7, num_updates=64900, lr=0.00012413, gnorm=0.813, train_wall=50, wall=0
2020-12-04 13:52:53 | INFO | train_inner | epoch 138:    479 / 539 loss=3.73, nll_loss=1.525, symm_mse=4.834, ppl=2.88, wps=21886.7, ups=2, wpb=10950.1, bsz=365.2, num_updates=65000, lr=0.000124035, gnorm=0.797, train_wall=50, wall=0
2020-12-04 13:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:40 | INFO | valid | epoch 138 | valid on 'valid' subset | symm_mse 0 | loss 8.786 | nll_loss 7.824 | ppl 226.55 | bleu 13.86 | wps 4601.5 | wpb 5891.5 | bsz 151.3 | num_updates 65060 | best_bleu 13.92
2020-12-04 13:53:40 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:53:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:41 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:42 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:53:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 138 @ 65060 updates, score 13.86) (writing took 3.6445770747959614 seconds)
2020-12-04 13:53:44 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2020-12-04 13:53:44 | INFO | train | epoch 138 | loss 3.701 | nll_loss 1.496 | symm_mse 4.782 | ppl 2.82 | wps 19997.9 | ups 1.84 | wpb 10884.9 | bsz 371.1 | num_updates 65060 | lr 0.000123978 | gnorm 0.797 | train_wall 269 | wall 0
2020-12-04 13:53:44 | INFO | fairseq.trainer | begin training epoch 139
2020-12-04 13:53:44 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:53:46 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:54:06 | INFO | train_inner | epoch 139:     40 / 539 loss=3.698, nll_loss=1.494, symm_mse=4.78, ppl=2.82, wps=14816.2, ups=1.37, wpb=10829.1, bsz=366.2, num_updates=65100, lr=0.000123939, gnorm=0.802, train_wall=49, wall=0
2020-12-04 13:54:56 | INFO | train_inner | epoch 139:    140 / 539 loss=3.662, nll_loss=1.464, symm_mse=4.684, ppl=2.76, wps=21623.4, ups=1.99, wpb=10871.9, bsz=388.8, num_updates=65200, lr=0.000123844, gnorm=0.79, train_wall=50, wall=0
2020-12-04 13:55:47 | INFO | train_inner | epoch 139:    240 / 539 loss=3.692, nll_loss=1.481, symm_mse=4.829, ppl=2.79, wps=21634.1, ups=1.98, wpb=10902.1, bsz=362, num_updates=65300, lr=0.000123749, gnorm=0.795, train_wall=50, wall=0
2020-12-04 13:56:37 | INFO | train_inner | epoch 139:    340 / 539 loss=3.694, nll_loss=1.49, symm_mse=4.77, ppl=2.81, wps=21528.6, ups=1.97, wpb=10904.7, bsz=372.5, num_updates=65400, lr=0.000123655, gnorm=0.796, train_wall=50, wall=0
2020-12-04 13:57:28 | INFO | train_inner | epoch 139:    440 / 539 loss=3.728, nll_loss=1.518, symm_mse=4.855, ppl=2.86, wps=21618.2, ups=1.97, wpb=10951, bsz=371, num_updates=65500, lr=0.00012356, gnorm=0.801, train_wall=50, wall=0
2020-12-04 13:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 13:58:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:20 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:35 | INFO | valid | epoch 139 | valid on 'valid' subset | symm_mse 0 | loss 8.771 | nll_loss 7.81 | ppl 224.37 | bleu 13.95 | wps 4548 | wpb 5891.5 | bsz 151.3 | num_updates 65599 | best_bleu 13.95
2020-12-04 13:58:35 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 13:58:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 139 @ 65599 updates, score 13.95) (writing took 6.051116265356541 seconds)
2020-12-04 13:58:41 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2020-12-04 13:58:41 | INFO | train | epoch 139 | loss 3.698 | nll_loss 1.493 | symm_mse 4.782 | ppl 2.82 | wps 19740.8 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 65599 | lr 0.000123467 | gnorm 0.798 | train_wall 270 | wall 0
2020-12-04 13:58:41 | INFO | fairseq.trainer | begin training epoch 140
2020-12-04 13:58:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 13:58:43 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 13:58:44 | INFO | train_inner | epoch 140:      1 / 539 loss=3.722, nll_loss=1.527, symm_mse=4.744, ppl=2.88, wps=14199.8, ups=1.31, wpb=10837.9, bsz=368.5, num_updates=65600, lr=0.000123466, gnorm=0.801, train_wall=50, wall=0
2020-12-04 13:59:34 | INFO | train_inner | epoch 140:    101 / 539 loss=3.672, nll_loss=1.463, symm_mse=4.77, ppl=2.76, wps=22003, ups=2.03, wpb=10849.4, bsz=373, num_updates=65700, lr=0.000123372, gnorm=0.791, train_wall=49, wall=0
2020-12-04 14:00:24 | INFO | train_inner | epoch 140:    201 / 539 loss=3.659, nll_loss=1.464, symm_mse=4.659, ppl=2.76, wps=21400.1, ups=1.97, wpb=10856.8, bsz=378.7, num_updates=65800, lr=0.000123278, gnorm=0.784, train_wall=51, wall=0
2020-12-04 14:01:15 | INFO | train_inner | epoch 140:    301 / 539 loss=3.695, nll_loss=1.49, symm_mse=4.781, ppl=2.81, wps=21545.3, ups=1.99, wpb=10834.9, bsz=378.5, num_updates=65900, lr=0.000123185, gnorm=0.796, train_wall=50, wall=0
2020-12-04 14:02:05 | INFO | train_inner | epoch 140:    401 / 539 loss=3.702, nll_loss=1.499, symm_mse=4.77, ppl=2.83, wps=21722.6, ups=1.98, wpb=10988.8, bsz=367.9, num_updates=66000, lr=0.000123091, gnorm=0.802, train_wall=50, wall=0
2020-12-04 14:02:56 | INFO | train_inner | epoch 140:    501 / 539 loss=3.737, nll_loss=1.524, symm_mse=4.89, ppl=2.88, wps=21634, ups=1.98, wpb=10922, bsz=351.2, num_updates=66100, lr=0.000122998, gnorm=0.803, train_wall=50, wall=0
2020-12-04 14:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:03:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:16 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:17 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:32 | INFO | valid | epoch 140 | valid on 'valid' subset | symm_mse 0 | loss 8.876 | nll_loss 7.921 | ppl 242.39 | bleu 13.58 | wps 4665.7 | wpb 5891.5 | bsz 151.3 | num_updates 66138 | best_bleu 13.95
2020-12-04 14:03:32 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:03:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:03:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 140 @ 66138 updates, score 13.58) (writing took 3.7082355450838804 seconds)
2020-12-04 14:03:35 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2020-12-04 14:03:35 | INFO | train | epoch 140 | loss 3.695 | nll_loss 1.49 | symm_mse 4.78 | ppl 2.81 | wps 19920.7 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 66138 | lr 0.000122963 | gnorm 0.797 | train_wall 270 | wall 0
2020-12-04 14:03:35 | INFO | fairseq.trainer | begin training epoch 141
2020-12-04 14:03:36 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:03:38 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:04:09 | INFO | train_inner | epoch 141:     62 / 539 loss=3.675, nll_loss=1.471, symm_mse=4.755, ppl=2.77, wps=14799.8, ups=1.37, wpb=10823.7, bsz=380.5, num_updates=66200, lr=0.000122905, gnorm=0.797, train_wall=49, wall=0
2020-12-04 14:04:59 | INFO | train_inner | epoch 141:    162 / 539 loss=3.668, nll_loss=1.462, symm_mse=4.748, ppl=2.75, wps=21698, ups=1.98, wpb=10979, bsz=380.7, num_updates=66300, lr=0.000122813, gnorm=0.8, train_wall=50, wall=0
2020-12-04 14:05:50 | INFO | train_inner | epoch 141:    262 / 539 loss=3.718, nll_loss=1.5, symm_mse=4.9, ppl=2.83, wps=21405.7, ups=1.98, wpb=10823, bsz=345.6, num_updates=66400, lr=0.00012272, gnorm=0.81, train_wall=50, wall=0
2020-12-04 14:06:41 | INFO | train_inner | epoch 141:    362 / 539 loss=3.707, nll_loss=1.499, symm_mse=4.818, ppl=2.83, wps=21307.4, ups=1.98, wpb=10783, bsz=364.1, num_updates=66500, lr=0.000122628, gnorm=0.818, train_wall=50, wall=0
2020-12-04 14:07:31 | INFO | train_inner | epoch 141:    462 / 539 loss=3.668, nll_loss=1.476, symm_mse=4.659, ppl=2.78, wps=21607.9, ups=1.97, wpb=10956.5, bsz=398.6, num_updates=66600, lr=0.000122536, gnorm=0.789, train_wall=51, wall=0
2020-12-04 14:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:27 | INFO | valid | epoch 141 | valid on 'valid' subset | symm_mse 0 | loss 8.871 | nll_loss 7.916 | ppl 241.54 | bleu 13.76 | wps 4617.3 | wpb 5891.5 | bsz 151.3 | num_updates 66677 | best_bleu 13.95
2020-12-04 14:08:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:08:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:30 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 141 @ 66677 updates, score 13.76) (writing took 3.706529403105378 seconds)
2020-12-04 14:08:31 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2020-12-04 14:08:31 | INFO | train | epoch 141 | loss 3.692 | nll_loss 1.487 | symm_mse 4.781 | ppl 2.8 | wps 19838.5 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 66677 | lr 0.000122465 | gnorm 0.802 | train_wall 271 | wall 0
2020-12-04 14:08:31 | INFO | fairseq.trainer | begin training epoch 142
2020-12-04 14:08:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:08:33 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:08:45 | INFO | train_inner | epoch 142:     23 / 539 loss=3.733, nll_loss=1.521, symm_mse=4.885, ppl=2.87, wps=14741.8, ups=1.35, wpb=10884.3, bsz=360.5, num_updates=66700, lr=0.000122444, gnorm=0.815, train_wall=50, wall=0
2020-12-04 14:09:35 | INFO | train_inner | epoch 142:    123 / 539 loss=3.656, nll_loss=1.452, symm_mse=4.724, ppl=2.74, wps=21975.2, ups=2.01, wpb=10952.4, bsz=389, num_updates=66800, lr=0.000122352, gnorm=0.788, train_wall=50, wall=0
2020-12-04 14:10:26 | INFO | train_inner | epoch 142:    223 / 539 loss=3.705, nll_loss=1.487, symm_mse=4.887, ppl=2.8, wps=21474.9, ups=1.97, wpb=10899.1, bsz=355.5, num_updates=66900, lr=0.000122261, gnorm=0.804, train_wall=51, wall=0
2020-12-04 14:11:16 | INFO | train_inner | epoch 142:    323 / 539 loss=3.644, nll_loss=1.453, symm_mse=4.614, ppl=2.74, wps=21667.1, ups=1.98, wpb=10968.6, bsz=379.1, num_updates=67000, lr=0.000122169, gnorm=0.775, train_wall=50, wall=0
2020-12-04 14:12:07 | INFO | train_inner | epoch 142:    423 / 539 loss=3.727, nll_loss=1.518, symm_mse=4.859, ppl=2.86, wps=21522.5, ups=1.99, wpb=10836, bsz=364.7, num_updates=67100, lr=0.000122078, gnorm=0.82, train_wall=50, wall=0
2020-12-04 14:12:57 | INFO | train_inner | epoch 142:    523 / 539 loss=3.719, nll_loss=1.514, symm_mse=4.809, ppl=2.86, wps=21328.9, ups=1.97, wpb=10812.1, bsz=370.2, num_updates=67200, lr=0.000121988, gnorm=0.802, train_wall=51, wall=0
2020-12-04 14:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:13:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:08 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:23 | INFO | valid | epoch 142 | valid on 'valid' subset | symm_mse 0 | loss 8.829 | nll_loss 7.868 | ppl 233.62 | bleu 13.62 | wps 4276.7 | wpb 5891.5 | bsz 151.3 | num_updates 67216 | best_bleu 13.95
2020-12-04 14:13:23 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:13:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:13:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 142 @ 67216 updates, score 13.62) (writing took 3.6406914982944727 seconds)
2020-12-04 14:13:27 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2020-12-04 14:13:27 | INFO | train | epoch 142 | loss 3.69 | nll_loss 1.484 | symm_mse 4.782 | ppl 2.8 | wps 19826.6 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 67216 | lr 0.000121973 | gnorm 0.8 | train_wall 270 | wall 0
2020-12-04 14:13:27 | INFO | fairseq.trainer | begin training epoch 143
2020-12-04 14:13:28 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:13:29 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:14:12 | INFO | train_inner | epoch 143:     84 / 539 loss=3.632, nll_loss=1.435, symm_mse=4.632, ppl=2.7, wps=14768.4, ups=1.35, wpb=10958.6, bsz=388.6, num_updates=67300, lr=0.000121897, gnorm=0.795, train_wall=49, wall=0
2020-12-04 14:15:02 | INFO | train_inner | epoch 143:    184 / 539 loss=3.688, nll_loss=1.475, symm_mse=4.82, ppl=2.78, wps=21567.1, ups=1.98, wpb=10882.9, bsz=351.4, num_updates=67400, lr=0.000121806, gnorm=0.809, train_wall=50, wall=0
2020-12-04 14:15:53 | INFO | train_inner | epoch 143:    284 / 539 loss=3.707, nll_loss=1.489, symm_mse=4.9, ppl=2.81, wps=21311.7, ups=1.98, wpb=10765.4, bsz=356.6, num_updates=67500, lr=0.000121716, gnorm=0.82, train_wall=50, wall=0
2020-12-04 14:16:43 | INFO | train_inner | epoch 143:    384 / 539 loss=3.702, nll_loss=1.498, symm_mse=4.789, ppl=2.82, wps=21585.9, ups=1.97, wpb=10940.2, bsz=372.1, num_updates=67600, lr=0.000121626, gnorm=0.804, train_wall=50, wall=0
2020-12-04 14:17:34 | INFO | train_inner | epoch 143:    484 / 539 loss=3.705, nll_loss=1.499, symm_mse=4.797, ppl=2.83, wps=21576.8, ups=1.99, wpb=10834.9, bsz=377.5, num_updates=67700, lr=0.000121536, gnorm=0.807, train_wall=50, wall=0
2020-12-04 14:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:02 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:04 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:20 | INFO | valid | epoch 143 | valid on 'valid' subset | symm_mse 0 | loss 8.861 | nll_loss 7.902 | ppl 239.19 | bleu 13.74 | wps 4064.9 | wpb 5891.5 | bsz 151.3 | num_updates 67755 | best_bleu 13.95
2020-12-04 14:18:20 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:18:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 143 @ 67755 updates, score 13.74) (writing took 3.767707921564579 seconds)
2020-12-04 14:18:23 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2020-12-04 14:18:23 | INFO | train | epoch 143 | loss 3.688 | nll_loss 1.481 | symm_mse 4.784 | ppl 2.79 | wps 19783.4 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 67755 | lr 0.000121487 | gnorm 0.806 | train_wall 270 | wall 0
2020-12-04 14:18:23 | INFO | fairseq.trainer | begin training epoch 144
2020-12-04 14:18:24 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:18:26 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:18:48 | INFO | train_inner | epoch 144:     45 / 539 loss=3.662, nll_loss=1.467, symm_mse=4.669, ppl=2.76, wps=14576.6, ups=1.33, wpb=10923, bsz=380.6, num_updates=67800, lr=0.000121447, gnorm=0.792, train_wall=49, wall=0
2020-12-04 14:19:39 | INFO | train_inner | epoch 144:    145 / 539 loss=3.681, nll_loss=1.465, symm_mse=4.844, ppl=2.76, wps=21646.3, ups=1.99, wpb=10883.5, bsz=355.4, num_updates=67900, lr=0.000121357, gnorm=0.81, train_wall=50, wall=0
2020-12-04 14:20:29 | INFO | train_inner | epoch 144:    245 / 539 loss=3.68, nll_loss=1.474, symm_mse=4.767, ppl=2.78, wps=21673.6, ups=1.98, wpb=10920.5, bsz=368.2, num_updates=68000, lr=0.000121268, gnorm=0.804, train_wall=50, wall=0
2020-12-04 14:21:19 | INFO | train_inner | epoch 144:    345 / 539 loss=3.675, nll_loss=1.474, symm_mse=4.734, ppl=2.78, wps=21572.4, ups=1.99, wpb=10864.8, bsz=395.4, num_updates=68100, lr=0.000121179, gnorm=0.802, train_wall=50, wall=0
2020-12-04 14:22:10 | INFO | train_inner | epoch 144:    445 / 539 loss=3.708, nll_loss=1.497, symm_mse=4.848, ppl=2.82, wps=21408.5, ups=1.98, wpb=10826.2, bsz=369.3, num_updates=68200, lr=0.00012109, gnorm=0.808, train_wall=50, wall=0
2020-12-04 14:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:22:58 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:00 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:16 | INFO | valid | epoch 144 | valid on 'valid' subset | symm_mse 0 | loss 8.799 | nll_loss 7.836 | ppl 228.46 | bleu 13.8 | wps 3990.1 | wpb 5891.5 | bsz 151.3 | num_updates 68294 | best_bleu 13.95
2020-12-04 14:23:16 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:23:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:23:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:23:17 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:23:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:19 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 144 @ 68294 updates, score 13.8) (writing took 3.6310597620904446 seconds)
2020-12-04 14:23:20 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2020-12-04 14:23:20 | INFO | train | epoch 144 | loss 3.685 | nll_loss 1.479 | symm_mse 4.783 | ppl 2.79 | wps 19787.5 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 68294 | lr 0.000121007 | gnorm 0.805 | train_wall 270 | wall 0
2020-12-04 14:23:20 | INFO | fairseq.trainer | begin training epoch 145
2020-12-04 14:23:21 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:23:22 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:23:26 | INFO | train_inner | epoch 145:      6 / 539 loss=3.707, nll_loss=1.504, symm_mse=4.788, ppl=2.84, wps=14384, ups=1.32, wpb=10922.2, bsz=363.6, num_updates=68300, lr=0.000121001, gnorm=0.805, train_wall=50, wall=0
2020-12-04 14:24:16 | INFO | train_inner | epoch 145:    106 / 539 loss=3.654, nll_loss=1.444, symm_mse=4.759, ppl=2.72, wps=21801.8, ups=2.01, wpb=10858.4, bsz=364, num_updates=68400, lr=0.000120913, gnorm=0.795, train_wall=50, wall=0
2020-12-04 14:25:06 | INFO | train_inner | epoch 145:    206 / 539 loss=3.666, nll_loss=1.461, symm_mse=4.736, ppl=2.75, wps=21561.3, ups=1.98, wpb=10899, bsz=380.1, num_updates=68500, lr=0.000120824, gnorm=0.797, train_wall=50, wall=0
2020-12-04 14:25:57 | INFO | train_inner | epoch 145:    306 / 539 loss=3.665, nll_loss=1.463, symm_mse=4.733, ppl=2.76, wps=21617.7, ups=1.98, wpb=10941.6, bsz=373.7, num_updates=68600, lr=0.000120736, gnorm=0.808, train_wall=50, wall=0
2020-12-04 14:26:48 | INFO | train_inner | epoch 145:    406 / 539 loss=3.714, nll_loss=1.5, symm_mse=4.879, ppl=2.83, wps=21593.9, ups=1.97, wpb=10936.7, bsz=359.3, num_updates=68700, lr=0.000120648, gnorm=0.811, train_wall=50, wall=0
2020-12-04 14:27:38 | INFO | train_inner | epoch 145:    506 / 539 loss=3.723, nll_loss=1.512, symm_mse=4.87, ppl=2.85, wps=21303.9, ups=1.98, wpb=10772.2, bsz=365.9, num_updates=68800, lr=0.000120561, gnorm=0.823, train_wall=50, wall=0
2020-12-04 14:27:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:27:56 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:27:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:27:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:27:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:27:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:28:12 | INFO | valid | epoch 145 | valid on 'valid' subset | symm_mse 0 | loss 8.836 | nll_loss 7.875 | ppl 234.79 | bleu 13.96 | wps 4416.6 | wpb 5891.5 | bsz 151.3 | num_updates 68833 | best_bleu 13.96
2020-12-04 14:28:12 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:28:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:28:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:28:13 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:28:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:28:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:28:15 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:28:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 145 @ 68833 updates, score 13.96) (writing took 6.107911188155413 seconds)
2020-12-04 14:28:19 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2020-12-04 14:28:19 | INFO | train | epoch 145 | loss 3.683 | nll_loss 1.475 | symm_mse 4.787 | ppl 2.78 | wps 19648.7 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 68833 | lr 0.000120532 | gnorm 0.807 | train_wall 271 | wall 0
2020-12-04 14:28:19 | INFO | fairseq.trainer | begin training epoch 146
2020-12-04 14:28:19 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:28:21 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:28:55 | INFO | train_inner | epoch 146:     67 / 539 loss=3.65, nll_loss=1.445, symm_mse=4.724, ppl=2.72, wps=14335.5, ups=1.31, wpb=10966.7, bsz=391.9, num_updates=68900, lr=0.000120473, gnorm=0.794, train_wall=50, wall=0
2020-12-04 14:29:45 | INFO | train_inner | epoch 146:    167 / 539 loss=3.662, nll_loss=1.45, symm_mse=4.791, ppl=2.73, wps=21783.3, ups=2, wpb=10904.5, bsz=363.6, num_updates=69000, lr=0.000120386, gnorm=0.813, train_wall=50, wall=0
2020-12-04 14:30:36 | INFO | train_inner | epoch 146:    267 / 539 loss=3.663, nll_loss=1.46, symm_mse=4.731, ppl=2.75, wps=21501.3, ups=1.96, wpb=10945.8, bsz=376.2, num_updates=69100, lr=0.000120299, gnorm=0.795, train_wall=51, wall=0
2020-12-04 14:31:26 | INFO | train_inner | epoch 146:    367 / 539 loss=3.678, nll_loss=1.469, symm_mse=4.793, ppl=2.77, wps=21470.1, ups=1.97, wpb=10908, bsz=380.1, num_updates=69200, lr=0.000120212, gnorm=0.805, train_wall=51, wall=0
2020-12-04 14:32:17 | INFO | train_inner | epoch 146:    467 / 539 loss=3.732, nll_loss=1.518, symm_mse=4.895, ppl=2.86, wps=21317, ups=1.99, wpb=10734.5, bsz=357, num_updates=69300, lr=0.000120125, gnorm=0.847, train_wall=50, wall=0
2020-12-04 14:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:32:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:32:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:33:10 | INFO | valid | epoch 146 | valid on 'valid' subset | symm_mse 0 | loss 8.868 | nll_loss 7.91 | ppl 240.59 | bleu 13.87 | wps 4554.3 | wpb 5891.5 | bsz 151.3 | num_updates 69372 | best_bleu 13.96
2020-12-04 14:33:10 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:33:11 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:33:13 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:33:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 146 @ 69372 updates, score 13.87) (writing took 3.789363346993923 seconds)
2020-12-04 14:33:14 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2020-12-04 14:33:14 | INFO | train | epoch 146 | loss 3.681 | nll_loss 1.473 | symm_mse 4.789 | ppl 2.78 | wps 19869.9 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 69372 | lr 0.000120063 | gnorm 0.809 | train_wall 270 | wall 0
2020-12-04 14:33:14 | INFO | fairseq.trainer | begin training epoch 147
2020-12-04 14:33:15 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:33:16 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:33:31 | INFO | train_inner | epoch 147:     28 / 539 loss=3.701, nll_loss=1.494, symm_mse=4.802, ppl=2.82, wps=14634.4, ups=1.35, wpb=10823.3, bsz=370.5, num_updates=69400, lr=0.000120038, gnorm=0.803, train_wall=50, wall=0
2020-12-04 14:34:21 | INFO | train_inner | epoch 147:    128 / 539 loss=3.637, nll_loss=1.434, symm_mse=4.69, ppl=2.7, wps=21799.1, ups=2.01, wpb=10869.4, bsz=398.5, num_updates=69500, lr=0.000119952, gnorm=0.805, train_wall=50, wall=0
2020-12-04 14:35:11 | INFO | train_inner | epoch 147:    228 / 539 loss=3.667, nll_loss=1.461, symm_mse=4.754, ppl=2.75, wps=21535.4, ups=1.98, wpb=10862.1, bsz=375.5, num_updates=69600, lr=0.000119866, gnorm=0.796, train_wall=50, wall=0
2020-12-04 14:36:01 | INFO | train_inner | epoch 147:    328 / 539 loss=3.701, nll_loss=1.484, symm_mse=4.877, ppl=2.8, wps=21505.6, ups=1.99, wpb=10833.5, bsz=356, num_updates=69700, lr=0.00011978, gnorm=0.827, train_wall=50, wall=0
2020-12-04 14:36:52 | INFO | train_inner | epoch 147:    428 / 539 loss=3.695, nll_loss=1.484, symm_mse=4.828, ppl=2.8, wps=21805.9, ups=2, wpb=10925.5, bsz=353.5, num_updates=69800, lr=0.000119694, gnorm=0.805, train_wall=50, wall=0
2020-12-04 14:37:42 | INFO | train_inner | epoch 147:    528 / 539 loss=3.684, nll_loss=1.484, symm_mse=4.733, ppl=2.8, wps=21557.7, ups=1.97, wpb=10925.6, bsz=370.3, num_updates=69900, lr=0.000119608, gnorm=0.802, train_wall=51, wall=0
2020-12-04 14:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:37:49 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:37:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:37:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:37:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:37:50 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:38:05 | INFO | valid | epoch 147 | valid on 'valid' subset | symm_mse 0 | loss 8.841 | nll_loss 7.887 | ppl 236.75 | bleu 14.08 | wps 4550.8 | wpb 5891.5 | bsz 151.3 | num_updates 69911 | best_bleu 14.08
2020-12-04 14:38:05 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:38:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:38:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:38:06 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:38:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:38:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:38:07 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:38:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_best.pt (epoch 147 @ 69911 updates, score 14.08) (writing took 6.359876453876495 seconds)
2020-12-04 14:38:11 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2020-12-04 14:38:11 | INFO | train | epoch 147 | loss 3.678 | nll_loss 1.469 | symm_mse 4.786 | ppl 2.77 | wps 19732 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 69911 | lr 0.000119599 | gnorm 0.808 | train_wall 270 | wall 0
2020-12-04 14:38:11 | INFO | fairseq.trainer | begin training epoch 148
2020-12-04 14:38:12 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:38:14 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:38:58 | INFO | train_inner | epoch 148:     89 / 539 loss=3.65, nll_loss=1.437, symm_mse=4.786, ppl=2.71, wps=14382.4, ups=1.32, wpb=10928.2, bsz=370.1, num_updates=70000, lr=0.000119523, gnorm=0.81, train_wall=49, wall=0
2020-12-04 14:39:49 | INFO | train_inner | epoch 148:    189 / 539 loss=3.686, nll_loss=1.468, symm_mse=4.864, ppl=2.77, wps=21446, ups=1.98, wpb=10856, bsz=366.2, num_updates=70100, lr=0.000119438, gnorm=0.818, train_wall=50, wall=0
2020-12-04 14:40:39 | INFO | train_inner | epoch 148:    289 / 539 loss=3.668, nll_loss=1.466, symm_mse=4.728, ppl=2.76, wps=21638.9, ups=1.99, wpb=10886, bsz=383.8, num_updates=70200, lr=0.000119352, gnorm=0.802, train_wall=50, wall=0
2020-12-04 14:41:30 | INFO | train_inner | epoch 148:    389 / 539 loss=3.682, nll_loss=1.469, symm_mse=4.828, ppl=2.77, wps=21755.8, ups=1.98, wpb=10979.5, bsz=370.3, num_updates=70300, lr=0.000119268, gnorm=0.813, train_wall=50, wall=0
2020-12-04 14:42:20 | INFO | train_inner | epoch 148:    489 / 539 loss=3.69, nll_loss=1.485, symm_mse=4.776, ppl=2.8, wps=21432.4, ups=1.97, wpb=10855.8, bsz=374.6, num_updates=70400, lr=0.000119183, gnorm=0.817, train_wall=50, wall=0
2020-12-04 14:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:42:46 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:42:48 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:43:02 | INFO | valid | epoch 148 | valid on 'valid' subset | symm_mse 0 | loss 8.856 | nll_loss 7.901 | ppl 238.98 | bleu 13.96 | wps 4579.5 | wpb 5891.5 | bsz 151.3 | num_updates 70450 | best_bleu 14.08
2020-12-04 14:43:02 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:43:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:43:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:43:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:43:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:43:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:43:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:43:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 148 @ 70450 updates, score 13.96) (writing took 3.644402712583542 seconds)
2020-12-04 14:43:06 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2020-12-04 14:43:06 | INFO | train | epoch 148 | loss 3.676 | nll_loss 1.467 | symm_mse 4.788 | ppl 2.76 | wps 19893 | ups 1.83 | wpb 10884.9 | bsz 371.1 | num_updates 70450 | lr 0.000119141 | gnorm 0.811 | train_wall 270 | wall 0
2020-12-04 14:43:06 | INFO | fairseq.trainer | begin training epoch 149
2020-12-04 14:43:07 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:43:09 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:43:34 | INFO | train_inner | epoch 149:     50 / 539 loss=3.655, nll_loss=1.454, symm_mse=4.706, ppl=2.74, wps=14631, ups=1.36, wpb=10788.7, bsz=371, num_updates=70500, lr=0.000119098, gnorm=0.8, train_wall=50, wall=0
2020-12-04 14:44:24 | INFO | train_inner | epoch 149:    150 / 539 loss=3.655, nll_loss=1.442, symm_mse=4.784, ppl=2.72, wps=21610.2, ups=1.98, wpb=10895.1, bsz=369.3, num_updates=70600, lr=0.000119014, gnorm=0.807, train_wall=50, wall=0
2020-12-04 14:45:15 | INFO | train_inner | epoch 149:    250 / 539 loss=3.688, nll_loss=1.469, symm_mse=4.873, ppl=2.77, wps=21506.7, ups=1.98, wpb=10855.6, bsz=356.1, num_updates=70700, lr=0.00011893, gnorm=0.823, train_wall=50, wall=0
2020-12-04 14:46:06 | INFO | train_inner | epoch 149:    350 / 539 loss=3.655, nll_loss=1.456, symm_mse=4.69, ppl=2.74, wps=21482.5, ups=1.97, wpb=10891.3, bsz=383.4, num_updates=70800, lr=0.000118846, gnorm=0.811, train_wall=51, wall=0
2020-12-04 14:46:56 | INFO | train_inner | epoch 149:    450 / 539 loss=3.699, nll_loss=1.487, symm_mse=4.855, ppl=2.8, wps=21499.7, ups=1.97, wpb=10892.1, bsz=365.1, num_updates=70900, lr=0.000118762, gnorm=0.819, train_wall=50, wall=0
2020-12-04 14:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:47:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:42 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:47:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:47:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:47:44 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:47:59 | INFO | valid | epoch 149 | valid on 'valid' subset | symm_mse 0 | loss 8.894 | nll_loss 7.937 | ppl 245.02 | bleu 13.84 | wps 4569.1 | wpb 5891.5 | bsz 151.3 | num_updates 70989 | best_bleu 14.08
2020-12-04 14:47:59 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:47:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:48:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:48:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:48:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:48:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 149 @ 70989 updates, score 13.84) (writing took 3.692665223032236 seconds)
2020-12-04 14:48:02 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2020-12-04 14:48:02 | INFO | train | epoch 149 | loss 3.674 | nll_loss 1.464 | symm_mse 4.792 | ppl 2.76 | wps 19806 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 70989 | lr 0.000118687 | gnorm 0.814 | train_wall 271 | wall 0
2020-12-04 14:48:02 | INFO | fairseq.trainer | begin training epoch 150
2020-12-04 14:48:03 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:48:05 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:48:11 | INFO | train_inner | epoch 150:     11 / 539 loss=3.676, nll_loss=1.472, symm_mse=4.755, ppl=2.77, wps=14702.8, ups=1.34, wpb=10953.6, bsz=377.7, num_updates=71000, lr=0.000118678, gnorm=0.81, train_wall=50, wall=0
2020-12-04 14:49:00 | INFO | train_inner | epoch 150:    111 / 539 loss=3.699, nll_loss=1.47, symm_mse=4.953, ppl=2.77, wps=21655.3, ups=2.02, wpb=10738.2, bsz=343.2, num_updates=71100, lr=0.000118595, gnorm=0.841, train_wall=49, wall=0
2020-12-04 14:49:51 | INFO | train_inner | epoch 150:    211 / 539 loss=3.618, nll_loss=1.418, symm_mse=4.65, ppl=2.67, wps=21541.2, ups=1.96, wpb=10997.8, bsz=400.6, num_updates=71200, lr=0.000118511, gnorm=0.8, train_wall=51, wall=0
2020-12-04 14:50:42 | INFO | train_inner | epoch 150:    311 / 539 loss=3.69, nll_loss=1.478, symm_mse=4.834, ppl=2.78, wps=21606, ups=1.99, wpb=10864, bsz=356.9, num_updates=71300, lr=0.000118428, gnorm=0.817, train_wall=50, wall=0
2020-12-04 14:51:32 | INFO | train_inner | epoch 150:    411 / 539 loss=3.663, nll_loss=1.461, symm_mse=4.725, ppl=2.75, wps=21600, ups=1.97, wpb=10937.1, bsz=379.8, num_updates=71400, lr=0.000118345, gnorm=0.81, train_wall=50, wall=0
2020-12-04 14:52:23 | INFO | train_inner | epoch 150:    511 / 539 loss=3.691, nll_loss=1.482, symm_mse=4.822, ppl=2.79, wps=21368.2, ups=1.96, wpb=10876.4, bsz=374.4, num_updates=71500, lr=0.000118262, gnorm=0.824, train_wall=51, wall=0
2020-12-04 14:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:38 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:40 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:54 | INFO | valid | epoch 150 | valid on 'valid' subset | symm_mse 0 | loss 8.879 | nll_loss 7.918 | ppl 241.93 | bleu 13.95 | wps 4604.5 | wpb 5891.5 | bsz 151.3 | num_updates 71528 | best_bleu 14.08
2020-12-04 14:52:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:52:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:55 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:52:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:57 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:52:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 150 @ 71528 updates, score 13.95) (writing took 3.705899577587843 seconds)
2020-12-04 14:52:58 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2020-12-04 14:52:58 | INFO | train | epoch 150 | loss 3.671 | nll_loss 1.462 | symm_mse 4.789 | ppl 2.75 | wps 19844.2 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 71528 | lr 0.000118239 | gnorm 0.817 | train_wall 271 | wall 0
2020-12-04 14:52:58 | INFO | fairseq.trainer | begin training epoch 151
2020-12-04 14:52:59 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:53:01 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:53:37 | INFO | train_inner | epoch 151:     72 / 539 loss=3.66, nll_loss=1.446, symm_mse=4.804, ppl=2.72, wps=14910.7, ups=1.36, wpb=10998, bsz=360.4, num_updates=71600, lr=0.00011818, gnorm=0.822, train_wall=50, wall=0
2020-12-04 14:54:28 | INFO | train_inner | epoch 151:    172 / 539 loss=3.649, nll_loss=1.442, symm_mse=4.73, ppl=2.72, wps=21471.2, ups=1.97, wpb=10879.2, bsz=382.4, num_updates=71700, lr=0.000118097, gnorm=0.806, train_wall=50, wall=0
2020-12-04 14:55:18 | INFO | train_inner | epoch 151:    272 / 539 loss=3.707, nll_loss=1.488, symm_mse=4.907, ppl=2.8, wps=21307.5, ups=1.98, wpb=10768.6, bsz=362.3, num_updates=71800, lr=0.000118015, gnorm=0.819, train_wall=50, wall=0
2020-12-04 14:56:09 | INFO | train_inner | epoch 151:    372 / 539 loss=3.647, nll_loss=1.445, symm_mse=4.706, ppl=2.72, wps=21439.3, ups=1.97, wpb=10901.5, bsz=388.8, num_updates=71900, lr=0.000117933, gnorm=0.819, train_wall=51, wall=0
2020-12-04 14:57:00 | INFO | train_inner | epoch 151:    472 / 539 loss=3.68, nll_loss=1.469, symm_mse=4.806, ppl=2.77, wps=21451.7, ups=1.96, wpb=10924.5, bsz=361, num_updates=72000, lr=0.000117851, gnorm=0.817, train_wall=51, wall=0
2020-12-04 14:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 14:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:35 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:37 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:52 | INFO | valid | epoch 151 | valid on 'valid' subset | symm_mse 0 | loss 8.878 | nll_loss 7.926 | ppl 243.17 | bleu 13.94 | wps 4209.8 | wpb 5891.5 | bsz 151.3 | num_updates 72067 | best_bleu 14.08
2020-12-04 14:57:52 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 14:57:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:53 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:57:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 151 @ 72067 updates, score 13.94) (writing took 3.7089683543890715 seconds)
2020-12-04 14:57:56 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2020-12-04 14:57:56 | INFO | train | epoch 151 | loss 3.669 | nll_loss 1.459 | symm_mse 4.79 | ppl 2.75 | wps 19693.4 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 72067 | lr 0.000117796 | gnorm 0.816 | train_wall 272 | wall 0
2020-12-04 14:57:56 | INFO | fairseq.trainer | begin training epoch 152
2020-12-04 14:57:57 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 14:57:58 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 14:58:15 | INFO | train_inner | epoch 152:     33 / 539 loss=3.691, nll_loss=1.476, symm_mse=4.859, ppl=2.78, wps=14492.5, ups=1.33, wpb=10877.1, bsz=357.8, num_updates=72100, lr=0.000117769, gnorm=0.81, train_wall=50, wall=0
2020-12-04 14:59:05 | INFO | train_inner | epoch 152:    133 / 539 loss=3.65, nll_loss=1.436, symm_mse=4.788, ppl=2.71, wps=21679.8, ups=1.99, wpb=10915.5, bsz=353.4, num_updates=72200, lr=0.000117688, gnorm=0.818, train_wall=50, wall=0
2020-12-04 14:59:56 | INFO | train_inner | epoch 152:    233 / 539 loss=3.654, nll_loss=1.444, symm_mse=4.769, ppl=2.72, wps=21279.7, ups=1.97, wpb=10790.1, bsz=383.4, num_updates=72300, lr=0.000117606, gnorm=0.818, train_wall=51, wall=0
2020-12-04 15:00:47 | INFO | train_inner | epoch 152:    333 / 539 loss=3.672, nll_loss=1.459, symm_mse=4.827, ppl=2.75, wps=21634, ups=1.97, wpb=10991.1, bsz=379.2, num_updates=72400, lr=0.000117525, gnorm=0.832, train_wall=51, wall=0
2020-12-04 15:01:38 | INFO | train_inner | epoch 152:    433 / 539 loss=3.69, nll_loss=1.482, symm_mse=4.797, ppl=2.79, wps=21180.5, ups=1.97, wpb=10747.4, bsz=363.2, num_updates=72500, lr=0.000117444, gnorm=0.828, train_wall=51, wall=0
2020-12-04 15:02:28 | INFO | train_inner | epoch 152:    533 / 539 loss=3.662, nll_loss=1.462, symm_mse=4.723, ppl=2.76, wps=21661.1, ups=1.97, wpb=10980.2, bsz=389.4, num_updates=72600, lr=0.000117363, gnorm=0.808, train_wall=51, wall=0
2020-12-04 15:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 15:02:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:32 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:34 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:49 | INFO | valid | epoch 152 | valid on 'valid' subset | symm_mse 0 | loss 8.86 | nll_loss 7.903 | ppl 239.41 | bleu 13.72 | wps 4263.2 | wpb 5891.5 | bsz 151.3 | num_updates 72606 | best_bleu 14.08
2020-12-04 15:02:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 15:02:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:50 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:02:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 152 @ 72606 updates, score 13.72) (writing took 3.6999057792127132 seconds)
2020-12-04 15:02:53 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2020-12-04 15:02:53 | INFO | train | epoch 152 | loss 3.667 | nll_loss 1.457 | symm_mse 4.791 | ppl 2.74 | wps 19754.3 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 72606 | lr 0.000117358 | gnorm 0.82 | train_wall 271 | wall 0
2020-12-04 15:02:53 | INFO | fairseq.trainer | begin training epoch 153
2020-12-04 15:02:54 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:02:55 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:03:43 | INFO | train_inner | epoch 153:     94 / 539 loss=3.623, nll_loss=1.418, symm_mse=4.694, ppl=2.67, wps=14544.9, ups=1.34, wpb=10847.8, bsz=381.8, num_updates=72700, lr=0.000117282, gnorm=0.806, train_wall=50, wall=0
2020-12-04 15:04:34 | INFO | train_inner | epoch 153:    194 / 539 loss=3.661, nll_loss=1.447, symm_mse=4.808, ppl=2.73, wps=21545.4, ups=1.98, wpb=10908.5, bsz=377.8, num_updates=72800, lr=0.000117202, gnorm=0.823, train_wall=50, wall=0
2020-12-04 15:05:24 | INFO | train_inner | epoch 153:    294 / 539 loss=3.666, nll_loss=1.455, symm_mse=4.797, ppl=2.74, wps=21541.9, ups=1.98, wpb=10904.5, bsz=371.4, num_updates=72900, lr=0.000117121, gnorm=0.81, train_wall=50, wall=0
2020-12-04 15:06:15 | INFO | train_inner | epoch 153:    394 / 539 loss=3.663, nll_loss=1.457, symm_mse=4.753, ppl=2.74, wps=21419, ups=1.96, wpb=10911.5, bsz=376.2, num_updates=73000, lr=0.000117041, gnorm=0.814, train_wall=51, wall=0
2020-12-04 15:07:06 | INFO | train_inner | epoch 153:    494 / 539 loss=3.684, nll_loss=1.466, symm_mse=4.878, ppl=2.76, wps=21358.4, ups=1.97, wpb=10865.3, bsz=355.8, num_updates=73100, lr=0.000116961, gnorm=0.84, train_wall=51, wall=0
2020-12-04 15:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 15:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:29 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:31 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:46 | INFO | valid | epoch 153 | valid on 'valid' subset | symm_mse 0 | loss 8.863 | nll_loss 7.907 | ppl 239.95 | bleu 13.56 | wps 4421.3 | wpb 5891.5 | bsz 151.3 | num_updates 73145 | best_bleu 14.08
2020-12-04 15:07:46 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 15:07:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:07:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 153 @ 73145 updates, score 13.56) (writing took 3.8300999607890844 seconds)
2020-12-04 15:07:50 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2020-12-04 15:07:50 | INFO | train | epoch 153 | loss 3.665 | nll_loss 1.454 | symm_mse 4.796 | ppl 2.74 | wps 19755.7 | ups 1.81 | wpb 10884.9 | bsz 371.1 | num_updates 73145 | lr 0.000116925 | gnorm 0.819 | train_wall 272 | wall 0
2020-12-04 15:07:50 | INFO | fairseq.trainer | begin training epoch 154
2020-12-04 15:07:51 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:07:52 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:08:20 | INFO | train_inner | epoch 154:     55 / 539 loss=3.675, nll_loss=1.467, symm_mse=4.773, ppl=2.76, wps=14465.3, ups=1.35, wpb=10736.2, bsz=356.1, num_updates=73200, lr=0.000116881, gnorm=0.813, train_wall=50, wall=0
2020-12-04 15:09:11 | INFO | train_inner | epoch 154:    155 / 539 loss=3.636, nll_loss=1.422, symm_mse=4.772, ppl=2.68, wps=21644.4, ups=1.97, wpb=10982, bsz=377.4, num_updates=73300, lr=0.000116801, gnorm=0.824, train_wall=51, wall=0
2020-12-04 15:10:01 | INFO | train_inner | epoch 154:    255 / 539 loss=3.69, nll_loss=1.466, symm_mse=4.921, ppl=2.76, wps=21327.6, ups=1.98, wpb=10752.5, bsz=360.2, num_updates=73400, lr=0.000116722, gnorm=0.84, train_wall=50, wall=0
2020-12-04 15:10:52 | INFO | train_inner | epoch 154:    355 / 539 loss=3.666, nll_loss=1.457, symm_mse=4.781, ppl=2.74, wps=21842.4, ups=1.99, wpb=10963.9, bsz=385.5, num_updates=73500, lr=0.000116642, gnorm=0.818, train_wall=50, wall=0
2020-12-04 15:11:42 | INFO | train_inner | epoch 154:    455 / 539 loss=3.662, nll_loss=1.457, symm_mse=4.749, ppl=2.75, wps=21530.9, ups=1.97, wpb=10953.4, bsz=373.1, num_updates=73600, lr=0.000116563, gnorm=0.816, train_wall=51, wall=0
2020-12-04 15:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-12-04 15:12:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:25 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:27 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:43 | INFO | valid | epoch 154 | valid on 'valid' subset | symm_mse 0 | loss 8.881 | nll_loss 7.926 | ppl 243.26 | bleu 13.74 | wps 4203.3 | wpb 5891.5 | bsz 151.3 | num_updates 73684 | best_bleu 14.08
2020-12-04 15:12:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-12-04 15:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:43 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ./examples/transformer_enzh/bash/../checkpoints/closer_all1/checkpoint_last.pt (epoch 154 @ 73684 updates, score 13.74) (writing took 3.8875285144895315 seconds)
2020-12-04 15:12:46 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2020-12-04 15:12:46 | INFO | train | epoch 154 | loss 3.663 | nll_loss 1.451 | symm_mse 4.791 | ppl 2.73 | wps 19780.4 | ups 1.82 | wpb 10884.9 | bsz 371.1 | num_updates 73684 | lr 0.000116497 | gnorm 0.82 | train_wall 271 | wall 0
2020-12-04 15:12:46 | INFO | fairseq.trainer | begin training epoch 155
2020-12-04 15:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:47 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:47 | INFO | transformers.file_utils | PyTorch version 1.6.0 available.
2020-12-04 15:12:49 | INFO | transformers.file_utils | TensorFlow version 2.2.0 available.
2020-12-04 15:12:58 | INFO | train_inner | epoch 155:     16 / 539 loss=3.675, nll_loss=1.465, symm_mse=4.807, ppl=2.76, wps=14510.9, ups=1.33, wpb=10901.5, bsz=357, num_updates=73700, lr=0.000116484, gnorm=0.806, train_wall=50, wall=0
2020-12-04 15:13:47 | INFO | train_inner | epoch 155:    116 / 539 loss=3.641, nll_loss=1.424, symm_mse=4.806, ppl=2.68, wps=21870.5, ups=2, wpb=10921.9, bsz=365.4, num_updates=73800, lr=0.000116405, gnorm=0.817, train_wall=50, wall=0
2020-12-04 15:14:38 | INFO | train_inner | epoch 155:    216 / 539 loss=3.618, nll_loss=1.415, symm_mse=4.67, ppl=2.67, wps=21700.7, ups=1.98, wpb=10981.6, bsz=391.4, num_updates=73900, lr=0.000116326, gnorm=0.806, train_wall=50, wall=0
2020-12-04 15:15:28 | INFO | train_inner | epoch 155:    316 / 539 loss=3.651, nll_loss=1.447, symm_mse=4.726, ppl=2.73, wps=21471.2, ups=1.99, wpb=10809.4, bsz=372.2, num_updates=74000, lr=0.000116248, gnorm=0.814, train_wall=50, wall=0
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/home/rcduan/fairseq/fairseq/fairseq_cli/train.py", line 354, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/rcduan/fairseq/fairseq/fairseq/distributed_utils.py", line 237, in call_main
    torch.multiprocessing.spawn(
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/rcduan/miniconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 0 terminated with signal SIGKILL
/home/rcduan/miniconda3/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 240 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
